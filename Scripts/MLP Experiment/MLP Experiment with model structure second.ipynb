{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_1(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_2(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_3(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_4(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_5(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_6(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 419us/step - loss: 15301.9310 - val_loss: 14768.9663\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13482.4023 - val_loss: 11348.2583\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8351.6999 - val_loss: 4539.0566\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 135us/step - loss: 2048.1950 - val_loss: 431.5358\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 131.0112 - val_loss: 33.6711\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 32.3387 - val_loss: 28.7004\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 27.0293 - val_loss: 26.4695\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 24.9464 - val_loss: 25.6167\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.9828 - val_loss: 25.3059\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.6331 - val_loss: 25.0563\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.0964 - val_loss: 25.1522\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.8936 - val_loss: 25.3034\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.6065 - val_loss: 25.0263\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.5311 - val_loss: 25.2437\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5044 - val_loss: 25.0648\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.6045 - val_loss: 25.1560\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4130 - val_loss: 25.2486\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.7418 - val_loss: 25.3007\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4326 - val_loss: 25.2454\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.6796 - val_loss: 25.6717\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5333 - val_loss: 25.5328\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2747 - val_loss: 25.3586\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3478 - val_loss: 25.4930\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3246 - val_loss: 25.7142\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3625 - val_loss: 25.4933\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3388 - val_loss: 25.6006\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4816 - val_loss: 26.0447\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3429 - val_loss: 25.2443\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.2402 - val_loss: 25.3419\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3179 - val_loss: 25.2364\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3319 - val_loss: 25.7868\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.4794 - val_loss: 25.6869\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2303 - val_loss: 25.3462\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.6908 - val_loss: 25.2295\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.2477 - val_loss: 25.2034\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.5821 - val_loss: 25.6034\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.1751 - val_loss: 25.7593\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.5367 - val_loss: 26.0440\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2907 - val_loss: 25.4127\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0530 - val_loss: 25.5158\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1292 - val_loss: 25.5795\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0610 - val_loss: 25.2763\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.7771 - val_loss: 26.6517\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3259 - val_loss: 25.7295\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8291 - val_loss: 25.1974\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.3613 - val_loss: 25.4904\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9162 - val_loss: 25.3467\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.3295 - val_loss: 25.4835\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1566 - val_loss: 25.5527\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3607 - val_loss: 26.1760\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9137 - val_loss: 25.5243\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.9969 - val_loss: 25.9009\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2399 - val_loss: 26.2862\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2208 - val_loss: 25.5887\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0008 - val_loss: 25.3827\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0619 - val_loss: 25.4893\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4908 - val_loss: 25.3437\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.7023 - val_loss: 26.3302\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1049 - val_loss: 25.9478\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2922 - val_loss: 25.6157\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0134 - val_loss: 26.1505\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0525 - val_loss: 26.0092\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.2198 - val_loss: 25.9833\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 21.7412 - val_loss: 25.5650\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1229 - val_loss: 25.5136\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.9177 - val_loss: 25.8949\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 22.1790 - val_loss: 26.2936\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2154 - val_loss: 25.6436\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.2645 - val_loss: 25.4360\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2862 - val_loss: 26.0401\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 21.9746 - val_loss: 27.5421\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1346 - val_loss: 26.1844\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2426 - val_loss: 25.2986\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2845 - val_loss: 27.0490\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5855 - val_loss: 27.8780\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.0181 - val_loss: 25.8190\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.9483 - val_loss: 25.7857\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9336 - val_loss: 26.0404\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8335 - val_loss: 25.5305\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4417 - val_loss: 27.5621\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9819 - val_loss: 25.6145\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6360 - val_loss: 27.3469\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.5103 - val_loss: 25.8293\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8310 - val_loss: 26.3180\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2063 - val_loss: 25.4525\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7714 - val_loss: 25.4792\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8469 - val_loss: 25.3590\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5457 - val_loss: 26.3680\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1012 - val_loss: 27.3855\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.3901 - val_loss: 26.3426\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2386 - val_loss: 26.5905\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.9984 - val_loss: 25.9281\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.6756 - val_loss: 26.1124\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0537 - val_loss: 26.1521\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1124 - val_loss: 27.6009\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2721 - val_loss: 26.2004\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.1683 - val_loss: 25.8367\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1507 - val_loss: 25.9871\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1627 - val_loss: 28.4428\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 22.7324 - val_loss: 26.0956\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7014 - val_loss: 26.6246\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0205 - val_loss: 26.1941\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2420 - val_loss: 27.7097\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3094 - val_loss: 25.7766\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1456 - val_loss: 26.0393\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8063 - val_loss: 25.6946\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7071 - val_loss: 26.5553\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.0664 - val_loss: 27.2853\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.2575 - val_loss: 25.5257\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4680 - val_loss: 25.7959\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0306 - val_loss: 26.0064\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6603 - val_loss: 25.6184\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0978 - val_loss: 25.6129\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7478 - val_loss: 26.2805\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.4456 - val_loss: 25.7345\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0507 - val_loss: 25.9997\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.1359 - val_loss: 26.5619\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.1243 - val_loss: 25.5622\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.1008 - val_loss: 25.7874\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2238 - val_loss: 26.1174\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.8674 - val_loss: 25.4716\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3926 - val_loss: 27.6464\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1043 - val_loss: 26.9051\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9954 - val_loss: 26.0576\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1743 - val_loss: 26.2424\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6113 - val_loss: 28.0858\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8829 - val_loss: 26.4323\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.3365 - val_loss: 26.3293\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9968 - val_loss: 25.3031\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7527 - val_loss: 25.4679\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8510 - val_loss: 26.2199\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6967 - val_loss: 27.3089\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9403 - val_loss: 25.0984\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.4373 - val_loss: 25.8774\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.3708 - val_loss: 25.4471\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7150 - val_loss: 25.8435\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1781 - val_loss: 25.6211\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3263 - val_loss: 25.5012\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1465 - val_loss: 25.3549\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6843 - val_loss: 25.4504\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.5955 - val_loss: 25.5613\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.4038 - val_loss: 25.2308\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6840 - val_loss: 26.2140\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.2403 - val_loss: 25.1299\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.2102 - val_loss: 26.0206\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7851 - val_loss: 24.6692\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.0939 - val_loss: 25.1799\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.2425 - val_loss: 24.9159\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 21.3742 - val_loss: 24.7083\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 20.5545 - val_loss: 25.4327\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5954 - val_loss: 25.6202\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.7125 - val_loss: 25.9572\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.3767 - val_loss: 24.5736\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 20.8558 - val_loss: 24.4934\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 20.3023 - val_loss: 24.0795\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.3071 - val_loss: 24.8491\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 20.6949 - val_loss: 23.7629\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 19.8581 - val_loss: 24.0977\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.2753 - val_loss: 23.8546\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.1276 - val_loss: 24.6905\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.0342 - val_loss: 23.8013\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.4679 - val_loss: 23.4406\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.5401 - val_loss: 23.4363\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.0806 - val_loss: 23.9091\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8408 - val_loss: 23.9885\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.6187 - val_loss: 22.9478\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2254 - val_loss: 22.4449\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1153 - val_loss: 22.3570\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4090 - val_loss: 23.5620\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.4085 - val_loss: 21.3686\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3789 - val_loss: 21.3279\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7439 - val_loss: 21.6530\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7823 - val_loss: 20.7952\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.8543 - val_loss: 21.9857\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9100 - val_loss: 20.8056\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5205 - val_loss: 21.2084\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8269 - val_loss: 21.6321\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5180 - val_loss: 22.2482\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5186 - val_loss: 19.8340\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2802 - val_loss: 20.0115\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.8328 - val_loss: 20.8876\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6287 - val_loss: 20.6370\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.6504 - val_loss: 20.0414\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.8337 - val_loss: 19.4073\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7935 - val_loss: 19.4476\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1750 - val_loss: 19.0638\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.7455 - val_loss: 21.1441\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6745 - val_loss: 22.2017\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.7658 - val_loss: 19.5344\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8712 - val_loss: 18.5594\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.2990 - val_loss: 19.8230\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.4735 - val_loss: 18.5478\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.3334 - val_loss: 18.2134\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.1454 - val_loss: 19.5496\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5431 - val_loss: 18.8401\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.1508 - val_loss: 18.6014\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.3713 - val_loss: 20.3769\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.0680 - val_loss: 17.9031\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.9913 - val_loss: 23.6710\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7614 - val_loss: 18.4109\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.1139 - val_loss: 17.9366\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.6226 - val_loss: 18.0871\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.4797 - val_loss: 18.0871\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5012 - val_loss: 18.6279\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.1254 - val_loss: 18.6211\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.5420 - val_loss: 18.0470\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.5527 - val_loss: 17.5342\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.0639 - val_loss: 17.9936\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.6617 - val_loss: 19.4410\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.3756 - val_loss: 19.4031\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.6582 - val_loss: 17.7092\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.0730 - val_loss: 19.4771\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.0502 - val_loss: 18.8977\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.0839 - val_loss: 17.4465\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.8509 - val_loss: 17.3820\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2031 - val_loss: 16.9816\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.8433 - val_loss: 17.1706\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6605 - val_loss: 16.9637\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7953 - val_loss: 17.3168\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2728 - val_loss: 16.8309\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.0836 - val_loss: 18.4755\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5885 - val_loss: 16.9238\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.6299 - val_loss: 17.2659\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.6944 - val_loss: 18.0790\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.6143 - val_loss: 17.4668\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6228 - val_loss: 17.3202\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.7443 - val_loss: 17.7016\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4123 - val_loss: 22.4449\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.6348 - val_loss: 19.8637\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.0109 - val_loss: 19.6325\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.3401 - val_loss: 19.1826\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 14.4955 - val_loss: 17.9755\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.6171 - val_loss: 17.8831\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.9698 - val_loss: 17.9959\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.4450 - val_loss: 16.4423\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.8321 - val_loss: 16.1987\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.9261 - val_loss: 17.4748\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 13.9593 - val_loss: 17.5028\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 14.3964 - val_loss: 17.1149\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.8184 - val_loss: 17.4412\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.7829 - val_loss: 16.0458\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.5430 - val_loss: 16.9986\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.6972 - val_loss: 17.5127\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.7747 - val_loss: 16.1840\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.4280 - val_loss: 17.3125\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 13.0283 - val_loss: 16.2406\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.1517 - val_loss: 17.3431\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 13.3645 - val_loss: 16.0235\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 12.7604 - val_loss: 15.7338\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.4957 - val_loss: 16.4795\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7523 - val_loss: 16.3923\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.2107 - val_loss: 17.8303\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.2833 - val_loss: 15.7859\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.9435 - val_loss: 16.2688\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8200 - val_loss: 16.9875\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.6476 - val_loss: 15.4672\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.3368 - val_loss: 15.7785\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.8554 - val_loss: 15.7812\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.3952 - val_loss: 16.0688\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6137 - val_loss: 17.2635\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3081 - val_loss: 16.2616\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 12.8284 - val_loss: 14.7888\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1225 - val_loss: 14.8432\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4209 - val_loss: 14.6268\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9349 - val_loss: 15.2628\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7694 - val_loss: 15.4300\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0270 - val_loss: 15.0376\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9559 - val_loss: 15.1802\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4745 - val_loss: 15.7192\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9011 - val_loss: 14.9721\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0801 - val_loss: 14.0747\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0368 - val_loss: 14.9899\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.8762 - val_loss: 15.9703\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6855 - val_loss: 13.8528\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9930 - val_loss: 16.9518\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.1296 - val_loss: 13.6055\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5390 - val_loss: 14.1265\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3794 - val_loss: 14.5913\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0663 - val_loss: 14.8265\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1759 - val_loss: 15.0125\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4961 - val_loss: 13.9353\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.2379 - val_loss: 14.0518\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0781 - val_loss: 14.2505\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8538 - val_loss: 13.7704\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4066 - val_loss: 13.5446\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4626 - val_loss: 15.6151\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.1747 - val_loss: 13.9924\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4559 - val_loss: 13.8732\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.9204 - val_loss: 14.0275\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9205 - val_loss: 13.9625\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0303 - val_loss: 12.7328\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9605 - val_loss: 13.2535\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0306 - val_loss: 13.7513\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.8789 - val_loss: 13.4011\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3305 - val_loss: 14.6132\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0307 - val_loss: 13.2914\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5227 - val_loss: 14.0889\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3854 - val_loss: 14.9727\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.8931 - val_loss: 13.8560\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8814 - val_loss: 13.3458\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0943 - val_loss: 13.2471\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3446 - val_loss: 17.2068\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.0981 - val_loss: 12.3783\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6802 - val_loss: 13.7699\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.5587 - val_loss: 12.9740\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2699 - val_loss: 12.8221\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9567 - val_loss: 12.4617\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.9988 - val_loss: 13.4704\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.4158 - val_loss: 12.5731\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1167 - val_loss: 13.2678\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.4708 - val_loss: 13.4030\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.8758 - val_loss: 14.6157\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9869 - val_loss: 13.2079\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.3076 - val_loss: 12.0984\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2594 - val_loss: 12.0135\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9312 - val_loss: 12.4721\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4583 - val_loss: 11.9049\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0696 - val_loss: 13.8353\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2893 - val_loss: 13.9619\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.4349 - val_loss: 13.0104\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 9.8925 - val_loss: 12.3102\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.7049 - val_loss: 12.4209\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 10.4963 - val_loss: 12.2836\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.9685 - val_loss: 12.6377\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.9812 - val_loss: 13.8966\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5573 - val_loss: 13.7065\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1194 - val_loss: 13.8994\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9165 - val_loss: 13.1313\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6977 - val_loss: 11.9856\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1650 - val_loss: 12.4775\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.7122 - val_loss: 12.9565\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.3037 - val_loss: 12.6939\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8061 - val_loss: 12.7325\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8224 - val_loss: 12.9034\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8986 - val_loss: 12.2704\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8651 - val_loss: 13.2914\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3617 - val_loss: 11.7745\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5140 - val_loss: 12.7841\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9137 - val_loss: 12.6593\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7886 - val_loss: 13.1761\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6448 - val_loss: 12.0150\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.4035 - val_loss: 14.1509\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.7170 - val_loss: 12.4552\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2770 - val_loss: 11.9129\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 154us/step - loss: 10.1325 - val_loss: 12.9921\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.5499 - val_loss: 12.3175\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.7431 - val_loss: 11.6364\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4661 - val_loss: 11.9060\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7072 - val_loss: 11.8404\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7470 - val_loss: 13.3220\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.6447 - val_loss: 13.4478\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3604 - val_loss: 11.9006\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.6930 - val_loss: 12.9858\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.8079 - val_loss: 12.7237\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.2492 - val_loss: 11.6610\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.4486 - val_loss: 12.2153\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.9134 - val_loss: 11.6446\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3086 - val_loss: 11.6327\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5031 - val_loss: 12.2335\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6516 - val_loss: 11.9512\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.3799 - val_loss: 11.2329\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0636 - val_loss: 11.3782\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5270 - val_loss: 10.9950\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.1506 - val_loss: 12.6998\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.4712 - val_loss: 11.1712\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.4239 - val_loss: 12.0570\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7076 - val_loss: 12.0299\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5063 - val_loss: 13.1685\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5736 - val_loss: 11.5382\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2235 - val_loss: 11.2146\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9830 - val_loss: 11.7677\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2131 - val_loss: 11.5110\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2530 - val_loss: 11.0122\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2405 - val_loss: 12.3898\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1175 - val_loss: 11.3962\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9823 - val_loss: 11.4283\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5617 - val_loss: 12.2698\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3051 - val_loss: 11.2163\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5845 - val_loss: 11.1058\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2634 - val_loss: 11.1096\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.9613 - val_loss: 10.9289\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0583 - val_loss: 10.8826\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2815 - val_loss: 11.6571\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.4041 - val_loss: 11.7184\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0050 - val_loss: 14.1685\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3852 - val_loss: 11.2627\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2109 - val_loss: 11.1596\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1127 - val_loss: 12.1319\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9852 - val_loss: 11.4422\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.0171 - val_loss: 12.7033\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2643 - val_loss: 11.2648\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.3428 - val_loss: 11.3428\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.0906 - val_loss: 12.2856\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2539 - val_loss: 10.8352\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.1710 - val_loss: 12.0017\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3741 - val_loss: 11.3501\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9466 - val_loss: 11.3141\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.8924 - val_loss: 11.0480\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.0178 - val_loss: 11.3422\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.3472 - val_loss: 11.1579\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2665 - val_loss: 11.0684\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3043 - val_loss: 13.1999\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2097 - val_loss: 11.4285\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2851 - val_loss: 11.5968\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1401 - val_loss: 11.6280\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9751 - val_loss: 11.2126\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1392 - val_loss: 11.2056\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1582 - val_loss: 12.6551\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6052 - val_loss: 10.9501\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.0526 - val_loss: 10.9775\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.9359 - val_loss: 11.9714\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2691 - val_loss: 11.0771\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 9.3696 - val_loss: 11.9710\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0625 - val_loss: 10.9360\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.5744 - val_loss: 11.1369\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 9.2267 - val_loss: 11.8938\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0000 - val_loss: 12.4857\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1748 - val_loss: 12.2854\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2614 - val_loss: 11.6034\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2339 - val_loss: 11.3887\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0517 - val_loss: 10.8700\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8473 - val_loss: 11.0559\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0688 - val_loss: 11.0304\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9482 - val_loss: 11.6201\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4647 - val_loss: 11.0544\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0065 - val_loss: 11.1432\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4854 - val_loss: 11.2752\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2313 - val_loss: 11.7425\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4372 - val_loss: 11.4248\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7218 - val_loss: 10.8214\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0386 - val_loss: 10.8808\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4362 - val_loss: 11.1955\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8331 - val_loss: 10.8655\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2737 - val_loss: 11.0097\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0845 - val_loss: 11.4240\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0198 - val_loss: 10.9509\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9313 - val_loss: 10.7778\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1476 - val_loss: 11.3414\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3382 - val_loss: 11.4705\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0936 - val_loss: 11.8895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8401 - val_loss: 11.1459\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3719 - val_loss: 10.9473\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6838 - val_loss: 11.0747\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1661 - val_loss: 10.9504\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2901 - val_loss: 11.0711\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0314 - val_loss: 11.4100\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1307 - val_loss: 12.6444\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9892 - val_loss: 10.8070\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9567 - val_loss: 12.1715\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1757 - val_loss: 11.1963\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9265 - val_loss: 11.1995\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3390 - val_loss: 10.9090\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1109 - val_loss: 11.6265\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0527 - val_loss: 11.9331\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3016 - val_loss: 10.8072\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.6987 - val_loss: 10.9782\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.8534 - val_loss: 11.4190\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0831 - val_loss: 11.4010\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0899 - val_loss: 10.9435\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3056 - val_loss: 12.0905\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9031 - val_loss: 10.9656\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6595 - val_loss: 12.0394\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9397 - val_loss: 11.7459\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8496 - val_loss: 11.1942\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0484 - val_loss: 11.4060\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8440 - val_loss: 10.9450\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2256 - val_loss: 11.0404\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1971 - val_loss: 11.0997\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1960 - val_loss: 11.2020\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4190 - val_loss: 11.5047\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3254 - val_loss: 10.7395\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4806 - val_loss: 11.6103\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1224 - val_loss: 10.8121\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0468 - val_loss: 11.3148\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8697 - val_loss: 10.7609\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6933 - val_loss: 10.8483\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1479 - val_loss: 11.1799\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1705 - val_loss: 11.0135\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8240 - val_loss: 10.7622\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2816 - val_loss: 11.0055\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9848 - val_loss: 11.6581\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2542 - val_loss: 11.3418\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0762 - val_loss: 11.2730\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9984 - val_loss: 11.0955\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8460 - val_loss: 10.6256\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 127us/step - loss: 8.9414 - val_loss: 11.1633\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1015 - val_loss: 11.0967\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1366 - val_loss: 11.5912\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2051 - val_loss: 11.9221\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9331 - val_loss: 10.8238\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8346 - val_loss: 11.4160\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0283 - val_loss: 10.7897\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8893 - val_loss: 12.1413\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9828 - val_loss: 11.0940\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1300 - val_loss: 11.2416\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2094 - val_loss: 12.0220\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1138 - val_loss: 11.1466\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0764 - val_loss: 10.8495\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2187 - val_loss: 11.3552\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9516 - val_loss: 11.2752\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0334 - val_loss: 11.2724\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8686 - val_loss: 11.2678\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1900 - val_loss: 11.5615\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0354 - val_loss: 11.0729\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9450 - val_loss: 10.9398\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0209 - val_loss: 12.0484\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8345 - val_loss: 10.6258\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0546 - val_loss: 12.8738\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2772 - val_loss: 13.0447\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0790 - val_loss: 11.1550\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8017 - val_loss: 11.4335\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1735 - val_loss: 11.0593\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9216 - val_loss: 10.6970\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9370 - val_loss: 12.1356\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0671 - val_loss: 11.5845\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1549 - val_loss: 11.2413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0839 - val_loss: 11.2873\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1123 - val_loss: 10.5798\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9814 - val_loss: 11.5405\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0983 - val_loss: 11.3628\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4000 - val_loss: 11.5109\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3143 - val_loss: 10.7776\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9335 - val_loss: 11.2973\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0947 - val_loss: 11.2524\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4851 - val_loss: 10.9904\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8254 - val_loss: 11.4431\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9856 - val_loss: 11.0433\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9254 - val_loss: 12.0766\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8412 - val_loss: 10.8723\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8116 - val_loss: 10.9487\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8582 - val_loss: 12.4493\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2749 - val_loss: 11.1862\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1232 - val_loss: 11.8353\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2166 - val_loss: 12.1795\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1483 - val_loss: 11.5699\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6878 - val_loss: 11.2688\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7956 - val_loss: 10.8419\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7484 - val_loss: 10.9611\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9381 - val_loss: 11.5906\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1650 - val_loss: 10.8861\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1069 - val_loss: 11.1554\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9589 - val_loss: 10.9547\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6294 - val_loss: 11.6579\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2468 - val_loss: 11.1484\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8283 - val_loss: 10.6081\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0960 - val_loss: 11.1206\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0080 - val_loss: 10.7346\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5009 - val_loss: 11.5225\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0251 - val_loss: 12.1722\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3111 - val_loss: 10.4861\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1987 - val_loss: 10.6167\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0025 - val_loss: 11.9809\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8015 - val_loss: 10.9048\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7939 - val_loss: 11.5292\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7103 - val_loss: 11.8591\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.0087 - val_loss: 11.5767\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0073 - val_loss: 14.3817\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4158 - val_loss: 10.9170\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0470 - val_loss: 10.9771\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8371 - val_loss: 11.2114\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8733 - val_loss: 10.8878\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0508 - val_loss: 10.7615\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7257 - val_loss: 10.9293\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9310 - val_loss: 12.5214\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0653 - val_loss: 10.6729\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1272 - val_loss: 10.5520\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6378 - val_loss: 11.0631\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0153 - val_loss: 10.8781\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1067 - val_loss: 11.0182\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4445 - val_loss: 11.7473\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8465 - val_loss: 11.0147\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1667 - val_loss: 11.2024\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1289 - val_loss: 10.6574\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8710 - val_loss: 10.5330\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1134 - val_loss: 11.6466\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0469 - val_loss: 10.5719\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0026 - val_loss: 10.5292\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0601 - val_loss: 11.5968\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8496 - val_loss: 11.0483\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9610 - val_loss: 10.6073\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2489 - val_loss: 11.1495\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2649 - val_loss: 11.1553\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8758 - val_loss: 10.8171\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9338 - val_loss: 10.7615\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8218 - val_loss: 10.6572\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5043 - val_loss: 12.1484\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4390 - val_loss: 10.6184\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8455 - val_loss: 11.4206\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9281 - val_loss: 11.1492\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9022 - val_loss: 10.8519\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8749 - val_loss: 10.7286\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9706 - val_loss: 11.0821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9442 - val_loss: 11.3665\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9025 - val_loss: 11.6454\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4168 - val_loss: 12.9046\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0659 - val_loss: 10.4290\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1782 - val_loss: 11.0713\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9592 - val_loss: 10.6660\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9270 - val_loss: 11.8285\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2110 - val_loss: 11.0800\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2499 - val_loss: 10.6401\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5315 - val_loss: 11.6833\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1874 - val_loss: 12.0875\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8189 - val_loss: 11.3427\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1630 - val_loss: 11.4082\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0642 - val_loss: 11.8775\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0829 - val_loss: 11.3667\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9619 - val_loss: 11.0172\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8070 - val_loss: 10.4675\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8529 - val_loss: 10.6126\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7176 - val_loss: 10.7748\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8089 - val_loss: 10.8033\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9302 - val_loss: 10.5218\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9376 - val_loss: 10.6310\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9733 - val_loss: 10.9839\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0802 - val_loss: 10.9834\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9688 - val_loss: 10.7151\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7421 - val_loss: 11.7152\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0890 - val_loss: 11.4422\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5729 - val_loss: 11.3065\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0053 - val_loss: 12.1714\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0257 - val_loss: 10.9258\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0609 - val_loss: 10.5638\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0446 - val_loss: 11.8945\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0793 - val_loss: 10.6362\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1035 - val_loss: 10.7872\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.6869 - val_loss: 11.5127\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.9867 - val_loss: 10.7030\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4149 - val_loss: 11.6345\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1157 - val_loss: 11.4396\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0086 - val_loss: 11.0514\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0769 - val_loss: 11.3031\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0696 - val_loss: 10.8850\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9961 - val_loss: 11.2001\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2527 - val_loss: 10.8999\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9435 - val_loss: 10.4208\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5299 - val_loss: 11.0215\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0227 - val_loss: 11.0989\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8709 - val_loss: 10.6817\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9078 - val_loss: 10.4659\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7688 - val_loss: 10.7963\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9339 - val_loss: 12.3107\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0763 - val_loss: 10.6027\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7645 - val_loss: 10.5919\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6061 - val_loss: 11.3176\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8703 - val_loss: 11.0138\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9443 - val_loss: 10.3677\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6573 - val_loss: 10.8773\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.9499 - val_loss: 10.2886\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1022 - val_loss: 11.1422\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9791 - val_loss: 10.5757\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0021 - val_loss: 10.7329\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6979 - val_loss: 10.3386\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0113 - val_loss: 11.6286\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1950 - val_loss: 10.3441\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8885 - val_loss: 10.9987\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8354 - val_loss: 11.3568\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7858 - val_loss: 10.3967\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8142 - val_loss: 11.3563\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1608 - val_loss: 10.9869\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9893 - val_loss: 10.8107\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7149 - val_loss: 11.2713\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0631 - val_loss: 10.5575\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9912 - val_loss: 11.6759\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9897 - val_loss: 11.1355\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5580 - val_loss: 10.8604\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6731 - val_loss: 10.8572\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8522 - val_loss: 10.4114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1113 - val_loss: 10.5109\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9056 - val_loss: 10.1656\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0936 - val_loss: 10.8279\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0025 - val_loss: 12.2026\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3768 - val_loss: 10.4031\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0089 - val_loss: 12.4670\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2685 - val_loss: 10.9389\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3703 - val_loss: 10.4377\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8308 - val_loss: 10.2360\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6216 - val_loss: 11.3762\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8012 - val_loss: 10.9670\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7819 - val_loss: 10.9095\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6391 - val_loss: 10.4733\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0582 - val_loss: 10.1934\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3840 - val_loss: 10.9299\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9848 - val_loss: 10.5294\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8428 - val_loss: 10.7025\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7645 - val_loss: 10.4493\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6383 - val_loss: 10.4413\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0310 - val_loss: 11.5144\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9232 - val_loss: 10.8392\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7344 - val_loss: 10.7733\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7717 - val_loss: 10.7745\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1697 - val_loss: 10.7608\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1031 - val_loss: 10.7867\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2302 - val_loss: 11.5306\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8230 - val_loss: 10.8008\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7123 - val_loss: 10.5221\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0883 - val_loss: 10.9647\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1121 - val_loss: 10.3560\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5311 - val_loss: 10.5375\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1291 - val_loss: 12.5067\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6496 - val_loss: 10.4954\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3691 - val_loss: 11.8776\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7725 - val_loss: 10.3430\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5913 - val_loss: 10.7092\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1432 - val_loss: 10.9371\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8407 - val_loss: 10.5425\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2451 - val_loss: 10.9941\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8207 - val_loss: 10.2804\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8168 - val_loss: 11.3089\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0024 - val_loss: 10.7980\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9538 - val_loss: 11.3176\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8064 - val_loss: 10.4008\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6084 - val_loss: 10.3493\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2399 - val_loss: 11.5079\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0388 - val_loss: 10.8079\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9995 - val_loss: 10.5807\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3207 - val_loss: 10.5212\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7258 - val_loss: 10.7646\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1787 - val_loss: 10.4154\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2695 - val_loss: 11.7053\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0848 - val_loss: 11.4763\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7745 - val_loss: 10.5910\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8220 - val_loss: 10.9076\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8374 - val_loss: 11.1796\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1761 - val_loss: 10.4741\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2359 - val_loss: 10.5894\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0626 - val_loss: 12.1269\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7171 - val_loss: 10.5353\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1972 - val_loss: 10.3774\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3028 - val_loss: 10.7144\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7505 - val_loss: 11.1724\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8913 - val_loss: 10.6977\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2925 - val_loss: 10.8625\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9064 - val_loss: 10.5012\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9846 - val_loss: 10.4163\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8044 - val_loss: 10.2732\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8442 - val_loss: 10.7666\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1297 - val_loss: 12.0961\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9828 - val_loss: 10.1501\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7061 - val_loss: 11.5679\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5616 - val_loss: 10.7770\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4130 - val_loss: 10.2744\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9106 - val_loss: 10.3965\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0187 - val_loss: 10.8789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9118 - val_loss: 11.2383\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7231 - val_loss: 10.9058\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7342 - val_loss: 11.1041\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7420 - val_loss: 10.2886\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9901 - val_loss: 10.1696\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7856 - val_loss: 10.8525\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7915 - val_loss: 10.3766\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.7411 - val_loss: 10.3195\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7028 - val_loss: 10.4013\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8815 - val_loss: 10.3316\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9025 - val_loss: 10.5742\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9339 - val_loss: 11.5213\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9412 - val_loss: 11.1657\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9184 - val_loss: 11.2033\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7970 - val_loss: 10.5666\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8257 - val_loss: 11.0948\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8816 - val_loss: 10.3454\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6338 - val_loss: 10.3662\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0552 - val_loss: 10.1614\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7643 - val_loss: 11.1456\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6791 - val_loss: 11.3993\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8699 - val_loss: 10.0911\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5343 - val_loss: 11.1393\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8264 - val_loss: 11.2113\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4921 - val_loss: 10.8604\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8555 - val_loss: 11.2311\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9060 - val_loss: 11.3967\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8448 - val_loss: 10.2562\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5835 - val_loss: 11.7631\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5789 - val_loss: 10.7478\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2441 - val_loss: 12.1222\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5795 - val_loss: 11.4935\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9278 - val_loss: 11.6001\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6206 - val_loss: 10.5454\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7764 - val_loss: 11.5724\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0784 - val_loss: 11.9326\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0518 - val_loss: 11.6791\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2475 - val_loss: 10.9404\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0878 - val_loss: 10.3311\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8042 - val_loss: 10.0823\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7372 - val_loss: 10.1908\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7707 - val_loss: 10.8806\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8689 - val_loss: 11.5088\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7617 - val_loss: 13.3169\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9424 - val_loss: 10.3759\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7564 - val_loss: 10.8004\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9912 - val_loss: 10.7401\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7869 - val_loss: 10.0859\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8998 - val_loss: 10.6130\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9976 - val_loss: 10.3372\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9514 - val_loss: 10.2981\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8992 - val_loss: 10.0746\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0017 - val_loss: 10.3685\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8452 - val_loss: 11.3857\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0406 - val_loss: 10.0888\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6649 - val_loss: 10.3639\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7259 - val_loss: 10.1268\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4051 - val_loss: 12.2794\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5652 - val_loss: 11.3343\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2559 - val_loss: 11.0222\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9787 - val_loss: 11.3094\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0957 - val_loss: 10.4304\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6038 - val_loss: 10.0738\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7896 - val_loss: 11.6854\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2805 - val_loss: 10.3931\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4792 - val_loss: 10.0016\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4947 - val_loss: 10.9330\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1917 - val_loss: 11.3920\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9234 - val_loss: 11.4488\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1638 - val_loss: 10.8467\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8920 - val_loss: 10.2954\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8076 - val_loss: 10.6289\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2295 - val_loss: 10.3450\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8640 - val_loss: 10.0708\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8670 - val_loss: 12.0081\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1052 - val_loss: 10.2841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7051 - val_loss: 10.4814\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9483 - val_loss: 10.0869\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6410 - val_loss: 10.2196\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7992 - val_loss: 10.3507\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9446 - val_loss: 10.4689\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7712 - val_loss: 10.8250\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6661 - val_loss: 10.8679\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2552 - val_loss: 10.4111\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6238 - val_loss: 10.3968\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9850 - val_loss: 11.0238\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4237 - val_loss: 10.6420\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6522 - val_loss: 10.1353\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8003 - val_loss: 10.9289\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8659 - val_loss: 9.9466\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1399 - val_loss: 10.4520\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8868 - val_loss: 11.6408\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0498 - val_loss: 10.3266\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9345 - val_loss: 10.0096\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7389 - val_loss: 10.7035\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6047 - val_loss: 10.2204\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7400 - val_loss: 10.0814\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3160 - val_loss: 10.8992\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1134 - val_loss: 11.0792\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2910 - val_loss: 10.3410\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0225 - val_loss: 10.5569\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9141 - val_loss: 10.3522\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5114 - val_loss: 10.1678\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7696 - val_loss: 10.3396\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3376 - val_loss: 10.3913\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7135 - val_loss: 10.7998\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9465 - val_loss: 11.2280\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9372 - val_loss: 10.0456\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5289 - val_loss: 10.8307\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8119 - val_loss: 11.1559\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9920 - val_loss: 11.2230\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1278 - val_loss: 10.0449\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0666 - val_loss: 10.5877\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4260 - val_loss: 10.0620\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9952 - val_loss: 10.2634\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6512 - val_loss: 11.9745\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8000 - val_loss: 11.7469\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0831 - val_loss: 10.7952\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7653 - val_loss: 9.9073\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8526 - val_loss: 10.1769\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7376 - val_loss: 11.8712\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2350 - val_loss: 10.1988\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6501 - val_loss: 10.9810\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1895 - val_loss: 10.6254\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5354 - val_loss: 10.9725\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8607 - val_loss: 10.4265\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9589 - val_loss: 11.2815\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4599 - val_loss: 11.7904\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6880 - val_loss: 10.3825\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9665 - val_loss: 10.4005\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0866 - val_loss: 10.3335\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1151 - val_loss: 13.7033\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3868 - val_loss: 10.8740\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9832 - val_loss: 10.4902\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8308 - val_loss: 11.9159\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6746 - val_loss: 11.0166\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9560 - val_loss: 10.0250\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8466 - val_loss: 10.8951\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8150 - val_loss: 10.2196\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0425 - val_loss: 11.3787\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7826 - val_loss: 9.9338\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6692 - val_loss: 10.4207\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5416 - val_loss: 11.1101\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6453 - val_loss: 9.8869\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6993 - val_loss: 10.9739\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6352 - val_loss: 10.3704\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0654 - val_loss: 10.0491\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7318 - val_loss: 10.1131\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9060 - val_loss: 10.2358\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7878 - val_loss: 11.2670\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9843 - val_loss: 11.2747\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0257 - val_loss: 10.2835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7561 - val_loss: 10.3538\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2805 - val_loss: 10.8510\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7006 - val_loss: 10.1282\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5204 - val_loss: 11.0204\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5293 - val_loss: 10.8083\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1649 - val_loss: 10.3947\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5897 - val_loss: 10.8829\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6897 - val_loss: 10.7956\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0491 - val_loss: 11.0319\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9973 - val_loss: 10.6468\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8368 - val_loss: 11.0927\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.4318 - val_loss: 10.2157\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.7499 - val_loss: 10.5235\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5993 - val_loss: 10.2084\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8670 - val_loss: 10.1655\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9533 - val_loss: 10.4205\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7522 - val_loss: 10.0591\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8477 - val_loss: 12.4539\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0158 - val_loss: 10.3284\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7735 - val_loss: 10.7637\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5898 - val_loss: 12.3950\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0996 - val_loss: 10.1227\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9052 - val_loss: 10.6137\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7516 - val_loss: 10.4234\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9487 - val_loss: 10.3678\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8494 - val_loss: 10.0489\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2036 - val_loss: 9.9154\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6473 - val_loss: 10.2099\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7326 - val_loss: 10.4851\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8896 - val_loss: 10.6269\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9635 - val_loss: 10.9973\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5387 - val_loss: 11.0879\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7902 - val_loss: 9.8262\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8448 - val_loss: 11.6530\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8241 - val_loss: 10.4854\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0246 - val_loss: 10.4939\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6772 - val_loss: 10.4715\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1800 - val_loss: 10.7365\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0322 - val_loss: 9.8457\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6973 - val_loss: 11.0095\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4471 - val_loss: 10.0991\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6670 - val_loss: 9.9058\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6906 - val_loss: 10.8015\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6868 - val_loss: 10.2812\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5540 - val_loss: 10.3816\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4565 - val_loss: 10.7450\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6370 - val_loss: 11.2501\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6704 - val_loss: 10.5999\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3332 - val_loss: 10.0536\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.5816 - val_loss: 10.0129\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6296 - val_loss: 10.1755\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8820 - val_loss: 10.4238\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9627 - val_loss: 10.6438\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1032 - val_loss: 10.5667\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0993 - val_loss: 10.1630\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0043 - val_loss: 11.1411\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5762 - val_loss: 10.5492\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4907 - val_loss: 9.8955\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5976 - val_loss: 10.8733\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6904 - val_loss: 10.0038\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6225 - val_loss: 9.9134\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1118 - val_loss: 10.4681\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9426 - val_loss: 10.1552\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0697 - val_loss: 13.4504\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1145 - val_loss: 10.3301\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7613 - val_loss: 9.8572\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7841 - val_loss: 11.3166\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6552 - val_loss: 10.5496\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8860 - val_loss: 10.2992\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5983 - val_loss: 9.9012\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8709 - val_loss: 11.4619\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8123 - val_loss: 10.9392\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2670 - val_loss: 14.0411\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3687 - val_loss: 9.8972\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5954 - val_loss: 11.2484\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8798 - val_loss: 11.1113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5619 - val_loss: 9.8434\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6203 - val_loss: 10.2479\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8904 - val_loss: 10.0805\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6399 - val_loss: 10.1060\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0197 - val_loss: 10.9173\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8023 - val_loss: 10.0754\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9734 - val_loss: 10.4716\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6428 - val_loss: 10.2365\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6078 - val_loss: 10.4844\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7460 - val_loss: 9.9317\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0573 - val_loss: 12.6580\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2420 - val_loss: 11.3453\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9470 - val_loss: 9.7538\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3646 - val_loss: 13.6052\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9792 - val_loss: 10.8554\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5656 - val_loss: 10.5325\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9959 - val_loss: 10.6079\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4051 - val_loss: 9.9391\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0162 - val_loss: 11.6855\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5142 - val_loss: 9.9372\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1555 - val_loss: 11.1352\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7622 - val_loss: 11.3280\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7605 - val_loss: 10.2069\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6117 - val_loss: 10.4324\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6229 - val_loss: 10.4936\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2406 - val_loss: 11.3001\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7751 - val_loss: 10.7132\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2023 - val_loss: 10.1915\n",
      "8.429568941416466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-4.0897183 ,  0.20294963,  1.4910512 ,  1.1518444 , -3.9177892 ],\n",
       "        [ 0.36034897,  0.26312467, -0.33617806,  0.11392819,  0.07633582],\n",
       "        [-0.656961  ,  0.37469736, -0.25279558,  0.3490771 ,  0.07739425],\n",
       "        [ 0.146966  , -0.09817263, -0.09108508, -0.1260312 ,  0.08331141],\n",
       "        [-0.42905676,  0.21014701,  0.16703925,  0.9846548 , -2.1844993 ]],\n",
       "       dtype=float32),\n",
       " array([-5.0597167 ,  0.23230127,  1.2123454 ,  2.913998  , -5.3612175 ],\n",
       "       dtype=float32),\n",
       " array([[ 2.842912  ,  2.2142937 ,  3.2297137 , -3.3318956 ,  2.2851353 ],\n",
       "        [ 0.6016961 ,  1.8716263 ,  1.8844707 , -0.60427463,  1.9031094 ],\n",
       "        [ 0.73900616,  1.1941285 ,  1.0457095 , -1.613533  ,  0.8235355 ],\n",
       "        [-2.309707  , -2.833071  , -2.4372993 ,  2.7908041 , -2.1663594 ],\n",
       "        [ 2.413546  ,  2.870484  ,  2.255688  , -2.582084  ,  2.9827347 ]],\n",
       "       dtype=float32),\n",
       " array([-2.3812776, -2.3147817, -2.2919624,  2.3475919, -2.2427897],\n",
       "       dtype=float32),\n",
       " array([[-2.5968869],\n",
       "        [-2.649389 ],\n",
       "        [-2.7521913],\n",
       "        [ 2.6200197],\n",
       "        [-2.9066398]], dtype=float32),\n",
       " array([2.0089853], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_1(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure1_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 195us/step - loss: 7601.2558 - val_loss: 765.8525\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 196.0745 - val_loss: 47.5410\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 36.0321 - val_loss: 27.9538\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 27.2558 - val_loss: 26.3230\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 24.8131 - val_loss: 26.2680\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.2577 - val_loss: 26.0040\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.6925 - val_loss: 25.8960\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.3137 - val_loss: 25.4377\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.3047 - val_loss: 26.5973\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.4121 - val_loss: 26.3312\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.0902 - val_loss: 25.5457\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.3075 - val_loss: 26.4726\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.6529 - val_loss: 27.0313\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.0614 - val_loss: 27.2210\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.8052 - val_loss: 26.2269\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5318 - val_loss: 26.3216\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5434 - val_loss: 25.7617\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.7976 - val_loss: 25.4058\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.4707 - val_loss: 25.5623\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.5432 - val_loss: 27.7981\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.0589 - val_loss: 26.5754\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.4630 - val_loss: 25.7131\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2610 - val_loss: 25.3464\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3730 - val_loss: 25.7854\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.5763 - val_loss: 25.4691\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.2555 - val_loss: 25.5254\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.6772 - val_loss: 27.6622\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.6954 - val_loss: 26.3683\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4605 - val_loss: 25.9258\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.5172 - val_loss: 25.8555\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.3747 - val_loss: 25.8834\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2914 - val_loss: 26.2365\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.6202 - val_loss: 25.7566\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.6074 - val_loss: 25.4336\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.1341 - val_loss: 25.7680\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2149 - val_loss: 26.1428\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2586 - val_loss: 25.8743\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.4345 - val_loss: 25.8279\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2007 - val_loss: 27.1034\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1031 - val_loss: 25.7908\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.1877 - val_loss: 25.4389\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3185 - val_loss: 26.7985\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.9961 - val_loss: 28.2696\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.9479 - val_loss: 25.6464\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.3031 - val_loss: 25.6772\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0960 - val_loss: 26.3615\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4384 - val_loss: 25.4760\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2068 - val_loss: 25.3673\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9736 - val_loss: 25.4570\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0892 - val_loss: 27.5601\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5304 - val_loss: 26.2490\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2806 - val_loss: 25.5431\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.1637 - val_loss: 27.7920\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.3265 - val_loss: 26.1430\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.2653 - val_loss: 28.1069\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.2313 - val_loss: 26.8523\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3421 - val_loss: 25.4994\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1240 - val_loss: 26.1352\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.9382 - val_loss: 25.9567\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.1621 - val_loss: 25.7007\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.3581 - val_loss: 26.5076\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.9061 - val_loss: 27.4945\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.7654 - val_loss: 26.6033\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.8464 - val_loss: 25.6290\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.9173 - val_loss: 25.6463\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2871 - val_loss: 25.2966\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8269 - val_loss: 26.0124\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.8379 - val_loss: 25.7805\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1476 - val_loss: 25.4008\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9497 - val_loss: 25.9883\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.6565 - val_loss: 25.8593\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.7302 - val_loss: 25.8332\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.2131 - val_loss: 26.6225\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.0987 - val_loss: 26.4060\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.2957 - val_loss: 25.6400\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9551 - val_loss: 26.1163\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5907 - val_loss: 26.7864\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.8881 - val_loss: 25.8838\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5564 - val_loss: 26.4406\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 22.0472 - val_loss: 25.8114\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1343 - val_loss: 25.9400\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9738 - val_loss: 28.2667\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1696 - val_loss: 26.0048\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.1546 - val_loss: 25.6303\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2340 - val_loss: 25.7541\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0832 - val_loss: 26.4002\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.8112 - val_loss: 25.2241\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.7399 - val_loss: 25.8270\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.7270 - val_loss: 25.2078\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.2384 - val_loss: 27.0215\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.0099 - val_loss: 27.0324\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.5815 - val_loss: 25.9517\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.7891 - val_loss: 25.3732\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.5376 - val_loss: 25.7780\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.5263 - val_loss: 25.6398\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.3950 - val_loss: 25.1964\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1988 - val_loss: 26.1887\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.0216 - val_loss: 25.0015\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.3215 - val_loss: 25.1575\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.4970 - val_loss: 24.8253\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.6494 - val_loss: 25.0441\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.4614 - val_loss: 25.4219\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9567 - val_loss: 24.8862\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.2527 - val_loss: 24.8872\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.9574 - val_loss: 24.7490\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.0284 - val_loss: 24.8537\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.3151 - val_loss: 26.9708\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.1999 - val_loss: 25.1963\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6125 - val_loss: 24.7642\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.9174 - val_loss: 24.8948\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.6122 - val_loss: 23.8880\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 20.7166 - val_loss: 24.4327\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.5234 - val_loss: 26.4929\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.5449 - val_loss: 24.1653\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.7050 - val_loss: 26.0681\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.3572 - val_loss: 23.4755\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.9060 - val_loss: 27.3596\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.6823 - val_loss: 23.8617\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.1074 - val_loss: 25.2059\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.3384 - val_loss: 23.4947\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.7824 - val_loss: 25.2726\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.9270 - val_loss: 23.2105\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.2906 - val_loss: 22.9665\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.2438 - val_loss: 22.9771\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8079 - val_loss: 23.7324\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.0108 - val_loss: 23.1469\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7966 - val_loss: 22.1530\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.5688 - val_loss: 24.2326\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9881 - val_loss: 22.5341\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2308 - val_loss: 21.4273\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.8048 - val_loss: 21.0041\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4337 - val_loss: 20.7171\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3625 - val_loss: 20.9034\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5482 - val_loss: 21.4900\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.6494 - val_loss: 20.2162\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.4236 - val_loss: 20.5989\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.2021 - val_loss: 23.1079\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9380 - val_loss: 20.6227\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2646 - val_loss: 19.3116\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4654 - val_loss: 20.6798\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9056 - val_loss: 19.5239\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5941 - val_loss: 23.3679\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4228 - val_loss: 18.8755\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.7830 - val_loss: 19.0402\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.6071 - val_loss: 18.3523\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.7076 - val_loss: 19.3983\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.4055 - val_loss: 18.7640\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.9941 - val_loss: 18.7176\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.1031 - val_loss: 18.5074\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.2524 - val_loss: 18.1922\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.0447 - val_loss: 18.8711\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.4204 - val_loss: 18.5524\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.1288 - val_loss: 18.0942\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.8791 - val_loss: 21.7190\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.6008 - val_loss: 18.6520\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.9893 - val_loss: 20.5940\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.5416 - val_loss: 18.2664\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.4759 - val_loss: 17.5139\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.9800 - val_loss: 18.1121\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.5396 - val_loss: 17.7274\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.3111 - val_loss: 18.0382\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.7809 - val_loss: 19.1689\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.3607 - val_loss: 18.0821\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.1305 - val_loss: 17.2450\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.1834 - val_loss: 17.5708\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.2233 - val_loss: 18.3566\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2180 - val_loss: 17.3575\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.0961 - val_loss: 16.8340\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.8883 - val_loss: 17.5465\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.7621 - val_loss: 16.7899\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.9439 - val_loss: 17.0032\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.8759 - val_loss: 16.7771\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.7182 - val_loss: 18.4868\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.0798 - val_loss: 17.4537\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.6667 - val_loss: 19.7657\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.4160 - val_loss: 17.7546\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6141 - val_loss: 18.6655\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4838 - val_loss: 17.1803\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.9956 - val_loss: 16.2702\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.5413 - val_loss: 16.3658\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2983 - val_loss: 17.7112\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9176 - val_loss: 16.7284\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8579 - val_loss: 16.9867\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7428 - val_loss: 16.7473\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8487 - val_loss: 17.3352\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0643 - val_loss: 17.9298\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.6295 - val_loss: 20.3880\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8603 - val_loss: 16.6938\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3830 - val_loss: 16.7858\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7081 - val_loss: 16.0275\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6425 - val_loss: 17.8473\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.1317 - val_loss: 16.6106\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.3768 - val_loss: 17.3713\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3902 - val_loss: 20.5792\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.8411 - val_loss: 15.5767\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.9670 - val_loss: 16.2963\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5262 - val_loss: 17.0583\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5094 - val_loss: 17.4006\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.8241 - val_loss: 15.1398\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.8320 - val_loss: 15.2490\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6395 - val_loss: 17.7049\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.7636 - val_loss: 15.5508\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.3897 - val_loss: 16.2606\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.3143 - val_loss: 16.1874\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9125 - val_loss: 14.6801\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4923 - val_loss: 17.4055\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.6599 - val_loss: 16.7404\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.4933 - val_loss: 16.4651\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.3211 - val_loss: 14.7028\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.7575 - val_loss: 14.8295\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4722 - val_loss: 17.8303\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0146 - val_loss: 15.0519\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.0528 - val_loss: 16.2222\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6450 - val_loss: 14.7892\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.5515 - val_loss: 15.4417\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2729 - val_loss: 14.7414\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0751 - val_loss: 15.5505\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3729 - val_loss: 14.2240\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.5252 - val_loss: 14.5372\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6619 - val_loss: 18.3387\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6703 - val_loss: 13.7289\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3221 - val_loss: 13.2236\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4247 - val_loss: 13.9834\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.5356 - val_loss: 13.6898\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.4418 - val_loss: 14.4441\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0130 - val_loss: 13.7660\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9047 - val_loss: 15.4665\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.1090 - val_loss: 13.5801\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.6803 - val_loss: 13.7338\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9734 - val_loss: 12.9877\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9347 - val_loss: 13.1711\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1985 - val_loss: 13.1522\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6609 - val_loss: 13.1638\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7106 - val_loss: 14.8265\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2770 - val_loss: 17.2830\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6495 - val_loss: 12.5871\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0995 - val_loss: 12.3098\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9821 - val_loss: 13.4107\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1683 - val_loss: 12.7104\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1493 - val_loss: 13.2473\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5538 - val_loss: 12.9193\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.4354 - val_loss: 12.6224\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9492 - val_loss: 12.4942\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3771 - val_loss: 14.1216\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7534 - val_loss: 12.1346\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7645 - val_loss: 13.5702\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5595 - val_loss: 12.0205\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7942 - val_loss: 13.3250\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0576 - val_loss: 12.7959\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2952 - val_loss: 11.9819\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3142 - val_loss: 12.1161\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5763 - val_loss: 13.1720\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1374 - val_loss: 11.5767\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.7494 - val_loss: 13.1290\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.5789 - val_loss: 12.1618\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.7475 - val_loss: 11.4503\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.7195 - val_loss: 12.0224\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4591 - val_loss: 11.4972\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.6763 - val_loss: 11.8420\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6867 - val_loss: 11.9083\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6051 - val_loss: 12.8488\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3991 - val_loss: 11.4792\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4027 - val_loss: 13.3715\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3032 - val_loss: 11.5162\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6045 - val_loss: 11.7099\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9266 - val_loss: 12.3410\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4804 - val_loss: 12.1083\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8765 - val_loss: 11.9775\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4234 - val_loss: 12.5286\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.7703 - val_loss: 13.7520\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5300 - val_loss: 12.6766\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3482 - val_loss: 12.1796\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3019 - val_loss: 11.4360\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1794 - val_loss: 11.5588\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1081 - val_loss: 12.4653\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2986 - val_loss: 11.3393\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1019 - val_loss: 11.6387\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3810 - val_loss: 12.1946\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1400 - val_loss: 11.6177\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0501 - val_loss: 12.2001\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4063 - val_loss: 11.3128\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5550 - val_loss: 12.0506\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9012 - val_loss: 12.4962\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5399 - val_loss: 12.3255\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4079 - val_loss: 12.5274\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3978 - val_loss: 11.9974\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0584 - val_loss: 12.2957\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0913 - val_loss: 13.1095\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9094 - val_loss: 12.3420\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1371 - val_loss: 12.3888\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2363 - val_loss: 11.2190\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3221 - val_loss: 12.0003\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5598 - val_loss: 11.5816\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9345 - val_loss: 13.1616\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3421 - val_loss: 11.4166\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2061 - val_loss: 12.3999\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4030 - val_loss: 11.2100\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3783 - val_loss: 11.6076\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0213 - val_loss: 11.2519\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0872 - val_loss: 11.3747\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2123 - val_loss: 12.4984\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1734 - val_loss: 11.3298\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1285 - val_loss: 13.5060\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8109 - val_loss: 11.6788\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5239 - val_loss: 12.3282\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2504 - val_loss: 12.3473\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4821 - val_loss: 11.0852\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3989 - val_loss: 11.9483\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0082 - val_loss: 12.3359\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6378 - val_loss: 12.5423\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3371 - val_loss: 11.1734\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6909 - val_loss: 13.6953\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2997 - val_loss: 11.3497\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1717 - val_loss: 11.0349\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3397 - val_loss: 12.5034\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3283 - val_loss: 11.2230\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9822 - val_loss: 11.8024\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0846 - val_loss: 11.2948\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2191 - val_loss: 11.1698\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2764 - val_loss: 13.3822\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5616 - val_loss: 11.2660\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9945 - val_loss: 11.3484\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4419 - val_loss: 13.6176\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3101 - val_loss: 11.0690\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1484 - val_loss: 12.1065\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4153 - val_loss: 10.6878\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0832 - val_loss: 12.1965\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2778 - val_loss: 11.3070\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2482 - val_loss: 11.9982\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7909 - val_loss: 12.1675\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3193 - val_loss: 11.7866\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1583 - val_loss: 11.0166\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0482 - val_loss: 13.0445\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3831 - val_loss: 10.7843\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4615 - val_loss: 12.6272\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0431 - val_loss: 10.9402\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2764 - val_loss: 11.6936\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4962 - val_loss: 11.4852\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2700 - val_loss: 11.3012\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1785 - val_loss: 11.1280\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9377 - val_loss: 11.1904\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2754 - val_loss: 11.7624\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3182 - val_loss: 11.1373\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5254 - val_loss: 13.6300\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6279 - val_loss: 11.6193\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0983 - val_loss: 11.1191\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0854 - val_loss: 11.2350\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2095 - val_loss: 11.1418\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9767 - val_loss: 11.4448\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8647 - val_loss: 11.3182\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7236 - val_loss: 11.5330\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2339 - val_loss: 11.8049\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0396 - val_loss: 10.8039\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2329 - val_loss: 11.2018\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6393 - val_loss: 13.4908\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4315 - val_loss: 10.7892\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6552 - val_loss: 11.6071\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2814 - val_loss: 10.9708\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9311 - val_loss: 11.2581\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0498 - val_loss: 10.9706\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1112 - val_loss: 11.2989\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9788 - val_loss: 11.6454\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5932 - val_loss: 11.2462\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1116 - val_loss: 11.3349\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1485 - val_loss: 12.8497\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4060 - val_loss: 11.4725\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9474 - val_loss: 11.2376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2842 - val_loss: 10.8414\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.0038 - val_loss: 11.7986\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3805 - val_loss: 11.3898\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2109 - val_loss: 11.6621\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8163 - val_loss: 10.9957\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7730 - val_loss: 14.0300\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3655 - val_loss: 11.5196\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2083 - val_loss: 12.7512\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2124 - val_loss: 11.1187\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1074 - val_loss: 11.7726\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1644 - val_loss: 12.9666\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3558 - val_loss: 10.7999\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9378 - val_loss: 10.6653\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8850 - val_loss: 11.2764\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0280 - val_loss: 12.1541\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0137 - val_loss: 10.7315\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2719 - val_loss: 11.6494\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2039 - val_loss: 11.4079\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.0674 - val_loss: 10.8631\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.9684 - val_loss: 11.1746\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3434 - val_loss: 10.8289\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7767 - val_loss: 11.8374\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.3700 - val_loss: 11.5713\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.1719 - val_loss: 11.1998\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.8324 - val_loss: 11.1646\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5592 - val_loss: 12.0948\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2219 - val_loss: 11.8554\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6522 - val_loss: 11.0346\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2302 - val_loss: 11.1013\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1181 - val_loss: 10.9426\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1402 - val_loss: 11.8057\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3220 - val_loss: 11.0038\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7513 - val_loss: 16.7081\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5631 - val_loss: 10.7865\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6722 - val_loss: 12.5142\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3505 - val_loss: 12.2314\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8763 - val_loss: 10.8276\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1640 - val_loss: 11.4834\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2318 - val_loss: 12.0304\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3644 - val_loss: 11.4246\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3276 - val_loss: 11.0742\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.199 - 0s 92us/step - loss: 9.3730 - val_loss: 11.8372\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4751 - val_loss: 12.2174\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.5517 - val_loss: 10.8911\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2612 - val_loss: 11.3414\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1015 - val_loss: 11.2850\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0197 - val_loss: 11.0946\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3301 - val_loss: 10.7999\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9903 - val_loss: 11.3069\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6850 - val_loss: 11.1572\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9658 - val_loss: 10.9966\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1272 - val_loss: 11.6618\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1873 - val_loss: 12.1429\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9801 - val_loss: 10.5636\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8397 - val_loss: 11.2112\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9546 - val_loss: 10.5921\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4660 - val_loss: 12.4457\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6805 - val_loss: 11.5597\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.9805 - val_loss: 10.7319\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9938 - val_loss: 11.5341\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.8549 - val_loss: 13.1946\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0663 - val_loss: 10.7560\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2002 - val_loss: 13.7462\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 10.1927 - val_loss: 10.9281\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2704 - val_loss: 13.0278\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2246 - val_loss: 13.0425\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 9.5424 - val_loss: 10.7897\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1943 - val_loss: 11.0634\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3914 - val_loss: 11.8013\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9788 - val_loss: 12.1733\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2592 - val_loss: 10.6997\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1239 - val_loss: 13.1336\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0802 - val_loss: 11.3442\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2746 - val_loss: 11.4278\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4348 - val_loss: 11.0103\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4234 - val_loss: 10.7055\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3011 - val_loss: 11.0872\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1684 - val_loss: 11.8890\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3372 - val_loss: 12.4316\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1433 - val_loss: 11.6118\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3389 - val_loss: 11.5858\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5544 - val_loss: 11.3383\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6845 - val_loss: 11.6285\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6834 - val_loss: 10.6073\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9183 - val_loss: 10.9132\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3839 - val_loss: 11.1343\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0647 - val_loss: 11.7313\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0210 - val_loss: 11.0944\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1559 - val_loss: 10.6115\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3307 - val_loss: 11.7299\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9419 - val_loss: 11.2795\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1271 - val_loss: 10.9651\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4801 - val_loss: 11.7584\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9934 - val_loss: 11.0469\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.8955 - val_loss: 10.9626\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1068 - val_loss: 11.1667\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0179 - val_loss: 11.1137\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.4217 - val_loss: 11.8936\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8947 - val_loss: 10.9141\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.4318 - val_loss: 11.7117\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.6505 - val_loss: 11.3650\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9740 - val_loss: 11.1572\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9739 - val_loss: 10.7054\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0256 - val_loss: 12.1073\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1949 - val_loss: 10.8754\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6132 - val_loss: 11.3892\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0591 - val_loss: 11.3819\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9921 - val_loss: 10.5459\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1573 - val_loss: 11.0047\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8200 - val_loss: 10.6756\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1161 - val_loss: 12.2062\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0241 - val_loss: 10.6127\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8202 - val_loss: 10.5985\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2254 - val_loss: 10.7032\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1228 - val_loss: 11.0454\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9774 - val_loss: 10.8150\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1560 - val_loss: 11.0134\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1592 - val_loss: 12.8985\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4036 - val_loss: 11.5854\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1020 - val_loss: 11.1778\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5596 - val_loss: 12.9519\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4047 - val_loss: 10.7888\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9888 - val_loss: 10.8976\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 133us/step - loss: 8.8364 - val_loss: 10.7608\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0562 - val_loss: 11.2929\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0503 - val_loss: 13.0625\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4633 - val_loss: 11.1881\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1775 - val_loss: 11.6324\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7456 - val_loss: 12.0000\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1155 - val_loss: 11.0238\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0146 - val_loss: 11.5712\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9216 - val_loss: 11.0394\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0888 - val_loss: 11.4809\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0558 - val_loss: 11.0788\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6237 - val_loss: 13.1170\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.8206 - val_loss: 11.0727\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4859 - val_loss: 11.1281\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0154 - val_loss: 12.3785\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3135 - val_loss: 10.7877\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6271 - val_loss: 10.9912\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8831 - val_loss: 11.5566\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9821 - val_loss: 10.6917\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0269 - val_loss: 11.0213\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4040 - val_loss: 11.2689\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9986 - val_loss: 11.0886\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9229 - val_loss: 10.8566\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9656 - val_loss: 11.1510\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.9813 - val_loss: 10.5862\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9959 - val_loss: 11.2994\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9197 - val_loss: 11.6642\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3589 - val_loss: 11.1028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1962 - val_loss: 11.4973\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5557 - val_loss: 10.9005\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7361 - val_loss: 10.5004\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9053 - val_loss: 11.5839\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5465 - val_loss: 10.9866\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2099 - val_loss: 10.4983\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4344 - val_loss: 10.6123\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6271 - val_loss: 14.2579\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2974 - val_loss: 11.5645\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3912 - val_loss: 10.5511\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2898 - val_loss: 12.0531\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0997 - val_loss: 11.3647\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3559 - val_loss: 10.9749\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1258 - val_loss: 10.7176\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1177 - val_loss: 10.8034\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0792 - val_loss: 11.0950\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6585 - val_loss: 10.9556\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8928 - val_loss: 10.8798\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2309 - val_loss: 11.9700\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1273 - val_loss: 11.8336\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1764 - val_loss: 12.3679\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6207 - val_loss: 12.9644\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3024 - val_loss: 11.2668\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3068 - val_loss: 11.2907\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9536 - val_loss: 11.0932\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2685 - val_loss: 11.7695\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1356 - val_loss: 10.5992\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6232 - val_loss: 11.1585\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9175 - val_loss: 11.3131\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0222 - val_loss: 10.8265\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8979 - val_loss: 12.2092\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3424 - val_loss: 10.6669\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1839 - val_loss: 11.1747\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5835 - val_loss: 10.4323\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7251 - val_loss: 11.2540\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7483 - val_loss: 11.7688\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1675 - val_loss: 11.4294\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0898 - val_loss: 10.6124\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3455 - val_loss: 12.7004\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7834 - val_loss: 10.7542\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0045 - val_loss: 10.8158\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1827 - val_loss: 12.3269\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4402 - val_loss: 10.6989\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7352 - val_loss: 10.5688\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7743 - val_loss: 11.1934\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1701 - val_loss: 11.1553\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2687 - val_loss: 10.3830\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0614 - val_loss: 12.0955\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0790 - val_loss: 11.0673\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1344 - val_loss: 10.7504\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5492 - val_loss: 10.4787\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0289 - val_loss: 11.5771\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1733 - val_loss: 11.0036\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0103 - val_loss: 12.2369\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2186 - val_loss: 11.7345\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8189 - val_loss: 10.7334\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9087 - val_loss: 11.0804\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0195 - val_loss: 10.9313\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9759 - val_loss: 10.7760\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8599 - val_loss: 10.8236\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0266 - val_loss: 11.4973\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6332 - val_loss: 12.1034\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5926 - val_loss: 10.8850\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8487 - val_loss: 10.9234\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0661 - val_loss: 11.1848\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1380 - val_loss: 11.8172\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1234 - val_loss: 10.4759\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7803 - val_loss: 10.9225\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9312 - val_loss: 11.0013\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9729 - val_loss: 11.5103\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8126 - val_loss: 10.9706\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4901 - val_loss: 12.5969\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8986 - val_loss: 10.6313\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3537 - val_loss: 11.0484\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 9.4972 - val_loss: 11.4086\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8948 - val_loss: 10.7961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6570 - val_loss: 10.4752\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8698 - val_loss: 11.6814\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4654 - val_loss: 12.1693\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.8588 - val_loss: 10.7773\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1937 - val_loss: 10.5676\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8821 - val_loss: 11.3954\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0515 - val_loss: 11.4168\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6042 - val_loss: 10.5977\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9019 - val_loss: 11.8115\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0614 - val_loss: 10.4100\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0172 - val_loss: 10.6181\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8121 - val_loss: 11.5723\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0814 - val_loss: 10.4161\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3523 - val_loss: 12.5947\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0863 - val_loss: 10.6088\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1474 - val_loss: 10.8817\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9398 - val_loss: 10.2106\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6931 - val_loss: 11.4127\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9624 - val_loss: 10.7885\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3075 - val_loss: 11.4204\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9337 - val_loss: 11.5098\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7862 - val_loss: 10.6944\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9934 - val_loss: 12.8627\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4347 - val_loss: 11.0044\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3381 - val_loss: 11.1715\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0320 - val_loss: 10.4036\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6678 - val_loss: 10.9325\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8386 - val_loss: 10.6361\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7668 - val_loss: 11.2723\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9469 - val_loss: 10.5432\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1671 - val_loss: 12.1714\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9634 - val_loss: 11.0357\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3242 - val_loss: 10.4928\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7389 - val_loss: 11.4624\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1893 - val_loss: 11.0988\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1364 - val_loss: 13.6298\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3452 - val_loss: 10.8248\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0087 - val_loss: 11.4680\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8459 - val_loss: 10.3416\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8314 - val_loss: 11.6452\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9936 - val_loss: 11.1065\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1057 - val_loss: 10.6696\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6609 - val_loss: 10.9815\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0709 - val_loss: 11.0696\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6627 - val_loss: 10.5396\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2787 - val_loss: 11.7283\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2991 - val_loss: 10.6499\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7140 - val_loss: 10.4356\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6057 - val_loss: 11.4428\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1250 - val_loss: 10.8667\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0181 - val_loss: 10.8042\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7075 - val_loss: 10.6172\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9864 - val_loss: 11.7202\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9276 - val_loss: 10.9127\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0385 - val_loss: 10.9852\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8526 - val_loss: 10.3831\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8255 - val_loss: 10.3466\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5601 - val_loss: 11.6255\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9620 - val_loss: 11.2407\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8054 - val_loss: 11.1469\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8075 - val_loss: 14.1720\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4387 - val_loss: 10.7864\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0937 - val_loss: 11.0438\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1770 - val_loss: 11.1767\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9025 - val_loss: 10.8599\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8003 - val_loss: 10.2858\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7855 - val_loss: 10.9726\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3257 - val_loss: 11.4915\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6601 - val_loss: 11.9742\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2527 - val_loss: 10.4976\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7742 - val_loss: 10.9475\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0465 - val_loss: 11.8332\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0961 - val_loss: 11.5046\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2459 - val_loss: 10.7141\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1458 - val_loss: 10.5223\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3769 - val_loss: 11.7253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9002 - val_loss: 11.3819\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4293 - val_loss: 10.7457\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8381 - val_loss: 11.1813\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6450 - val_loss: 10.9740\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3068 - val_loss: 10.6622\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3941 - val_loss: 10.6898\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1325 - val_loss: 11.1360\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8861 - val_loss: 10.9177\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0441 - val_loss: 11.3427\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0711 - val_loss: 11.6181\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2603 - val_loss: 11.3978\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6562 - val_loss: 12.1222\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6326 - val_loss: 10.7764\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8271 - val_loss: 11.4101\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2393 - val_loss: 11.4142\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1067 - val_loss: 10.8336\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0626 - val_loss: 10.7444\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4551 - val_loss: 10.3373\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9398 - val_loss: 10.7170\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5971 - val_loss: 10.7735\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8491 - val_loss: 10.7703\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6457 - val_loss: 10.9100\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3798 - val_loss: 10.6142\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9091 - val_loss: 10.1540\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7920 - val_loss: 10.5409\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7301 - val_loss: 10.2083\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8618 - val_loss: 10.9173\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9654 - val_loss: 11.2922\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8876 - val_loss: 10.6464\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4870 - val_loss: 11.4986\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5684 - val_loss: 10.5743\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0910 - val_loss: 11.1681\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7237 - val_loss: 11.1085\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7792 - val_loss: 10.7001\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0349 - val_loss: 11.1065\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5343 - val_loss: 11.8454\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4807 - val_loss: 10.4422\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9327 - val_loss: 10.2448\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0319 - val_loss: 12.5683\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7420 - val_loss: 10.0303\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0773 - val_loss: 12.0797\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3074 - val_loss: 12.1791\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9933 - val_loss: 10.6086\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5389 - val_loss: 10.4220\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7813 - val_loss: 10.3102\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6237 - val_loss: 10.3032\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6429 - val_loss: 10.0531\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4256 - val_loss: 10.6147\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7214 - val_loss: 11.4790\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2877 - val_loss: 10.4350\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3316 - val_loss: 14.2394\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1758 - val_loss: 11.2317\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9815 - val_loss: 10.9391\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9007 - val_loss: 10.3786\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8735 - val_loss: 10.0831\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0284 - val_loss: 10.7567\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6519 - val_loss: 10.5204\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1633 - val_loss: 10.6437\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9299 - val_loss: 11.2137\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7208 - val_loss: 10.4066\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8481 - val_loss: 11.1609\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9975 - val_loss: 10.3353\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1958 - val_loss: 10.2721\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7689 - val_loss: 10.0427\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9483 - val_loss: 11.6393\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6078 - val_loss: 10.0741\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1954 - val_loss: 10.1992\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7612 - val_loss: 10.0692\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4581 - val_loss: 11.1667\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0520 - val_loss: 10.8167\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4977 - val_loss: 10.8913\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2003 - val_loss: 11.3802\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3847 - val_loss: 11.0182\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5844 - val_loss: 10.1365\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0488 - val_loss: 11.6750\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5864 - val_loss: 10.9084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5250 - val_loss: 11.0209\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7594 - val_loss: 11.0841\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8023 - val_loss: 10.7035\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7333 - val_loss: 11.4654\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1514 - val_loss: 10.5225\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9234 - val_loss: 10.6048\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3074 - val_loss: 13.2049\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7303 - val_loss: 10.5584\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8465 - val_loss: 11.2586\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8947 - val_loss: 11.0005\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7792 - val_loss: 12.3370\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3584 - val_loss: 10.3781\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7336 - val_loss: 10.7757\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9924 - val_loss: 10.2519\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6259 - val_loss: 10.6674\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5560 - val_loss: 10.1258\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9274 - val_loss: 10.1984\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0459 - val_loss: 10.3542\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7621 - val_loss: 10.5409\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9942 - val_loss: 10.2316\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1166 - val_loss: 10.8573\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7959 - val_loss: 10.9245\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8184 - val_loss: 10.7577\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5646 - val_loss: 11.7210\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0000 - val_loss: 10.6920\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9296 - val_loss: 10.4339\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8254 - val_loss: 11.6283\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6639 - val_loss: 10.5507\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3783 - val_loss: 11.0510\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9177 - val_loss: 9.8793\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2571 - val_loss: 13.6119\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0934 - val_loss: 10.7429\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4518 - val_loss: 10.5660\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1929 - val_loss: 10.1936\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.7069 - val_loss: 10.1535\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9887 - val_loss: 10.0879\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8371 - val_loss: 10.7557\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9334 - val_loss: 10.1065\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6418 - val_loss: 10.3379\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8410 - val_loss: 10.2439\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0154 - val_loss: 13.5139\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0873 - val_loss: 10.7937\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1716 - val_loss: 10.2498\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1162 - val_loss: 12.5681\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2833 - val_loss: 10.3116\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1117 - val_loss: 10.0777\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0555 - val_loss: 10.4340\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8095 - val_loss: 10.1694\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6391 - val_loss: 10.1771\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3321 - val_loss: 10.8953\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4588 - val_loss: 10.3665\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9852 - val_loss: 10.3395\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9471 - val_loss: 10.3366\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2967 - val_loss: 11.2659\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8832 - val_loss: 10.5711\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6241 - val_loss: 10.3682\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7632 - val_loss: 10.1145\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8425 - val_loss: 11.2668\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2706 - val_loss: 10.8236\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3517 - val_loss: 9.9658\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0096 - val_loss: 10.4546\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8977 - val_loss: 10.5873\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6048 - val_loss: 10.7633\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9121 - val_loss: 10.1493\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7384 - val_loss: 11.0508\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1200 - val_loss: 11.4650\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7789 - val_loss: 10.4372\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6127 - val_loss: 10.3465\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7782 - val_loss: 9.9974\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6411 - val_loss: 10.2269\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8570 - val_loss: 10.0372\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8371 - val_loss: 10.0543\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5291 - val_loss: 11.4816\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6676 - val_loss: 10.7405\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8974 - val_loss: 10.0551\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0739 - val_loss: 12.5148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1908 - val_loss: 11.8977\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5823 - val_loss: 10.8613\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2744 - val_loss: 10.1276\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7701 - val_loss: 9.9519\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6978 - val_loss: 10.2053\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7077 - val_loss: 10.3473\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2314 - val_loss: 11.2218\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9654 - val_loss: 10.7237\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6111 - val_loss: 11.1061\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6690 - val_loss: 10.6208\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7363 - val_loss: 11.5972\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7688 - val_loss: 10.8706\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8965 - val_loss: 11.0197\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0700 - val_loss: 10.0383\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8573 - val_loss: 10.7635\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8497 - val_loss: 10.3076\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9176 - val_loss: 12.2314\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6756 - val_loss: 10.6933\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6068 - val_loss: 11.4186\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8554 - val_loss: 10.4572\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5998 - val_loss: 9.7541\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6816 - val_loss: 10.1332\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9467 - val_loss: 10.9784\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9973 - val_loss: 11.5532\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0146 - val_loss: 13.3102\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0968 - val_loss: 10.1840\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0596 - val_loss: 10.3473\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6989 - val_loss: 11.7396\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7868 - val_loss: 10.4890\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7152 - val_loss: 9.9284\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5671 - val_loss: 10.1964\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9010 - val_loss: 10.3297\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5839 - val_loss: 9.9311\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7558 - val_loss: 10.9857\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0077 - val_loss: 10.5503\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6308 - val_loss: 11.8107\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3655 - val_loss: 10.2158\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6269 - val_loss: 10.3836\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8468 - val_loss: 11.1218\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8306 - val_loss: 10.5633\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5088 - val_loss: 10.7750\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0087 - val_loss: 9.8945\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8413 - val_loss: 11.2876\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5390 - val_loss: 9.9990\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6159 - val_loss: 10.0539\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7527 - val_loss: 10.1345\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8119 - val_loss: 10.3820\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6730 - val_loss: 10.4879\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1276 - val_loss: 12.5716\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5682 - val_loss: 11.7694\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6048 - val_loss: 11.4014\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9670 - val_loss: 10.1303\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6802 - val_loss: 10.0856\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9126 - val_loss: 10.7312\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1397 - val_loss: 10.1064\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5752 - val_loss: 10.5345\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7138 - val_loss: 12.0325\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7916 - val_loss: 10.0214\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7231 - val_loss: 10.9133\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6699 - val_loss: 10.5040\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9676 - val_loss: 12.0831\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9866 - val_loss: 11.8577\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7456 - val_loss: 9.9956\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8028 - val_loss: 9.9444\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9529 - val_loss: 10.4962\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5839 - val_loss: 9.6675\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2712 - val_loss: 10.6274\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6799 - val_loss: 11.1177\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7545 - val_loss: 10.0004\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8446 - val_loss: 11.2271\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5796 - val_loss: 10.4522\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4800 - val_loss: 10.1286\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9196 - val_loss: 11.3656\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7673 - val_loss: 10.6793\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1673 - val_loss: 10.0149\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1218 - val_loss: 11.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6730 - val_loss: 9.7149\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6039 - val_loss: 10.2477\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8815 - val_loss: 10.0389\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5184 - val_loss: 10.6394\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7649 - val_loss: 10.2736\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9266 - val_loss: 10.5641\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9230 - val_loss: 10.9645\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0474 - val_loss: 11.0230\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2330 - val_loss: 11.6175\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7321 - val_loss: 11.2044\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7939 - val_loss: 10.1188\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0758 - val_loss: 11.0353\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0114 - val_loss: 9.8099\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6893 - val_loss: 10.2058\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4885 - val_loss: 10.6600\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5598 - val_loss: 9.8475\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4281 - val_loss: 9.9505\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6738 - val_loss: 11.6150\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2487 - val_loss: 12.3189\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8711 - val_loss: 11.5486\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8908 - val_loss: 9.9520\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6504 - val_loss: 12.0175\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7962 - val_loss: 10.8973\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0551 - val_loss: 11.2073\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0213 - val_loss: 9.9535\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5507 - val_loss: 9.9593\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7122 - val_loss: 10.2212\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9047 - val_loss: 11.1396\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6805 - val_loss: 9.9420\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5508 - val_loss: 10.1041\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7722 - val_loss: 10.6099\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5825 - val_loss: 10.0582\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9956 - val_loss: 10.2409\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1164 - val_loss: 11.8108\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1678 - val_loss: 10.3367\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4210 - val_loss: 10.0621\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4239 - val_loss: 10.5387\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6876 - val_loss: 11.0343\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6588 - val_loss: 10.7160\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0588 - val_loss: 10.2323\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6079 - val_loss: 10.4257\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0376 - val_loss: 10.2404\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5033 - val_loss: 10.1135\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6339 - val_loss: 10.8966\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9618 - val_loss: 10.1233\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4243 - val_loss: 9.8792\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.5955 - val_loss: 10.4833\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6269 - val_loss: 11.0855\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8499 - val_loss: 10.1547\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3211 - val_loss: 10.2300\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2866 - val_loss: 9.7943\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8718 - val_loss: 9.8708\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6621 - val_loss: 10.9374\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9582 - val_loss: 10.6892\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7294 - val_loss: 10.4648\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8076 - val_loss: 9.8536\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9071 - val_loss: 9.8107\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4360 - val_loss: 9.6246\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7550 - val_loss: 9.8546\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5328 - val_loss: 9.8310\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6943 - val_loss: 9.6021\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8929 - val_loss: 10.3084\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0938 - val_loss: 10.9969\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9789 - val_loss: 10.5138\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8611 - val_loss: 10.2016\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8777 - val_loss: 10.5042\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0494 - val_loss: 10.1709\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7088 - val_loss: 9.7034\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6705 - val_loss: 11.0943\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7379 - val_loss: 10.6227\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5516 - val_loss: 10.4545\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8418 - val_loss: 10.6415\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3776 - val_loss: 10.0201\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7319 - val_loss: 10.8859\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7237 - val_loss: 9.7220\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4048 - val_loss: 9.8180\n",
      "Epoch 975/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5234 - val_loss: 10.8772\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8712 - val_loss: 11.7992\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3013 - val_loss: 10.0362\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1607 - val_loss: 10.3723\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6772 - val_loss: 10.4805\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6524 - val_loss: 11.3664\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7131 - val_loss: 10.2985\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6030 - val_loss: 9.9162\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0983 - val_loss: 10.1898\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5781 - val_loss: 13.7459\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3631 - val_loss: 9.7026\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5922 - val_loss: 9.6504\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7310 - val_loss: 9.7780\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6487 - val_loss: 9.5384\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9226 - val_loss: 10.2429\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1129 - val_loss: 10.2390\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4320 - val_loss: 10.2532\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8178 - val_loss: 9.5213\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3516 - val_loss: 9.7274\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5141 - val_loss: 9.9654\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6087 - val_loss: 12.8915\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3539 - val_loss: 10.3363\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8458 - val_loss: 11.3861\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5707 - val_loss: 11.8689\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8703 - val_loss: 9.6237\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7380 - val_loss: 10.3815\n",
      "8.591126320900115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-4.1505246 ,  0.15476568,  4.1660204 ,  1.3145167 , -1.4364762 ],\n",
       "        [ 0.3391187 ,  0.25200796, -0.06585328,  0.115622  ,  0.3018943 ],\n",
       "        [-0.707991  ,  0.36330968, -0.10965822,  0.35833016,  0.2306936 ],\n",
       "        [ 0.17200775, -0.0794817 , -0.08613301, -0.14420195,  0.05515834],\n",
       "        [-0.40839565,  0.2017554 ,  2.2008257 ,  0.968707  , -0.16303156]],\n",
       "       dtype=float32),\n",
       " array([-5.1657286 ,  0.29125994,  5.534727  ,  2.6142447 , -1.1628367 ],\n",
       "       dtype=float32),\n",
       " array([[-1.0954572 ,  1.8518851 , -1.8723832 , -2.4609966 ,  1.891905  ,\n",
       "         -1.953476  ,  2.224686  ,  2.453822  ,  1.60024   ,  1.8109215 ],\n",
       "        [-1.3287536 ,  1.0080909 , -1.3975655 , -1.2597661 ,  0.62724495,\n",
       "         -1.3384815 ,  0.7788654 ,  0.647432  ,  0.6210419 ,  1.3702668 ],\n",
       "        [ 0.8276924 , -1.39233   ,  2.1468153 ,  1.6171973 , -1.8247293 ,\n",
       "          1.935787  , -1.4345741 , -2.1272771 , -2.1461022 , -1.7483677 ],\n",
       "        [ 0.50650924, -1.1015131 ,  1.5892018 ,  1.0955733 , -1.1793468 ,\n",
       "          0.7879006 , -1.5800036 , -1.4884565 , -1.839252  , -1.5924298 ],\n",
       "        [ 0.19060254, -0.5675068 ,  0.8947972 ,  0.914755  , -1.0598742 ,\n",
       "          0.521731  , -1.1840683 , -0.77034944, -0.96533275, -0.3927517 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.9528831, -2.2594683,  2.319437 ,  2.3171413, -2.27565  ,\n",
       "         2.2709315, -2.3249555, -2.321653 , -2.2954082, -2.2564266],\n",
       "       dtype=float32),\n",
       " array([[ 0.9955365],\n",
       "        [-1.7390244],\n",
       "        [ 2.2052345],\n",
       "        [ 2.147931 ],\n",
       "        [-1.805022 ],\n",
       "        [ 1.8291739],\n",
       "        [-2.2067068],\n",
       "        [-2.225374 ],\n",
       "        [-1.9766074],\n",
       "        [-1.7515997]], dtype=float32),\n",
       " array([2.487163], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_2(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure2_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 136\n",
      "Trainable params: 136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 212us/step - loss: 7059.1027 - val_loss: 358.4551\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 203.0925 - val_loss: 80.6328\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 55.1009 - val_loss: 45.5387\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 33.8956 - val_loss: 35.7198\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 28.3883 - val_loss: 31.4678\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 24.9294 - val_loss: 29.4825\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.5140 - val_loss: 28.5949\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4477 - val_loss: 27.7928\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5916 - val_loss: 27.7089\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.0252 - val_loss: 26.5091\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.7750 - val_loss: 26.4700\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.2101 - val_loss: 25.8519\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.8370 - val_loss: 26.5144\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.1179 - val_loss: 27.0617\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.3076 - val_loss: 25.2915\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1582 - val_loss: 25.5419\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 19.2552 - val_loss: 24.4037\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.8515 - val_loss: 25.1445\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.9768 - val_loss: 25.1729\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7191 - val_loss: 24.8546\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.5181 - val_loss: 24.6543\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5777 - val_loss: 24.8767\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5492 - val_loss: 24.2865\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4139 - val_loss: 24.1596\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3343 - val_loss: 23.9246\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5924 - val_loss: 23.5355\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0865 - val_loss: 23.9670\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1638 - val_loss: 23.5442\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0408 - val_loss: 23.4183\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1891 - val_loss: 23.1113\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9958 - val_loss: 23.3741\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.4331 - val_loss: 23.3427\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9230 - val_loss: 23.1275\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7373 - val_loss: 22.8258\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8003 - val_loss: 22.2912\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9218 - val_loss: 23.5126\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6488 - val_loss: 22.6634\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8551 - val_loss: 22.4188\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4975 - val_loss: 21.7357\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3973 - val_loss: 21.5264\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5730 - val_loss: 21.6569\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2420 - val_loss: 21.6511\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3685 - val_loss: 21.2975\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2775 - val_loss: 22.7900\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1851 - val_loss: 20.7327\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5366 - val_loss: 20.8706\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0959 - val_loss: 21.4583\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0482 - val_loss: 20.3949\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0582 - val_loss: 20.5110\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.5925 - val_loss: 20.3993\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.9839 - val_loss: 20.6944\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4559 - val_loss: 21.0463\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5030 - val_loss: 19.6202\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.2647 - val_loss: 19.4838\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.3456 - val_loss: 19.4333\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.1852 - val_loss: 19.0284\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.2810 - val_loss: 19.7235\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.9808 - val_loss: 19.2140\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.2200 - val_loss: 19.5092\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.9239 - val_loss: 20.0333\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.7714 - val_loss: 18.8338\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.0329 - val_loss: 18.8736\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.8952 - val_loss: 18.7008\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.8479 - val_loss: 19.5686\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.3737 - val_loss: 18.6611\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6565 - val_loss: 18.1438\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.1999 - val_loss: 19.2733\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 15.4067 - val_loss: 19.0220\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.4535 - val_loss: 18.4699\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.3069 - val_loss: 18.5459\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.0496 - val_loss: 19.2589\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 15.1918 - val_loss: 19.6996\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 15.1390 - val_loss: 18.7794\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.0921 - val_loss: 17.9556\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0470 - val_loss: 19.3717\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.9885 - val_loss: 18.1548\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6235 - val_loss: 18.2739\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5790 - val_loss: 17.8616\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8798 - val_loss: 18.0784\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.7470 - val_loss: 18.4666\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.9135 - val_loss: 17.5338\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.0543 - val_loss: 17.5041\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4316 - val_loss: 18.3288\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 14.57 - 0s 86us/step - loss: 15.0386 - val_loss: 17.2889\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2283 - val_loss: 17.5588\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4214 - val_loss: 18.1549\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.5132 - val_loss: 17.3308\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3577 - val_loss: 18.2883\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3357 - val_loss: 19.2396\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2103 - val_loss: 17.7732\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8862 - val_loss: 16.7281\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.7811 - val_loss: 18.4746\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1532 - val_loss: 16.7321\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.6056 - val_loss: 17.8049\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3634 - val_loss: 16.9934\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3366 - val_loss: 17.7419\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9714 - val_loss: 17.4251\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7743 - val_loss: 19.7342\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6342 - val_loss: 17.1195\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7123 - val_loss: 18.0149\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5205 - val_loss: 16.6994\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6070 - val_loss: 17.5546\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6333 - val_loss: 17.3438\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.9577 - val_loss: 16.0821\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.6005 - val_loss: 17.1015\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.4656 - val_loss: 17.8803\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.7422 - val_loss: 16.5915\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.2627 - val_loss: 17.1814\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.5437 - val_loss: 18.4320\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.3375 - val_loss: 16.8133\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7596 - val_loss: 16.9226\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.8977 - val_loss: 18.1551\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.1298 - val_loss: 16.9126\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8175 - val_loss: 15.8991\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.9895 - val_loss: 21.2489\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.0187 - val_loss: 15.6860\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5715 - val_loss: 16.1503\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7327 - val_loss: 16.1013\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.3612 - val_loss: 15.3182\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.6595 - val_loss: 17.2934\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.8983 - val_loss: 15.4785\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7461 - val_loss: 15.5344\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2308 - val_loss: 15.5979\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.3026 - val_loss: 15.0198\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4392 - val_loss: 16.0248\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4430 - val_loss: 15.1005\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5664 - val_loss: 16.6904\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6581 - val_loss: 15.2171\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2577 - val_loss: 15.8858\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5290 - val_loss: 19.6361\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.4871 - val_loss: 15.9058\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1428 - val_loss: 16.1246\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9565 - val_loss: 15.6553\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2965 - val_loss: 16.6276\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6913 - val_loss: 14.9905\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.9920 - val_loss: 15.2664\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.7143 - val_loss: 15.1574\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0372 - val_loss: 14.7384\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 12.8695 - val_loss: 15.1701\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.2761 - val_loss: 14.7359\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.5396 - val_loss: 16.4949\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9948 - val_loss: 14.8406\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9344 - val_loss: 13.6515\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.6640 - val_loss: 15.1842\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8228 - val_loss: 14.7216\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 11.9990 - val_loss: 15.3657\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 10.9637 - val_loss: 14.8973\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 10.5466 - val_loss: 14.0157\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 10.7552 - val_loss: 15.0306\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 11.4357 - val_loss: 13.4375\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 11.2139 - val_loss: 16.6123\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8755 - val_loss: 17.0062\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4322 - val_loss: 14.4869\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.6514 - val_loss: 13.1539\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5265 - val_loss: 14.7861\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4355 - val_loss: 14.3292\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.3009 - val_loss: 13.2871\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.3232 - val_loss: 14.5866\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7869 - val_loss: 12.3015\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1889 - val_loss: 13.2499\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.6296 - val_loss: 13.8075\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4912 - val_loss: 12.3915\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.7830 - val_loss: 13.1083\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.6481 - val_loss: 12.6107\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 10.5852 - val_loss: 13.6456\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 10.0518 - val_loss: 13.8692\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 10.9203 - val_loss: 11.9484\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 10.2758 - val_loss: 11.5298\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.2606 - val_loss: 12.6855\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 10.7080 - val_loss: 13.8292\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.7739 - val_loss: 14.8484\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.3824 - val_loss: 11.7854\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0640 - val_loss: 11.5783\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8221 - val_loss: 11.9260\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7973 - val_loss: 13.0040\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9143 - val_loss: 11.6813\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.8556 - val_loss: 12.6249\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6997 - val_loss: 11.9048\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3214 - val_loss: 11.8069\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3614 - val_loss: 11.6388\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0480 - val_loss: 12.1445\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8213 - val_loss: 11.4897\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5068 - val_loss: 11.6848\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0331 - val_loss: 11.5351\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6427 - val_loss: 11.7940\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4426 - val_loss: 11.8013\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4319 - val_loss: 13.0981\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8708 - val_loss: 11.0968\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5044 - val_loss: 11.8272\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5036 - val_loss: 11.2787\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6332 - val_loss: 12.0497\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.7593 - val_loss: 11.1208\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2807 - val_loss: 11.7041\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4932 - val_loss: 14.0507\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4282 - val_loss: 12.4952\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1142 - val_loss: 11.7176\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2311 - val_loss: 11.3544\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9078 - val_loss: 11.5278\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5427 - val_loss: 11.7849\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4425 - val_loss: 14.4400\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1310 - val_loss: 11.0561\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1972 - val_loss: 11.3088\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3243 - val_loss: 11.2899\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3338 - val_loss: 12.2281\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1962 - val_loss: 11.9027\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5815 - val_loss: 11.5701\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3998 - val_loss: 11.1811\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0026 - val_loss: 10.9375\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6177 - val_loss: 11.8853\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3928 - val_loss: 10.7710\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1644 - val_loss: 11.8012\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4250 - val_loss: 12.6006\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0983 - val_loss: 10.8325\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1470 - val_loss: 11.0071\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0572 - val_loss: 11.1848\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8193 - val_loss: 12.3567\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9995 - val_loss: 11.7478\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4595 - val_loss: 11.5144\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8039 - val_loss: 10.8337\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2392 - val_loss: 11.4192\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3212 - val_loss: 10.6455\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8058 - val_loss: 11.6072\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8115 - val_loss: 11.9838\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2250 - val_loss: 10.8308\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.7295 - val_loss: 11.5613\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 137us/step - loss: 8.9702 - val_loss: 10.8232\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 126us/step - loss: 9.1037 - val_loss: 10.9245\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.1105 - val_loss: 10.4389\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.7863 - val_loss: 14.1863\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2236 - val_loss: 11.4510\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2152 - val_loss: 10.3462\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0519 - val_loss: 10.7871\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8698 - val_loss: 11.0325\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8089 - val_loss: 10.9154\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2162 - val_loss: 11.9465\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0219 - val_loss: 13.0350\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9929 - val_loss: 10.5208\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1126 - val_loss: 10.2434\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1489 - val_loss: 10.9017\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1440 - val_loss: 10.7528\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.0130 - val_loss: 10.2241\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.8893 - val_loss: 10.7787\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 9.3781 - val_loss: 11.1614\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8782 - val_loss: 10.7786\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 9.0997 - val_loss: 10.8578\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.8308 - val_loss: 10.4328\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7899 - val_loss: 10.5536\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 10.0493 - val_loss: 10.2904\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8454 - val_loss: 10.7538\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.8808 - val_loss: 10.8977\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.3491 - val_loss: 11.5931\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0955 - val_loss: 10.6458\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8664 - val_loss: 13.1584\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.3192 - val_loss: 10.1411\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.3612 - val_loss: 10.4422\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6381 - val_loss: 10.1270\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2874 - val_loss: 11.8923\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6769 - val_loss: 10.4271\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8659 - val_loss: 11.0631\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2623 - val_loss: 10.6358\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5540 - val_loss: 10.5119\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9566 - val_loss: 11.0718\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2658 - val_loss: 10.6790\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7309 - val_loss: 13.9634\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9452 - val_loss: 9.9644\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.6562 - val_loss: 11.0323\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.8804 - val_loss: 10.3824\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7317 - val_loss: 10.6242\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.7297 - val_loss: 11.0123\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.9129 - val_loss: 12.3127\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.3676 - val_loss: 10.2968\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.6722 - val_loss: 10.5632\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4496 - val_loss: 11.0238\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.5595 - val_loss: 12.3452\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.8595 - val_loss: 10.8319\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 147us/step - loss: 8.7193 - val_loss: 11.0236\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 8.9399 - val_loss: 12.1363\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.973 - 0s 103us/step - loss: 8.9329 - val_loss: 11.0509\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0888 - val_loss: 10.0811\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4937 - val_loss: 10.0558\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4329 - val_loss: 10.2095\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7880 - val_loss: 11.6808\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8187 - val_loss: 10.9311\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7241 - val_loss: 10.5786\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7209 - val_loss: 12.6994\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0357 - val_loss: 10.4578\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7773 - val_loss: 10.9817\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7286 - val_loss: 9.9761\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4113 - val_loss: 10.2417\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5088 - val_loss: 10.3750\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.6098 - val_loss: 10.6592\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7062 - val_loss: 10.8857\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.9418 - val_loss: 10.1524\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1133 - val_loss: 10.6598\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5492 - val_loss: 10.2595\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.3844 - val_loss: 11.7974\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9574 - val_loss: 10.8073\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.7639 - val_loss: 12.1574\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.8587 - val_loss: 9.8597\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.8057 - val_loss: 10.0718\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7058 - val_loss: 10.4617\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.1738 - val_loss: 10.1014\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.7495 - val_loss: 10.1651\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6682 - val_loss: 10.0412\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3874 - val_loss: 11.8218\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6940 - val_loss: 11.2593\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1096 - val_loss: 11.8561\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8313 - val_loss: 10.1833\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0156 - val_loss: 12.1040\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8983 - val_loss: 10.5119\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4530 - val_loss: 11.4383\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3886 - val_loss: 9.8603\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5827 - val_loss: 9.6713\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3678 - val_loss: 10.3502\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4561 - val_loss: 10.3543\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3465 - val_loss: 11.8387\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.1762 - val_loss: 10.4457\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9354 - val_loss: 10.2569\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0594 - val_loss: 10.8087\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.0274 - val_loss: 11.8528\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7988 - val_loss: 10.7014\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4578 - val_loss: 9.6328\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4383 - val_loss: 10.0716\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4280 - val_loss: 10.6873\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5759 - val_loss: 10.0570\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6032 - val_loss: 11.0648\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8822 - val_loss: 11.5701\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3676 - val_loss: 10.2481\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.5067 - val_loss: 10.2875\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.5254 - val_loss: 10.3430\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.7039 - val_loss: 12.7086\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.2968 - val_loss: 10.0268\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6285 - val_loss: 10.2828\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3786 - val_loss: 10.1218\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3644 - val_loss: 10.0983\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6587 - val_loss: 10.8850\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0903 - val_loss: 10.2745\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8884 - val_loss: 9.8953\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.5130 - val_loss: 9.7849\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4206 - val_loss: 9.7592\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6951 - val_loss: 9.9731\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2742 - val_loss: 11.8852\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7728 - val_loss: 10.2383\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7232 - val_loss: 9.8885\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6191 - val_loss: 10.7837\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6758 - val_loss: 10.0043\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7397 - val_loss: 10.9075\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.0307 - val_loss: 10.5385\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7983 - val_loss: 9.7500\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.7881 - val_loss: 10.0040\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.6190 - val_loss: 10.1943\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.9421 - val_loss: 13.2624\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4284 - val_loss: 11.1625\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4215 - val_loss: 10.3067\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6124 - val_loss: 10.4253\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8592 - val_loss: 9.9159\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7644 - val_loss: 10.1214\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.4800 - val_loss: 9.8435\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5578 - val_loss: 9.9574\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4850 - val_loss: 10.5053\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0948 - val_loss: 10.3545\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.6583 - val_loss: 10.6551\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 131us/step - loss: 8.7420 - val_loss: 10.0186\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.3833 - val_loss: 10.5479\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4865 - val_loss: 10.5396\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.9272 - val_loss: 9.9417\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.3836 - val_loss: 10.5797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8485 - val_loss: 9.5505\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6949 - val_loss: 11.0238\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.1732 - val_loss: 10.6767\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.7308 - val_loss: 10.0783\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4544 - val_loss: 10.6555\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4745 - val_loss: 11.4818\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6548 - val_loss: 12.1804\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4994 - val_loss: 10.5669\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6503 - val_loss: 10.6844\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7801 - val_loss: 10.6120\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2132 - val_loss: 10.0083\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1814 - val_loss: 10.5495\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1786 - val_loss: 10.1422\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5579 - val_loss: 9.6134\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3820 - val_loss: 10.1419\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4540 - val_loss: 11.7797\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4558 - val_loss: 9.6737\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6813 - val_loss: 10.4505\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5615 - val_loss: 11.1929\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 8.5910 - val_loss: 9.8320\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5288 - val_loss: 9.3582\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3754 - val_loss: 10.5017\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 9.0094 - val_loss: 9.7842\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.8912 - val_loss: 10.0704\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.3387 - val_loss: 11.3962\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7258 - val_loss: 10.2156\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5112 - val_loss: 10.5513\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5007 - val_loss: 10.3338\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5570 - val_loss: 10.0426\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9285 - val_loss: 9.7586\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4766 - val_loss: 11.7511\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3384 - val_loss: 10.5236\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7810 - val_loss: 10.1780\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8462 - val_loss: 9.7694\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6417 - val_loss: 10.3954\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4799 - val_loss: 9.5760\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4468 - val_loss: 10.6249\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2262 - val_loss: 9.6656\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2691 - val_loss: 9.2897\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1792 - val_loss: 9.6044\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2139 - val_loss: 9.8017\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3880 - val_loss: 9.6975\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9351 - val_loss: 10.3221\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0148 - val_loss: 9.9299\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4005 - val_loss: 9.6497\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.3347 - val_loss: 11.1705\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4214 - val_loss: 11.0836\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2020 - val_loss: 10.2275\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3973 - val_loss: 9.8219\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1482 - val_loss: 9.7377\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4268 - val_loss: 9.4370\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7336 - val_loss: 12.3832\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7755 - val_loss: 10.5324\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3209 - val_loss: 9.5116\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4220 - val_loss: 10.0934\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.5746 - val_loss: 10.4210\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9688 - val_loss: 11.1921\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.6794 - val_loss: 9.4207\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1235 - val_loss: 10.3125\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1701 - val_loss: 9.5144\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.1139 - val_loss: 9.4246\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7357 - val_loss: 9.8879\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3634 - val_loss: 10.6004\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0564 - val_loss: 10.6267\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2738 - val_loss: 10.9235\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4690 - val_loss: 9.5148\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1570 - val_loss: 10.1863\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5994 - val_loss: 11.0702\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7165 - val_loss: 10.0987\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5036 - val_loss: 9.9821\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2656 - val_loss: 9.5300\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6082 - val_loss: 10.2594\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4708 - val_loss: 9.4010\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3849 - val_loss: 10.9562\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.5694 - val_loss: 11.9087\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3160 - val_loss: 9.3197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1629 - val_loss: 9.4447\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1337 - val_loss: 10.6800\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6559 - val_loss: 9.7492\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5649 - val_loss: 10.5463\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3545 - val_loss: 10.1091\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7244 - val_loss: 9.6219\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5358 - val_loss: 9.3921\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5051 - val_loss: 9.7637\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.4037 - val_loss: 10.0208\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4986 - val_loss: 11.0403\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3024 - val_loss: 9.5691\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3573 - val_loss: 10.6910\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.6916 - val_loss: 10.6446\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6405 - val_loss: 9.1091\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5161 - val_loss: 9.5353\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6035 - val_loss: 9.8041\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3280 - val_loss: 9.5223\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7095 - val_loss: 10.3041\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3218 - val_loss: 9.7401\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4626 - val_loss: 9.7233\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5430 - val_loss: 10.4015\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.410 - 0s 87us/step - loss: 8.3519 - val_loss: 10.6616\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0230 - val_loss: 11.1103\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4520 - val_loss: 10.2004\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3086 - val_loss: 10.6029\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5093 - val_loss: 9.2196\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4660 - val_loss: 9.8666\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9187 - val_loss: 10.5805\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2476 - val_loss: 10.0858\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4255 - val_loss: 10.7095\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2260 - val_loss: 9.2524\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4781 - val_loss: 9.4775\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4893 - val_loss: 9.8653\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4785 - val_loss: 9.5342\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1698 - val_loss: 9.1194\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3815 - val_loss: 9.5384\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5355 - val_loss: 10.6099\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3773 - val_loss: 9.3367\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8707 - val_loss: 10.0136\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8034 - val_loss: 9.6288\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5609 - val_loss: 10.7341\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1450 - val_loss: 10.2685\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5731 - val_loss: 9.9290\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3260 - val_loss: 10.2224\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2683 - val_loss: 9.2585\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5436 - val_loss: 10.4501\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5923 - val_loss: 11.0596\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4790 - val_loss: 11.8224\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5092 - val_loss: 10.1713\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1921 - val_loss: 10.4971\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7512 - val_loss: 10.8761\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5808 - val_loss: 10.5561\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6801 - val_loss: 9.8760\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8630 - val_loss: 9.2538\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5400 - val_loss: 9.1615\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4401 - val_loss: 10.9561\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5501 - val_loss: 9.6103\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9714 - val_loss: 9.2383\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2289 - val_loss: 9.3089\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8739 - val_loss: 12.3856\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8058 - val_loss: 10.0095\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2174 - val_loss: 10.5276\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4308 - val_loss: 10.0536\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2294 - val_loss: 9.3307\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1859 - val_loss: 9.3299\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1579 - val_loss: 9.0609\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6330 - val_loss: 9.6337\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3128 - val_loss: 9.3078\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3811 - val_loss: 9.1429\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2150 - val_loss: 9.5141\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3686 - val_loss: 10.5763\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2463 - val_loss: 9.3032\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5475 - val_loss: 9.2887\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3598 - val_loss: 9.1060\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5771 - val_loss: 9.4400\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0838 - val_loss: 9.1836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0971 - val_loss: 10.4467\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9850 - val_loss: 10.6194\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6496 - val_loss: 10.2920\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7724 - val_loss: 10.7903\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0135 - val_loss: 9.7904\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3362 - val_loss: 9.6644\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1666 - val_loss: 9.2770\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7649 - val_loss: 11.6987\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6591 - val_loss: 9.3214\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0883 - val_loss: 9.9775\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4507 - val_loss: 9.3968\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3765 - val_loss: 11.1604\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2708 - val_loss: 9.4807\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2828 - val_loss: 10.6042\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2777 - val_loss: 9.7081\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1841 - val_loss: 10.3115\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 135us/step - loss: 8.2917 - val_loss: 11.3964\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.5207 - val_loss: 11.1794\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2179 - val_loss: 11.0178\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2321 - val_loss: 10.2484\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1022 - val_loss: 9.4413\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0950 - val_loss: 9.9151\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4159 - val_loss: 9.8895\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4171 - val_loss: 9.3563\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1646 - val_loss: 10.1463\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2417 - val_loss: 9.1826\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8244 - val_loss: 10.0957\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2485 - val_loss: 10.3886\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5310 - val_loss: 10.1370\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7717 - val_loss: 9.3883\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5167 - val_loss: 10.3667\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2363 - val_loss: 10.0432\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5689 - val_loss: 10.9837\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2127 - val_loss: 9.5504\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4941 - val_loss: 9.9715\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5565 - val_loss: 10.8219\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4142 - val_loss: 9.1457\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5390 - val_loss: 9.1130\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3346 - val_loss: 9.3116\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3001 - val_loss: 9.0466\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4509 - val_loss: 8.8886\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4516 - val_loss: 9.1469\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0551 - val_loss: 9.4273\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1726 - val_loss: 9.2937\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3208 - val_loss: 10.2520\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1457 - val_loss: 9.3207\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0762 - val_loss: 11.1551\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6467 - val_loss: 10.3930\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9466 - val_loss: 9.4910\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2432 - val_loss: 9.2933\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4051 - val_loss: 11.3385\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1512 - val_loss: 9.2044\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1816 - val_loss: 9.5662\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8607 - val_loss: 11.6445\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3501 - val_loss: 9.2462\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9879 - val_loss: 9.3445\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3704 - val_loss: 10.7545\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5036 - val_loss: 9.5589\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2907 - val_loss: 11.8312\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0842 - val_loss: 9.0798\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2518 - val_loss: 10.2327\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3747 - val_loss: 9.4136\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7282 - val_loss: 10.1860\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1817 - val_loss: 10.9995\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0610 - val_loss: 9.0831\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2383 - val_loss: 10.4329\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1420 - val_loss: 9.1764\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6277 - val_loss: 10.1641\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1855 - val_loss: 9.5204\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5788 - val_loss: 10.0809\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.6398 - val_loss: 9.3268\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0745 - val_loss: 9.5198\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2730 - val_loss: 9.6234\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7752 - val_loss: 9.0654\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.1242 - val_loss: 9.0928\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2642 - val_loss: 10.0919\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3750 - val_loss: 9.5244\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4036 - val_loss: 12.9614\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4126 - val_loss: 9.5758\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7285 - val_loss: 9.2601\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7632 - val_loss: 10.0235\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2002 - val_loss: 9.0643\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5908 - val_loss: 9.1134\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2486 - val_loss: 13.3718\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4276 - val_loss: 9.8087\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9510 - val_loss: 9.8024\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0131 - val_loss: 9.2241\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4588 - val_loss: 9.2859\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0870 - val_loss: 9.8241\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4606 - val_loss: 10.4295\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1705 - val_loss: 9.2018\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0145 - val_loss: 9.5939\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8266 - val_loss: 10.3432\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0316 - val_loss: 9.6001\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1538 - val_loss: 9.7932\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0969 - val_loss: 9.9376\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1769 - val_loss: 10.2819\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8210 - val_loss: 8.9402\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9621 - val_loss: 9.3197\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2739 - val_loss: 9.4474\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2032 - val_loss: 9.2841\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2761 - val_loss: 9.2620\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3663 - val_loss: 11.1838\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3028 - val_loss: 9.4777\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0394 - val_loss: 9.0032\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4964 - val_loss: 9.3430\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2931 - val_loss: 9.5336\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2939 - val_loss: 9.0534\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4960 - val_loss: 9.1198\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4636 - val_loss: 9.3148\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7055 - val_loss: 9.1557\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4112 - val_loss: 9.3044\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1342 - val_loss: 9.2627\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0981 - val_loss: 11.0808\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0370 - val_loss: 10.0624\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2686 - val_loss: 9.1313\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3188 - val_loss: 10.9444\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0961 - val_loss: 9.2166\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3865 - val_loss: 9.2699\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6968 - val_loss: 9.6153\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2522 - val_loss: 10.9255\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3540 - val_loss: 9.3016\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3043 - val_loss: 10.2084\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2048 - val_loss: 9.5439\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1607 - val_loss: 9.5320\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1068 - val_loss: 9.1470\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9766 - val_loss: 9.6963\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6638 - val_loss: 11.6695\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2316 - val_loss: 8.8139\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1113 - val_loss: 9.6940\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2309 - val_loss: 9.5733\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3078 - val_loss: 9.0877\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1778 - val_loss: 9.8332\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2718 - val_loss: 8.8640\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1411 - val_loss: 13.4588\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7666 - val_loss: 10.4439\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5059 - val_loss: 9.8374\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0490 - val_loss: 8.9037\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4420 - val_loss: 9.4709\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9350 - val_loss: 9.5659\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8534 - val_loss: 9.1018\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3420 - val_loss: 8.7891\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1946 - val_loss: 10.4171\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1735 - val_loss: 9.7411\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0783 - val_loss: 10.1731\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2796 - val_loss: 9.8655\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9514 - val_loss: 9.0040\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8701 - val_loss: 9.1094\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9626 - val_loss: 9.3351\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7381 - val_loss: 9.7753\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4094 - val_loss: 9.5360\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0420 - val_loss: 9.0071\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1404 - val_loss: 8.8220\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4090 - val_loss: 9.2097\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0614 - val_loss: 8.8011\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3261 - val_loss: 9.3333\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0478 - val_loss: 9.0199\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2980 - val_loss: 9.1635\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9266 - val_loss: 8.8138\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1140 - val_loss: 8.9283\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0922 - val_loss: 9.2325\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2433 - val_loss: 10.6216\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1554 - val_loss: 9.9955\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2333 - val_loss: 9.5092\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8872 - val_loss: 9.9008\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1696 - val_loss: 8.5718\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9953 - val_loss: 9.2702\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2068 - val_loss: 9.0594\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9921 - val_loss: 8.8892\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4343 - val_loss: 9.3524\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8415 - val_loss: 9.3491\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7216 - val_loss: 8.8213\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9467 - val_loss: 9.4452\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3747 - val_loss: 8.6602\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4081 - val_loss: 9.3847\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3908 - val_loss: 9.4426\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9811 - val_loss: 8.6785\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1106 - val_loss: 9.1220\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7077 - val_loss: 8.7940\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2600 - val_loss: 8.6513\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1546 - val_loss: 8.6133\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1265 - val_loss: 8.5983\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4103 - val_loss: 11.5651\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2778 - val_loss: 10.1181\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3210 - val_loss: 10.5480\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1530 - val_loss: 10.3734\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2552 - val_loss: 8.8820\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7978 - val_loss: 9.2507\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7918 - val_loss: 9.9803\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0887 - val_loss: 9.1576\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0906 - val_loss: 9.1620\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9915 - val_loss: 8.5829\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9221 - val_loss: 8.7511\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1953 - val_loss: 9.3359\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0889 - val_loss: 10.3365\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3268 - val_loss: 8.8943\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0061 - val_loss: 9.1700\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7823 - val_loss: 8.7053\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8989 - val_loss: 8.6023\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9099 - val_loss: 8.9082\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9689 - val_loss: 9.6582\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8954 - val_loss: 10.4667\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0054 - val_loss: 8.6204\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1488 - val_loss: 9.1519\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9480 - val_loss: 9.6972\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0955 - val_loss: 8.8520\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7596 - val_loss: 8.6302\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1234 - val_loss: 10.8730\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2094 - val_loss: 9.0765\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2115 - val_loss: 8.7792\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0395 - val_loss: 9.8227\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4728 - val_loss: 10.4814\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0082 - val_loss: 8.7867\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0132 - val_loss: 8.9071\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0004 - val_loss: 9.4717\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2192 - val_loss: 8.8570\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5270 - val_loss: 8.9225\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8108 - val_loss: 9.6494\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1621 - val_loss: 11.2071\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6692 - val_loss: 14.1168\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6122 - val_loss: 9.2034\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9387 - val_loss: 8.6308\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9025 - val_loss: 10.1126\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7376 - val_loss: 9.3016\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1446 - val_loss: 9.1141\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1034 - val_loss: 9.3793\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0770 - val_loss: 9.4832\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9651 - val_loss: 11.9135\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5067 - val_loss: 9.0027\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0682 - val_loss: 9.6593\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8271 - val_loss: 9.0969\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4417 - val_loss: 9.4129\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0744 - val_loss: 8.5814\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7615 - val_loss: 8.5141\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0462 - val_loss: 8.6147\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8828 - val_loss: 9.1561\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0080 - val_loss: 9.4808\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8423 - val_loss: 10.9313\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3747 - val_loss: 9.1772\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9777 - val_loss: 9.0964\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0962 - val_loss: 9.1050\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0656 - val_loss: 9.0682\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7978 - val_loss: 8.6500\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5100 - val_loss: 9.7104\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.9869 - val_loss: 8.7376\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8014 - val_loss: 8.8343\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0389 - val_loss: 10.3525\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0835 - val_loss: 9.0431\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8131 - val_loss: 10.2785\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9332 - val_loss: 8.7707\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9197 - val_loss: 8.6378\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8534 - val_loss: 9.3655\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9847 - val_loss: 8.5395\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7290 - val_loss: 8.5383\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9274 - val_loss: 8.7753\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9903 - val_loss: 9.7438\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0966 - val_loss: 10.1661\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3230 - val_loss: 8.7545\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9707 - val_loss: 8.9684\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2059 - val_loss: 8.9831\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8697 - val_loss: 9.0993\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1793 - val_loss: 10.1650\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0442 - val_loss: 9.0703\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4825 - val_loss: 8.8328\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6662 - val_loss: 8.5695\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7421 - val_loss: 9.3201\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8829 - val_loss: 9.3561\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1386 - val_loss: 8.6638\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0777 - val_loss: 8.8093\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0671 - val_loss: 9.9508\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1528 - val_loss: 9.8198\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7053 - val_loss: 9.0883\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0214 - val_loss: 8.8758\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8122 - val_loss: 9.5361\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0358 - val_loss: 8.9641\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8903 - val_loss: 9.7522\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1005 - val_loss: 14.3134\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1468 - val_loss: 9.0638\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9565 - val_loss: 8.6490\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8340 - val_loss: 8.7539\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8074 - val_loss: 9.3336\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7294 - val_loss: 9.1793\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9943 - val_loss: 9.2294\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0488 - val_loss: 8.9315\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4277 - val_loss: 9.0933\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3709 - val_loss: 8.9366\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1603 - val_loss: 9.7016\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9555 - val_loss: 9.3043\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7843 - val_loss: 9.1830\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9806 - val_loss: 8.5556\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0675 - val_loss: 10.0103\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9459 - val_loss: 9.0199\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4984 - val_loss: 8.6160\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7936 - val_loss: 8.9289\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2980 - val_loss: 8.9715\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9571 - val_loss: 10.1103\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8948 - val_loss: 8.9449\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2291 - val_loss: 8.6689\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1660 - val_loss: 9.6278\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7466 - val_loss: 8.7333\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8370 - val_loss: 9.1311\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7889 - val_loss: 9.9716\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5274 - val_loss: 8.5189\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0097 - val_loss: 8.7226\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2721 - val_loss: 9.0789\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8888 - val_loss: 9.0883\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1332 - val_loss: 9.0228\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8449 - val_loss: 9.4141\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1363 - val_loss: 8.9675\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0437 - val_loss: 9.9646\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8997 - val_loss: 9.7236\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1689 - val_loss: 9.0821\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1240 - val_loss: 11.4596\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4157 - val_loss: 8.8393\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8626 - val_loss: 8.8440\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5200 - val_loss: 8.6285\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3992 - val_loss: 8.5573\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4915 - val_loss: 8.7251\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0045 - val_loss: 9.1417\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0272 - val_loss: 8.6368\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9404 - val_loss: 8.7556\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5117 - val_loss: 8.7117\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2609 - val_loss: 8.3353\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6857 - val_loss: 8.7971\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0546 - val_loss: 9.2453\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1815 - val_loss: 8.6230\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3179 - val_loss: 8.3844\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0167 - val_loss: 10.1730\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1556 - val_loss: 10.7572\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1827 - val_loss: 8.6001\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8571 - val_loss: 9.4968\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2056 - val_loss: 8.4527\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2137 - val_loss: 8.5363\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4049 - val_loss: 8.9593\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8682 - val_loss: 8.8430\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1055 - val_loss: 9.1208\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0893 - val_loss: 8.7131\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0825 - val_loss: 8.7110\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1601 - val_loss: 9.5442\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9858 - val_loss: 9.5700\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0333 - val_loss: 9.2366\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6320 - val_loss: 8.6917\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0512 - val_loss: 8.5347\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0614 - val_loss: 8.7774\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3762 - val_loss: 9.6925\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9828 - val_loss: 8.9888\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9515 - val_loss: 8.9692\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9044 - val_loss: 8.6670\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7846 - val_loss: 11.1963\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5428 - val_loss: 8.7134\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0540 - val_loss: 8.6495\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7176 - val_loss: 8.8625\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2535 - val_loss: 8.6712\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0099 - val_loss: 8.3166\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8972 - val_loss: 8.5283\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8425 - val_loss: 8.6734\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9486 - val_loss: 10.1710\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0267 - val_loss: 8.4249\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8208 - val_loss: 8.8896\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7599 - val_loss: 9.4414\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3088 - val_loss: 12.3465\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7485 - val_loss: 8.9474\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3130 - val_loss: 9.3374\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8280 - val_loss: 11.0340\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5036 - val_loss: 9.4439\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3762 - val_loss: 8.9804\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2998 - val_loss: 8.7671\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4012 - val_loss: 9.0326\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2859 - val_loss: 9.0358\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4467 - val_loss: 8.7514\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9109 - val_loss: 9.0207\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8747 - val_loss: 9.5279\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7853 - val_loss: 9.1269\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7811 - val_loss: 8.4357\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9824 - val_loss: 9.0417\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7812 - val_loss: 8.7251\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9695 - val_loss: 8.7799\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8632 - val_loss: 8.7121\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0888 - val_loss: 8.4096\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1488 - val_loss: 9.2550\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2760 - val_loss: 8.7447\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0120 - val_loss: 8.8631\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3694 - val_loss: 11.4256\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3496 - val_loss: 8.8427\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1153 - val_loss: 8.6216\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2766 - val_loss: 8.6937\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4490 - val_loss: 8.8885\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0845 - val_loss: 9.7044\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4622 - val_loss: 10.8528\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9549 - val_loss: 8.9603\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9353 - val_loss: 9.5931\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9387 - val_loss: 8.4786\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7036 - val_loss: 9.0474\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2606 - val_loss: 10.2087\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9897 - val_loss: 9.3606\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9169 - val_loss: 8.5895\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4119 - val_loss: 9.4439\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4366 - val_loss: 8.9242\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0459 - val_loss: 9.1814\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9447 - val_loss: 8.6140\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0022 - val_loss: 9.4799\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1565 - val_loss: 8.5324\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2627 - val_loss: 9.0412\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1012 - val_loss: 9.4708\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1727 - val_loss: 9.5323\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9525 - val_loss: 8.6465\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4950 - val_loss: 9.7355\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8931 - val_loss: 8.5386\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3262 - val_loss: 8.9803\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9949 - val_loss: 9.2934\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7334 - val_loss: 9.7237\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8564 - val_loss: 8.8260\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8642 - val_loss: 8.4920\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0552 - val_loss: 9.0021\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0358 - val_loss: 8.6427\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0272 - val_loss: 8.4241\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9827 - val_loss: 8.8201\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0497 - val_loss: 9.3089\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.8409 - val_loss: 8.6962\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1195 - val_loss: 9.4424\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.7537 - val_loss: 9.0013\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0990 - val_loss: 8.5051\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.8226 - val_loss: 10.0663\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0898 - val_loss: 9.3626\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5685 - val_loss: 8.6912\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0602 - val_loss: 8.7093\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2383 - val_loss: 8.9245\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6327 - val_loss: 10.5267\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0519 - val_loss: 8.4984\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9772 - val_loss: 8.7692\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9088 - val_loss: 8.4322\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8885 - val_loss: 10.0805\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1142 - val_loss: 9.4281\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8526 - val_loss: 8.6479\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7963 - val_loss: 9.7766\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3409 - val_loss: 11.5248\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7625 - val_loss: 8.4253\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8899 - val_loss: 9.5707\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9365 - val_loss: 8.9178\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2257 - val_loss: 8.5235\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2321 - val_loss: 9.9171\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1382 - val_loss: 10.2576\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3169 - val_loss: 9.4308\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9859 - val_loss: 8.6869\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1743 - val_loss: 10.4515\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6958 - val_loss: 8.6894\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9287 - val_loss: 8.8601\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8974 - val_loss: 8.5680\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1156 - val_loss: 8.4084\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.203 - 0s 90us/step - loss: 7.8608 - val_loss: 9.1582\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0265 - val_loss: 11.6836\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3876 - val_loss: 8.9914\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0355 - val_loss: 8.4492\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0943 - val_loss: 11.3671\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5633 - val_loss: 9.1606\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2869 - val_loss: 9.7295\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9079 - val_loss: 8.6204\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1793 - val_loss: 9.8702\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8835 - val_loss: 8.8679\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8280 - val_loss: 8.5605\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0170 - val_loss: 9.7143\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8678 - val_loss: 9.0436\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9869 - val_loss: 9.7396\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8722 - val_loss: 8.9448\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9049 - val_loss: 8.8083\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4139 - val_loss: 8.8304\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1644 - val_loss: 10.5081\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0433 - val_loss: 8.8337\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.5706 - val_loss: 9.4658\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2540 - val_loss: 11.0292\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0042 - val_loss: 10.0522\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9233 - val_loss: 8.7476\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8050 - val_loss: 8.6047\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2377 - val_loss: 8.4440\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0673 - val_loss: 11.9057\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6013 - val_loss: 8.7422\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9618 - val_loss: 8.9779\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5071 - val_loss: 8.6618\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0139 - val_loss: 12.3765\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6687 - val_loss: 9.1942\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8630 - val_loss: 8.3987\n",
      "7.219736839817688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.85346943, -2.1789339 ,  0.29538095, -3.530977  ,  3.3994591 ],\n",
       "        [ 1.9697311 ,  0.4923424 ,  0.1959119 ,  0.1482339 , -0.0514848 ],\n",
       "        [ 2.4308016 ,  0.36377305,  0.42316145, -0.8372641 , -0.00640358],\n",
       "        [-0.41652805,  0.01712474, -0.18393423,  0.14243858, -0.05126983],\n",
       "        [-0.89154863, -0.29412702,  0.35875502, -0.27712104,  2.2884166 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.1832584, -1.3751085, -0.6532213, -4.5993385,  4.91756  ],\n",
       "       dtype=float32),\n",
       " array([[-0.2402981 ,  0.352329  , -0.30730477, -0.19603644,  0.53829145,\n",
       "          0.13814636,  0.6548321 ,  0.629318  , -0.05803755, -0.40725568,\n",
       "         -0.5868875 , -0.7142429 ,  0.2383918 ,  0.17176844,  0.10203674],\n",
       "        [ 0.0682101 , -0.7753987 ,  0.07264737, -0.772795  , -0.8039052 ,\n",
       "         -0.08553825, -0.5229733 , -0.3350849 ,  0.12042087,  0.48839143,\n",
       "          0.8573923 ,  0.7019924 ,  0.07577219,  0.44396344,  0.66432583],\n",
       "        [ 0.9489872 ,  0.6535794 ,  0.54525787,  0.6971635 ,  0.48511645,\n",
       "          0.20542733, -0.09340414,  0.7006364 ,  0.01485796, -0.87215364,\n",
       "         -0.26344904, -0.54826546, -0.4941304 , -0.48188746, -0.40829453],\n",
       "        [ 1.9378465 ,  1.7887768 ,  2.2908492 ,  2.1119883 ,  2.128664  ,\n",
       "          1.5028769 ,  1.2143438 ,  1.5924526 ,  1.8392437 , -1.417364  ,\n",
       "         -0.9764246 , -2.2529705 ,  1.2325085 , -1.9267083 , -1.2101119 ],\n",
       "        [-2.0425856 , -1.6846455 , -1.8598118 , -2.1951027 , -1.2585775 ,\n",
       "         -1.7406476 , -1.5459201 , -1.48297   , -1.1404998 ,  2.0428512 ,\n",
       "          0.9979734 ,  1.7902831 , -0.78443635,  1.0510789 ,  1.9332039 ]],\n",
       "       dtype=float32),\n",
       " array([-2.2423658, -2.2555957, -2.2381454, -2.2926462, -2.2315054,\n",
       "        -2.2162604, -2.1080446, -2.1968224, -2.0040452,  2.2057505,\n",
       "         1.9264977,  2.2734098, -1.8226335,  2.131407 ,  2.176262 ],\n",
       "       dtype=float32),\n",
       " array([[-1.813789  ],\n",
       "        [-1.8224744 ],\n",
       "        [-1.79471   ],\n",
       "        [-2.0861487 ],\n",
       "        [-1.6052766 ],\n",
       "        [-1.6109264 ],\n",
       "        [-1.2222719 ],\n",
       "        [-1.510287  ],\n",
       "        [-1.1597847 ],\n",
       "        [ 1.5147109 ],\n",
       "        [ 0.86633694],\n",
       "        [ 1.8978558 ],\n",
       "        [-0.81927496],\n",
       "        [ 1.3245242 ],\n",
       "        [ 1.411839  ]], dtype=float32),\n",
       " array([2.4581106], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_3(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure3_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 224us/step - loss: 8609.7787 - val_loss: 1047.5256\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 256.2732 - val_loss: 61.0380\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 42.9747 - val_loss: 31.5888\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 31.5942 - val_loss: 29.1740\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 28.7626 - val_loss: 27.8421\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 26.9784 - val_loss: 27.0882\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 25.9990 - val_loss: 26.9565\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 24.9830 - val_loss: 26.2144\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 24.2815 - val_loss: 26.2272\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.3836 - val_loss: 25.5928\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.7338 - val_loss: 25.4536\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0043 - val_loss: 25.6980\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.2972 - val_loss: 25.5359\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.7873 - val_loss: 26.0353\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.2665 - val_loss: 25.4627\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.9481 - val_loss: 25.7670\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.4693 - val_loss: 25.0961\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.4776 - val_loss: 25.2393\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0501 - val_loss: 24.9415\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.1476 - val_loss: 24.9703\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6628 - val_loss: 24.6226\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6206 - val_loss: 24.2490\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4742 - val_loss: 24.4045\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.4791 - val_loss: 24.0759\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6424 - val_loss: 24.0499\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3431 - val_loss: 24.0575\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1467 - val_loss: 23.8106\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1152 - val_loss: 23.7229\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1770 - val_loss: 23.6114\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.9764 - val_loss: 23.5133\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0932 - val_loss: 23.5542\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9973 - val_loss: 23.0726\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8188 - val_loss: 23.1002\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9611 - val_loss: 23.0450\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8394 - val_loss: 22.8886\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5230 - val_loss: 23.1010\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7609 - val_loss: 22.5063\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4701 - val_loss: 22.7270\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4320 - val_loss: 22.3202\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3886 - val_loss: 22.1039\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4883 - val_loss: 22.2556\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2758 - val_loss: 22.0629\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1737 - val_loss: 21.9848\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3187 - val_loss: 21.9636\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1242 - val_loss: 23.1592\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1936 - val_loss: 21.0612\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.9751 - val_loss: 20.9697\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.8941 - val_loss: 20.9560\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.7527 - val_loss: 20.5198\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.5985 - val_loss: 20.4304\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.3628 - val_loss: 20.2134\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7581 - val_loss: 20.5290\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.0462 - val_loss: 20.6002\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.1212 - val_loss: 19.5885\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.3686 - val_loss: 20.3890\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.0242 - val_loss: 19.3880\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.1478 - val_loss: 19.0343\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.0882 - val_loss: 18.3824\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7165 - val_loss: 18.1059\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5948 - val_loss: 18.1283\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4567 - val_loss: 18.3191\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3169 - val_loss: 17.6046\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1395 - val_loss: 17.6356\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8860 - val_loss: 17.7201\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6059 - val_loss: 17.2059\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7273 - val_loss: 17.3353\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.5054 - val_loss: 16.8570\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3930 - val_loss: 17.8513\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9452 - val_loss: 16.6790\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3012 - val_loss: 16.5872\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1164 - val_loss: 16.6363\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.0655 - val_loss: 16.6278\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.9508 - val_loss: 17.0794\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2706 - val_loss: 16.4417\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8294 - val_loss: 17.5029\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7290 - val_loss: 16.3507\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5770 - val_loss: 16.7685\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.7767 - val_loss: 17.4773\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7977 - val_loss: 16.8620\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7643 - val_loss: 16.0170\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8984 - val_loss: 16.0700\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8199 - val_loss: 15.9300\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.2444 - val_loss: 15.6091\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5009 - val_loss: 16.4701\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3449 - val_loss: 15.8333\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.3707 - val_loss: 15.8339\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3285 - val_loss: 15.5643\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3760 - val_loss: 15.4428\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0673 - val_loss: 15.0367\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2476 - val_loss: 15.6489\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3248 - val_loss: 15.7597\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9958 - val_loss: 16.2942\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5669 - val_loss: 16.1852\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5532 - val_loss: 15.1398\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0380 - val_loss: 16.0032\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0021 - val_loss: 15.6689\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9211 - val_loss: 17.7162\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7687 - val_loss: 15.3489\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5816 - val_loss: 14.5569\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.5506 - val_loss: 14.9031\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6959 - val_loss: 15.9695\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.1183 - val_loss: 15.2731\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.4819 - val_loss: 14.1542\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.6798 - val_loss: 15.3097\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.3941 - val_loss: 14.4609\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.2785 - val_loss: 14.2142\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.5739 - val_loss: 15.0403\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.6032 - val_loss: 14.0586\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.2270 - val_loss: 15.2682\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9915 - val_loss: 13.7396\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.0184 - val_loss: 14.0127\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1097 - val_loss: 15.1475\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3477 - val_loss: 13.7032\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.0604 - val_loss: 13.6315\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2384 - val_loss: 14.4354\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9737 - val_loss: 15.0627\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3312 - val_loss: 13.6405\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2180 - val_loss: 14.5044\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.8280 - val_loss: 13.1096\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.8706 - val_loss: 13.9085\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6474 - val_loss: 13.1002\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 125us/step - loss: 10.6882 - val_loss: 14.9278\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.9867 - val_loss: 13.7541\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.9051 - val_loss: 13.7849\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5888 - val_loss: 13.9657\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4156 - val_loss: 14.0526\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.7911 - val_loss: 13.1766\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.5213 - val_loss: 13.6539\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2731 - val_loss: 12.8283\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7854 - val_loss: 14.5297\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9946 - val_loss: 13.4577\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6969 - val_loss: 13.6397\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7745 - val_loss: 13.6101\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0417 - val_loss: 13.3008\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.8325 - val_loss: 12.6514\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7160 - val_loss: 12.8499\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9376 - val_loss: 12.8756\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4870 - val_loss: 12.7152\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7022 - val_loss: 12.8686\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0869 - val_loss: 13.4533\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0244 - val_loss: 12.8137\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4676 - val_loss: 12.2109\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2412 - val_loss: 12.5041\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9831 - val_loss: 13.1364\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0448 - val_loss: 12.3577\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3183 - val_loss: 13.2410\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0289 - val_loss: 13.2772\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9607 - val_loss: 12.2351\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7548 - val_loss: 11.7815\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9456 - val_loss: 12.4579\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6909 - val_loss: 12.6543\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1664 - val_loss: 13.5063\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8765 - val_loss: 12.9867\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2078 - val_loss: 11.6667\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3174 - val_loss: 11.4292\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5573 - val_loss: 11.2579\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8192 - val_loss: 12.7264\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.4570 - val_loss: 12.4913\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0352 - val_loss: 11.6670\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6678 - val_loss: 12.6844\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7207 - val_loss: 11.5867\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5597 - val_loss: 11.6196\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4634 - val_loss: 11.5374\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8879 - val_loss: 10.8962\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5939 - val_loss: 12.0900\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4832 - val_loss: 12.0971\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4245 - val_loss: 12.1644\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8310 - val_loss: 11.8067\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5676 - val_loss: 11.2393\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1627 - val_loss: 10.8853\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5859 - val_loss: 12.6738\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6169 - val_loss: 11.4530\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1455 - val_loss: 12.2955\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6297 - val_loss: 11.7476\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0954 - val_loss: 12.5182\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5391 - val_loss: 11.5046\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9380 - val_loss: 11.8102\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6525 - val_loss: 11.2044\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1221 - val_loss: 10.9296\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9513 - val_loss: 10.6040\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2080 - val_loss: 12.6237\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8991 - val_loss: 10.9770\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1285 - val_loss: 10.8424\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1044 - val_loss: 10.9749\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7042 - val_loss: 10.2328\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6784 - val_loss: 10.0903\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8179 - val_loss: 11.9452\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3307 - val_loss: 10.0953\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4317 - val_loss: 10.7547\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3618 - val_loss: 11.6997\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2138 - val_loss: 11.4726\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9801 - val_loss: 10.2699\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8159 - val_loss: 9.9194\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7982 - val_loss: 11.7098\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0986 - val_loss: 10.1021\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6103 - val_loss: 11.6818\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4961 - val_loss: 10.5463\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0329 - val_loss: 10.4081\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5790 - val_loss: 10.2637\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6892 - val_loss: 10.6524\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6633 - val_loss: 10.2066\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5877 - val_loss: 11.7369\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9996 - val_loss: 11.4695\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6458 - val_loss: 10.0383\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2913 - val_loss: 11.4464\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0697 - val_loss: 11.2542\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8841 - val_loss: 11.7879\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6862 - val_loss: 9.8455\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5088 - val_loss: 9.3470\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8620 - val_loss: 9.8706\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3401 - val_loss: 10.9196\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8816 - val_loss: 9.6503\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8850 - val_loss: 10.0717\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4812 - val_loss: 10.6662\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2797 - val_loss: 9.6281\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5019 - val_loss: 12.1967\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4937 - val_loss: 10.1393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4365 - val_loss: 10.0573\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1404 - val_loss: 11.2669\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8227 - val_loss: 9.1628\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3187 - val_loss: 9.5693\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7310 - val_loss: 11.1434\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6465 - val_loss: 10.1012\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1574 - val_loss: 10.0884\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4035 - val_loss: 10.2130\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3878 - val_loss: 9.6406\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6181 - val_loss: 10.0459\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6139 - val_loss: 11.3384\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1640 - val_loss: 9.5441\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5361 - val_loss: 9.5882\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3855 - val_loss: 9.2531\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8507 - val_loss: 9.4758\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6200 - val_loss: 9.7772\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4024 - val_loss: 9.3447\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2583 - val_loss: 9.5889\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8578 - val_loss: 10.2308\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4932 - val_loss: 10.8614\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4868 - val_loss: 9.6416\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2990 - val_loss: 9.1623\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5210 - val_loss: 10.1437\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3274 - val_loss: 10.0795\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3612 - val_loss: 11.7047\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1024 - val_loss: 10.5100\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3126 - val_loss: 9.2673\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5874 - val_loss: 10.3109\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5243 - val_loss: 9.5069\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6821 - val_loss: 10.7205\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8137 - val_loss: 9.3509\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3605 - val_loss: 9.1928\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3516 - val_loss: 11.4700\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6187 - val_loss: 9.1219\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3329 - val_loss: 9.7070\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6414 - val_loss: 9.0921\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4520 - val_loss: 12.3463\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8919 - val_loss: 12.1590\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4029 - val_loss: 9.4717\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2439 - val_loss: 9.0187\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6930 - val_loss: 10.7431\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3491 - val_loss: 9.7259\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3085 - val_loss: 9.8454\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9701 - val_loss: 10.2425\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3072 - val_loss: 9.6220\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4351 - val_loss: 9.7798\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0053 - val_loss: 9.1361\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8069 - val_loss: 9.4434\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4917 - val_loss: 9.6666\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4252 - val_loss: 10.1919\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2594 - val_loss: 9.4808\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9271 - val_loss: 9.4395\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9885 - val_loss: 9.7130\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1512 - val_loss: 10.2066\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0720 - val_loss: 10.7593\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5783 - val_loss: 10.6283\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.6253 - val_loss: 9.6381\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1813 - val_loss: 9.6778\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0690 - val_loss: 9.8371\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2165 - val_loss: 9.7527\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0776 - val_loss: 9.2415\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3351 - val_loss: 11.4229\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4347 - val_loss: 9.1900\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4901 - val_loss: 9.1275\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9882 - val_loss: 9.1610\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1627 - val_loss: 9.3760\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5258 - val_loss: 9.4451\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2080 - val_loss: 10.2129\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2007 - val_loss: 9.4727\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9333 - val_loss: 9.8047\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0235 - val_loss: 8.8430\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8827 - val_loss: 9.6481\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1719 - val_loss: 9.7488\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0351 - val_loss: 9.8222\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5046 - val_loss: 9.6725\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1433 - val_loss: 8.9478\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8806 - val_loss: 9.2674\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9079 - val_loss: 9.4845\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5423 - val_loss: 9.2115\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0796 - val_loss: 9.5188\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0921 - val_loss: 9.1477\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8328 - val_loss: 8.9186\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9036 - val_loss: 9.9877\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3051 - val_loss: 9.4868\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3451 - val_loss: 10.1945\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1844 - val_loss: 8.7680\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1237 - val_loss: 9.6957\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6986 - val_loss: 9.5077\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1096 - val_loss: 8.9289\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4872 - val_loss: 9.5462\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8675 - val_loss: 9.3127\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9793 - val_loss: 9.5279\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4655 - val_loss: 9.7193\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3275 - val_loss: 9.5792\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3421 - val_loss: 8.9146\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0871 - val_loss: 9.4486\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2400 - val_loss: 11.2755\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8053 - val_loss: 9.2040\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0406 - val_loss: 9.3189\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2170 - val_loss: 10.1935\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2864 - val_loss: 11.0747\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6079 - val_loss: 10.6445\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3702 - val_loss: 9.7580\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1913 - val_loss: 9.2756\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8705 - val_loss: 9.2720\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7812 - val_loss: 8.8394\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8517 - val_loss: 8.9168\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0936 - val_loss: 9.0633\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9320 - val_loss: 8.8536\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7387 - val_loss: 9.5825\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8504 - val_loss: 9.2949\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3505 - val_loss: 9.2517\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3071 - val_loss: 9.5118\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6784 - val_loss: 9.3415\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0264 - val_loss: 9.0025\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0714 - val_loss: 11.6479\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9972 - val_loss: 9.5618\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8984 - val_loss: 8.8589\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2570 - val_loss: 10.2512\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4865 - val_loss: 8.8197\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7573 - val_loss: 8.6811\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0886 - val_loss: 8.7289\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0238 - val_loss: 10.3884\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7355 - val_loss: 8.9624\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4663 - val_loss: 8.8092\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7152 - val_loss: 8.9818\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7619 - val_loss: 10.3343\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9256 - val_loss: 8.8252\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0896 - val_loss: 11.7079\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0703 - val_loss: 9.5362\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6515 - val_loss: 8.8936\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7963 - val_loss: 9.0785\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0213 - val_loss: 8.9709\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6662 - val_loss: 10.3005\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9648 - val_loss: 9.0606\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9908 - val_loss: 9.3050\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8453 - val_loss: 8.8206\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8726 - val_loss: 10.9433\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7973 - val_loss: 9.5058\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0361 - val_loss: 9.0214\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8390 - val_loss: 10.7149\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0586 - val_loss: 8.7462\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9573 - val_loss: 8.9910\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7826 - val_loss: 8.8116\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7051 - val_loss: 9.2410\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0155 - val_loss: 8.9304\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3094 - val_loss: 8.8318\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3774 - val_loss: 9.8696\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1978 - val_loss: 10.3495\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8331 - val_loss: 8.6177\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8599 - val_loss: 9.8346\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1090 - val_loss: 10.2611\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3102 - val_loss: 8.5600\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6140 - val_loss: 9.0143\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0569 - val_loss: 9.2112\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9059 - val_loss: 9.1115\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8310 - val_loss: 8.9175\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7812 - val_loss: 8.7262\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1701 - val_loss: 8.4176\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0569 - val_loss: 8.8111\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7295 - val_loss: 8.9212\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7144 - val_loss: 9.8513\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9538 - val_loss: 8.7737\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7793 - val_loss: 8.8471\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7216 - val_loss: 9.4333\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8516 - val_loss: 8.4103\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9138 - val_loss: 8.9571\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8235 - val_loss: 8.5827\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7523 - val_loss: 8.8267\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4448 - val_loss: 8.7950\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7860 - val_loss: 8.8964\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7816 - val_loss: 9.3572\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6931 - val_loss: 9.7525\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0430 - val_loss: 8.4546\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8562 - val_loss: 11.4221\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1934 - val_loss: 8.6056\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8217 - val_loss: 10.0975\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9125 - val_loss: 8.8665\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6972 - val_loss: 8.7610\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6041 - val_loss: 9.0577\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0935 - val_loss: 9.1629\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3336 - val_loss: 8.6768\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6314 - val_loss: 8.3249\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7472 - val_loss: 8.4457\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7331 - val_loss: 8.5945\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8161 - val_loss: 8.4323\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6175 - val_loss: 11.1276\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1961 - val_loss: 8.7242\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6897 - val_loss: 11.7148\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8781 - val_loss: 9.9953\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3344 - val_loss: 9.5155\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7698 - val_loss: 8.8286\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6664 - val_loss: 8.3908\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5909 - val_loss: 8.2991\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5691 - val_loss: 9.1977\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7934 - val_loss: 8.9242\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6789 - val_loss: 8.9598\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7941 - val_loss: 8.3664\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7216 - val_loss: 8.4888\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5834 - val_loss: 8.8680\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8352 - val_loss: 8.5950\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6023 - val_loss: 8.5081\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8154 - val_loss: 8.2445\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7561 - val_loss: 8.3189\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6060 - val_loss: 8.9553\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8843 - val_loss: 9.0452\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8585 - val_loss: 11.9166\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0083 - val_loss: 8.5084\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7261 - val_loss: 8.4311\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7470 - val_loss: 9.8126\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8037 - val_loss: 8.2840\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6220 - val_loss: 8.5357\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7251 - val_loss: 8.9891\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7702 - val_loss: 8.5505\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7589 - val_loss: 10.7331\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6836 - val_loss: 10.7945\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0570 - val_loss: 8.5132\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8024 - val_loss: 9.5320\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9380 - val_loss: 8.3799\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0030 - val_loss: 8.6467\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6634 - val_loss: 8.6821\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5855 - val_loss: 8.3523\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8925 - val_loss: 8.4941\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6568 - val_loss: 8.7328\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9778 - val_loss: 10.4665\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6254 - val_loss: 10.5079\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3232 - val_loss: 9.5388\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7703 - val_loss: 8.6889\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6518 - val_loss: 8.7404\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9378 - val_loss: 9.1654\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8449 - val_loss: 8.2040\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6580 - val_loss: 9.0188\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6727 - val_loss: 8.2871\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6865 - val_loss: 8.3583\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7369 - val_loss: 8.6849\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6219 - val_loss: 9.0066\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9707 - val_loss: 8.9302\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6284 - val_loss: 9.4143\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7754 - val_loss: 8.9498\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6250 - val_loss: 9.3922\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7444 - val_loss: 8.7455\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6842 - val_loss: 8.8779\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7686 - val_loss: 10.9773\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7844 - val_loss: 8.6259\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6594 - val_loss: 8.7361\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6206 - val_loss: 8.6508\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6014 - val_loss: 9.2150\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0091 - val_loss: 8.4483\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4554 - val_loss: 8.8054\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5531 - val_loss: 8.3115\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5095 - val_loss: 10.5004\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8864 - val_loss: 8.5146\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5822 - val_loss: 8.9623\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9881 - val_loss: 8.1805\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6996 - val_loss: 8.5131\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8542 - val_loss: 8.5696\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6990 - val_loss: 10.1768\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5401 - val_loss: 8.3747\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6444 - val_loss: 8.8256\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4455 - val_loss: 8.6591\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7231 - val_loss: 8.6588\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7072 - val_loss: 8.7159\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8393 - val_loss: 9.5301\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7140 - val_loss: 8.2447\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5091 - val_loss: 8.2112\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5816 - val_loss: 8.4817\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5604 - val_loss: 8.4600\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6854 - val_loss: 9.1438\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4957 - val_loss: 8.2423\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6087 - val_loss: 9.0099\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4755 - val_loss: 8.2707\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7249 - val_loss: 8.5376\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8764 - val_loss: 8.6270\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9367 - val_loss: 8.1053\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7633 - val_loss: 10.0228\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7133 - val_loss: 8.3312\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8387 - val_loss: 8.2786\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5718 - val_loss: 9.7122\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7732 - val_loss: 9.8510\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1038 - val_loss: 8.4980\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5705 - val_loss: 9.1058\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5274 - val_loss: 8.6575\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7337 - val_loss: 9.0566\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1678 - val_loss: 8.4341\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4817 - val_loss: 9.4087\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5709 - val_loss: 8.3228\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9715 - val_loss: 8.2037\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7793 - val_loss: 9.2641\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4497 - val_loss: 9.4442\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9598 - val_loss: 8.5867\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7409 - val_loss: 8.3837\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5998 - val_loss: 8.4242\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7765 - val_loss: 8.4194\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7851 - val_loss: 9.1339\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5306 - val_loss: 9.1508\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9338 - val_loss: 8.5581\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4897 - val_loss: 8.7332\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9198 - val_loss: 8.9966\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5881 - val_loss: 8.3377\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4472 - val_loss: 8.7152\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5237 - val_loss: 8.1909\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7514 - val_loss: 8.6408\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5852 - val_loss: 8.2485\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7410 - val_loss: 8.9567\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0182 - val_loss: 10.3083\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9381 - val_loss: 8.6356\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5751 - val_loss: 9.2195\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7897 - val_loss: 8.8694\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7531 - val_loss: 9.1554\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6447 - val_loss: 8.7868\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5233 - val_loss: 8.6801\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8532 - val_loss: 8.5991\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6578 - val_loss: 8.2822\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5025 - val_loss: 9.0425\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7628 - val_loss: 8.1964\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4387 - val_loss: 8.3654\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5455 - val_loss: 8.5335\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5400 - val_loss: 9.6373\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5707 - val_loss: 8.4752\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0304 - val_loss: 8.2835\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5451 - val_loss: 8.4927\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4719 - val_loss: 8.5251\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6948 - val_loss: 9.1403\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5569 - val_loss: 8.6932\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9457 - val_loss: 8.7588\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6208 - val_loss: 9.0355\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4769 - val_loss: 8.4603\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7884 - val_loss: 8.8067\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8046 - val_loss: 8.7522\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6613 - val_loss: 8.1668\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5537 - val_loss: 8.9522\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6080 - val_loss: 9.6586\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6482 - val_loss: 8.3514\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6522 - val_loss: 8.7164\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7112 - val_loss: 8.3633\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3813 - val_loss: 8.4504\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5548 - val_loss: 9.7561\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6572 - val_loss: 9.0354\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5306 - val_loss: 8.6767\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3612 - val_loss: 8.9689\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3806 - val_loss: 9.7157\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4829 - val_loss: 8.2228\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4979 - val_loss: 9.6035\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7778 - val_loss: 8.2229\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5738 - val_loss: 8.2714\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4587 - val_loss: 8.7661\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3936 - val_loss: 9.5463\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6216 - val_loss: 8.5204\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5494 - val_loss: 9.9098\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7897 - val_loss: 8.9641\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6909 - val_loss: 9.0996\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4621 - val_loss: 8.5829\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9786 - val_loss: 8.9897\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8373 - val_loss: 8.5094\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5859 - val_loss: 9.5697\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6942 - val_loss: 8.0991\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4637 - val_loss: 8.9756\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4060 - val_loss: 8.4741\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4320 - val_loss: 8.3016\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6838 - val_loss: 9.3082\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5790 - val_loss: 8.8984\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6691 - val_loss: 8.5269\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8266 - val_loss: 8.5801\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8845 - val_loss: 10.0238\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5385 - val_loss: 9.7023\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9114 - val_loss: 7.9830\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3869 - val_loss: 8.8999\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5971 - val_loss: 8.0559\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2113 - val_loss: 8.3133\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7025 - val_loss: 9.3794\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2259 - val_loss: 8.9476\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6509 - val_loss: 9.1413\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3512 - val_loss: 8.1427\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8182 - val_loss: 8.2214\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6288 - val_loss: 9.6914\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6196 - val_loss: 8.4485\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4097 - val_loss: 8.4212\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4817 - val_loss: 9.6584\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.6317 - val_loss: 8.2177\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8590 - val_loss: 8.0353\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5882 - val_loss: 8.1559\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.3961 - val_loss: 10.6841\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7269 - val_loss: 9.0669\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.5859 - val_loss: 8.2059\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.3967 - val_loss: 10.5941\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6005 - val_loss: 8.1205\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3196 - val_loss: 11.3662\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8614 - val_loss: 8.4927\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5820 - val_loss: 8.3099\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1675 - val_loss: 8.2396\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4926 - val_loss: 9.7027\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6544 - val_loss: 8.9407\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6875 - val_loss: 8.9949\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.5395 - val_loss: 8.6367\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9862 - val_loss: 9.3041\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6827 - val_loss: 8.5322\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3356 - val_loss: 7.9697\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5784 - val_loss: 9.2318\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6299 - val_loss: 8.0937\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4144 - val_loss: 10.4899\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.5445 - val_loss: 8.0554\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7470 - val_loss: 8.3685\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5390 - val_loss: 9.2424\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5296 - val_loss: 8.3324\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5560 - val_loss: 8.6896\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.8623 - val_loss: 8.4054\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5145 - val_loss: 8.5106\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5912 - val_loss: 8.4153\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.3986 - val_loss: 8.2610\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4270 - val_loss: 8.6066\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4754 - val_loss: 8.7742\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4767 - val_loss: 8.4513\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5963 - val_loss: 8.0303\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3874 - val_loss: 8.0356\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4221 - val_loss: 8.5815\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3751 - val_loss: 8.1531\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5893 - val_loss: 7.9298\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1996 - val_loss: 8.8525\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5278 - val_loss: 8.6794\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4743 - val_loss: 8.4330\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7425 - val_loss: 9.1533\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6861 - val_loss: 9.1420\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5848 - val_loss: 8.2175\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9779 - val_loss: 8.4151\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8854 - val_loss: 9.2254\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4971 - val_loss: 8.3015\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6306 - val_loss: 8.9175\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5240 - val_loss: 8.2630\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3378 - val_loss: 10.0660\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4758 - val_loss: 8.1758\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5990 - val_loss: 8.3858\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5633 - val_loss: 8.9594\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4644 - val_loss: 12.0096\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8636 - val_loss: 8.5476\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6495 - val_loss: 8.2475\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4695 - val_loss: 8.5439\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2626 - val_loss: 8.2664\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4021 - val_loss: 8.2655\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6138 - val_loss: 7.9941\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6305 - val_loss: 8.9888\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3162 - val_loss: 7.9696\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4731 - val_loss: 8.4325\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3404 - val_loss: 8.3081\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3181 - val_loss: 8.1829\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2431 - val_loss: 8.2021\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5138 - val_loss: 8.4025\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3673 - val_loss: 8.3168\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3354 - val_loss: 8.3140\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8805 - val_loss: 8.4560\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5633 - val_loss: 7.8963\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2802 - val_loss: 9.2188\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3065 - val_loss: 8.8215\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4534 - val_loss: 8.6072\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2287 - val_loss: 8.4721\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2477 - val_loss: 7.9064\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9988 - val_loss: 9.5917\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4965 - val_loss: 9.1613\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7794 - val_loss: 8.4109\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4787 - val_loss: 8.1821\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5652 - val_loss: 7.8994\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2800 - val_loss: 8.2816\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1966 - val_loss: 8.3514\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3769 - val_loss: 8.4968\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5687 - val_loss: 8.2313\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4443 - val_loss: 8.8426\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2035 - val_loss: 8.2391\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1862 - val_loss: 8.3964\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4709 - val_loss: 8.0376\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5611 - val_loss: 8.4265\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6603 - val_loss: 9.3213\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4715 - val_loss: 8.0243\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3405 - val_loss: 8.8123\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6145 - val_loss: 8.1519\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5477 - val_loss: 8.7211\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4065 - val_loss: 8.3763\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3392 - val_loss: 8.9703\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8039 - val_loss: 8.7671\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.3625 - val_loss: 8.2439\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6591 - val_loss: 8.7619\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3654 - val_loss: 9.2038\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6722 - val_loss: 8.1774\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4659 - val_loss: 8.0694\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3437 - val_loss: 8.0303\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3137 - val_loss: 8.0265\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1943 - val_loss: 7.9928\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1714 - val_loss: 8.2291\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5181 - val_loss: 7.7970\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3753 - val_loss: 8.0909\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.4606 - val_loss: 8.3300\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.2323 - val_loss: 8.5393\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4950 - val_loss: 8.9228\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.5659 - val_loss: 8.1680\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5567 - val_loss: 9.2407\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5270 - val_loss: 8.2228\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3089 - val_loss: 7.9077\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1997 - val_loss: 8.0325\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.5276 - val_loss: 9.7993\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4659 - val_loss: 7.6541\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2043 - val_loss: 8.0854\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6834 - val_loss: 8.0588\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5284 - val_loss: 7.9581\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2900 - val_loss: 8.4513\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.3875 - val_loss: 7.9472\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2156 - val_loss: 7.9596\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3366 - val_loss: 7.7697\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4792 - val_loss: 9.2530\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5920 - val_loss: 9.3140\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2821 - val_loss: 9.0074\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5083 - val_loss: 9.0346\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3936 - val_loss: 8.3612\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4019 - val_loss: 7.8949\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6415 - val_loss: 8.6538\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3266 - val_loss: 8.0021\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4279 - val_loss: 8.4304\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4588 - val_loss: 10.8905\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9002 - val_loss: 8.4206\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1069 - val_loss: 8.2403\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 7.4926 - val_loss: 8.9289\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4198 - val_loss: 8.7789\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3876 - val_loss: 7.8908\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.1549 - val_loss: 8.0135\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.1527 - val_loss: 8.6998\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2663 - val_loss: 9.3029\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8510 - val_loss: 9.4972\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3946 - val_loss: 8.8283\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3953 - val_loss: 7.8434\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4385 - val_loss: 8.3160\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3874 - val_loss: 7.6845\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2211 - val_loss: 9.6610\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.5650 - val_loss: 8.8210\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.3508 - val_loss: 7.7875\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.3684 - val_loss: 7.9903\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.1241 - val_loss: 10.0660\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3178 - val_loss: 7.5987\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1611 - val_loss: 8.4862\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2904 - val_loss: 8.0571\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4681 - val_loss: 7.7556\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7524 - val_loss: 8.3787\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.5543 - val_loss: 8.1871\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5183 - val_loss: 7.9904\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4716 - val_loss: 8.2085\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5683 - val_loss: 9.4296\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4202 - val_loss: 8.3639\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1966 - val_loss: 7.5750\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6283 - val_loss: 8.4693\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4905 - val_loss: 8.4094\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1461 - val_loss: 7.8491\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8629 - val_loss: 9.4778\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4144 - val_loss: 8.0321\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.3409 - val_loss: 8.4521\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4066 - val_loss: 8.5501\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2565 - val_loss: 8.0534\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.3617 - val_loss: 8.3614\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.1845 - val_loss: 8.0557\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3096 - val_loss: 7.9391\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7071 - val_loss: 8.5822\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.1406 - val_loss: 8.2359\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3874 - val_loss: 8.8942\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1004 - val_loss: 9.6167\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4900 - val_loss: 8.2824\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2639 - val_loss: 8.5352\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5616 - val_loss: 8.1799\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3415 - val_loss: 8.6698\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2598 - val_loss: 8.1260\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.0802 - val_loss: 8.1851\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.0967 - val_loss: 8.5992\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.9061 - val_loss: 8.6136\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.2705 - val_loss: 7.9768\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.5198 - val_loss: 8.5502\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.3889 - val_loss: 8.7675\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.8144 - val_loss: 7.9325\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.2624 - val_loss: 8.2193\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7918 - val_loss: 9.2767\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.2699 - val_loss: 8.3964\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7801 - val_loss: 10.4068\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4461 - val_loss: 8.0158\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2642 - val_loss: 8.0217\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6564 - val_loss: 8.2842\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5108 - val_loss: 8.4395\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.9562 - val_loss: 8.8492\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1835 - val_loss: 7.7712\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.1066 - val_loss: 7.8103\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.2471 - val_loss: 9.9286\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2369 - val_loss: 7.9736\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2260 - val_loss: 7.9638\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4337 - val_loss: 8.6922\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6283 - val_loss: 9.3039\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.1840 - val_loss: 8.7621\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3397 - val_loss: 8.4279\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2344 - val_loss: 8.2470\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1679 - val_loss: 9.2511\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.2524 - val_loss: 7.9861\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.3825 - val_loss: 7.8357\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1737 - val_loss: 8.1521\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.9715 - val_loss: 9.7981\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3592 - val_loss: 7.6567\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0316 - val_loss: 7.8794\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0682 - val_loss: 8.0160\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1436 - val_loss: 8.5039\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1749 - val_loss: 7.8604\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3310 - val_loss: 7.9726\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1158 - val_loss: 8.1217\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0411 - val_loss: 8.7384\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0983 - val_loss: 8.7845\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7070 - val_loss: 7.8323\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1463 - val_loss: 7.8333\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1212 - val_loss: 7.5488\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0220 - val_loss: 7.9601\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0096 - val_loss: 8.0488\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0498 - val_loss: 8.0574\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1615 - val_loss: 8.2156\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6470 - val_loss: 8.1431\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3522 - val_loss: 8.1068\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.7921 - val_loss: 10.3639\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6157 - val_loss: 8.4087\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3105 - val_loss: 7.6420\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1729 - val_loss: 9.6059\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0389 - val_loss: 7.7780\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3008 - val_loss: 9.8398\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0660 - val_loss: 7.5841\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4180 - val_loss: 7.7888\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3232 - val_loss: 7.7674\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0691 - val_loss: 8.7362\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4155 - val_loss: 7.6932\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2535 - val_loss: 8.8182\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9962 - val_loss: 7.9623\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2730 - val_loss: 8.4957\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2263 - val_loss: 8.7182\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9960 - val_loss: 8.4219\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0644 - val_loss: 9.5290\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2934 - val_loss: 9.1759\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1004 - val_loss: 8.1408\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3524 - val_loss: 8.6475\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3565 - val_loss: 8.7542\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3243 - val_loss: 9.2080\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1924 - val_loss: 8.3647\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5265 - val_loss: 8.7399\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7078 - val_loss: 7.7601\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0880 - val_loss: 8.0982\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2114 - val_loss: 7.7572\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0548 - val_loss: 10.1653\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9392 - val_loss: 7.6836\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1216 - val_loss: 7.9082\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2443 - val_loss: 8.2935\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2501 - val_loss: 8.8696\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1161 - val_loss: 8.8820\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0999 - val_loss: 7.6654\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1419 - val_loss: 7.9834\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9898 - val_loss: 9.1144\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0390 - val_loss: 7.5528\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1079 - val_loss: 7.7446\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3163 - val_loss: 8.4386\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1298 - val_loss: 8.4095\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1556 - val_loss: 8.9787\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0974 - val_loss: 8.3098\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1966 - val_loss: 8.3641\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1114 - val_loss: 7.9299\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2272 - val_loss: 7.7718\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5666 - val_loss: 7.6797\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4381 - val_loss: 8.0189\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0335 - val_loss: 7.8213\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2874 - val_loss: 8.4006\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4967 - val_loss: 10.0007\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0947 - val_loss: 7.9078\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0648 - val_loss: 8.2969\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.1376 - val_loss: 7.9029\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5154 - val_loss: 7.6733\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1625 - val_loss: 8.1644\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0393 - val_loss: 8.1188\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2485 - val_loss: 7.7967\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2443 - val_loss: 7.7915\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2344 - val_loss: 7.8969\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0533 - val_loss: 7.8401\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0920 - val_loss: 7.7295\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3987 - val_loss: 8.2074\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2734 - val_loss: 7.6669\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2206 - val_loss: 9.2095\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9560 - val_loss: 8.2619\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9926 - val_loss: 7.6198\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8962 - val_loss: 7.5989\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2273 - val_loss: 8.3217\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0941 - val_loss: 7.8042\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9992 - val_loss: 7.6535\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2913 - val_loss: 9.1520\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1133 - val_loss: 8.1022\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1941 - val_loss: 9.0448\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1078 - val_loss: 7.9588\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2131 - val_loss: 8.8932\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2344 - val_loss: 8.4192\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1213 - val_loss: 7.9653\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6208 - val_loss: 9.0610\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1745 - val_loss: 8.1579\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3078 - val_loss: 8.0829\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1685 - val_loss: 8.1007\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2223 - val_loss: 8.4919\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0054 - val_loss: 8.0071\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1893 - val_loss: 8.2862\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0810 - val_loss: 8.0396\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3602 - val_loss: 8.4437\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5243 - val_loss: 7.6899\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4161 - val_loss: 7.7559\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0394 - val_loss: 8.2063\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4199 - val_loss: 9.7903\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4594 - val_loss: 7.8942\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2547 - val_loss: 8.2523\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1611 - val_loss: 8.0938\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1367 - val_loss: 8.7518\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2287 - val_loss: 11.2559\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3777 - val_loss: 7.8060\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2704 - val_loss: 8.1386\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9841 - val_loss: 8.4913\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3973 - val_loss: 8.0711\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4183 - val_loss: 9.5068\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2643 - val_loss: 9.6342\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0811 - val_loss: 8.0930\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0229 - val_loss: 8.0436\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0259 - val_loss: 7.6843\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0912 - val_loss: 7.6138\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1423 - val_loss: 7.8652\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2871 - val_loss: 7.7496\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1234 - val_loss: 7.9719\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1149 - val_loss: 8.5140\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3178 - val_loss: 7.8673\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3025 - val_loss: 8.4373\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4642 - val_loss: 8.3042\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1125 - val_loss: 9.2342\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4142 - val_loss: 7.7381\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1457 - val_loss: 8.8122\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0503 - val_loss: 7.9756\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0579 - val_loss: 8.0495\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1668 - val_loss: 8.0712\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2230 - val_loss: 8.4113\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3263 - val_loss: 8.1823\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5389 - val_loss: 7.7159\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0762 - val_loss: 8.9392\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.2657 - val_loss: 7.9214\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.9948 - val_loss: 7.8575\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.0787 - val_loss: 8.0612\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.1828 - val_loss: 7.7614\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.2103 - val_loss: 8.6680\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.9798 - val_loss: 8.9109\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.3573 - val_loss: 7.8102\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.1108 - val_loss: 7.8668\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4187 - val_loss: 8.3439\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0191 - val_loss: 8.8761\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1047 - val_loss: 8.3953\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9980 - val_loss: 7.7181\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8502 - val_loss: 8.0574\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0894 - val_loss: 8.1667\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2621 - val_loss: 8.0233\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0070 - val_loss: 7.9379\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.2135 - val_loss: 7.7314\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2737 - val_loss: 8.2116\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3784 - val_loss: 8.2057\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9894 - val_loss: 7.6740\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.3912 - val_loss: 7.9749\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.1010 - val_loss: 8.5536\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9993 - val_loss: 9.1188\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2471 - val_loss: 7.6438\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3337 - val_loss: 8.6467\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4464 - val_loss: 9.5374\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9621 - val_loss: 8.1684\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8263 - val_loss: 7.6371\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3486 - val_loss: 8.3846\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2951 - val_loss: 8.2246\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0111 - val_loss: 7.5610\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1851 - val_loss: 8.9556\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3241 - val_loss: 9.0312\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3886 - val_loss: 8.2903\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9960 - val_loss: 7.9056\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4593 - val_loss: 8.4611\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8774 - val_loss: 8.6064\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1464 - val_loss: 7.8734\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9533 - val_loss: 7.7621\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0206 - val_loss: 7.7034\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3575 - val_loss: 8.3554\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1589 - val_loss: 7.8483\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3057 - val_loss: 8.2904\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0369 - val_loss: 7.9078\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1435 - val_loss: 7.8243\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2488 - val_loss: 11.1210\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6102 - val_loss: 7.8427\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0932 - val_loss: 7.8830\n",
      "7.674031477058883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.95092314e-01,  5.07176638e-01,  4.88057089e+00,\n",
       "          3.17043990e-01,  5.64508557e-01, -5.20645916e-01,\n",
       "         -2.37642139e-01, -5.21843863e+00,  1.69647074e+00,\n",
       "          4.30521393e+00],\n",
       "        [-5.23071826e-01,  1.20774055e+00, -2.28234336e-01,\n",
       "          6.53233171e-01,  8.08367431e-01, -3.99232656e-01,\n",
       "         -1.86323315e-01, -1.98227808e-01, -1.56775042e-01,\n",
       "         -4.23849560e-02],\n",
       "        [-7.56681502e-01,  1.82341349e+00,  1.34337139e+00,\n",
       "          9.32926595e-01,  1.59977758e+00, -6.90866172e-01,\n",
       "         -4.01334971e-01,  6.25746250e-02, -6.56992868e-02,\n",
       "          1.29846871e+00],\n",
       "        [ 1.08904406e-01,  3.92923951e-01, -1.86798647e-01,\n",
       "         -2.51446175e-03, -2.28729650e-01,  2.99601853e-01,\n",
       "          9.71929610e-01,  6.57775328e-02, -7.93439448e-02,\n",
       "         -2.46725023e-01],\n",
       "        [-3.85078758e-01,  6.34336650e-01,  2.53758520e-01,\n",
       "          4.28221017e-01,  9.46744323e-01, -5.07243752e-01,\n",
       "         -4.08247232e-01, -1.92404592e+00,  1.23656146e-01,\n",
       "          4.13348627e+00]], dtype=float32),\n",
       " array([ 5.4105415, -5.5250635,  6.0748687, -5.1725426,  1.7198762,\n",
       "         0.9931237,  3.38791  , -6.097255 ,  1.0786762,  5.5315394],\n",
       "       dtype=float32),\n",
       " array([[ 1.3776953 ,  1.1576093 ,  2.238381  ,  2.2181113 ,  1.768702  ],\n",
       "        [-1.6851683 , -0.8517612 , -2.487705  , -1.527396  , -1.3152    ],\n",
       "        [ 1.5807754 ,  2.2000265 ,  2.9034345 ,  2.967795  ,  2.8860486 ],\n",
       "        [-1.9448692 , -1.5311115 , -1.5514753 , -2.1279438 , -1.6636506 ],\n",
       "        [-1.3987722 , -0.7085404 , -0.55385137, -1.0338037 , -0.5149654 ],\n",
       "        [ 1.0001264 , -0.60802877,  0.43397018,  1.2058996 ,  0.3042436 ],\n",
       "        [ 1.1453745 ,  1.6654302 ,  2.3789992 ,  1.9653177 ,  1.8462721 ],\n",
       "        [-1.7604854 , -1.347436  , -2.7573876 , -1.9268769 , -2.452907  ],\n",
       "        [-0.67261755, -1.2203645 , -1.3955501 , -1.8153977 , -1.244415  ],\n",
       "        [ 0.98994064, -0.40526992,  1.0835382 ,  0.50815797,  0.98756295]],\n",
       "       dtype=float32),\n",
       " array([2.0779164, 1.1923175, 2.3176732, 2.2919297, 2.2638078],\n",
       "       dtype=float32),\n",
       " array([[1.3784628],\n",
       "        [1.0052961],\n",
       "        [2.5889065],\n",
       "        [2.0427225],\n",
       "        [1.8829365]], dtype=float32),\n",
       " array([2.3908088], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_4(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure4_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 181\n",
      "Trainable params: 181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 242us/step - loss: 6413.1052 - val_loss: 617.0908\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 156.1246 - val_loss: 44.9586\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 31.7930 - val_loss: 28.3870\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 25.1336 - val_loss: 27.3966\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.9160 - val_loss: 27.2237\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7241 - val_loss: 26.5495\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.9137 - val_loss: 26.0932\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.1702 - val_loss: 26.1382\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.9001 - val_loss: 25.8180\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.5205 - val_loss: 26.0035\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.4498 - val_loss: 25.0016\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.1127 - val_loss: 25.0901\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.2305 - val_loss: 24.6283\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.9542 - val_loss: 25.4042\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.8408 - val_loss: 24.5631\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6483 - val_loss: 24.7105\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.6548 - val_loss: 24.6996\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.6248 - val_loss: 24.3801\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2867 - val_loss: 24.5760\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2721 - val_loss: 24.3828\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0033 - val_loss: 23.6537\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0716 - val_loss: 23.6223\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0204 - val_loss: 23.5500\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0078 - val_loss: 23.5601\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.6779 - val_loss: 22.8618\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6377 - val_loss: 22.9720\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6878 - val_loss: 22.3703\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4996 - val_loss: 21.9802\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2456 - val_loss: 22.0029\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1874 - val_loss: 21.8211\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2435 - val_loss: 21.4721\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.1133 - val_loss: 21.0684\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9478 - val_loss: 21.3974\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.7582 - val_loss: 21.2527\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.5626 - val_loss: 20.7188\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.6067 - val_loss: 21.0477\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.5154 - val_loss: 20.1623\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 16.3283 - val_loss: 20.4805\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.2134 - val_loss: 20.5687\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.0349 - val_loss: 19.8016\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.9407 - val_loss: 20.4284\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.9949 - val_loss: 19.8165\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.6764 - val_loss: 19.5726\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.7756 - val_loss: 19.7155\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.6790 - val_loss: 20.1609\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.6346 - val_loss: 19.2942\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.3148 - val_loss: 19.8717\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.8839 - val_loss: 19.6609\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.7097 - val_loss: 18.5442\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.3868 - val_loss: 18.7658\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0608 - val_loss: 18.9898\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.1550 - val_loss: 18.6181\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.1167 - val_loss: 18.4642\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2301 - val_loss: 19.8768\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.9918 - val_loss: 18.3347\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.1761 - val_loss: 19.2062\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.9213 - val_loss: 18.6973\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.7848 - val_loss: 18.2526\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6657 - val_loss: 19.2087\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1571 - val_loss: 20.0044\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9026 - val_loss: 18.9437\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6624 - val_loss: 18.1072\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5026 - val_loss: 17.7416\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7995 - val_loss: 17.8451\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6984 - val_loss: 19.2271\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3154 - val_loss: 17.8599\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6882 - val_loss: 17.1268\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1954 - val_loss: 19.8190\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5990 - val_loss: 18.4403\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2316 - val_loss: 17.4480\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.7540 - val_loss: 17.2663\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.1956 - val_loss: 19.0268\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.8561 - val_loss: 17.5094\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3251 - val_loss: 17.2204\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1247 - val_loss: 17.1757\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9006 - val_loss: 18.0473\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 13.8654 - val_loss: 16.9799\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0135 - val_loss: 17.4059\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7445 - val_loss: 16.5244\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.5868 - val_loss: 16.8587\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 13.51 - 0s 85us/step - loss: 13.8365 - val_loss: 21.1108\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5843 - val_loss: 17.9906\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6272 - val_loss: 17.4750\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7893 - val_loss: 18.4851\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1472 - val_loss: 16.8715\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.3538 - val_loss: 17.4694\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.4747 - val_loss: 17.4108\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.1609 - val_loss: 16.7658\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.4555 - val_loss: 17.3125\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4854 - val_loss: 16.2813\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.4153 - val_loss: 17.4125\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.1213 - val_loss: 17.6663\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4240 - val_loss: 16.3615\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.2146 - val_loss: 16.0356\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.2202 - val_loss: 15.9520\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.1476 - val_loss: 16.1833\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.5842 - val_loss: 15.7525\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8666 - val_loss: 17.2269\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6115 - val_loss: 16.0750\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.7377 - val_loss: 16.3944\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6493 - val_loss: 15.6383\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3341 - val_loss: 15.7954\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5951 - val_loss: 16.9503\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2571 - val_loss: 15.4175\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9519 - val_loss: 15.3462\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8575 - val_loss: 16.7396\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5971 - val_loss: 15.2159\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3794 - val_loss: 16.0644\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9977 - val_loss: 17.3004\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7778 - val_loss: 15.0260\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.8087 - val_loss: 14.8943\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9420 - val_loss: 16.6714\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.6061 - val_loss: 14.3612\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5678 - val_loss: 14.8847\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.8484 - val_loss: 15.5751\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9553 - val_loss: 14.4191\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.4495 - val_loss: 14.8581\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.5183 - val_loss: 13.7747\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.8897 - val_loss: 13.9928\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6521 - val_loss: 13.7956\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 11.0653 - val_loss: 13.9980\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0630 - val_loss: 13.8211\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8261 - val_loss: 12.9918\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1163 - val_loss: 14.7274\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.5890 - val_loss: 13.3620\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.6964 - val_loss: 13.5918\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4204 - val_loss: 14.1507\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7192 - val_loss: 13.5691\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1734 - val_loss: 13.3374\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1865 - val_loss: 13.7906\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.4150 - val_loss: 13.4176\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3934 - val_loss: 12.5610\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4113 - val_loss: 13.8420\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4500 - val_loss: 12.8583\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.0913 - val_loss: 12.7922\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3606 - val_loss: 12.3580\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3569 - val_loss: 11.9358\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.3560 - val_loss: 15.0141\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9689 - val_loss: 12.9780\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4388 - val_loss: 12.0212\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3586 - val_loss: 11.6335\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8391 - val_loss: 13.1751\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1414 - val_loss: 12.3052\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.2546 - val_loss: 12.1582\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5413 - val_loss: 12.3836\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2241 - val_loss: 13.2500\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0341 - val_loss: 11.7535\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7194 - val_loss: 12.2959\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8712 - val_loss: 12.0796\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7016 - val_loss: 16.2571\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.2090 - val_loss: 13.9655\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0416 - val_loss: 12.1073\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8933 - val_loss: 13.7399\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5964 - val_loss: 11.0229\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9900 - val_loss: 13.5834\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0486 - val_loss: 11.1958\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5178 - val_loss: 11.5288\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0588 - val_loss: 13.0667\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.4662 - val_loss: 11.2145\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5237 - val_loss: 12.0002\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5963 - val_loss: 11.7535\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1364 - val_loss: 11.8566\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9804 - val_loss: 11.0619\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2722 - val_loss: 12.1089\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2210 - val_loss: 11.2474\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5489 - val_loss: 12.2745\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0089 - val_loss: 11.6539\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.7646 - val_loss: 12.2931\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1925 - val_loss: 13.1681\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2726 - val_loss: 10.7644\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2705 - val_loss: 10.9380\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6011 - val_loss: 13.3077\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3999 - val_loss: 11.2407\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6251 - val_loss: 10.7401\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1627 - val_loss: 11.2372\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0819 - val_loss: 11.5079\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1085 - val_loss: 11.0103\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1384 - val_loss: 10.9744\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2090 - val_loss: 10.9501\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0607 - val_loss: 10.9990\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0542 - val_loss: 11.7111\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3804 - val_loss: 10.6202\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8990 - val_loss: 11.9490\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7443 - val_loss: 11.0325\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2594 - val_loss: 10.4120\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1775 - val_loss: 10.7396\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8151 - val_loss: 11.6939\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1969 - val_loss: 12.9005\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0664 - val_loss: 10.8609\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4829 - val_loss: 10.4394\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1070 - val_loss: 11.4904\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1324 - val_loss: 10.7348\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7725 - val_loss: 11.2977\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2340 - val_loss: 12.1151\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2135 - val_loss: 11.1075\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1934 - val_loss: 10.6705\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4189 - val_loss: 10.3517\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7963 - val_loss: 11.2006\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9383 - val_loss: 10.6481\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1315 - val_loss: 11.8833\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1262 - val_loss: 10.7760\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0559 - val_loss: 10.7260\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8188 - val_loss: 10.5591\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0085 - val_loss: 10.5904\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1073 - val_loss: 11.0917\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1543 - val_loss: 11.2844\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9899 - val_loss: 10.2702\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7875 - val_loss: 10.7130\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7847 - val_loss: 11.4079\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9873 - val_loss: 11.4085\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8274 - val_loss: 11.7009\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6003 - val_loss: 10.7884\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7030 - val_loss: 11.6324\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2474 - val_loss: 12.0578\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9737 - val_loss: 10.7365\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7762 - val_loss: 10.6467\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9083 - val_loss: 10.3976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6467 - val_loss: 10.4682\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1566 - val_loss: 10.5164\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1741 - val_loss: 13.7055\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9927 - val_loss: 10.7527\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8033 - val_loss: 11.0874\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9085 - val_loss: 10.3363\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7654 - val_loss: 12.3299\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7186 - val_loss: 12.0738\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8344 - val_loss: 10.1442\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1329 - val_loss: 10.3681\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9602 - val_loss: 10.6667\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2217 - val_loss: 10.2366\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1689 - val_loss: 9.9408\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8056 - val_loss: 10.8634\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9365 - val_loss: 11.5071\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7223 - val_loss: 10.7127\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5178 - val_loss: 10.2796\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0731 - val_loss: 10.0208\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6644 - val_loss: 11.1745\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8121 - val_loss: 9.8653\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2189 - val_loss: 10.2241\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3341 - val_loss: 10.2651\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0145 - val_loss: 17.2502\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3354 - val_loss: 10.2256\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8948 - val_loss: 10.7159\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7857 - val_loss: 10.2168\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7605 - val_loss: 10.3763\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5567 - val_loss: 10.4246\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7055 - val_loss: 10.0263\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4268 - val_loss: 10.6123\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8224 - val_loss: 10.7109\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9321 - val_loss: 10.3632\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1146 - val_loss: 10.6954\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2718 - val_loss: 11.2299\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4427 - val_loss: 11.3569\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2315 - val_loss: 10.9228\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4025 - val_loss: 10.3302\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6404 - val_loss: 10.0078\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7744 - val_loss: 11.4074\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6868 - val_loss: 9.9566\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9622 - val_loss: 10.4661\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7146 - val_loss: 10.0962\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7167 - val_loss: 11.3753\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9577 - val_loss: 9.8279\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5680 - val_loss: 10.3773\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6393 - val_loss: 10.8655\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5770 - val_loss: 10.0814\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4453 - val_loss: 9.6824\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9439 - val_loss: 9.8999\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6037 - val_loss: 9.8811\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4512 - val_loss: 10.5612\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4166 - val_loss: 10.5395\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9750 - val_loss: 11.0536\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0541 - val_loss: 10.6604\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8583 - val_loss: 11.5703\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0555 - val_loss: 12.4219\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4301 - val_loss: 9.9321\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0652 - val_loss: 10.7620\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5239 - val_loss: 11.3326\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3362 - val_loss: 9.9663\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8465 - val_loss: 10.5113\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0795 - val_loss: 10.0877\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5107 - val_loss: 9.9150\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8309 - val_loss: 10.2667\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7214 - val_loss: 10.3531\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3587 - val_loss: 9.8571\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9434 - val_loss: 9.8490\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4896 - val_loss: 10.0391\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5014 - val_loss: 9.8304\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3048 - val_loss: 10.0841\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7174 - val_loss: 12.2362\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4727 - val_loss: 10.0174\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4436 - val_loss: 9.7434\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7700 - val_loss: 10.0790\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2745 - val_loss: 10.6200\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6543 - val_loss: 10.1601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3164 - val_loss: 9.6853\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2527 - val_loss: 10.0372\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3704 - val_loss: 9.4903\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9432 - val_loss: 12.1776\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3324 - val_loss: 10.4272\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5301 - val_loss: 10.2670\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2911 - val_loss: 9.5914\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9872 - val_loss: 11.5682\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7659 - val_loss: 9.7922\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2365 - val_loss: 9.9035\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4587 - val_loss: 10.4633\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3456 - val_loss: 11.9305\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9923 - val_loss: 10.8003\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4550 - val_loss: 10.2260\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7114 - val_loss: 10.0274\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3458 - val_loss: 10.4102\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4070 - val_loss: 10.8296\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4803 - val_loss: 9.8218\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6833 - val_loss: 9.5129\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6399 - val_loss: 10.1861\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5001 - val_loss: 11.0374\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5656 - val_loss: 11.8453\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6540 - val_loss: 11.9420\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3649 - val_loss: 9.3498\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1224 - val_loss: 9.7916\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2562 - val_loss: 10.5647\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0376 - val_loss: 9.6839\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3301 - val_loss: 14.0196\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8006 - val_loss: 10.1524\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2227 - val_loss: 12.1530\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5153 - val_loss: 10.0482\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2413 - val_loss: 9.7890\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5636 - val_loss: 10.1215\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5547 - val_loss: 10.0651\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2001 - val_loss: 9.4737\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3331 - val_loss: 9.9666\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4072 - val_loss: 9.9734\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4786 - val_loss: 9.4349\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7677 - val_loss: 9.8132\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5529 - val_loss: 10.4022\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1482 - val_loss: 10.0407\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5815 - val_loss: 10.0218\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6303 - val_loss: 9.6593\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5181 - val_loss: 9.7979\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8215 - val_loss: 10.6425\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4934 - val_loss: 9.9121\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3582 - val_loss: 9.5581\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4220 - val_loss: 10.4834\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3737 - val_loss: 10.2276\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5580 - val_loss: 9.5390\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3138 - val_loss: 9.4711\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0346 - val_loss: 11.4332\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7700 - val_loss: 10.4598\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3453 - val_loss: 9.5773\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6422 - val_loss: 11.1628\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3122 - val_loss: 9.6839\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6945 - val_loss: 10.1017\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8323 - val_loss: 11.2160\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6996 - val_loss: 9.3986\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5012 - val_loss: 9.5478\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4792 - val_loss: 10.3759\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7460 - val_loss: 9.9536\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2811 - val_loss: 11.1941\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2312 - val_loss: 9.4143\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1721 - val_loss: 10.0983\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5711 - val_loss: 9.8823\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1584 - val_loss: 9.2148\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1553 - val_loss: 9.8143\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3435 - val_loss: 10.0426\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3701 - val_loss: 9.3628\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3049 - val_loss: 10.8477\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5806 - val_loss: 10.8149\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3780 - val_loss: 9.9832\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8396 - val_loss: 10.2168\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6640 - val_loss: 12.0309\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2899 - val_loss: 10.5184\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2979 - val_loss: 10.4932\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4650 - val_loss: 12.1695\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0212 - val_loss: 11.3192\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1732 - val_loss: 9.3537\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2408 - val_loss: 10.3348\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1944 - val_loss: 9.9949\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5186 - val_loss: 9.5825\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4785 - val_loss: 10.1015\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2864 - val_loss: 9.8424\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4211 - val_loss: 11.1041\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2421 - val_loss: 9.8919\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2144 - val_loss: 9.3892\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8653 - val_loss: 10.1777\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4923 - val_loss: 9.5886\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6206 - val_loss: 9.6164\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2778 - val_loss: 9.7127\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0567 - val_loss: 10.0272\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3226 - val_loss: 12.7419\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6800 - val_loss: 9.6583\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1458 - val_loss: 9.4275\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2522 - val_loss: 9.8301\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0541 - val_loss: 9.9044\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2109 - val_loss: 9.6858\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3232 - val_loss: 10.2846\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6845 - val_loss: 12.0454\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4602 - val_loss: 9.2832\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1203 - val_loss: 10.4604\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1137 - val_loss: 9.7061\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9812 - val_loss: 9.3379\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1888 - val_loss: 10.0534\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2482 - val_loss: 10.0368\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1273 - val_loss: 9.6410\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0985 - val_loss: 9.4842\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5076 - val_loss: 9.1743\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1396 - val_loss: 9.7922\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6616 - val_loss: 10.6151\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1311 - val_loss: 11.9515\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9428 - val_loss: 11.3558\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3714 - val_loss: 12.1485\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9576 - val_loss: 9.4701\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4002 - val_loss: 9.7208\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2135 - val_loss: 9.5333\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3774 - val_loss: 10.0925\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0803 - val_loss: 9.7043\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3115 - val_loss: 9.3607\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1934 - val_loss: 9.3274\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1942 - val_loss: 9.5647\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3653 - val_loss: 9.4010\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0846 - val_loss: 9.5448\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0459 - val_loss: 9.6002\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2723 - val_loss: 12.1786\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7051 - val_loss: 10.2635\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1332 - val_loss: 9.7102\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0199 - val_loss: 9.3689\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3496 - val_loss: 10.6979\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1943 - val_loss: 11.8036\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1620 - val_loss: 9.5373\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4965 - val_loss: 10.0567\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9871 - val_loss: 10.7870\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1538 - val_loss: 11.2524\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1834 - val_loss: 11.2662\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9070 - val_loss: 11.4994\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5520 - val_loss: 9.4073\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2010 - val_loss: 10.0913\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3787 - val_loss: 9.5705\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4147 - val_loss: 9.5644\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7432 - val_loss: 9.5843\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1389 - val_loss: 9.4413\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.2552 - val_loss: 10.4736\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0068 - val_loss: 9.2139\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2904 - val_loss: 10.7238\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4948 - val_loss: 9.4025\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4918 - val_loss: 9.4038\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1440 - val_loss: 9.4147\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3155 - val_loss: 13.4511\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0696 - val_loss: 10.3754\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2936 - val_loss: 9.1227\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3172 - val_loss: 10.9174\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6328 - val_loss: 14.5892\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7161 - val_loss: 9.7737\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0020 - val_loss: 10.5626\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3113 - val_loss: 10.1466\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1490 - val_loss: 10.3467\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3741 - val_loss: 11.0351\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6147 - val_loss: 9.5385\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1506 - val_loss: 10.6846\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1675 - val_loss: 10.4706\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1419 - val_loss: 10.0404\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8506 - val_loss: 9.9935\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6824 - val_loss: 10.4841\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6631 - val_loss: 9.7719\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9678 - val_loss: 9.2180\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6005 - val_loss: 10.8462\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5187 - val_loss: 9.7116\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9528 - val_loss: 10.4559\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3482 - val_loss: 10.2195\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9841 - val_loss: 9.5246\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.1106 - val_loss: 9.6010\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0443 - val_loss: 9.2016\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2823 - val_loss: 10.7211\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6664 - val_loss: 9.5565\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1715 - val_loss: 9.9462\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0305 - val_loss: 9.6196\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2313 - val_loss: 9.5829\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6937 - val_loss: 9.8008\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6044 - val_loss: 9.6616\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4563 - val_loss: 10.6287\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0503 - val_loss: 9.8455\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0706 - val_loss: 9.7268\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5509 - val_loss: 11.4000\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0693 - val_loss: 9.4199\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2023 - val_loss: 9.7137\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9524 - val_loss: 9.0287\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1730 - val_loss: 10.9190\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4412 - val_loss: 10.6990\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5494 - val_loss: 9.2913\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1112 - val_loss: 9.3567\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9090 - val_loss: 9.7734\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1887 - val_loss: 12.4812\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7660 - val_loss: 10.0460\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4355 - val_loss: 12.7271\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7980 - val_loss: 10.4529\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.4057 - val_loss: 9.5159\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2926 - val_loss: 9.4317\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2487 - val_loss: 12.8816\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4795 - val_loss: 10.7149\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9295 - val_loss: 9.3711\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0416 - val_loss: 9.1095\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9064 - val_loss: 9.5205\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9322 - val_loss: 9.6175\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9629 - val_loss: 9.9803\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6770 - val_loss: 10.4358\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8404 - val_loss: 9.9368\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3856 - val_loss: 9.9297\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9414 - val_loss: 9.2216\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9792 - val_loss: 12.6940\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3945 - val_loss: 10.1594\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9039 - val_loss: 10.5319\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4148 - val_loss: 9.4036\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9387 - val_loss: 9.4483\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8034 - val_loss: 9.1673\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8948 - val_loss: 11.5982\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5082 - val_loss: 10.1054\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5551 - val_loss: 9.0143\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3819 - val_loss: 9.6432\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3393 - val_loss: 10.6515\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0189 - val_loss: 9.6682\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.356 - 0s 85us/step - loss: 7.9278 - val_loss: 11.0578\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3852 - val_loss: 9.2838\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9750 - val_loss: 9.2415\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9160 - val_loss: 9.5126\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0604 - val_loss: 10.1698\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9949 - val_loss: 10.0187\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1729 - val_loss: 9.0852\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0709 - val_loss: 10.0123\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0803 - val_loss: 9.6823\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0894 - val_loss: 9.8021\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8240 - val_loss: 9.5000\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6170 - val_loss: 9.5646\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2691 - val_loss: 9.2119\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2110 - val_loss: 9.4832\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1333 - val_loss: 9.0679\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3964 - val_loss: 10.0844\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2901 - val_loss: 10.0462\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6304 - val_loss: 9.3430\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5374 - val_loss: 13.6107\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4921 - val_loss: 9.5505\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3624 - val_loss: 9.8256\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9088 - val_loss: 9.2718\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8359 - val_loss: 9.3949\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2808 - val_loss: 9.4272\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9067 - val_loss: 10.4851\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0487 - val_loss: 9.6154\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1442 - val_loss: 9.4854\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9341 - val_loss: 10.0767\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9062 - val_loss: 9.2112\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1441 - val_loss: 9.6137\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2033 - val_loss: 9.1875\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2021 - val_loss: 9.1170\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9711 - val_loss: 9.4198\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5102 - val_loss: 10.4698\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4844 - val_loss: 9.5796\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2829 - val_loss: 9.3015\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7242 - val_loss: 9.6495\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9696 - val_loss: 10.3338\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.0157 - val_loss: 9.7880\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2591 - val_loss: 9.0672\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9350 - val_loss: 10.6066\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3090 - val_loss: 9.7337\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3119 - val_loss: 9.7666\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9110 - val_loss: 10.0045\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9735 - val_loss: 9.4692\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1191 - val_loss: 9.2176\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0314 - val_loss: 9.1953\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5077 - val_loss: 9.3603\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2076 - val_loss: 9.4073\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0988 - val_loss: 9.1890\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9162 - val_loss: 9.3702\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6276 - val_loss: 9.5173\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3538 - val_loss: 9.6543\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0468 - val_loss: 9.9272\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3927 - val_loss: 9.3161\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1404 - val_loss: 9.2306\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0578 - val_loss: 11.1765\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9464 - val_loss: 9.3230\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9380 - val_loss: 9.4991\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9430 - val_loss: 9.5153\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4183 - val_loss: 12.7932\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5359 - val_loss: 10.3270\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0147 - val_loss: 10.0754\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3683 - val_loss: 10.2702\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4002 - val_loss: 9.3721\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3419 - val_loss: 9.1941\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6368 - val_loss: 9.9381\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2934 - val_loss: 11.3652\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1231 - val_loss: 9.5916\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8766 - val_loss: 9.0845\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9400 - val_loss: 10.0247\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9905 - val_loss: 9.1980\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3606 - val_loss: 9.2908\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1539 - val_loss: 10.2414\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0842 - val_loss: 10.0882\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.7597 - val_loss: 9.3291\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1978 - val_loss: 10.2139\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0074 - val_loss: 8.9763\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3151 - val_loss: 9.0191\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3198 - val_loss: 10.0176\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9568 - val_loss: 10.3150\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5513 - val_loss: 10.5764\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1577 - val_loss: 9.1485\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0674 - val_loss: 9.6820\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1540 - val_loss: 8.9895\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0255 - val_loss: 10.2112\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1054 - val_loss: 9.9564\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9688 - val_loss: 9.1547\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9262 - val_loss: 9.0148\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.1737 - val_loss: 9.3401\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0748 - val_loss: 10.2502\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0084 - val_loss: 10.3580\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5520 - val_loss: 10.0319\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8342 - val_loss: 8.9638\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2501 - val_loss: 9.6452\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9648 - val_loss: 9.7065\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9225 - val_loss: 9.8339\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0301 - val_loss: 10.1923\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3827 - val_loss: 9.1611\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9578 - val_loss: 9.0047\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3690 - val_loss: 9.7740\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0139 - val_loss: 11.1705\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0091 - val_loss: 9.6912\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5773 - val_loss: 11.2305\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2075 - val_loss: 9.0142\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2808 - val_loss: 9.2100\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9854 - val_loss: 12.5839\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4591 - val_loss: 11.1069\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9376 - val_loss: 9.3709\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1442 - val_loss: 10.0774\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9704 - val_loss: 10.0883\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3155 - val_loss: 9.2653\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8583 - val_loss: 8.9836\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8207 - val_loss: 9.9764\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0805 - val_loss: 9.0151\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8999 - val_loss: 13.9950\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5950 - val_loss: 9.3140\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8936 - val_loss: 9.2291\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1358 - val_loss: 9.2329\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1317 - val_loss: 9.2177\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1124 - val_loss: 9.8345\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8529 - val_loss: 10.4244\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3193 - val_loss: 9.7679\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8703 - val_loss: 9.3731\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.1037 - val_loss: 10.1896\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4969 - val_loss: 9.2441\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.9486 - val_loss: 9.3011\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9161 - val_loss: 9.5621\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1893 - val_loss: 8.8762\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1760 - val_loss: 9.4488\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3967 - val_loss: 9.9236\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2171 - val_loss: 9.5431\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5193 - val_loss: 9.1632\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3569 - val_loss: 9.0254\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1977 - val_loss: 10.9676\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7143 - val_loss: 9.3390\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1095 - val_loss: 9.6244\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9298 - val_loss: 9.6827\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9269 - val_loss: 10.0126\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3927 - val_loss: 9.5875\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1633 - val_loss: 9.0025\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7447 - val_loss: 9.6602\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6684 - val_loss: 9.2438\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1790 - val_loss: 9.9020\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4515 - val_loss: 9.5481\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0345 - val_loss: 12.7386\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9047 - val_loss: 9.0789\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6981 - val_loss: 10.0088\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0235 - val_loss: 10.8178\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3496 - val_loss: 9.6669\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9534 - val_loss: 9.6118\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1106 - val_loss: 9.4923\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0378 - val_loss: 9.1986\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4000 - val_loss: 10.9208\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6068 - val_loss: 9.8496\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3206 - val_loss: 9.1285\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8700 - val_loss: 10.1081\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8414 - val_loss: 10.4807\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 127us/step - loss: 8.0608 - val_loss: 10.3562\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3281 - val_loss: 11.1816\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1416 - val_loss: 9.5355\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8108 - val_loss: 9.1224\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8867 - val_loss: 9.3472\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2074 - val_loss: 9.9767\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1618 - val_loss: 11.3102\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8895 - val_loss: 9.8078\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0962 - val_loss: 13.3253\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8931 - val_loss: 9.1290\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9457 - val_loss: 9.2717\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8466 - val_loss: 9.4898\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0844 - val_loss: 9.0440\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4634 - val_loss: 8.9494\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9740 - val_loss: 10.2360\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9943 - val_loss: 9.1087\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9561 - val_loss: 9.6649\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8582 - val_loss: 9.3620\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6251 - val_loss: 11.5103\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4267 - val_loss: 10.2280\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1844 - val_loss: 9.1621\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0553 - val_loss: 9.2949\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7139 - val_loss: 10.7154\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0822 - val_loss: 8.9965\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0773 - val_loss: 8.9357\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4564 - val_loss: 9.2066\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1702 - val_loss: 9.2078\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9540 - val_loss: 9.1694\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9034 - val_loss: 9.5691\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7760 - val_loss: 9.1986\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7511 - val_loss: 9.6209\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.7386 - val_loss: 9.0125\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8161 - val_loss: 9.8831\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1175 - val_loss: 9.3869\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6867 - val_loss: 9.3397\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8819 - val_loss: 10.3192\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7581 - val_loss: 10.2815\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0919 - val_loss: 10.3335\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0610 - val_loss: 8.9238\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1004 - val_loss: 10.0019\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9088 - val_loss: 11.2774\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2148 - val_loss: 11.2058\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8500 - val_loss: 10.1146\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8486 - val_loss: 9.1990\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8998 - val_loss: 9.8005\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8790 - val_loss: 10.3813\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9257 - val_loss: 8.9541\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9785 - val_loss: 9.1674\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8752 - val_loss: 9.3716\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2166 - val_loss: 8.8634\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.0180 - val_loss: 9.7948\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9240 - val_loss: 9.5897\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8324 - val_loss: 9.3243\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9198 - val_loss: 9.6185\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8956 - val_loss: 9.1806\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2469 - val_loss: 9.7610\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1193 - val_loss: 9.0200\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.3647 - val_loss: 9.0615\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4297 - val_loss: 9.2334\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0061 - val_loss: 8.9900\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0946 - val_loss: 8.9986\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9076 - val_loss: 9.0077\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8333 - val_loss: 9.2062\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9484 - val_loss: 9.1768\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8686 - val_loss: 9.7070\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8548 - val_loss: 8.8857\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8837 - val_loss: 9.5900\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6899 - val_loss: 9.5296\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7870 - val_loss: 8.8617\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0504 - val_loss: 8.9961\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1181 - val_loss: 9.5536\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4304 - val_loss: 9.7544\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1541 - val_loss: 11.5124\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7877 - val_loss: 9.0084\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9972 - val_loss: 9.4943\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5238 - val_loss: 9.4986\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7196 - val_loss: 10.5923\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5413 - val_loss: 10.6458\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2284 - val_loss: 9.0992\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2463 - val_loss: 8.9824\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9751 - val_loss: 9.0927\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0558 - val_loss: 8.8992\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.8054 - val_loss: 9.6242\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1007 - val_loss: 8.9457\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4833 - val_loss: 8.8502\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6772 - val_loss: 8.7813\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0055 - val_loss: 9.1321\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.8723 - val_loss: 8.6961\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1444 - val_loss: 9.2169\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7459 - val_loss: 8.8493\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2057 - val_loss: 9.3731\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9907 - val_loss: 11.6162\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2050 - val_loss: 9.8687\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2274 - val_loss: 10.1003\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8835 - val_loss: 9.4522\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9364 - val_loss: 8.6896\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9694 - val_loss: 8.8473\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9532 - val_loss: 9.0192\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8637 - val_loss: 9.8880\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8883 - val_loss: 10.2404\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0114 - val_loss: 9.0086\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1587 - val_loss: 9.7720\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3792 - val_loss: 9.1394\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2108 - val_loss: 8.6508\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7651 - val_loss: 9.0053\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1661 - val_loss: 10.1418\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1712 - val_loss: 11.2804\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0731 - val_loss: 9.0425\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8346 - val_loss: 9.0490\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8151 - val_loss: 9.6330\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9693 - val_loss: 9.2443\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2335 - val_loss: 8.7076\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1198 - val_loss: 8.6352\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9161 - val_loss: 8.8167\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2377 - val_loss: 10.1041\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2292 - val_loss: 15.1453\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6028 - val_loss: 8.9509\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8165 - val_loss: 9.2541\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1032 - val_loss: 9.7906\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.8409 - val_loss: 8.6857\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3098 - val_loss: 9.5006\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0292 - val_loss: 9.0407\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0220 - val_loss: 9.3640\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3668 - val_loss: 9.2656\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0249 - val_loss: 9.5457\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9428 - val_loss: 8.9168\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9741 - val_loss: 8.8128\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0180 - val_loss: 9.3823\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9356 - val_loss: 9.7689\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0505 - val_loss: 8.7800\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9453 - val_loss: 8.8653\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8531 - val_loss: 9.1294\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6553 - val_loss: 8.7535\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8522 - val_loss: 8.9163\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9032 - val_loss: 9.4145\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9031 - val_loss: 9.6296\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.6848 - val_loss: 9.2300\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0011 - val_loss: 9.1581\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.9677 - val_loss: 9.1553\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.8497 - val_loss: 9.9766\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.9649 - val_loss: 10.2688\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.4939 - val_loss: 8.8896\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0272 - val_loss: 9.4590\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9595 - val_loss: 9.5770\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8742 - val_loss: 9.3284\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9385 - val_loss: 11.5701\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6169 - val_loss: 9.3789\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7463 - val_loss: 9.1197\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8088 - val_loss: 9.4208\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7280 - val_loss: 9.5268\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7576 - val_loss: 10.3899\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2227 - val_loss: 10.2468\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6623 - val_loss: 8.8262\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8736 - val_loss: 8.8470\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1043 - val_loss: 8.7855\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9528 - val_loss: 9.7793\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7346 - val_loss: 8.9038\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9969 - val_loss: 8.7242\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8415 - val_loss: 10.6678\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2039 - val_loss: 9.4621\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7342 - val_loss: 9.1798\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8020 - val_loss: 9.4425\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3178 - val_loss: 9.7378\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0578 - val_loss: 8.9638\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1002 - val_loss: 9.3731\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8970 - val_loss: 8.7290\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5378 - val_loss: 8.6568\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0110 - val_loss: 8.5834\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0383 - val_loss: 9.1087\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8374 - val_loss: 9.1125\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8432 - val_loss: 8.6475\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2630 - val_loss: 9.3956\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3438 - val_loss: 9.4398\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0622 - val_loss: 9.0173\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7246 - val_loss: 8.8534\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8111 - val_loss: 9.1885\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8766 - val_loss: 9.2841\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8885 - val_loss: 10.0621\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8165 - val_loss: 9.4736\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0657 - val_loss: 9.5535\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2358 - val_loss: 8.7040\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9011 - val_loss: 8.9937\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7557 - val_loss: 9.4572\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5068 - val_loss: 8.7344\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0624 - val_loss: 8.9338\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2208 - val_loss: 8.8539\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9266 - val_loss: 11.1744\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2241 - val_loss: 9.6210\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9387 - val_loss: 9.0666\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0163 - val_loss: 8.7336\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7504 - val_loss: 8.8551\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6579 - val_loss: 8.8221\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1506 - val_loss: 9.2852\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8256 - val_loss: 9.1451\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2450 - val_loss: 9.4107\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4477 - val_loss: 8.8897\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8150 - val_loss: 8.9394\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7528 - val_loss: 8.7921\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0377 - val_loss: 10.2303\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4019 - val_loss: 8.8572\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2457 - val_loss: 8.8850\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9791 - val_loss: 9.1299\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6540 - val_loss: 9.6955\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6647 - val_loss: 8.4872\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8461 - val_loss: 8.5985\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8652 - val_loss: 8.6333\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.8806 - val_loss: 8.8030\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.8466 - val_loss: 9.8916\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1973 - val_loss: 8.6992\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8680 - val_loss: 10.1836\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2165 - val_loss: 9.1576\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1535 - val_loss: 8.8286\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8672 - val_loss: 8.6708\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8243 - val_loss: 9.0850\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7586 - val_loss: 8.9572\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5079 - val_loss: 10.4223\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2452 - val_loss: 9.3738\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0877 - val_loss: 8.4589\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4709 - val_loss: 9.3407\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8696 - val_loss: 9.0367\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8452 - val_loss: 9.6849\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1402 - val_loss: 9.4014\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8658 - val_loss: 9.4974\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1963 - val_loss: 9.0229\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2385 - val_loss: 8.4702\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0222 - val_loss: 8.8858\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0079 - val_loss: 10.3000\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8623 - val_loss: 8.7199\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.9739 - val_loss: 8.7850\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9414 - val_loss: 9.4185\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6936 - val_loss: 8.3736\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8867 - val_loss: 8.8520\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9377 - val_loss: 8.6912\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9525 - val_loss: 11.7110\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7786 - val_loss: 9.2586\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.8068 - val_loss: 8.4412\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0575 - val_loss: 9.6238\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0144 - val_loss: 8.9919\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1695 - val_loss: 8.5298\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8059 - val_loss: 9.9867\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3148 - val_loss: 9.7532\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8287 - val_loss: 8.7896\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0415 - val_loss: 8.7632\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0705 - val_loss: 8.6678\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9012 - val_loss: 8.9688\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0872 - val_loss: 9.5392\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9961 - val_loss: 9.5780\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2905 - val_loss: 9.2193\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8356 - val_loss: 9.0708\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9368 - val_loss: 9.3346\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8890 - val_loss: 8.4308\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4357 - val_loss: 11.8364\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9613 - val_loss: 10.3700\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2236 - val_loss: 11.1005\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1120 - val_loss: 8.9238\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1608 - val_loss: 9.9156\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7586 - val_loss: 8.5909\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8743 - val_loss: 8.6729\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7186 - val_loss: 8.4182\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5312 - val_loss: 8.8898\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8840 - val_loss: 8.7420\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8036 - val_loss: 11.0801\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9854 - val_loss: 8.5613\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3831 - val_loss: 9.1890\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8666 - val_loss: 11.0866\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3643 - val_loss: 9.1057\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6956 - val_loss: 8.9561\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6754 - val_loss: 8.2606\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9577 - val_loss: 8.8665\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9553 - val_loss: 8.6075\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1531 - val_loss: 9.1706\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8091 - val_loss: 8.8419\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7152 - val_loss: 9.6457\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1648 - val_loss: 8.5897\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7121 - val_loss: 8.7003\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.6397 - val_loss: 14.3278\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7048 - val_loss: 10.3341\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7971 - val_loss: 8.7638\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1969 - val_loss: 12.3759\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3319 - val_loss: 9.0964\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8923 - val_loss: 8.7027\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7031 - val_loss: 8.8279\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.0115 - val_loss: 8.7815\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8384 - val_loss: 9.0156\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.5644 - val_loss: 9.8794\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5597 - val_loss: 9.8214\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9038 - val_loss: 8.5634\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8474 - val_loss: 8.8303\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1925 - val_loss: 9.1308\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6809 - val_loss: 8.9122\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8529 - val_loss: 8.4969\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6143 - val_loss: 8.4571\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8504 - val_loss: 9.0684\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9457 - val_loss: 9.5336\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5292 - val_loss: 10.0086\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8638 - val_loss: 9.8935\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6798 - val_loss: 8.7952\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.8894 - val_loss: 8.6487\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.9426 - val_loss: 8.7529\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.7911 - val_loss: 9.1735\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8238 - val_loss: 9.0730\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7774 - val_loss: 10.5351\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.8684 - val_loss: 10.4596\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7511 - val_loss: 8.6970\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7682 - val_loss: 9.4817\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0409 - val_loss: 9.2802\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1075 - val_loss: 9.7548\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.9888 - val_loss: 9.2596\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5767 - val_loss: 8.6386\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8295 - val_loss: 9.2805\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8442 - val_loss: 8.6679\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1174 - val_loss: 8.6210\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7697 - val_loss: 8.6721\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9229 - val_loss: 8.8586\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7506 - val_loss: 8.5761\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8989 - val_loss: 9.2180\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5239 - val_loss: 9.6745\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0724 - val_loss: 10.2293\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.7568 - val_loss: 9.2117\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9787 - val_loss: 8.8219\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7964 - val_loss: 9.5306\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9615 - val_loss: 8.5443\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2279 - val_loss: 8.6298\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7250 - val_loss: 9.5772\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0261 - val_loss: 8.8716\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0004 - val_loss: 9.1923\n",
      "7.327037382969814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.16869591, -4.5830703 ,  0.21853624,  0.34685877,  2.134072  ,\n",
       "         -0.52742636,  4.362717  ,  0.20580088,  0.24192305, -0.25082925],\n",
       "        [ 0.14573134,  0.13558641,  0.0393726 ,  0.15022649, -0.24018942,\n",
       "         -1.3695341 ,  0.21921332,  0.03771839,  0.04177385, -0.04437679],\n",
       "        [ 0.28876925, -1.1104798 ,  0.3465955 ,  0.45129636, -0.23567395,\n",
       "         -1.6067374 ,  0.36886227,  0.34542382,  0.339256  , -0.35149327],\n",
       "        [ 0.34279472,  0.19039941, -0.9646872 , -0.17773917, -0.07163884,\n",
       "          0.24728714, -0.14898492, -0.96232986, -0.93833876,  0.96948516],\n",
       "        [ 0.20692174, -0.28288946,  0.44806746,  0.49227995,  0.2068768 ,\n",
       "          0.50140893,  3.5404427 ,  0.4430999 ,  0.44466478, -0.4614763 ]],\n",
       "       dtype=float32),\n",
       " array([-3.872446  , -5.503177  , -4.111775  , -0.6098754 ,  1.1344056 ,\n",
       "        -0.97056836,  5.187788  , -4.2110896 , -4.176836  ,  3.9304414 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.3923874e+00, -1.1029625e+00,  1.2223166e+00,  1.4514405e+00,\n",
       "         -1.2398922e+00,  2.2947349e-04, -7.6066357e-01,  1.0698818e+00,\n",
       "         -9.0779036e-01,  1.1742592e+00],\n",
       "        [ 1.5704627e+00, -1.8050007e+00,  2.0242550e+00,  2.3663945e+00,\n",
       "         -2.1846659e+00,  1.8703775e+00, -1.3290417e+00,  2.2896607e+00,\n",
       "         -2.2517626e+00,  1.3689981e+00],\n",
       "        [ 1.1556432e+00, -1.4157474e+00,  8.4534550e-01,  7.6667112e-01,\n",
       "         -1.0116992e+00,  1.9904384e-01, -7.8392655e-01,  1.3659192e+00,\n",
       "         -1.4647653e+00,  1.0150459e+00],\n",
       "        [ 1.0128042e+00, -4.9473935e-01,  6.0361755e-01,  1.5203680e-01,\n",
       "         -4.6928117e-01, -3.3379212e-01, -6.1715144e-01,  2.9769412e-01,\n",
       "         -8.6451471e-01,  9.1817600e-01],\n",
       "        [ 9.7671747e-01, -1.9246483e-01,  8.7762892e-01,  8.5638016e-01,\n",
       "         -8.4663796e-01,  1.7602438e-01, -7.9614282e-01,  2.3359860e-01,\n",
       "         -6.4612710e-01,  4.5109162e-01],\n",
       "        [ 5.2452434e-02,  9.5416820e-01, -8.3492815e-01, -8.4320432e-01,\n",
       "          4.9029130e-01, -5.1223993e-01,  4.5473152e-01, -3.3338434e-01,\n",
       "         -1.2528920e-01, -6.0820711e-01],\n",
       "        [-5.3106207e-01,  5.5266559e-01, -1.0789669e+00, -8.7522113e-01,\n",
       "          2.7149367e-01,  1.7529498e-01,  1.9901757e-01, -7.6565903e-01,\n",
       "          9.4518989e-01, -1.2807232e-01],\n",
       "        [ 1.5012157e+00, -1.2756903e+00,  6.6121733e-01,  1.4180840e+00,\n",
       "         -1.2109449e+00,  3.5331205e-01, -9.5859849e-01,  3.9720011e-01,\n",
       "         -1.5104389e+00,  7.9465640e-01],\n",
       "        [ 1.1126115e+00, -8.2785416e-01,  1.7383384e+00,  1.7867092e+00,\n",
       "         -9.8854905e-01,  1.0001818e+00, -5.0537324e-01,  1.5070783e+00,\n",
       "         -1.3409154e+00,  1.0893536e+00],\n",
       "        [-1.2879064e+00,  1.0718778e+00, -1.5000777e+00, -1.5071639e+00,\n",
       "          1.0417253e+00, -6.0464382e-01,  5.6896621e-01, -7.0783454e-01,\n",
       "          6.6145986e-01, -9.0067452e-01]], dtype=float32),\n",
       " array([-1.7864723,  1.7458553, -1.8224072, -1.8480237,  1.7041183,\n",
       "        -1.2564114,  1.4522282, -1.6869788,  1.8531739, -1.6982784],\n",
       "       dtype=float32),\n",
       " array([[-1.5100183 ],\n",
       "        [ 1.3298726 ],\n",
       "        [-1.6034814 ],\n",
       "        [-1.7516365 ],\n",
       "        [ 1.2280858 ],\n",
       "        [-0.5182408 ],\n",
       "        [ 0.71961117],\n",
       "        [-1.2109622 ],\n",
       "        [ 1.7701172 ],\n",
       "        [-1.1663871 ]], dtype=float32),\n",
       " array([2.1512187], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_5(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure5_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 255us/step - loss: 6245.8909 - val_loss: 664.9625\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 139.6237 - val_loss: 35.5458\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 30.5677 - val_loss: 26.8163\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.9055 - val_loss: 23.6879\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.4093 - val_loss: 23.0502\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.9693 - val_loss: 22.2076\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3647 - val_loss: 21.6599\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8175 - val_loss: 21.5681\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2619 - val_loss: 21.5638\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9582 - val_loss: 21.4546\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9046 - val_loss: 20.7564\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.6570 - val_loss: 20.4997\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.6325 - val_loss: 20.2820\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.5096 - val_loss: 19.9051\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.3099 - val_loss: 19.8044\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1357 - val_loss: 20.4592\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.1935 - val_loss: 19.3631\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.7928 - val_loss: 19.1787\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.6414 - val_loss: 18.7733\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.8113 - val_loss: 19.2197\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2761 - val_loss: 18.6602\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.4275 - val_loss: 18.2963\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0279 - val_loss: 18.0557\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3016 - val_loss: 18.5712\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8973 - val_loss: 17.8878\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6207 - val_loss: 18.3072\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 14.7143 - val_loss: 17.8724\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 14.7381 - val_loss: 18.2931\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 15.2431 - val_loss: 17.3078\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.0770 - val_loss: 17.1171\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.6779 - val_loss: 17.6398\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.7204 - val_loss: 18.5010\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.5206 - val_loss: 16.8936\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.2279 - val_loss: 16.6360\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9315 - val_loss: 16.8884\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.2995 - val_loss: 17.4444\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9212 - val_loss: 17.5208\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5238 - val_loss: 17.4653\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.7792 - val_loss: 16.5999\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9925 - val_loss: 16.0306\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7976 - val_loss: 16.3942\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9725 - val_loss: 15.9076\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8030 - val_loss: 17.3369\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9478 - val_loss: 15.7821\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7023 - val_loss: 15.7140\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.4669 - val_loss: 15.7581\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5942 - val_loss: 16.2404\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0628 - val_loss: 15.6853\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8005 - val_loss: 17.3761\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6550 - val_loss: 15.5673\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4379 - val_loss: 15.2602\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.4789 - val_loss: 15.4859\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3640 - val_loss: 15.0488\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5731 - val_loss: 15.2280\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9924 - val_loss: 15.2382\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2875 - val_loss: 16.4614\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.5491 - val_loss: 17.4833\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2368 - val_loss: 15.2399\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.7030 - val_loss: 14.8359\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0495 - val_loss: 16.4393\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2914 - val_loss: 15.5387\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.0407 - val_loss: 15.0301\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.2380 - val_loss: 15.5693\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1438 - val_loss: 15.0004\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7116 - val_loss: 16.0660\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1679 - val_loss: 14.4448\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.8849 - val_loss: 14.6735\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.4410 - val_loss: 14.8840\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.8463 - val_loss: 14.6931\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5069 - val_loss: 14.3315\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.3790 - val_loss: 14.0956\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5050 - val_loss: 14.2997\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6325 - val_loss: 13.8672\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3889 - val_loss: 15.8649\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4547 - val_loss: 13.8593\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6060 - val_loss: 14.7240\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5283 - val_loss: 15.7683\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7902 - val_loss: 15.0772\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5019 - val_loss: 14.2028\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1738 - val_loss: 13.5012\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0963 - val_loss: 13.5613\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5109 - val_loss: 13.4482\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7932 - val_loss: 14.1218\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4428 - val_loss: 14.4432\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3770 - val_loss: 13.2434\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3261 - val_loss: 13.4790\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6104 - val_loss: 15.7268\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7442 - val_loss: 12.8519\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5508 - val_loss: 14.3425\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.2512 - val_loss: 12.2135\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4613 - val_loss: 14.6119\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4532 - val_loss: 12.6265\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4219 - val_loss: 11.9198\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6253 - val_loss: 12.9527\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0345 - val_loss: 12.0199\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.0666 - val_loss: 12.2647\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2526 - val_loss: 12.1041\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1761 - val_loss: 12.1782\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8639 - val_loss: 12.5264\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9396 - val_loss: 11.9042\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7093 - val_loss: 11.8223\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2416 - val_loss: 12.1527\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8307 - val_loss: 12.2407\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5949 - val_loss: 12.1797\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8945 - val_loss: 11.7468\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7985 - val_loss: 12.1380\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2944 - val_loss: 11.4183\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4340 - val_loss: 11.7435\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0462 - val_loss: 12.8786\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.4528 - val_loss: 11.4696\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3835 - val_loss: 11.8132\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3781 - val_loss: 11.5690\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8293 - val_loss: 11.9534\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0509 - val_loss: 10.9524\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1881 - val_loss: 11.5235\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6622 - val_loss: 11.3360\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8855 - val_loss: 11.7268\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6701 - val_loss: 10.9405\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6147 - val_loss: 10.2554\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5488 - val_loss: 11.5382\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4310 - val_loss: 12.5521\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3599 - val_loss: 10.4596\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5865 - val_loss: 11.2135\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3547 - val_loss: 11.3789\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4195 - val_loss: 12.4325\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3449 - val_loss: 11.6750\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4237 - val_loss: 11.4751\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7108 - val_loss: 9.9856\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6171 - val_loss: 11.5287\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5476 - val_loss: 10.1299\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7486 - val_loss: 10.1209\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0371 - val_loss: 10.9448\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6980 - val_loss: 10.7850\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3282 - val_loss: 9.9880\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8134 - val_loss: 10.0361\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8466 - val_loss: 10.1237\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8050 - val_loss: 11.6487\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1573 - val_loss: 9.6857\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0837 - val_loss: 10.4619\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9564 - val_loss: 10.2021\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3661 - val_loss: 10.5009\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.5473 - val_loss: 10.4240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2733 - val_loss: 10.1605\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4915 - val_loss: 11.6016\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8348 - val_loss: 9.9954\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4765 - val_loss: 10.3518\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.3667 - val_loss: 9.2169\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5000 - val_loss: 9.0866\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1656 - val_loss: 9.3191\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5301 - val_loss: 10.6372\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4282 - val_loss: 9.4615\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3780 - val_loss: 9.1674\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4604 - val_loss: 10.0235\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9727 - val_loss: 11.5193\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7575 - val_loss: 8.8128\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2904 - val_loss: 9.0029\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2823 - val_loss: 8.9075\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6768 - val_loss: 11.3366\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1138 - val_loss: 9.4837\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6140 - val_loss: 10.2524\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5097 - val_loss: 13.0628\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5906 - val_loss: 8.9881\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3287 - val_loss: 9.4454\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3991 - val_loss: 11.3161\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7125 - val_loss: 8.8283\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9073 - val_loss: 9.6177\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3568 - val_loss: 9.6028\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7704 - val_loss: 10.3883\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8947 - val_loss: 8.8668\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3607 - val_loss: 11.1839\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1956 - val_loss: 10.4212\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3047 - val_loss: 9.7841\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8275 - val_loss: 9.5595\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9008 - val_loss: 9.1633\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0314 - val_loss: 8.4144\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8373 - val_loss: 8.6886\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9624 - val_loss: 8.7806\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2545 - val_loss: 10.2553\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3935 - val_loss: 10.9506\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2911 - val_loss: 9.0975\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8726 - val_loss: 9.1418\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9931 - val_loss: 8.4794\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8063 - val_loss: 8.7449\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7257 - val_loss: 8.5484\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1657 - val_loss: 8.7598\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0819 - val_loss: 8.5645\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7598 - val_loss: 9.1815\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8694 - val_loss: 8.8701\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8792 - val_loss: 9.5662\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8147 - val_loss: 8.8000\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4308 - val_loss: 10.1713\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9245 - val_loss: 8.3741\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1194 - val_loss: 9.6608\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2904 - val_loss: 11.6070\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1244 - val_loss: 8.6072\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5440 - val_loss: 9.8333\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2774 - val_loss: 9.2958\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8021 - val_loss: 8.7927\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1190 - val_loss: 9.2221\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8974 - val_loss: 9.2218\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6505 - val_loss: 8.2860\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7190 - val_loss: 8.4450\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2586 - val_loss: 9.2334\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7712 - val_loss: 8.3200\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9521 - val_loss: 8.6078\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3152 - val_loss: 9.0715\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2699 - val_loss: 9.4383\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9279 - val_loss: 8.8599\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7342 - val_loss: 8.8919\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7135 - val_loss: 10.8287\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5759 - val_loss: 8.7650\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9774 - val_loss: 9.1880\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0810 - val_loss: 8.8105\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7520 - val_loss: 9.2090\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7781 - val_loss: 8.5805\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8055 - val_loss: 9.7784\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4633 - val_loss: 9.0020\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6060 - val_loss: 8.6368\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8027 - val_loss: 8.8921\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8732 - val_loss: 8.8576\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6781 - val_loss: 8.6292\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6264 - val_loss: 8.6966\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8540 - val_loss: 9.1595\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7316 - val_loss: 8.9397\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9613 - val_loss: 8.6367\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1696 - val_loss: 10.2898\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5281 - val_loss: 8.3528\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9642 - val_loss: 10.8724\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1212 - val_loss: 8.9515\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7940 - val_loss: 8.9339\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5766 - val_loss: 11.3712\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7893 - val_loss: 8.6308\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6599 - val_loss: 8.2956\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0991 - val_loss: 13.1204\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1011 - val_loss: 9.1810\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7200 - val_loss: 8.5090\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9738 - val_loss: 8.3586\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0762 - val_loss: 8.4188\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5666 - val_loss: 8.8426\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3138 - val_loss: 8.9514\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2812 - val_loss: 8.8086\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8670 - val_loss: 8.5611\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3331 - val_loss: 11.5992\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5719 - val_loss: 9.5163\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8324 - val_loss: 8.7801\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5295 - val_loss: 8.6953\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2743 - val_loss: 9.7787\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6586 - val_loss: 10.3381\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4862 - val_loss: 8.9830\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5581 - val_loss: 9.2650\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8616 - val_loss: 9.4655\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3435 - val_loss: 8.9824\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7001 - val_loss: 9.3069\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8810 - val_loss: 8.5209\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5622 - val_loss: 10.5968\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3857 - val_loss: 8.2568\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0269 - val_loss: 8.8889\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7734 - val_loss: 8.2493\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2625 - val_loss: 8.6048\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9186 - val_loss: 10.6764\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8800 - val_loss: 8.6619\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6778 - val_loss: 8.8882\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7670 - val_loss: 8.5368\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2757 - val_loss: 8.4417\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5109 - val_loss: 8.3161\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1871 - val_loss: 8.6279\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2337 - val_loss: 8.0827\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3088 - val_loss: 8.3773\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5105 - val_loss: 8.3384\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0880 - val_loss: 8.7318\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4158 - val_loss: 8.2538\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1916 - val_loss: 9.1142\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3496 - val_loss: 8.2652\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2584 - val_loss: 9.6544\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9666 - val_loss: 9.2141\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8243 - val_loss: 10.2275\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3811 - val_loss: 9.1741\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2316 - val_loss: 8.5072\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6900 - val_loss: 9.3460\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1817 - val_loss: 8.7994\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4663 - val_loss: 8.1540\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.4481 - val_loss: 8.9669\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.2473 - val_loss: 8.4295\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2588 - val_loss: 8.8684\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6658 - val_loss: 8.9132\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8001 - val_loss: 9.2700\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0746 - val_loss: 8.3865\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7453 - val_loss: 9.1571\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4133 - val_loss: 8.1808\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8601 - val_loss: 8.9095\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5108 - val_loss: 8.7655\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4099 - val_loss: 8.8002\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6083 - val_loss: 9.7806\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5602 - val_loss: 8.4021\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6856 - val_loss: 9.9444\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7588 - val_loss: 8.6988\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6054 - val_loss: 8.8464\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0572 - val_loss: 8.2975\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2954 - val_loss: 9.9817\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2068 - val_loss: 8.4897\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1954 - val_loss: 9.0634\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4489 - val_loss: 8.8754\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0611 - val_loss: 9.6904\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2876 - val_loss: 9.7811\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1461 - val_loss: 8.5040\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0575 - val_loss: 8.8886\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6487 - val_loss: 9.3102\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3605 - val_loss: 9.0576\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8943 - val_loss: 8.4191\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0099 - val_loss: 8.2754\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1538 - val_loss: 8.9337\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.0233 - val_loss: 9.5843\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.3890 - val_loss: 8.0772\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.3806 - val_loss: 8.2816\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1289 - val_loss: 8.5701\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.2964 - val_loss: 8.6742\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7778 - val_loss: 8.7599\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.3770 - val_loss: 8.3818\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3411 - val_loss: 8.5148\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0385 - val_loss: 8.9148\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2270 - val_loss: 8.5661\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6614 - val_loss: 8.9920\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2421 - val_loss: 8.8708\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1806 - val_loss: 8.0879\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0919 - val_loss: 9.0510\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2352 - val_loss: 8.4789\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0937 - val_loss: 8.4448\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2237 - val_loss: 9.2723\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2658 - val_loss: 7.9795\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2402 - val_loss: 8.7543\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3792 - val_loss: 8.5092\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2984 - val_loss: 8.5253\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5170 - val_loss: 9.0203\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5038 - val_loss: 8.5570\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1651 - val_loss: 8.9718\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2663 - val_loss: 9.2184\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4522 - val_loss: 9.6609\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0735 - val_loss: 8.6905\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1766 - val_loss: 8.2740\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2644 - val_loss: 8.4186\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0415 - val_loss: 8.2327\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1668 - val_loss: 8.4124\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2508 - val_loss: 9.1394\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3495 - val_loss: 10.1372\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.0941 - val_loss: 8.7841\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6763 - val_loss: 11.2171\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1249 - val_loss: 8.4441\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6960 - val_loss: 9.7812\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1043 - val_loss: 8.7614\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3475 - val_loss: 8.0317\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2088 - val_loss: 10.1641\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1006 - val_loss: 9.8398\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0724 - val_loss: 8.7696\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1059 - val_loss: 11.0085\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1773 - val_loss: 8.2823\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.2379 - val_loss: 8.7679\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.2746 - val_loss: 10.1331\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8788 - val_loss: 8.4296\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.3806 - val_loss: 8.1224\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0201 - val_loss: 8.3100\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2267 - val_loss: 7.9102\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8691 - val_loss: 7.9749\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0113 - val_loss: 8.2646\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0479 - val_loss: 8.3958\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1783 - val_loss: 8.2345\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1143 - val_loss: 8.5918\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8494 - val_loss: 8.7627\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5776 - val_loss: 8.5995\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7786 - val_loss: 9.1060\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1440 - val_loss: 8.8773\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2524 - val_loss: 8.0903\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3501 - val_loss: 8.7693\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9894 - val_loss: 9.0655\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3855 - val_loss: 8.0003\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.2160 - val_loss: 8.2150\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4104 - val_loss: 8.2621\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3998 - val_loss: 11.1546\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2101 - val_loss: 8.0225\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1192 - val_loss: 8.0284\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8123 - val_loss: 9.1824\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8113 - val_loss: 8.2012\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3778 - val_loss: 9.9836\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.2826 - val_loss: 8.0952\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.5454 - val_loss: 10.9528\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.3616 - val_loss: 8.8529\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.9239 - val_loss: 7.9519\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1564 - val_loss: 8.7493\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9399 - val_loss: 8.2799\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0531 - val_loss: 9.1559\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0319 - val_loss: 8.0268\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1621 - val_loss: 8.4915\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1841 - val_loss: 10.7539\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5334 - val_loss: 7.9381\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8420 - val_loss: 8.1394\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.1148 - val_loss: 8.7386\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.1213 - val_loss: 8.1022\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.1058 - val_loss: 9.3209\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.2855 - val_loss: 8.1764\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5061 - val_loss: 8.6442\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9910 - val_loss: 9.0015\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9963 - val_loss: 8.3628\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1191 - val_loss: 10.2704\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1649 - val_loss: 7.8511\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6365 - val_loss: 8.1486\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0493 - val_loss: 9.4063\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.8292 - val_loss: 8.1506\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.3766 - val_loss: 8.1155\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2066 - val_loss: 7.7989\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3074 - val_loss: 8.6719\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9642 - val_loss: 8.2629\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1767 - val_loss: 8.1031\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1158 - val_loss: 8.3534\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1908 - val_loss: 9.4994\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4409 - val_loss: 8.8317\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1981 - val_loss: 9.3037\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.3340 - val_loss: 8.1555\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.1441 - val_loss: 10.7627\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.1511 - val_loss: 8.4838\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8535 - val_loss: 8.0161\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.3904 - val_loss: 8.4300\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6899 - val_loss: 9.6641\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3997 - val_loss: 8.1313\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8165 - val_loss: 8.3585\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9585 - val_loss: 8.6169\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8475 - val_loss: 8.5567\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.2250 - val_loss: 8.7947\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.0675 - val_loss: 8.3041\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.0116 - val_loss: 8.3001\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0932 - val_loss: 8.0209\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9826 - val_loss: 9.5715\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5845 - val_loss: 9.8143\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.2861 - val_loss: 8.6147\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.0654 - val_loss: 8.7957\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9240 - val_loss: 8.4493\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0448 - val_loss: 8.4644\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9636 - val_loss: 7.7287\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.1695 - val_loss: 8.6813\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6967 - val_loss: 8.2156\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8779 - val_loss: 7.9206\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3280 - val_loss: 8.1672\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0426 - val_loss: 8.4634\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1756 - val_loss: 8.1493\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.9023 - val_loss: 8.5863\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9091 - val_loss: 7.8652\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5737 - val_loss: 9.1159\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1079 - val_loss: 8.5617\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.8295 - val_loss: 7.8712\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.1870 - val_loss: 8.4880\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.1340 - val_loss: 8.7921\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.1282 - val_loss: 9.6255\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5050 - val_loss: 9.5300\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6649 - val_loss: 8.2846\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2491 - val_loss: 8.3517\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1095 - val_loss: 8.8948\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.755 - 0s 96us/step - loss: 7.4384 - val_loss: 7.9820\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1417 - val_loss: 8.1645\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2801 - val_loss: 7.7369\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3224 - val_loss: 8.6998\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.1592 - val_loss: 8.2387\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1303 - val_loss: 8.0801\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 127us/step - loss: 7.2754 - val_loss: 8.2973\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1065 - val_loss: 8.9654\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1330 - val_loss: 8.2322\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5192 - val_loss: 8.1866\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3374 - val_loss: 11.1187\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9854 - val_loss: 9.5215\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1379 - val_loss: 7.6402\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4211 - val_loss: 8.4414\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0162 - val_loss: 7.8664\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9409 - val_loss: 8.0972\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2063 - val_loss: 8.7678\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5202 - val_loss: 9.2397\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6487 - val_loss: 10.7408\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4065 - val_loss: 8.8242\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4383 - val_loss: 8.2262\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.1457 - val_loss: 8.5546\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.0684 - val_loss: 8.1115\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.1439 - val_loss: 7.7308\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.0095 - val_loss: 8.4619\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.1977 - val_loss: 8.7124\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.0119 - val_loss: 9.5054\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.2934 - val_loss: 8.3219\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.9018 - val_loss: 8.0792\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1493 - val_loss: 7.7637\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7768 - val_loss: 8.1972\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2150 - val_loss: 8.3505\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9113 - val_loss: 7.8718\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9263 - val_loss: 8.4261\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9099 - val_loss: 7.6990\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2564 - val_loss: 8.4829\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2129 - val_loss: 7.7923\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8033 - val_loss: 8.4469\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0636 - val_loss: 8.4788\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8935 - val_loss: 8.1387\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9573 - val_loss: 9.1985\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9597 - val_loss: 7.8637\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2680 - val_loss: 10.3553\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0980 - val_loss: 9.9936\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4522 - val_loss: 8.9458\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2780 - val_loss: 9.8412\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2144 - val_loss: 9.5720\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7643 - val_loss: 11.7334\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8887 - val_loss: 8.0069\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0086 - val_loss: 10.1864\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0442 - val_loss: 9.9082\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4445 - val_loss: 8.0260\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9205 - val_loss: 8.4997\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9573 - val_loss: 8.7030\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5227 - val_loss: 8.1483\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9063 - val_loss: 8.3438\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7238 - val_loss: 8.1143\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7705 - val_loss: 8.5367\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2834 - val_loss: 10.9942\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7808 - val_loss: 7.8074\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9898 - val_loss: 8.1935\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8899 - val_loss: 8.2299\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4063 - val_loss: 8.3173\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3680 - val_loss: 8.2044\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7845 - val_loss: 8.3495\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1599 - val_loss: 7.8752\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6646 - val_loss: 8.8029\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6201 - val_loss: 8.2143\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8074 - val_loss: 8.8387\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9299 - val_loss: 9.1158\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0065 - val_loss: 7.8557\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0737 - val_loss: 8.8549\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9102 - val_loss: 8.8403\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8503 - val_loss: 8.0288\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9759 - val_loss: 8.1357\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4528 - val_loss: 8.0586\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2634 - val_loss: 8.6973\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1122 - val_loss: 8.0639\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.7851 - val_loss: 8.4441\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7380 - val_loss: 8.0483\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7424 - val_loss: 8.3446\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6203 - val_loss: 9.1827\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4961 - val_loss: 9.3471\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4992 - val_loss: 9.5655\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1939 - val_loss: 8.1527\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2833 - val_loss: 7.7042\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9101 - val_loss: 7.9584\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0482 - val_loss: 7.9850\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0965 - val_loss: 9.1055\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.8660 - val_loss: 7.9168\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0944 - val_loss: 8.5345\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9928 - val_loss: 9.3557\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9649 - val_loss: 8.8620\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0227 - val_loss: 9.5632\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1342 - val_loss: 9.2501\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5890 - val_loss: 7.8529\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0875 - val_loss: 11.3135\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3026 - val_loss: 9.6243\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9932 - val_loss: 8.0801\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6751 - val_loss: 9.7642\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3182 - val_loss: 9.1444\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0405 - val_loss: 8.9750\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8037 - val_loss: 7.7054\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9923 - val_loss: 8.3442\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3500 - val_loss: 8.5127\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9905 - val_loss: 8.4399\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9828 - val_loss: 8.2427\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3849 - val_loss: 8.1278\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9535 - val_loss: 9.6325\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2959 - val_loss: 8.4661\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0296 - val_loss: 8.5513\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4681 - val_loss: 7.9108\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9878 - val_loss: 9.3937\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4234 - val_loss: 7.7324\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5059 - val_loss: 10.0529\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.9420 - val_loss: 8.2111\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8645 - val_loss: 8.1670\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8370 - val_loss: 7.4782\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9565 - val_loss: 8.2142\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1299 - val_loss: 8.6548\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0214 - val_loss: 7.9414\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3593 - val_loss: 8.3238\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9292 - val_loss: 8.3591\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0436 - val_loss: 9.1887\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2046 - val_loss: 8.6338\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0822 - val_loss: 7.8872\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8964 - val_loss: 8.8727\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0308 - val_loss: 8.9770\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8830 - val_loss: 8.4122\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0020 - val_loss: 12.1008\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0431 - val_loss: 10.9980\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3770 - val_loss: 8.5814\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9399 - val_loss: 8.0017\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7476 - val_loss: 7.9049\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1205 - val_loss: 8.4445\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0439 - val_loss: 7.9320\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2921 - val_loss: 10.2726\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1839 - val_loss: 8.5110\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0419 - val_loss: 8.9500\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2517 - val_loss: 9.5431\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3563 - val_loss: 7.7354\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1917 - val_loss: 8.7157\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6926 - val_loss: 8.5007\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9531 - val_loss: 8.7795\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1763 - val_loss: 8.0852\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0127 - val_loss: 8.3425\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9239 - val_loss: 7.6967\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0073 - val_loss: 7.8207\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1629 - val_loss: 10.2555\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3465 - val_loss: 10.4141\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9241 - val_loss: 7.9673\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2750 - val_loss: 8.5936\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1834 - val_loss: 9.1962\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9247 - val_loss: 7.7816\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8963 - val_loss: 8.4282\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1422 - val_loss: 7.6324\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8199 - val_loss: 11.0181\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2306 - val_loss: 8.8168\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8757 - val_loss: 7.7827\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8109 - val_loss: 8.7068\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8360 - val_loss: 8.9327\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0914 - val_loss: 8.9474\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2888 - val_loss: 8.7193\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0828 - val_loss: 8.2998\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0140 - val_loss: 8.3277\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9228 - val_loss: 8.5110\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1966 - val_loss: 8.4685\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4274 - val_loss: 7.7518\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9211 - val_loss: 9.1649\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0385 - val_loss: 8.6407\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5466 - val_loss: 7.8668\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9857 - val_loss: 7.7821\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8555 - val_loss: 8.7200\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8474 - val_loss: 8.4272\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0748 - val_loss: 7.9380\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8621 - val_loss: 7.7620\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7737 - val_loss: 10.6687\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1869 - val_loss: 8.7519\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1548 - val_loss: 10.2035\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6228 - val_loss: 7.6057\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0268 - val_loss: 8.7430\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0225 - val_loss: 11.0465\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1616 - val_loss: 8.9166\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9267 - val_loss: 8.9469\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7879 - val_loss: 9.7284\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4847 - val_loss: 7.9873\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2554 - val_loss: 9.4959\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2933 - val_loss: 8.8415\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3706 - val_loss: 9.0001\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1686 - val_loss: 9.1307\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9899 - val_loss: 11.9977\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.4308 - val_loss: 7.7511\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.0878 - val_loss: 9.8805\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4688 - val_loss: 9.1523\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.8775 - val_loss: 7.6890\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.8400 - val_loss: 7.8338\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.9041 - val_loss: 7.4968\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8952 - val_loss: 9.2010\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.0011 - val_loss: 9.2603\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0235 - val_loss: 7.7622\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8377 - val_loss: 7.7997\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2108 - val_loss: 8.1633\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9903 - val_loss: 8.9214\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0256 - val_loss: 8.9976\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.8574 - val_loss: 8.0616\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2188 - val_loss: 8.2155\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8709 - val_loss: 8.6369\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7856 - val_loss: 8.0430\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0331 - val_loss: 7.8267\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3671 - val_loss: 9.0583\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1166 - val_loss: 7.6646\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8871 - val_loss: 8.6815\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0598 - val_loss: 8.1002\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.1421 - val_loss: 9.0843\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0281 - val_loss: 8.1022\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0216 - val_loss: 7.9031\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0350 - val_loss: 7.7614\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6652 - val_loss: 8.5409\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8215 - val_loss: 9.8879\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7722 - val_loss: 8.5186\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4232 - val_loss: 8.1822\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0352 - val_loss: 10.3527\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3796 - val_loss: 8.9096\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3844 - val_loss: 7.8612\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7598 - val_loss: 7.6515\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1497 - val_loss: 10.4485\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1255 - val_loss: 10.1495\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1994 - val_loss: 9.3540\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0552 - val_loss: 9.9312\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0188 - val_loss: 7.9258\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6771 - val_loss: 7.7204\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9497 - val_loss: 7.9847\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0036 - val_loss: 9.0291\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7558 - val_loss: 7.9712\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1233 - val_loss: 7.9055\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7146 - val_loss: 8.1721\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9116 - val_loss: 7.7104\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9254 - val_loss: 9.2874\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8126 - val_loss: 8.8210\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9693 - val_loss: 7.4485\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3062 - val_loss: 8.3174\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0454 - val_loss: 8.4295\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7511 - val_loss: 9.1521\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.8337 - val_loss: 7.6566\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9881 - val_loss: 11.8323\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9560 - val_loss: 10.1347\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9981 - val_loss: 9.1837\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1747 - val_loss: 7.5277\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8950 - val_loss: 10.0417\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9875 - val_loss: 7.8736\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1832 - val_loss: 8.5437\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1942 - val_loss: 7.7237\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8085 - val_loss: 7.9436\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8989 - val_loss: 8.5785\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7435 - val_loss: 7.8816\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7954 - val_loss: 7.8353\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7043 - val_loss: 8.3337\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9854 - val_loss: 8.0048\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2919 - val_loss: 7.8486\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9378 - val_loss: 7.6343\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1067 - val_loss: 9.3936\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9899 - val_loss: 7.5796\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0523 - val_loss: 9.9120\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5436 - val_loss: 10.7225\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2599 - val_loss: 7.7796\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8937 - val_loss: 8.5382\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8930 - val_loss: 8.6053\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3563 - val_loss: 7.8324\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9062 - val_loss: 8.1225\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7785 - val_loss: 9.5030\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0152 - val_loss: 8.6096\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0501 - val_loss: 8.3000\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0372 - val_loss: 8.7809\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5203 - val_loss: 7.9293\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7716 - val_loss: 7.7845\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9145 - val_loss: 7.5356\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3138 - val_loss: 9.2275\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3796 - val_loss: 7.5923\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8637 - val_loss: 7.8572\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3646 - val_loss: 8.5501\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0666 - val_loss: 9.0566\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7951 - val_loss: 7.7354\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6481 - val_loss: 8.6895\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3851 - val_loss: 7.6156\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2791 - val_loss: 8.3086\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0645 - val_loss: 8.0677\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1960 - val_loss: 8.1886\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0370 - val_loss: 8.1892\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0060 - val_loss: 8.2885\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0519 - val_loss: 7.3315\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5346 - val_loss: 7.6615\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9460 - val_loss: 8.0385\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6736 - val_loss: 8.0466\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9536 - val_loss: 7.7153\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8231 - val_loss: 9.4707\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1249 - val_loss: 8.3385\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0505 - val_loss: 7.5105\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9068 - val_loss: 8.1477\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2761 - val_loss: 7.4967\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5195 - val_loss: 8.7371\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1637 - val_loss: 8.0743\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8398 - val_loss: 8.0194\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9569 - val_loss: 8.7062\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4001 - val_loss: 7.5629\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0471 - val_loss: 8.0261\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7800 - val_loss: 10.2392\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8558 - val_loss: 8.5955\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4571 - val_loss: 8.6088\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8685 - val_loss: 7.7946\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6534 - val_loss: 8.1466\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2246 - val_loss: 8.1532\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3108 - val_loss: 7.7679\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3430 - val_loss: 9.3019\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2565 - val_loss: 9.5610\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2869 - val_loss: 9.8541\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1704 - val_loss: 10.4022\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2122 - val_loss: 11.9689\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2962 - val_loss: 9.2485\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9453 - val_loss: 10.6717\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1174 - val_loss: 8.1238\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1601 - val_loss: 8.8865\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1800 - val_loss: 8.9859\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8486 - val_loss: 8.6570\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1578 - val_loss: 9.3608\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8216 - val_loss: 8.2694\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1466 - val_loss: 8.3133\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2530 - val_loss: 7.8697\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8847 - val_loss: 7.6681\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7451 - val_loss: 8.1904\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9052 - val_loss: 9.2278\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8810 - val_loss: 7.6996\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7548 - val_loss: 7.4215\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0314 - val_loss: 8.0739\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1537 - val_loss: 8.0060\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1504 - val_loss: 7.7528\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9296 - val_loss: 7.6393\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7986 - val_loss: 8.6722\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8781 - val_loss: 7.9361\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6613 - val_loss: 8.6876\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7743 - val_loss: 8.8528\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.0096 - val_loss: 7.2756\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7461 - val_loss: 8.2903\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4775 - val_loss: 8.0092\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4438 - val_loss: 9.0014\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4896 - val_loss: 8.2714\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5678 - val_loss: 9.8015\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4112 - val_loss: 8.8270\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2231 - val_loss: 7.7495\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7344 - val_loss: 8.8753\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9392 - val_loss: 11.6211\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4579 - val_loss: 8.3214\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8519 - val_loss: 7.4375\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0673 - val_loss: 8.0539\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7624 - val_loss: 8.4853\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2465 - val_loss: 7.7862\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3968 - val_loss: 7.5359\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9601 - val_loss: 8.4457\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9686 - val_loss: 8.4720\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7989 - val_loss: 7.6786\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0268 - val_loss: 13.2058\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5081 - val_loss: 7.8576\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6586 - val_loss: 8.3983\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.7670 - val_loss: 8.5608\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.9944 - val_loss: 7.8369\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.0470 - val_loss: 8.4030\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.8151 - val_loss: 7.7804\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.6141 - val_loss: 7.6598\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.1833 - val_loss: 7.7473\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1987 - val_loss: 8.6411\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.3002 - val_loss: 7.8316\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8667 - val_loss: 9.8080\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4180 - val_loss: 8.0979\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2152 - val_loss: 7.9259\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9506 - val_loss: 7.5379\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9125 - val_loss: 7.6190\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8266 - val_loss: 8.1846\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0581 - val_loss: 11.5701\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5762 - val_loss: 11.5554\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4976 - val_loss: 8.0586\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8663 - val_loss: 7.5181\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0389 - val_loss: 7.9951\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9602 - val_loss: 8.8146\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8675 - val_loss: 7.8018\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6193 - val_loss: 10.4777\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0017 - val_loss: 7.4241\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3805 - val_loss: 7.8322\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3346 - val_loss: 8.6913\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3195 - val_loss: 7.4955\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7546 - val_loss: 8.6770\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9919 - val_loss: 7.5946\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0170 - val_loss: 7.4769\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9278 - val_loss: 8.2836\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7565 - val_loss: 7.3293\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7364 - val_loss: 7.6694\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6952 - val_loss: 8.6189\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.9224 - val_loss: 9.0271\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8530 - val_loss: 8.4596\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5458 - val_loss: 7.8440\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6672 - val_loss: 7.7631\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9860 - val_loss: 7.8720\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0091 - val_loss: 7.6613\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2375 - val_loss: 7.7272\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9371 - val_loss: 7.4063\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9529 - val_loss: 7.2332\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2832 - val_loss: 7.4015\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0956 - val_loss: 7.3475\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6924 - val_loss: 7.7802\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9793 - val_loss: 7.6085\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8689 - val_loss: 8.5784\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8028 - val_loss: 8.8872\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2978 - val_loss: 7.6567\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7586 - val_loss: 7.5702\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7969 - val_loss: 7.5415\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7908 - val_loss: 7.4616\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7257 - val_loss: 7.5229\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6948 - val_loss: 7.5748\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8126 - val_loss: 7.1632\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8997 - val_loss: 8.4098\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0242 - val_loss: 8.0009\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9127 - val_loss: 9.1810\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4905 - val_loss: 7.8157\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1225 - val_loss: 8.6426\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3208 - val_loss: 10.0267\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1154 - val_loss: 8.7966\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7262 - val_loss: 7.1243\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1618 - val_loss: 8.0807\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9112 - val_loss: 7.9308\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7634 - val_loss: 7.6077\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.0205 - val_loss: 7.7050\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0675 - val_loss: 8.9177\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8505 - val_loss: 8.0462\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5398 - val_loss: 8.4959\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0677 - val_loss: 7.8562\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0008 - val_loss: 7.5411\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0355 - val_loss: 9.1526\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1084 - val_loss: 8.2246\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2451 - val_loss: 9.2978\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7341 - val_loss: 7.5574\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3329 - val_loss: 10.8470\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8688 - val_loss: 8.1491\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7126 - val_loss: 8.4492\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2400 - val_loss: 7.3674\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0632 - val_loss: 8.2190\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9301 - val_loss: 7.4920\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7912 - val_loss: 8.1373\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5669 - val_loss: 8.0974\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0734 - val_loss: 9.0855\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8831 - val_loss: 7.2538\n",
      "Epoch 903/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2597 - val_loss: 7.3529\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8960 - val_loss: 7.6019\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1663 - val_loss: 8.5923\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5846 - val_loss: 9.5824\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9346 - val_loss: 7.3088\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7606 - val_loss: 7.5741\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5758 - val_loss: 8.1231\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3403 - val_loss: 7.1867\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0490 - val_loss: 8.2262\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9765 - val_loss: 8.3986\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6730 - val_loss: 7.6771\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6942 - val_loss: 8.6213\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9989 - val_loss: 7.6706\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1517 - val_loss: 8.1324\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2632 - val_loss: 8.2000\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9834 - val_loss: 7.8039\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6857 - val_loss: 7.3497\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1608 - val_loss: 7.4441\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9705 - val_loss: 7.1719\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0056 - val_loss: 7.4480\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8000 - val_loss: 8.0998\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7921 - val_loss: 9.6542\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1682 - val_loss: 7.6109\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0705 - val_loss: 8.5477\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9323 - val_loss: 7.9876\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.6570 - val_loss: 8.9301\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.1874 - val_loss: 9.0991\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8026 - val_loss: 8.4722\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2596 - val_loss: 11.2058\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4431 - val_loss: 8.4207\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2529 - val_loss: 7.6299\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9368 - val_loss: 8.2315\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2538 - val_loss: 10.2904\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1325 - val_loss: 8.1706\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7358 - val_loss: 7.7439\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8733 - val_loss: 7.2741\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3539 - val_loss: 7.4469\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8720 - val_loss: 7.2539\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6959 - val_loss: 7.3947\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4412 - val_loss: 8.5734\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0705 - val_loss: 7.2675\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0315 - val_loss: 7.2651\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4164 - val_loss: 9.2500\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0149 - val_loss: 7.7018\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9222 - val_loss: 7.4022\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9162 - val_loss: 8.6018\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6392 - val_loss: 8.0490\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7535 - val_loss: 7.8085\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6872 - val_loss: 7.4621\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7387 - val_loss: 7.7758\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8266 - val_loss: 9.4442\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9556 - val_loss: 7.3621\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1823 - val_loss: 7.8475\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3965 - val_loss: 7.8996\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9067 - val_loss: 7.9215\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8695 - val_loss: 7.3877\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7616 - val_loss: 7.9300\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8121 - val_loss: 10.1808\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1691 - val_loss: 7.5555\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7871 - val_loss: 7.2310\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7508 - val_loss: 7.7700\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6381 - val_loss: 8.3690\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7007 - val_loss: 7.9499\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4118 - val_loss: 7.9332\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9356 - val_loss: 8.5031\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.8571 - val_loss: 7.8256\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8821 - val_loss: 9.4060\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2127 - val_loss: 8.1088\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9208 - val_loss: 7.8704\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4215 - val_loss: 7.4873\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0665 - val_loss: 7.5920\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8049 - val_loss: 8.6915\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7441 - val_loss: 7.9365\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9232 - val_loss: 7.3987\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1226 - val_loss: 7.2463\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7559 - val_loss: 7.5630\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8449 - val_loss: 9.3040\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8270 - val_loss: 7.2229\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8112 - val_loss: 7.6882\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7750 - val_loss: 7.4331\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5508 - val_loss: 8.0315\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5757 - val_loss: 7.6749\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0938 - val_loss: 8.6203\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9312 - val_loss: 7.6599\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4131 - val_loss: 9.5471\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.4553 - val_loss: 7.4345\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9437 - val_loss: 7.6479\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.8951 - val_loss: 7.5452\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.9390 - val_loss: 7.4596\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9156 - val_loss: 8.6749\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.0518 - val_loss: 7.9938\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8174 - val_loss: 8.0942\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7209 - val_loss: 8.0083\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7692 - val_loss: 8.4155\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2268 - val_loss: 7.5958\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8324 - val_loss: 8.4809\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1571 - val_loss: 7.7700\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1091 - val_loss: 8.1881\n",
      "7.382673449220911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.47793466e-01,  3.61094522e+00,  4.24492687e-01,\n",
       "          1.47435784e-01,  4.46640682e+00, -2.56397223e+00,\n",
       "          1.48210302e-01,  1.47676364e-01, -2.77113914e-01,\n",
       "          1.87571704e+00],\n",
       "        [-1.97419614e-01,  3.02350134e-01,  6.73184514e-01,\n",
       "          1.74133524e-01, -1.42767847e-01, -1.53159845e+00,\n",
       "          1.74932569e-01,  1.74360529e-01, -6.45039916e-01,\n",
       "          1.08035171e+00],\n",
       "        [-3.64782602e-01,  1.09964681e+00,  1.48487186e+00,\n",
       "          2.38617003e-01,  1.15158808e+00, -3.05185378e-01,\n",
       "          2.39781246e-01,  2.38938406e-01, -1.05844760e+00,\n",
       "          1.06740512e-01],\n",
       "        [ 2.82195628e-01, -1.90865025e-01, -1.32741570e-01,\n",
       "         -3.57131008e-03, -1.96244135e-01,  1.80269733e-01,\n",
       "         -3.07226880e-03, -3.39731830e-03, -5.19601166e-01,\n",
       "         -1.88727871e-01],\n",
       "        [-2.14215666e-01,  3.42611015e-01, -8.18934850e-03,\n",
       "          1.09354384e-01,  3.76127660e-01, -2.43394017e+00,\n",
       "          1.10053815e-01,  1.09613836e-01, -3.77358466e-01,\n",
       "         -1.12755194e-01]], dtype=float32),\n",
       " array([ 1.73952   ,  3.2081168 ,  0.94856274, -3.5837753 ,  3.3141174 ,\n",
       "        -3.3801765 , -3.3081222 , -3.453687  ,  3.993265  ,  1.076128  ],\n",
       "       dtype=float32),\n",
       " array([[ 1.0395671 ,  1.2128946 ,  0.7584143 ,  1.5584306 ,  1.5852792 ,\n",
       "         -0.30080464, -1.1502005 , -0.17127228,  1.0461454 , -0.8192836 ,\n",
       "          1.0328879 ,  0.9246473 ,  1.5588241 , -0.05758896,  0.7081439 ],\n",
       "        [ 1.6653826 ,  1.6473767 ,  0.81004   ,  1.4386364 ,  1.4677734 ,\n",
       "         -0.97361743, -1.3899317 ,  0.13696788,  1.7996172 , -1.6357477 ,\n",
       "          1.9098402 ,  0.99920857,  1.4008487 , -1.1038494 ,  1.1920307 ],\n",
       "        [-1.0246849 , -1.0206236 , -0.50427884, -0.28521177, -0.53271806,\n",
       "          0.5279384 ,  0.9187584 , -0.07430129, -0.65766215,  0.4603556 ,\n",
       "         -0.5346275 , -1.0066767 , -0.09176181,  0.38797393, -0.34068006],\n",
       "        [-0.9549095 , -0.6893728 , -0.6777193 , -1.8030009 , -1.5316195 ,\n",
       "          0.4235916 ,  0.7413625 ,  0.23476359, -1.5973505 ,  1.4130642 ,\n",
       "         -1.6259649 , -1.2850169 , -1.4262729 ,  0.6780999 , -0.61060816],\n",
       "        [-0.7033638 , -1.0158079 , -0.8297786 , -0.64891595, -0.7188991 ,\n",
       "          0.77702785,  1.0742695 , -0.07683671, -1.135429  ,  0.4649578 ,\n",
       "         -0.24258184, -0.7183515 , -0.67941695,  0.57129973, -0.5161672 ],\n",
       "        [-0.66425604, -0.3544617 ,  0.2547192 , -0.7750002 , -0.8065544 ,\n",
       "         -0.29454267,  0.5117694 , -0.03181762, -0.72252995,  0.8930884 ,\n",
       "         -0.63208103, -0.01634381, -0.5123959 ,  0.37047443, -0.39201695],\n",
       "        [-1.4273313 , -0.9840221 , -0.8011978 , -1.6504295 , -1.4869194 ,\n",
       "          0.17938444,  1.0869198 ,  0.0232286 , -0.87926656,  1.2505074 ,\n",
       "         -1.2905444 , -0.95739675, -1.4846139 ,  0.47819778, -0.6076668 ],\n",
       "        [-0.7494812 , -1.3926942 , -0.1232562 , -1.8430582 , -1.6945606 ,\n",
       "          0.34825876,  0.7590491 ,  0.1554371 , -1.3534994 ,  1.4094191 ,\n",
       "         -1.7093667 , -1.567639  , -1.2832212 ,  0.9238244 , -0.47946885],\n",
       "        [ 1.2008008 ,  1.4525807 ,  0.07428155,  1.4502178 ,  1.714464  ,\n",
       "         -0.4922405 , -1.4911032 , -0.03933166,  1.3592899 , -1.3090576 ,\n",
       "          1.1944458 ,  1.4380982 ,  1.6679176 , -0.7855078 ,  0.94778   ],\n",
       "        [-0.9104522 , -0.5593734 , -1.2301636 , -0.6049282 , -0.53179777,\n",
       "          1.2365538 ,  1.2090905 , -0.03603654, -1.2625014 ,  1.2261347 ,\n",
       "         -1.1511867 , -0.73754126, -0.7732623 ,  1.5994085 , -1.5478587 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.6864016 ,  1.7294166 ,  0.85475075,  1.854755  ,  1.8689498 ,\n",
       "        -1.054243  , -1.6426942 ,  0.5497472 ,  1.8338127 , -1.7472389 ,\n",
       "         1.8220218 ,  1.6853054 ,  1.8492708 , -1.2118582 ,  1.3299224 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.0533615 ],\n",
       "        [ 1.1108648 ],\n",
       "        [ 0.26773354],\n",
       "        [ 1.6058625 ],\n",
       "        [ 1.6437638 ],\n",
       "        [-0.23252946],\n",
       "        [-0.9274759 ],\n",
       "        [ 0.0032106 ],\n",
       "        [ 1.4340053 ],\n",
       "        [-1.2173514 ],\n",
       "        [ 1.4844195 ],\n",
       "        [ 1.0277    ],\n",
       "        [ 1.5754315 ],\n",
       "        [-0.46023422],\n",
       "        [ 0.55358267]], dtype=float32),\n",
       " array([2.137697], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_6(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure6_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 778us/step - loss: 541.7679 - val_loss: 412.3449\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 287.5470 - val_loss: 134.2546\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 90.1228 - val_loss: 60.9192\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 35.5329 - val_loss: 28.7072\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 25.9778 - val_loss: 21.4686\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 20.6861 - val_loss: 19.5673\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 19.4729 - val_loss: 19.0863\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.1681 - val_loss: 18.4444\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.2092 - val_loss: 18.3419\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 16.4660 - val_loss: 17.4127\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 15.4628 - val_loss: 16.8226\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 14.8530 - val_loss: 16.2506\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 13.4473 - val_loss: 15.7319\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 12.5881 - val_loss: 14.8302\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.4968 - val_loss: 14.2269\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.7946 - val_loss: 13.4109\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.3049 - val_loss: 12.5533\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.6941 - val_loss: 12.1073\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 9.3305 - val_loss: 11.8024\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.0142 - val_loss: 11.1981\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9129 - val_loss: 10.8314\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7292 - val_loss: 10.4493\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.5149 - val_loss: 10.2042\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.6861 - val_loss: 10.5262\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4476 - val_loss: 10.1839\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1422 - val_loss: 9.8574\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0545 - val_loss: 10.0517\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1400 - val_loss: 9.9719\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.8471 - val_loss: 9.8085\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8298 - val_loss: 9.8041\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.8068 - val_loss: 9.6863\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6025 - val_loss: 9.9132\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5763 - val_loss: 9.9069\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.6237 - val_loss: 10.0268\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4490 - val_loss: 10.0569\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.5359 - val_loss: 9.9652\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3888 - val_loss: 9.9060\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3196 - val_loss: 9.9373\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2996 - val_loss: 9.8553\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2501 - val_loss: 9.7790\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2564 - val_loss: 9.7640\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2384 - val_loss: 9.6511\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1871 - val_loss: 9.8266\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2224 - val_loss: 9.6971\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1396 - val_loss: 9.4100\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2599 - val_loss: 9.4585\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2429 - val_loss: 9.4654\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1314 - val_loss: 9.6179\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1034 - val_loss: 9.7420\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1687 - val_loss: 9.7240\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1165 - val_loss: 9.6394\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1317 - val_loss: 9.4976\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2810 - val_loss: 9.3289\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.1092 - val_loss: 9.7115\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1755 - val_loss: 9.8410\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0722 - val_loss: 9.6352\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1821 - val_loss: 9.4845\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1094 - val_loss: 9.7320\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1552 - val_loss: 9.4908\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4293 - val_loss: 9.3265\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2588 - val_loss: 9.3369\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1870 - val_loss: 9.6882\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1520 - val_loss: 9.3043\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1906 - val_loss: 9.4742\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.1112 - val_loss: 9.8296\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1478 - val_loss: 9.8667\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3294 - val_loss: 9.4276\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0586 - val_loss: 9.9577\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 7.1227 - val_loss: 9.3638\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0851 - val_loss: 9.4406\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1238 - val_loss: 9.4670\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0666 - val_loss: 9.7162\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1370 - val_loss: 9.5185\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0704 - val_loss: 9.5101\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0139 - val_loss: 9.6685\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.0194 - val_loss: 9.3185\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2111 - val_loss: 9.5054\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2834 - val_loss: 9.6334\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9898 - val_loss: 9.4044\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9962 - val_loss: 9.4847\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0441 - val_loss: 9.3468\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9701 - val_loss: 9.6569\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9799 - val_loss: 9.7260\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9463 - val_loss: 9.4863\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1005 - val_loss: 9.5040\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9957 - val_loss: 9.6348\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0528 - val_loss: 9.4461\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0577 - val_loss: 9.6919\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0083 - val_loss: 9.6188\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0731 - val_loss: 9.6437\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9357 - val_loss: 9.3662\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0200 - val_loss: 9.8108\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1032 - val_loss: 9.5103\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0884 - val_loss: 9.4483\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0886 - val_loss: 9.5476\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0550 - val_loss: 9.5862\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9613 - val_loss: 9.6563\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9809 - val_loss: 9.5796\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9293 - val_loss: 9.5003\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9143 - val_loss: 9.4883\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0715 - val_loss: 9.9927\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9774 - val_loss: 9.4746\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9803 - val_loss: 9.4762\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9627 - val_loss: 9.7541\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8933 - val_loss: 9.5408\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9968 - val_loss: 9.4796\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0242 - val_loss: 9.7633\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9942 - val_loss: 9.5611\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9856 - val_loss: 9.6109\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9126 - val_loss: 9.6314\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9492 - val_loss: 9.6420\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0969 - val_loss: 9.3672\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9626 - val_loss: 9.4872\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9029 - val_loss: 9.6508\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9237 - val_loss: 9.7965\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0213 - val_loss: 9.3078\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0838 - val_loss: 9.7761\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9235 - val_loss: 9.8975\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9639 - val_loss: 9.4241\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0346 - val_loss: 9.6472\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8866 - val_loss: 9.5965\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9054 - val_loss: 9.5669\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1405 - val_loss: 9.5567\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9926 - val_loss: 9.6070\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8978 - val_loss: 9.9030\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8704 - val_loss: 9.7202\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9857 - val_loss: 9.8774\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0371 - val_loss: 9.6214\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8369 - val_loss: 9.3838\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9676 - val_loss: 9.8457\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9716 - val_loss: 9.5833\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1313 - val_loss: 9.7831\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0466 - val_loss: 9.7515\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.9978 - val_loss: 9.2833\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0211 - val_loss: 9.4903\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9135 - val_loss: 9.3459\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9388 - val_loss: 9.7283\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9404 - val_loss: 9.5193\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8590 - val_loss: 9.7246\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1936 - val_loss: 9.4877\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0183 - val_loss: 9.6689\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8037 - val_loss: 9.9564\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2506 - val_loss: 9.6542\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7644 - val_loss: 10.0124\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8944 - val_loss: 9.6056\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9547 - val_loss: 9.6003\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0198 - val_loss: 9.5963\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1248 - val_loss: 9.5812\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9200 - val_loss: 9.5380\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9332 - val_loss: 9.5193\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8292 - val_loss: 9.4431\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8362 - val_loss: 9.6581\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8342 - val_loss: 9.6838\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8197 - val_loss: 9.6603\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8424 - val_loss: 9.6591\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9847 - val_loss: 9.6096\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8370 - val_loss: 9.5732\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8436 - val_loss: 9.4735\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8195 - val_loss: 9.6347\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8365 - val_loss: 9.6699\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7766 - val_loss: 9.5215\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8289 - val_loss: 9.6709\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8163 - val_loss: 9.6960\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7783 - val_loss: 9.3599\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9177 - val_loss: 9.6533\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8452 - val_loss: 9.4212\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7934 - val_loss: 9.6090\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8126 - val_loss: 9.4247\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8284 - val_loss: 9.5560\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7974 - val_loss: 9.5246\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7663 - val_loss: 9.4016\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9004 - val_loss: 9.6124\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8850 - val_loss: 9.3880\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9041 - val_loss: 9.9409\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7731 - val_loss: 9.4707\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8882 - val_loss: 9.4675\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8948 - val_loss: 9.8931\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9773 - val_loss: 9.7294\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9102 - val_loss: 9.4180\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9593 - val_loss: 9.9799\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8118 - val_loss: 9.5636\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0957 - val_loss: 9.6716\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0521 - val_loss: 9.5612\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7966 - val_loss: 9.5717\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7321 - val_loss: 9.9210\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8002 - val_loss: 9.4713\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0833 - val_loss: 9.7428\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9402 - val_loss: 9.8220\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7966 - val_loss: 9.2514\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8723 - val_loss: 9.5537\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9420 - val_loss: 9.7340\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8536 - val_loss: 9.5639\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7839 - val_loss: 9.5873\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9663 - val_loss: 9.4406\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7511 - val_loss: 9.7338\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7435 - val_loss: 9.6274\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9056 - val_loss: 9.4834\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9291 - val_loss: 9.6650\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0019 - val_loss: 9.6716\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9119 - val_loss: 9.6015\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9238 - val_loss: 9.7749\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0857 - val_loss: 9.4997\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0257 - val_loss: 9.7079\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7193 - val_loss: 9.4083\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0664 - val_loss: 9.6527\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7835 - val_loss: 9.3561\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7510 - val_loss: 9.8176\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8583 - val_loss: 9.6702\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8178 - val_loss: 9.7561\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7393 - val_loss: 9.5681\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8578 - val_loss: 9.6186\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9915 - val_loss: 9.6237\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7523 - val_loss: 9.6375\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9638 - val_loss: 9.7246\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7576 - val_loss: 9.4951\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7096 - val_loss: 9.6236\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7221 - val_loss: 9.3734\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7383 - val_loss: 9.5834\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7039 - val_loss: 9.3792\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7475 - val_loss: 9.7343\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.7086 - val_loss: 9.3297\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7684 - val_loss: 9.4104\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7156 - val_loss: 9.3902\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7717 - val_loss: 9.2196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7172 - val_loss: 9.5818\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6865 - val_loss: 9.5145\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7090 - val_loss: 9.3930\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7215 - val_loss: 9.2417\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7632 - val_loss: 9.5293\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7293 - val_loss: 9.5376\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7980 - val_loss: 9.5078\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7091 - val_loss: 9.7736\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8123 - val_loss: 9.3798\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6405 - val_loss: 9.6183\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7223 - val_loss: 9.3694\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.8619 - val_loss: 9.5530\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7676 - val_loss: 9.7618\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6608 - val_loss: 9.2983\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8521 - val_loss: 9.7713\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6120 - val_loss: 9.5984\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8687 - val_loss: 9.4714\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6949 - val_loss: 9.8204\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7494 - val_loss: 9.3908\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8049 - val_loss: 9.4088\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7097 - val_loss: 9.5803\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6763 - val_loss: 9.3436\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8501 - val_loss: 9.4920\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6362 - val_loss: 9.4764\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7108 - val_loss: 9.5085\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7045 - val_loss: 9.3175\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8139 - val_loss: 9.2837\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6327 - val_loss: 9.4846\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7472 - val_loss: 9.7496\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7001 - val_loss: 9.1505\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7122 - val_loss: 9.3767\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6151 - val_loss: 9.4324\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6756 - val_loss: 9.8053\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8038 - val_loss: 9.5851\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7721 - val_loss: 9.7710\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9345 - val_loss: 9.5065\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.8277 - val_loss: 10.0810\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8069 - val_loss: 9.3427\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0207 - val_loss: 9.5716\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8437 - val_loss: 9.5276\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7506 - val_loss: 9.5726\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6553 - val_loss: 9.6556\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6568 - val_loss: 9.2579\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6793 - val_loss: 9.6158\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6712 - val_loss: 9.8147\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7871 - val_loss: 9.4714\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9899 - val_loss: 9.3697\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7897 - val_loss: 9.8684\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6423 - val_loss: 9.2529\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5838 - val_loss: 9.5063\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6592 - val_loss: 9.4552\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6596 - val_loss: 9.5325\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6056 - val_loss: 9.3923\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6425 - val_loss: 9.7988\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7134 - val_loss: 9.3531\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8419 - val_loss: 9.0890\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7789 - val_loss: 9.8391\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6387 - val_loss: 9.4345\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6237 - val_loss: 9.6748\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6350 - val_loss: 9.4185\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6424 - val_loss: 9.5135\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5873 - val_loss: 9.5857\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7672 - val_loss: 9.5911\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9899 - val_loss: 9.6470\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5958 - val_loss: 9.4509\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7410 - val_loss: 9.5406\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6424 - val_loss: 9.4888\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6345 - val_loss: 9.8426\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7486 - val_loss: 9.4763\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9107 - val_loss: 9.3481\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6668 - val_loss: 9.6121\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6534 - val_loss: 9.3114\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6425 - val_loss: 9.6730\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6176 - val_loss: 9.3563\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6281 - val_loss: 9.6646\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6167 - val_loss: 9.3120\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7431 - val_loss: 9.7124\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6671 - val_loss: 9.3907\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7731 - val_loss: 9.6754\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8156 - val_loss: 9.4942\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6416 - val_loss: 9.3902\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7418 - val_loss: 9.7813\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6070 - val_loss: 9.3205\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5547 - val_loss: 9.5110\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6072 - val_loss: 9.4973\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5772 - val_loss: 9.3917\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6130 - val_loss: 9.5691\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7995 - val_loss: 9.5760\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7209 - val_loss: 9.6946\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6157 - val_loss: 9.6639\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6233 - val_loss: 9.4200\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7352 - val_loss: 9.7103\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9861 - val_loss: 9.3800\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8455 - val_loss: 10.0181\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8940 - val_loss: 9.5872\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6189 - val_loss: 9.7710\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6230 - val_loss: 9.6815\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5717 - val_loss: 9.5398\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7977 - val_loss: 9.7383\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6257 - val_loss: 9.7673\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6488 - val_loss: 9.3496\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5956 - val_loss: 9.7084\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6026 - val_loss: 9.5204\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8490 - val_loss: 9.4706\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9916 - val_loss: 9.8557\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0322 - val_loss: 9.4776\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7650 - val_loss: 9.6431\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5283 - val_loss: 9.8617\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5898 - val_loss: 9.8028\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5708 - val_loss: 9.4955\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5166 - val_loss: 9.6805\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6302 - val_loss: 9.5247\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7366 - val_loss: 9.6005\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5984 - val_loss: 9.7797\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5104 - val_loss: 9.4952\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6590 - val_loss: 9.7067\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5651 - val_loss: 9.5173\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5605 - val_loss: 9.5737\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6834 - val_loss: 9.8269\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6578 - val_loss: 9.6401\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5327 - val_loss: 9.4687\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5533 - val_loss: 9.6766\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5767 - val_loss: 9.5499\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5518 - val_loss: 9.4731\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5490 - val_loss: 9.7242\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5507 - val_loss: 9.4868\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5520 - val_loss: 9.3924\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4711 - val_loss: 9.6008\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7418 - val_loss: 9.7937\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6249 - val_loss: 9.5170\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6651 - val_loss: 9.8129\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5709 - val_loss: 9.4982\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6313 - val_loss: 9.7358\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4906 - val_loss: 9.4029\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7136 - val_loss: 9.5347\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6245 - val_loss: 9.4178\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5150 - val_loss: 9.5019\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5718 - val_loss: 9.4031\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7854 - val_loss: 9.7798\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7270 - val_loss: 9.5725\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4618 - val_loss: 9.1978\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6652 - val_loss: 9.3231\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4952 - val_loss: 9.6846\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5743 - val_loss: 9.7067\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5479 - val_loss: 9.4198\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5436 - val_loss: 9.6847\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5310 - val_loss: 9.4829\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6681 - val_loss: 9.3444\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5086 - val_loss: 9.5849\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5930 - val_loss: 9.3978\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5118 - val_loss: 9.1875\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6499 - val_loss: 9.9778\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5575 - val_loss: 9.3950\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5141 - val_loss: 9.3510\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5092 - val_loss: 9.4831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4627 - val_loss: 9.3690\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4931 - val_loss: 9.7361\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5118 - val_loss: 9.6017\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5057 - val_loss: 9.6406\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4482 - val_loss: 9.3137\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5615 - val_loss: 9.4749\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4765 - val_loss: 9.4938\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4750 - val_loss: 9.5404\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5045 - val_loss: 9.2448\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5262 - val_loss: 9.4178\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5166 - val_loss: 9.5393\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5524 - val_loss: 9.3532\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4598 - val_loss: 9.7240\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5122 - val_loss: 9.4215\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6270 - val_loss: 9.6619\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6497 - val_loss: 9.4746\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6030 - val_loss: 9.2448\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5632 - val_loss: 9.3884\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0342 - val_loss: 9.7689\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5844 - val_loss: 9.7282\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5427 - val_loss: 9.5569\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6668 - val_loss: 9.6115\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4990 - val_loss: 9.4136\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5961 - val_loss: 9.3465\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5324 - val_loss: 9.6282\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6420 - val_loss: 9.4131\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3982 - val_loss: 9.9119\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5981 - val_loss: 9.5477\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5224 - val_loss: 9.2952\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5852 - val_loss: 9.6582\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7017 - val_loss: 9.3697\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5494 - val_loss: 9.8717\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5075 - val_loss: 9.2904\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5402 - val_loss: 9.4605\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7284 - val_loss: 9.2056\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5285 - val_loss: 9.7737\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5254 - val_loss: 9.3587\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5126 - val_loss: 9.4034\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4469 - val_loss: 9.5114\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5137 - val_loss: 9.4757\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5205 - val_loss: 9.4490\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3702 - val_loss: 9.5311\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5243 - val_loss: 9.6191\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4446 - val_loss: 9.4535\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5468 - val_loss: 9.2364\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8173 - val_loss: 9.3669\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6710 - val_loss: 9.4681\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4715 - val_loss: 9.5613\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5716 - val_loss: 9.4879\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5404 - val_loss: 9.5122\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4774 - val_loss: 9.4565\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4719 - val_loss: 9.3024\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4832 - val_loss: 9.6522\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4319 - val_loss: 9.5735\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5588 - val_loss: 9.2895\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4453 - val_loss: 9.3811\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4794 - val_loss: 9.5105\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4316 - val_loss: 9.3784\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3880 - val_loss: 9.4185\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4063 - val_loss: 9.3362\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3799 - val_loss: 9.2937\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4170 - val_loss: 9.3017\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4777 - val_loss: 9.3342\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4716 - val_loss: 9.4971\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4476 - val_loss: 9.6515\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4456 - val_loss: 9.3706\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5468 - val_loss: 9.6691\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6597 - val_loss: 9.1975\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4324 - val_loss: 9.1932\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3769 - val_loss: 9.3583\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3925 - val_loss: 9.3295\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4587 - val_loss: 9.2615\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7986 - val_loss: 9.6029\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4315 - val_loss: 9.4063\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6021 - val_loss: 9.7694\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4681 - val_loss: 9.4214\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5085 - val_loss: 9.3493\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5672 - val_loss: 9.5288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5985 - val_loss: 9.5492\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6675 - val_loss: 9.2638\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4392 - val_loss: 9.3610\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5028 - val_loss: 9.3586\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4326 - val_loss: 9.5125\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4812 - val_loss: 9.2284\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3471 - val_loss: 9.7232\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3831 - val_loss: 9.3782\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4748 - val_loss: 9.4011\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5717 - val_loss: 9.3391\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5766 - val_loss: 9.2110\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4271 - val_loss: 9.2560\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4241 - val_loss: 9.5700\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 6.6762 - val_loss: 9.5230\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6093 - val_loss: 9.3479\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3317 - val_loss: 9.6407\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4288 - val_loss: 9.3912\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4299 - val_loss: 9.4025\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4144 - val_loss: 9.3554\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5028 - val_loss: 9.4016\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3780 - val_loss: 9.3740\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4497 - val_loss: 9.3534\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4421 - val_loss: 9.4957\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4915 - val_loss: 9.5268\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4334 - val_loss: 9.2856\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4614 - val_loss: 9.6137\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4133 - val_loss: 9.5055\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4155 - val_loss: 9.5571\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4552 - val_loss: 9.4814\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9232 - val_loss: 9.4926\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.5487 - val_loss: 9.3238\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4592 - val_loss: 9.6327\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6334 - val_loss: 9.4237\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5224 - val_loss: 9.6934\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3938 - val_loss: 9.2391\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3366 - val_loss: 9.7522\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7888 - val_loss: 9.5693\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9335 - val_loss: 9.2735\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6475 - val_loss: 9.4090\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4081 - val_loss: 9.7577\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3584 - val_loss: 9.3298\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4816 - val_loss: 9.4006\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3886 - val_loss: 9.3917\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4350 - val_loss: 9.4736\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3845 - val_loss: 9.3136\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4401 - val_loss: 9.6213\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6516 - val_loss: 9.2651\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6142 - val_loss: 9.4497\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3502 - val_loss: 9.5213\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.4784 - val_loss: 9.4267\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3810 - val_loss: 9.6733\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3346 - val_loss: 9.4827\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5416 - val_loss: 9.5432\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3476 - val_loss: 9.6107\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3454 - val_loss: 9.5716\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3242 - val_loss: 9.3342\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5061 - val_loss: 9.5174\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4740 - val_loss: 9.2269\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3658 - val_loss: 9.4727\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3850 - val_loss: 9.5016\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3845 - val_loss: 9.4073\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6719 - val_loss: 9.4065\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5409 - val_loss: 9.2773\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4023 - val_loss: 9.4627\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3517 - val_loss: 9.2927\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4798 - val_loss: 9.4437\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4536 - val_loss: 9.4770\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5055 - val_loss: 9.5378\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4973 - val_loss: 9.4893\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4907 - val_loss: 9.4869\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3778 - val_loss: 9.4631\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3435 - val_loss: 9.1812\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3171 - val_loss: 9.2534\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3030 - val_loss: 9.3821\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4865 - val_loss: 9.4496\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4620 - val_loss: 9.7414\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8044 - val_loss: 9.5913\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4356 - val_loss: 9.3826\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3778 - val_loss: 9.2404\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5570 - val_loss: 9.8043\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5718 - val_loss: 9.4609\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4120 - val_loss: 9.4083\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4170 - val_loss: 9.2878\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4424 - val_loss: 9.5356\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4129 - val_loss: 9.7054\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3820 - val_loss: 9.4457\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5103 - val_loss: 9.6490\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4048 - val_loss: 9.3296\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3835 - val_loss: 9.5387\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3179 - val_loss: 9.3056\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4759 - val_loss: 9.5860\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4119 - val_loss: 9.8060\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3878 - val_loss: 9.3303\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3537 - val_loss: 9.5372\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4153 - val_loss: 9.3664\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5893 - val_loss: 9.7305\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5146 - val_loss: 9.6319\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3391 - val_loss: 9.3776\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3316 - val_loss: 9.4807\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3394 - val_loss: 9.6460\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4033 - val_loss: 9.5458\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3213 - val_loss: 9.6443\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2573 - val_loss: 9.3104\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4386 - val_loss: 9.1786\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3620 - val_loss: 9.7159\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3124 - val_loss: 9.4455\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3160 - val_loss: 9.5526\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4603 - val_loss: 9.3859\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3052 - val_loss: 9.4907\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3503 - val_loss: 9.3550\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2419 - val_loss: 9.3822\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3041 - val_loss: 9.3385\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3392 - val_loss: 9.5422\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3408 - val_loss: 9.4668\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3730 - val_loss: 9.4807\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3562 - val_loss: 9.5381\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3462 - val_loss: 9.6382\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3059 - val_loss: 9.3967\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2787 - val_loss: 9.5067\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3586 - val_loss: 9.4876\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3359 - val_loss: 9.5362\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3332 - val_loss: 9.4523\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2894 - val_loss: 9.5056\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4639 - val_loss: 9.3518\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4954 - val_loss: 9.5305\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3182 - val_loss: 9.3358\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5111 - val_loss: 9.9506\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3230 - val_loss: 9.3253\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4234 - val_loss: 9.6141\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4536 - val_loss: 9.6166\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4660 - val_loss: 9.7391\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5345 - val_loss: 9.7393\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3361 - val_loss: 9.9380\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3208 - val_loss: 9.3041\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3323 - val_loss: 9.6682\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3230 - val_loss: 9.4640\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4796 - val_loss: 9.5936\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2307 - val_loss: 9.3711\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4814 - val_loss: 9.6798\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8717 - val_loss: 9.9036\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5005 - val_loss: 9.2131\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4175 - val_loss: 9.3996\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3420 - val_loss: 9.6857\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.5514 - val_loss: 9.3472\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2978 - val_loss: 9.4024\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2637 - val_loss: 9.6853\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3050 - val_loss: 9.3583\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2666 - val_loss: 9.4580\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3427 - val_loss: 9.5621\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3747 - val_loss: 9.4790\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2476 - val_loss: 9.5438\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2902 - val_loss: 9.5447\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2407 - val_loss: 9.4516\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2597 - val_loss: 9.4413\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2575 - val_loss: 9.5180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2901 - val_loss: 9.3021\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2321 - val_loss: 9.4562\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4187 - val_loss: 9.5610\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3680 - val_loss: 9.5269\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3151 - val_loss: 9.3429\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3055 - val_loss: 9.5596\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2323 - val_loss: 9.3556\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3227 - val_loss: 9.6393\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3200 - val_loss: 9.3893\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2247 - val_loss: 9.5265\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3325 - val_loss: 9.4854\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3669 - val_loss: 9.4876\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3177 - val_loss: 9.7117\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3513 - val_loss: 9.5274\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4627 - val_loss: 9.5052\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3630 - val_loss: 9.9110\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2678 - val_loss: 9.6564\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2401 - val_loss: 9.5991\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3286 - val_loss: 9.5397\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3555 - val_loss: 9.5011\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2282 - val_loss: 9.3781\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2687 - val_loss: 9.4862\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2169 - val_loss: 9.7919\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3906 - val_loss: 9.5367\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2403 - val_loss: 9.6798\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4415 - val_loss: 9.7105\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3988 - val_loss: 9.8779\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3352 - val_loss: 9.3321\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2955 - val_loss: 9.7255\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3350 - val_loss: 9.3583\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5270 - val_loss: 9.7562\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4704 - val_loss: 9.4471\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6693 - val_loss: 9.7641\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3366 - val_loss: 9.8285\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2323 - val_loss: 9.8365\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4686 - val_loss: 9.5220\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3227 - val_loss: 9.5503\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3235 - val_loss: 9.4399\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2940 - val_loss: 9.7267\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3088 - val_loss: 9.7940\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3353 - val_loss: 9.6935\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1354 - val_loss: 9.4711\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3849 - val_loss: 9.8151\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3510 - val_loss: 9.4140\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3830 - val_loss: 9.6558\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4432 - val_loss: 9.6624\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2552 - val_loss: 9.6339\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2474 - val_loss: 9.8203\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2074 - val_loss: 9.6865\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3817 - val_loss: 9.5395\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4767 - val_loss: 9.2424\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3900 - val_loss: 9.5208\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4195 - val_loss: 9.5823\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2812 - val_loss: 9.3911\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2206 - val_loss: 9.5459\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2504 - val_loss: 9.4423\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3979 - val_loss: 9.6527\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4417 - val_loss: 9.7005\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2820 - val_loss: 9.5711\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2858 - val_loss: 9.4947\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1926 - val_loss: 9.4240\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1923 - val_loss: 9.5482\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.3114 - val_loss: 9.4670\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3237 - val_loss: 9.8296\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4994 - val_loss: 9.9364\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3121 - val_loss: 9.3706\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2353 - val_loss: 9.3640\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6228 - val_loss: 9.5492\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2904 - val_loss: 9.2615\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3994 - val_loss: 9.7252\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2850 - val_loss: 9.3996\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2841 - val_loss: 9.7604\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3133 - val_loss: 9.4808\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2825 - val_loss: 9.6276\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2296 - val_loss: 9.4614\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2848 - val_loss: 9.8544\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2057 - val_loss: 9.5760\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2403 - val_loss: 9.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4563 - val_loss: 9.5090\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3241 - val_loss: 9.8035\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2443 - val_loss: 9.5423\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2987 - val_loss: 9.3935\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3576 - val_loss: 9.8774\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3651 - val_loss: 9.3323\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2691 - val_loss: 9.6725\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2820 - val_loss: 9.9629\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2915 - val_loss: 9.3756\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2211 - val_loss: 9.6624\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2249 - val_loss: 9.7296\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2988 - val_loss: 9.4310\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3313 - val_loss: 9.5531\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2671 - val_loss: 9.3645\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1265 - val_loss: 9.9148\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2364 - val_loss: 9.5729\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2195 - val_loss: 9.5552\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1398 - val_loss: 9.4987\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2180 - val_loss: 9.5934\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1655 - val_loss: 9.6959\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1922 - val_loss: 10.0191\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2564 - val_loss: 9.4272\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2789 - val_loss: 9.5662\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2236 - val_loss: 9.8887\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2673 - val_loss: 9.6816\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1478 - val_loss: 9.3425\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2264 - val_loss: 9.4189\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3408 - val_loss: 9.5966\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2426 - val_loss: 9.6756\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2326 - val_loss: 9.9285\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2490 - val_loss: 9.5647\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3341 - val_loss: 9.5025\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1410 - val_loss: 9.5487\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3620 - val_loss: 9.7734\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2260 - val_loss: 9.6246\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2048 - val_loss: 9.4810\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2001 - val_loss: 9.6175\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2212 - val_loss: 9.5989\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2290 - val_loss: 9.5145\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1435 - val_loss: 9.6159\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2686 - val_loss: 9.4584\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6438 - val_loss: 9.5887\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5050 - val_loss: 9.6784\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3748 - val_loss: 9.6506\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1941 - val_loss: 9.6761\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2187 - val_loss: 9.5047\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1921 - val_loss: 9.6319\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2096 - val_loss: 9.8301\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1849 - val_loss: 9.3677\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1911 - val_loss: 9.4113\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1805 - val_loss: 9.6252\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1818 - val_loss: 9.7349\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1582 - val_loss: 10.0267\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2498 - val_loss: 9.6746\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2636 - val_loss: 9.7527\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1808 - val_loss: 9.5983\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2613 - val_loss: 9.7204\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3775 - val_loss: 9.6307\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3516 - val_loss: 9.2657\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2018 - val_loss: 9.7061\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1739 - val_loss: 9.7005\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1621 - val_loss: 9.7343\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2125 - val_loss: 9.4581\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2216 - val_loss: 9.2930\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1682 - val_loss: 9.5488\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1859 - val_loss: 9.4663\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2914 - val_loss: 9.6344\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2871 - val_loss: 9.8791\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2557 - val_loss: 9.5841\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1654 - val_loss: 9.7296\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1339 - val_loss: 9.6003\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1296 - val_loss: 9.8201\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1838 - val_loss: 9.4094\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2115 - val_loss: 9.3235\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1313 - val_loss: 9.7550\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4290 - val_loss: 9.5168\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5827 - val_loss: 9.6464\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1521 - val_loss: 9.5566\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1449 - val_loss: 9.7175\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1806 - val_loss: 9.7109\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1476 - val_loss: 9.5887\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2562 - val_loss: 9.5756\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1599 - val_loss: 9.5679\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1496 - val_loss: 9.6100\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1058 - val_loss: 9.5327\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2177 - val_loss: 9.7104\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0782 - val_loss: 9.8010\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5761 - val_loss: 10.2266\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4193 - val_loss: 9.4893\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1228 - val_loss: 9.6588\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2363 - val_loss: 9.4063\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1476 - val_loss: 9.6995\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1211 - val_loss: 9.7838\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1970 - val_loss: 9.6527\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1609 - val_loss: 9.6976\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2136 - val_loss: 9.5081\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1830 - val_loss: 9.6635\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1078 - val_loss: 9.7237\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2355 - val_loss: 9.9760\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3234 - val_loss: 9.5554\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4964 - val_loss: 9.5085\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1687 - val_loss: 9.7413\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1056 - val_loss: 9.4981\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2562 - val_loss: 9.6982\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2242 - val_loss: 9.5374\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1338 - val_loss: 9.9597\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1180 - val_loss: 9.5312\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1569 - val_loss: 9.5988\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1585 - val_loss: 9.5809\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3891 - val_loss: 9.9172\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6186 - val_loss: 9.5375\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3509 - val_loss: 9.2970\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2604 - val_loss: 9.5803\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1059 - val_loss: 9.4673\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1720 - val_loss: 9.7108\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1154 - val_loss: 9.6983\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1654 - val_loss: 9.4846\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1551 - val_loss: 9.7639\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1783 - val_loss: 9.5495\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1116 - val_loss: 9.7877\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1778 - val_loss: 9.5690\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0904 - val_loss: 9.6388\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2091 - val_loss: 9.4803\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1664 - val_loss: 9.6493\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0956 - val_loss: 9.6171\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1740 - val_loss: 9.5475\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1451 - val_loss: 9.4933\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1071 - val_loss: 9.6603\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1501 - val_loss: 9.4489\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1549 - val_loss: 9.7389\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1913 - val_loss: 9.6394\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0508 - val_loss: 9.8351\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3409 - val_loss: 9.4681\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1933 - val_loss: 10.1839\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4265 - val_loss: 9.8160\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2971 - val_loss: 9.5637\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2523 - val_loss: 9.6200\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2064 - val_loss: 9.3745\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1715 - val_loss: 9.8316\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1022 - val_loss: 9.5195\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1664 - val_loss: 9.8178\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1981 - val_loss: 9.5485\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1873 - val_loss: 9.6366\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3089 - val_loss: 9.6424\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2263 - val_loss: 9.7412\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0955 - val_loss: 9.6484\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0882 - val_loss: 9.4931\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1378 - val_loss: 9.5264\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1515 - val_loss: 9.7129\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1521 - val_loss: 9.5355\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2863 - val_loss: 10.0226\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 6.3552 - val_loss: 9.3346\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4806 - val_loss: 9.8993\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3257 - val_loss: 9.5635\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1333 - val_loss: 9.7962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1267 - val_loss: 9.7445\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0790 - val_loss: 9.7196\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1939 - val_loss: 9.5502\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2554 - val_loss: 9.9799\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1509 - val_loss: 9.7210\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1447 - val_loss: 9.6797\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0593 - val_loss: 9.6463\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1015 - val_loss: 9.8201\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1343 - val_loss: 9.5965\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.2618 - val_loss: 10.1895\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4349 - val_loss: 9.5254\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5039 - val_loss: 9.8842\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1516 - val_loss: 9.4269\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4177 - val_loss: 9.5208\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2147 - val_loss: 9.9937\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1928 - val_loss: 9.5258\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0983 - val_loss: 9.9717\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1025 - val_loss: 9.5259\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2072 - val_loss: 9.8443\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2176 - val_loss: 9.8869\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1510 - val_loss: 9.6039\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0480 - val_loss: 9.6875\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0716 - val_loss: 9.6856\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1423 - val_loss: 9.5506\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2328 - val_loss: 9.5148\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2728 - val_loss: 9.6587\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1509 - val_loss: 9.6846\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0431 - val_loss: 9.6824\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1136 - val_loss: 9.3662\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1646 - val_loss: 9.5610\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1834 - val_loss: 9.3693\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2110 - val_loss: 9.6889\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.0648 - val_loss: 9.5379\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1465 - val_loss: 9.6707\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0406 - val_loss: 9.6136\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0740 - val_loss: 9.5422\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0942 - val_loss: 9.4030\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0613 - val_loss: 9.6999\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0833 - val_loss: 9.4641\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0891 - val_loss: 9.4892\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0706 - val_loss: 9.6638\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0679 - val_loss: 9.6335\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2271 - val_loss: 9.6607\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1462 - val_loss: 9.6264\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0918 - val_loss: 9.6822\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1781 - val_loss: 9.5575\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1373 - val_loss: 9.5761\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1848 - val_loss: 9.6460\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.750 - 0s 99us/step - loss: 6.1024 - val_loss: 9.6214\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2121 - val_loss: 9.5071\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0887 - val_loss: 9.5135\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1331 - val_loss: 9.6588\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2264 - val_loss: 9.5847\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2162 - val_loss: 9.9199\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1485 - val_loss: 9.5022\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0920 - val_loss: 9.6260\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0329 - val_loss: 9.7614\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0992 - val_loss: 9.7335\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1307 - val_loss: 9.3731\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0968 - val_loss: 9.7377\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1716 - val_loss: 9.6119\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0436 - val_loss: 9.6160\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1078 - val_loss: 9.5959\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2669 - val_loss: 9.6645\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0464 - val_loss: 9.7433\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0496 - val_loss: 9.3158\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2832 - val_loss: 9.7293\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0219 - val_loss: 9.6939\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.0582 - val_loss: 9.9686\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1526 - val_loss: 9.6652\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2522 - val_loss: 9.6728\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1391 - val_loss: 9.7050\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0887 - val_loss: 9.6279\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1179 - val_loss: 9.8779\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0545 - val_loss: 9.6504\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1736 - val_loss: 9.6116\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1318 - val_loss: 9.6613\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0484 - val_loss: 9.7692\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0672 - val_loss: 9.5064\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0648 - val_loss: 9.8318\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1497 - val_loss: 9.5163\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1841 - val_loss: 9.9171\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1597 - val_loss: 9.4710\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0857 - val_loss: 9.6727\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0679 - val_loss: 9.6038\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1007 - val_loss: 9.5988\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0993 - val_loss: 9.6111\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0204 - val_loss: 9.7651\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1127 - val_loss: 9.5301\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0809 - val_loss: 9.7140\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0884 - val_loss: 9.5216\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0200 - val_loss: 9.6354\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3444 - val_loss: 9.9287\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4379 - val_loss: 9.6761\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0533 - val_loss: 10.1533\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2428 - val_loss: 9.4541\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2284 - val_loss: 9.6619\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0822 - val_loss: 9.5673\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1272 - val_loss: 9.6589\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.0855 - val_loss: 9.5038\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0222 - val_loss: 9.8223\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2046 - val_loss: 9.4851\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2009 - val_loss: 9.5898\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0611 - val_loss: 9.6573\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1080 - val_loss: 9.6309\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2067 - val_loss: 9.5690\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2044 - val_loss: 9.7046\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0657 - val_loss: 9.5686\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2218 - val_loss: 9.9039\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0661 - val_loss: 9.8699\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1373 - val_loss: 9.4525\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0370 - val_loss: 9.7812\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9946 - val_loss: 9.4448\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1311 - val_loss: 9.7890\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0702 - val_loss: 9.8443\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0326 - val_loss: 9.5558\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3316 - val_loss: 9.7797\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1131 - val_loss: 9.7956\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0472 - val_loss: 9.5989\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1122 - val_loss: 9.6850\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0890 - val_loss: 9.4859\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2040 - val_loss: 9.6228\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1421 - val_loss: 9.6500\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1190 - val_loss: 9.7228\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0126 - val_loss: 9.8527\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1322 - val_loss: 9.6197\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9629 - val_loss: 9.6921\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0233 - val_loss: 9.6338\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0365 - val_loss: 9.7303\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.2381 - val_loss: 9.6432\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9880 - val_loss: 9.4986\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0877 - val_loss: 9.9847\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0905 - val_loss: 9.8459\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0402 - val_loss: 9.5564\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9577 - val_loss: 9.9314\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1300 - val_loss: 9.6797\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4186 - val_loss: 9.6974\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.1548 - val_loss: 9.6599\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0357 - val_loss: 9.4377\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3394 - val_loss: 9.7916\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2231 - val_loss: 9.5389\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9327 - val_loss: 9.8396\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1589 - val_loss: 9.7305\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0407 - val_loss: 9.6457\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1158 - val_loss: 9.5053\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.9621 - val_loss: 9.3835\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9848 - val_loss: 9.5489\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0169 - val_loss: 9.7388\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0294 - val_loss: 9.8483\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0221 - val_loss: 9.6641\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0992 - val_loss: 9.9735\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1080 - val_loss: 9.5097\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2189 - val_loss: 9.9879\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2279 - val_loss: 9.6467\n",
      "Epoch 1000/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 110us/step - loss: 6.2183 - val_loss: 9.7685\n",
      "6.663557723417121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 8.5977864e-01,  2.8469706e+00, -3.9561072e-01,  1.8970086e-01,\n",
       "         -2.3424170e+00],\n",
       "        [-1.2839850e+00,  3.3574734e+00, -1.6425178e+00, -3.9922032e-01,\n",
       "          1.3754725e-01],\n",
       "        [-1.7036173e-01, -2.2711823e+00, -3.0983596e+00, -2.2707460e-04,\n",
       "          5.1260465e-01],\n",
       "        [ 8.7766141e-01, -2.9744709e-01,  2.1063912e-01,  6.9774294e-01,\n",
       "          8.1938338e-01],\n",
       "        [-9.5679188e-01,  1.4381605e-01, -9.2261642e-01, -2.2024387e-01,\n",
       "          4.6889967e-01],\n",
       "        [ 6.7043227e-01,  2.5877359e+00, -7.9490113e-01, -1.5886112e-01,\n",
       "         -2.2414677e-01],\n",
       "        [ 1.4893905e+00, -2.1596235e-01,  1.3260319e+00,  2.8514113e-02,\n",
       "          7.5780994e-01]], dtype=float32),\n",
       " array([ 2.4181623 ,  2.5415113 , -1.2846136 ,  0.19532198, -3.80093   ],\n",
       "       dtype=float32),\n",
       " array([[ 0.4826093 ,  1.391788  ,  0.7483634 , -0.7809304 ,  1.20772   ],\n",
       "        [ 0.09191418,  0.8145214 , -0.02129825,  0.31373885,  0.65178853],\n",
       "        [ 0.2492145 ,  1.4384949 , -0.08068402, -0.31715894,  0.32671246],\n",
       "        [-2.267933  , -1.8465904 , -0.04935163,  0.9022098 , -2.137262  ],\n",
       "        [-1.1960608 , -1.5956298 ,  0.9209379 ,  0.68049854, -0.7466873 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.1207952,  2.1187243,  0.2135248, -1.5060558,  2.156991 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.7920433 ],\n",
       "        [ 1.6640489 ],\n",
       "        [-0.01990101],\n",
       "        [-0.7133685 ],\n",
       "        [ 1.3053195 ]], dtype=float32),\n",
       " array([1.9741118], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_1(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure1_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 916us/step - loss: 457.4052 - val_loss: 261.4614\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 202.8726 - val_loss: 75.6939\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 52.3693 - val_loss: 44.1601\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 32.6496 - val_loss: 36.0028\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 28.3885 - val_loss: 24.9158\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 25.1597 - val_loss: 20.9470\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 22.6948 - val_loss: 18.4686\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 20.5877 - val_loss: 18.2894\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 20.3510 - val_loss: 17.9569\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 19.0836 - val_loss: 16.7039\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 18.3228 - val_loss: 15.5815\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.2685 - val_loss: 14.6300\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 16.3882 - val_loss: 14.0595\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 15.4326 - val_loss: 13.1977\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 14.7624 - val_loss: 12.6372\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 13.6409 - val_loss: 12.2266\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 12.2287 - val_loss: 11.2834\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 11.5337 - val_loss: 12.0965\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.8815 - val_loss: 10.9291\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 9.8340 - val_loss: 10.5859\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.4457 - val_loss: 10.5176\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.2667 - val_loss: 10.1956\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 9.5505 - val_loss: 10.0429\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 8.9664 - val_loss: 10.2685\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.1531 - val_loss: 10.2420\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 182us/step - loss: 8.7161 - val_loss: 9.9738\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 8.5783 - val_loss: 10.1361\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 8.7769 - val_loss: 9.8046\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 8.1734 - val_loss: 9.7444\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 8.4548 - val_loss: 9.6695\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.4354 - val_loss: 9.1979\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 8.3271 - val_loss: 9.3273\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 175us/step - loss: 8.2908 - val_loss: 9.7686\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 137us/step - loss: 8.2168 - val_loss: 9.1401\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.0422 - val_loss: 9.2601\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 8.1279 - val_loss: 9.3273\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.0373 - val_loss: 9.1366\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.9974 - val_loss: 9.2401\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.8924 - val_loss: 9.4754\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 8.1968 - val_loss: 9.2255\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.1790 - val_loss: 9.4491\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 8.1147 - val_loss: 9.4066\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9264 - val_loss: 8.9419\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 8.0372 - val_loss: 8.7596\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8193 - val_loss: 9.1359\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.8909 - val_loss: 8.9444\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8147 - val_loss: 8.9199\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.8006 - val_loss: 9.1691\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7907 - val_loss: 9.2668\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8879 - val_loss: 9.1609\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.6429 - val_loss: 8.6940\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.7289 - val_loss: 8.7584\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.1877 - val_loss: 9.0932\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0015 - val_loss: 9.1066\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8459 - val_loss: 9.2036\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5938 - val_loss: 9.2565\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7201 - val_loss: 8.9982\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5627 - val_loss: 8.9728\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8010 - val_loss: 9.0733\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.6517 - val_loss: 8.9943\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.7496 - val_loss: 9.2601\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9604 - val_loss: 9.2902\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5424 - val_loss: 9.2757\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.7766 - val_loss: 9.1809\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4257 - val_loss: 8.9335\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5756 - val_loss: 8.8167\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5278 - val_loss: 8.9739\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4889 - val_loss: 8.8778\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5563 - val_loss: 8.9117\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.5141 - val_loss: 9.1165\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4223 - val_loss: 8.8537\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4021 - val_loss: 8.8154\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4628 - val_loss: 8.9713\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4365 - val_loss: 8.9013\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3898 - val_loss: 8.9467\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.3581 - val_loss: 8.7425\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.9157 - val_loss: 9.1127\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3230 - val_loss: 8.7918\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3766 - val_loss: 8.6730\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1339 - val_loss: 8.7467\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.3925 - val_loss: 9.0878\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1678 - val_loss: 8.7691\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 141us/step - loss: 7.3092 - val_loss: 8.5609\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.0493 - val_loss: 8.6831\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1435 - val_loss: 8.7000\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.0060 - val_loss: 8.7350\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8935 - val_loss: 8.3505\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9097 - val_loss: 8.2671\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8903 - val_loss: 8.2466\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8856 - val_loss: 8.3541\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8539 - val_loss: 8.0298\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8189 - val_loss: 8.2894\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.8617 - val_loss: 8.0272\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8554 - val_loss: 8.2931\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7918 - val_loss: 8.3020\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0539 - val_loss: 8.0895\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7843 - val_loss: 8.3673\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7618 - val_loss: 8.0951\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8128 - val_loss: 8.0147\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8470 - val_loss: 8.3829\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6930 - val_loss: 8.3317\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.6857 - val_loss: 8.3356\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8563 - val_loss: 7.9441\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2260 - val_loss: 8.2867\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.3139 - val_loss: 8.2342\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8379 - val_loss: 8.2804\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8033 - val_loss: 8.0664\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8678 - val_loss: 8.3476\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0001 - val_loss: 8.3453\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7637 - val_loss: 8.2139\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7770 - val_loss: 8.3436\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8353 - val_loss: 8.2593\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7869 - val_loss: 8.1121\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8495 - val_loss: 8.2165\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6261 - val_loss: 7.9047\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6594 - val_loss: 8.0548\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0723 - val_loss: 8.3739\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6119 - val_loss: 7.9604\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5024 - val_loss: 8.2606\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6591 - val_loss: 8.0263\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6373 - val_loss: 7.9601\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6856 - val_loss: 8.0599\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7080 - val_loss: 7.9481\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7876 - val_loss: 8.3715\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6607 - val_loss: 7.9523\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5490 - val_loss: 7.9243\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5966 - val_loss: 8.2422\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4544 - val_loss: 8.2287\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5624 - val_loss: 8.1292\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9397 - val_loss: 8.0424\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7483 - val_loss: 8.4006\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5090 - val_loss: 7.9615\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4955 - val_loss: 8.1613\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5037 - val_loss: 7.9819\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5422 - val_loss: 8.0109\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4392 - val_loss: 7.8954\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6807 - val_loss: 7.8268\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7351 - val_loss: 8.3837\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0173 - val_loss: 8.2481\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7632 - val_loss: 8.0858\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3747 - val_loss: 8.0251\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4229 - val_loss: 8.2009\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6493 - val_loss: 7.9792\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5840 - val_loss: 8.3649\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4278 - val_loss: 8.0651\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.7336 - val_loss: 8.2764\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4319 - val_loss: 7.9687\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4623 - val_loss: 8.1737\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5009 - val_loss: 8.0598\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6419 - val_loss: 7.8546\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6105 - val_loss: 8.1596\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5263 - val_loss: 7.8630\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5371 - val_loss: 8.3366\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5865 - val_loss: 8.2561\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6674 - val_loss: 8.2033\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5413 - val_loss: 8.0714\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5477 - val_loss: 8.0764\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5122 - val_loss: 8.3397\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3473 - val_loss: 8.2076\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3600 - val_loss: 7.9421\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3931 - val_loss: 8.0097\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6006 - val_loss: 7.7744\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3901 - val_loss: 8.0163\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6276 - val_loss: 8.0127\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4137 - val_loss: 8.3057\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5295 - val_loss: 8.0608\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6057 - val_loss: 8.5377\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6311 - val_loss: 8.1825\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6595 - val_loss: 8.2239\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4692 - val_loss: 7.9909\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2535 - val_loss: 8.2875\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5046 - val_loss: 8.2325\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5485 - val_loss: 8.2810\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5049 - val_loss: 7.8953\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4570 - val_loss: 8.0188\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2506 - val_loss: 7.8944\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3701 - val_loss: 8.2424\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4730 - val_loss: 8.1410\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3274 - val_loss: 8.0144\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3778 - val_loss: 8.0329\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3233 - val_loss: 8.1309\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2536 - val_loss: 7.8664\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3392 - val_loss: 8.1555\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3053 - val_loss: 7.8755\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2468 - val_loss: 7.9820\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3913 - val_loss: 8.1856\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2606 - val_loss: 7.9799\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3952 - val_loss: 7.9129\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4156 - val_loss: 7.7662\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3875 - val_loss: 7.9371\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3714 - val_loss: 8.1979\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2513 - val_loss: 7.8194\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3288 - val_loss: 7.9932\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3185 - val_loss: 7.7852\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2355 - val_loss: 7.9641\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5672 - val_loss: 8.0923\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3424 - val_loss: 7.9423\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2739 - val_loss: 7.9607\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3804 - val_loss: 7.6457\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3066 - val_loss: 7.8146\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2879 - val_loss: 7.8274\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2179 - val_loss: 7.8809\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2181 - val_loss: 7.9261\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2900 - val_loss: 7.8249\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2226 - val_loss: 7.6352\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2339 - val_loss: 7.7316\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2373 - val_loss: 7.9787\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6391 - val_loss: 8.1940\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4353 - val_loss: 7.8837\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1610 - val_loss: 7.9179\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4454 - val_loss: 7.7280\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0736 - val_loss: 7.9527\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3901 - val_loss: 8.5822\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6407 - val_loss: 8.0042\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2745 - val_loss: 8.4158\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2919 - val_loss: 7.9734\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2991 - val_loss: 8.0171\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3075 - val_loss: 7.7395\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3850 - val_loss: 7.9080\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1832 - val_loss: 7.8436\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2011 - val_loss: 7.7337\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5089 - val_loss: 8.1451\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3689 - val_loss: 8.0192\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.6168 - val_loss: 8.1658\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2905 - val_loss: 7.8141\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1687 - val_loss: 8.1433\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2355 - val_loss: 8.0984\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2840 - val_loss: 7.9906\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1785 - val_loss: 7.8054\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1865 - val_loss: 7.8583\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1615 - val_loss: 7.8737\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2939 - val_loss: 7.7138\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2076 - val_loss: 8.0132\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1198 - val_loss: 7.8810\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1695 - val_loss: 7.9587\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1237 - val_loss: 7.7113\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1344 - val_loss: 7.8101\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1085 - val_loss: 7.8793\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1580 - val_loss: 7.7933\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1518 - val_loss: 7.9736\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2677 - val_loss: 7.9714\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2203 - val_loss: 7.9087\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1563 - val_loss: 7.8585\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2963 - val_loss: 8.1004\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2886 - val_loss: 8.0867\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1274 - val_loss: 7.9757\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2562 - val_loss: 7.9511\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3592 - val_loss: 7.9509\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3367 - val_loss: 7.8948\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3511 - val_loss: 7.9927\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1321 - val_loss: 7.8018\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2478 - val_loss: 8.1394\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3047 - val_loss: 7.7159\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4020 - val_loss: 7.8820\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1837 - val_loss: 7.6924\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4446 - val_loss: 7.5688\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5314 - val_loss: 7.9423\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1454 - val_loss: 8.1148\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1661 - val_loss: 7.7342\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3721 - val_loss: 8.1805\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1788 - val_loss: 7.7667\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0960 - val_loss: 7.8591\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3180 - val_loss: 7.8407\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1791 - val_loss: 7.9502\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1285 - val_loss: 7.8091\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9894 - val_loss: 7.8087\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0870 - val_loss: 7.9532\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2661 - val_loss: 8.1959\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2461 - val_loss: 8.2871\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4609 - val_loss: 7.9334\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1130 - val_loss: 8.1188\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1393 - val_loss: 8.3652\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1683 - val_loss: 7.8866\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0998 - val_loss: 7.8533\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1297 - val_loss: 7.7276\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1574 - val_loss: 7.8777\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0262 - val_loss: 7.7383\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0524 - val_loss: 7.8088\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0326 - val_loss: 7.8278\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1050 - val_loss: 7.7804\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1976 - val_loss: 8.0343\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2007 - val_loss: 8.1890\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1602 - val_loss: 7.7995\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1568 - val_loss: 7.8378\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1680 - val_loss: 8.1091\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1069 - val_loss: 7.9857\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3426 - val_loss: 8.4637\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3459 - val_loss: 7.7369\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0611 - val_loss: 7.7430\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0635 - val_loss: 7.9469\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1493 - val_loss: 8.4672\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2417 - val_loss: 7.9104\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9975 - val_loss: 7.8233\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0768 - val_loss: 7.8956\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2378 - val_loss: 8.1288\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1793 - val_loss: 7.9858\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0965 - val_loss: 8.0183\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1180 - val_loss: 7.8303\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9877 - val_loss: 7.8664\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9775 - val_loss: 7.6488\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9907 - val_loss: 7.6448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0228 - val_loss: 7.9409\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2741 - val_loss: 7.8158\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3226 - val_loss: 7.8789\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1869 - val_loss: 7.8631\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0429 - val_loss: 7.8995\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1077 - val_loss: 8.2990\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2962 - val_loss: 7.7488\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5633 - val_loss: 7.8618\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1728 - val_loss: 7.8445\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2514 - val_loss: 8.1674\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0601 - val_loss: 7.9340\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0794 - val_loss: 8.0731\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9729 - val_loss: 7.9212\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9396 - val_loss: 7.9276\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1678 - val_loss: 7.8838\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0512 - val_loss: 7.9794\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9347 - val_loss: 8.0287\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3350 - val_loss: 7.8909\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0354 - val_loss: 8.2553\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.0545 - val_loss: 7.8644\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1729 - val_loss: 7.8934\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0242 - val_loss: 7.6041\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0948 - val_loss: 7.7052\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0365 - val_loss: 8.0931\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1988 - val_loss: 8.2114\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3936 - val_loss: 8.0289\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3170 - val_loss: 7.9094\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2406 - val_loss: 7.9576\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2407 - val_loss: 8.0746\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4547 - val_loss: 8.5465\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5587 - val_loss: 8.2452\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0056 - val_loss: 8.2113\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8245 - val_loss: 8.7266\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5003 - val_loss: 8.7188\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2708 - val_loss: 8.4842\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1260 - val_loss: 8.9034\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3961 - val_loss: 8.6820\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2765 - val_loss: 8.5679\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1789 - val_loss: 8.3985\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1240 - val_loss: 7.8561\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0931 - val_loss: 7.8907\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0466 - val_loss: 7.7695\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3015 - val_loss: 8.1406\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1062 - val_loss: 7.8092\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1790 - val_loss: 7.9342\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1727 - val_loss: 7.9923\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1792 - val_loss: 8.2468\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2489 - val_loss: 7.9740\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0960 - val_loss: 7.9923\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4343 - val_loss: 8.1990\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3534 - val_loss: 8.0579\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9730 - val_loss: 7.9390\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1118 - val_loss: 7.6833\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9067 - val_loss: 7.8780\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1488 - val_loss: 8.4022\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.2693 - val_loss: 8.0406\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9767 - val_loss: 7.9545\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0382 - val_loss: 7.9755\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2655 - val_loss: 8.1218\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2197 - val_loss: 7.9684\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0406 - val_loss: 7.9659\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9551 - val_loss: 8.2585\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0827 - val_loss: 7.7387\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9640 - val_loss: 7.9119\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8601 - val_loss: 7.9151\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9328 - val_loss: 8.0054\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0096 - val_loss: 8.0716\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0923 - val_loss: 7.9642\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0056 - val_loss: 8.2264\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1008 - val_loss: 7.7697\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9863 - val_loss: 8.0151\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0189 - val_loss: 8.1771\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1395 - val_loss: 8.2407\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1017 - val_loss: 7.8051\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0158 - val_loss: 8.0152\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1965 - val_loss: 8.0229\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9277 - val_loss: 8.4367\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3411 - val_loss: 8.2292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0499 - val_loss: 8.8429\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6846 - val_loss: 8.2762\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2707 - val_loss: 8.6687\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1605 - val_loss: 8.6825\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3898 - val_loss: 8.8463\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3905 - val_loss: 7.9247\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0417 - val_loss: 8.2732\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2147 - val_loss: 8.1759\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1536 - val_loss: 8.3895\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0560 - val_loss: 7.7837\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0074 - val_loss: 8.2494\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9612 - val_loss: 8.2272\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0750 - val_loss: 8.1204\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1694 - val_loss: 8.2218\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0544 - val_loss: 8.1013\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0709 - val_loss: 8.1758\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9993 - val_loss: 8.2094\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0135 - val_loss: 7.8142\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9911 - val_loss: 8.0631\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1774 - val_loss: 8.2627\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9802 - val_loss: 8.0104\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1558 - val_loss: 7.7314\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8310 - val_loss: 8.1898\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0564 - val_loss: 8.1416\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1380 - val_loss: 8.3196\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1685 - val_loss: 8.3248\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1186 - val_loss: 8.5633\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0576 - val_loss: 8.5171\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9265 - val_loss: 7.8684\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9303 - val_loss: 8.0463\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9927 - val_loss: 8.0789\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9234 - val_loss: 7.5931\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8503 - val_loss: 8.2902\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0742 - val_loss: 8.2819\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4423 - val_loss: 8.1446\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0542 - val_loss: 8.0349\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9163 - val_loss: 8.6130\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8636 - val_loss: 8.2485\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9127 - val_loss: 8.1652\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8653 - val_loss: 8.0347\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9163 - val_loss: 8.0629\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0532 - val_loss: 8.1017\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2797 - val_loss: 8.5816\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9761 - val_loss: 8.1978\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0871 - val_loss: 7.6148\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9997 - val_loss: 7.7423\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9734 - val_loss: 8.2426\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3776 - val_loss: 8.2212\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8954 - val_loss: 8.5666\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9688 - val_loss: 7.9546\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9787 - val_loss: 8.4430\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0289 - val_loss: 8.2240\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8892 - val_loss: 8.0860\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0075 - val_loss: 8.0727\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8816 - val_loss: 7.9792\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7989 - val_loss: 7.9380\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0124 - val_loss: 8.7001\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9372 - val_loss: 8.3111\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9604 - val_loss: 8.4916\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3773 - val_loss: 7.9661\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7795 - val_loss: 8.0665\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6316 - val_loss: 8.9891\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0575 - val_loss: 8.3455\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2451 - val_loss: 8.6690\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2288 - val_loss: 8.2864\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1701 - val_loss: 8.1647\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0268 - val_loss: 8.4156\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9194 - val_loss: 8.3260\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0023 - val_loss: 8.5107\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9181 - val_loss: 8.0972\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9509 - val_loss: 8.2210\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8921 - val_loss: 8.0908\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0049 - val_loss: 8.0854\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0128 - val_loss: 8.0733\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9349 - val_loss: 8.0148\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9494 - val_loss: 8.3835\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9864 - val_loss: 8.5864\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8283 - val_loss: 7.8460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9750 - val_loss: 8.0052\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2985 - val_loss: 7.6082\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0453 - val_loss: 8.2786\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9034 - val_loss: 8.3260\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8506 - val_loss: 8.2204\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9534 - val_loss: 8.9010\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9274 - val_loss: 8.5547\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0486 - val_loss: 7.8274\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9545 - val_loss: 7.9938\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8793 - val_loss: 8.4774\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.029 - 0s 95us/step - loss: 6.2332 - val_loss: 8.7195\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0277 - val_loss: 7.9385\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9826 - val_loss: 8.3676\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8606 - val_loss: 8.5672\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0109 - val_loss: 8.5910\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0559 - val_loss: 8.4351\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8894 - val_loss: 8.4147\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9868 - val_loss: 8.2001\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8033 - val_loss: 8.2763\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8117 - val_loss: 8.4193\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0145 - val_loss: 8.6474\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1865 - val_loss: 8.1129\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0494 - val_loss: 8.2562\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0755 - val_loss: 8.5894\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2403 - val_loss: 9.2204\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1622 - val_loss: 8.1154\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9865 - val_loss: 8.1762\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8612 - val_loss: 8.1991\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8953 - val_loss: 8.2443\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8900 - val_loss: 8.2580\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9732 - val_loss: 8.2052\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9586 - val_loss: 8.8006\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0735 - val_loss: 8.1303\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8447 - val_loss: 8.8970\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1211 - val_loss: 8.0083\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9918 - val_loss: 8.0062\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2658 - val_loss: 8.3299\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1702 - val_loss: 8.6748\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6897 - val_loss: 8.6245\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0401 - val_loss: 8.3647\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9787 - val_loss: 8.2081\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9274 - val_loss: 8.5336\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8880 - val_loss: 8.1319\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7898 - val_loss: 8.4513\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7874 - val_loss: 8.2267\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7897 - val_loss: 8.3563\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8514 - val_loss: 8.0938\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7946 - val_loss: 8.4065\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8580 - val_loss: 8.6334\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8541 - val_loss: 8.4188\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4483 - val_loss: 8.3979\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0143 - val_loss: 8.7478\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8725 - val_loss: 8.0859\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4587 - val_loss: 8.9988\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8035 - val_loss: 8.4052\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8547 - val_loss: 8.5449\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8169 - val_loss: 8.2215\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7402 - val_loss: 8.4150\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9852 - val_loss: 8.4787\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9934 - val_loss: 8.3065\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7470 - val_loss: 8.5495\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8904 - val_loss: 8.7711\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9328 - val_loss: 8.3885\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8966 - val_loss: 8.4640\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9752 - val_loss: 8.3129\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1586 - val_loss: 8.1311\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7527 - val_loss: 8.4120\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7659 - val_loss: 8.2181\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7757 - val_loss: 8.4434\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8037 - val_loss: 8.5752\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8629 - val_loss: 8.4181\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8549 - val_loss: 8.6668\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9938 - val_loss: 7.9519\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8268 - val_loss: 8.4322\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8661 - val_loss: 8.6915\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8109 - val_loss: 8.4081\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8567 - val_loss: 8.5393\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0612 - val_loss: 8.9234\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9883 - val_loss: 8.8791\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7540 - val_loss: 8.4430\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8219 - val_loss: 8.2914\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9477 - val_loss: 8.3409\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8332 - val_loss: 8.7160\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0866 - val_loss: 8.3493\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3815 - val_loss: 8.3589\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1852 - val_loss: 8.9804\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9674 - val_loss: 8.1669\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7496 - val_loss: 8.4609\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8133 - val_loss: 8.4164\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8640 - val_loss: 9.0153\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8770 - val_loss: 8.1996\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9087 - val_loss: 8.4488\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9330 - val_loss: 8.9665\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8231 - val_loss: 8.4205\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8019 - val_loss: 8.3837\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1433 - val_loss: 7.9870\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8524 - val_loss: 8.4563\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0658 - val_loss: 8.7281\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9917 - val_loss: 8.7949\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0254 - val_loss: 8.8217\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9482 - val_loss: 8.7682\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.9421 - val_loss: 8.5546\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9333 - val_loss: 8.3699\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7218 - val_loss: 8.6818\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8005 - val_loss: 8.3317\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7752 - val_loss: 8.2974\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7510 - val_loss: 8.1399\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8059 - val_loss: 8.5719\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7789 - val_loss: 8.7047\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4781 - val_loss: 8.7239\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3476 - val_loss: 8.4530\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9130 - val_loss: 8.8876\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9716 - val_loss: 9.0276\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9642 - val_loss: 8.4270\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9875 - val_loss: 8.6306\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2889 - val_loss: 8.5224\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1069 - val_loss: 9.5780\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9111 - val_loss: 8.6663\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8892 - val_loss: 8.4923\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0016 - val_loss: 8.7916\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7887 - val_loss: 8.6553\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7810 - val_loss: 8.7103\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8936 - val_loss: 8.1667\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7219 - val_loss: 8.6887\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7383 - val_loss: 8.8034\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8355 - val_loss: 8.7205\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7180 - val_loss: 8.8544\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9361 - val_loss: 8.5189\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7645 - val_loss: 8.3730\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7836 - val_loss: 8.7556\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8129 - val_loss: 8.2911\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7828 - val_loss: 8.6044\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7741 - val_loss: 8.5378\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7064 - val_loss: 8.6103\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.9654 - val_loss: 8.4307\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.0236 - val_loss: 8.2262\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7325 - val_loss: 8.5126\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7876 - val_loss: 8.2128\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7381 - val_loss: 8.5781\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0078 - val_loss: 8.6240\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2388 - val_loss: 9.1164\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6585 - val_loss: 8.7683\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3806 - val_loss: 9.0279\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0470 - val_loss: 8.7220\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8516 - val_loss: 8.6450\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6743 - val_loss: 8.5938\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8339 - val_loss: 8.4938\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8960 - val_loss: 8.5940\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.8200 - val_loss: 8.4820\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.7551 - val_loss: 8.4153\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 126us/step - loss: 5.8454 - val_loss: 8.5993\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7602 - val_loss: 8.3719\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7140 - val_loss: 8.3875\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7271 - val_loss: 8.2501\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6845 - val_loss: 8.8001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7349 - val_loss: 8.4534\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7128 - val_loss: 8.7005\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7223 - val_loss: 8.1128\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7125 - val_loss: 8.5042\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0211 - val_loss: 8.9720\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8627 - val_loss: 8.7070\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7220 - val_loss: 8.6817\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7052 - val_loss: 8.7477\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.6648 - val_loss: 8.3895\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7394 - val_loss: 8.7411\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8224 - val_loss: 8.2291\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7563 - val_loss: 8.2253\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7576 - val_loss: 8.7142\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7997 - val_loss: 8.4418\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6408 - val_loss: 8.9761\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9604 - val_loss: 8.8522\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7171 - val_loss: 8.5536\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6675 - val_loss: 8.3287\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7433 - val_loss: 8.4677\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7287 - val_loss: 8.5829\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8632 - val_loss: 8.3352\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7274 - val_loss: 9.1513\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7192 - val_loss: 8.7503\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6789 - val_loss: 8.2905\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7984 - val_loss: 8.2403\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8507 - val_loss: 8.1682\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9324 - val_loss: 8.8034\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8594 - val_loss: 8.4269\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8494 - val_loss: 8.5204\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6569 - val_loss: 8.5008\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7336 - val_loss: 8.4899\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6943 - val_loss: 8.6830\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8473 - val_loss: 8.5016\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7959 - val_loss: 8.5749\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6805 - val_loss: 8.5568\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7255 - val_loss: 8.2415\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7780 - val_loss: 8.4311\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6798 - val_loss: 8.5450\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6595 - val_loss: 8.5955\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8271 - val_loss: 8.6761\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7068 - val_loss: 8.5255\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6844 - val_loss: 8.4696\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7277 - val_loss: 8.4598\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6924 - val_loss: 8.3835\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6793 - val_loss: 8.1074\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7688 - val_loss: 8.3486\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2371 - val_loss: 8.7168\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9282 - val_loss: 8.9983\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9530 - val_loss: 9.0165\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8088 - val_loss: 8.7358\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6614 - val_loss: 8.3280\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9147 - val_loss: 8.9248\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6371 - val_loss: 8.4542\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9601 - val_loss: 9.0442\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7611 - val_loss: 8.5652\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8829 - val_loss: 8.7181\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7354 - val_loss: 8.6073\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8838 - val_loss: 8.5133\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0737 - val_loss: 8.6652\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1044 - val_loss: 8.7328\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8542 - val_loss: 8.6597\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6735 - val_loss: 8.7070\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7110 - val_loss: 8.8096\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6731 - val_loss: 8.5967\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6940 - val_loss: 8.8387\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6381 - val_loss: 8.6684\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6887 - val_loss: 8.1536\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6132 - val_loss: 8.5713\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4472 - val_loss: 8.6706\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3945 - val_loss: 9.3118\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9392 - val_loss: 9.0079\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7698 - val_loss: 8.7435\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6653 - val_loss: 8.6863\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6984 - val_loss: 8.7371\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7427 - val_loss: 8.2986\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7225 - val_loss: 8.4748\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8213 - val_loss: 8.5086\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8669 - val_loss: 8.8046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6847 - val_loss: 8.5402\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6217 - val_loss: 8.3660\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7292 - val_loss: 8.1995\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7649 - val_loss: 8.4223\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8627 - val_loss: 8.5415\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7337 - val_loss: 8.4919\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8104 - val_loss: 8.0921\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6009 - val_loss: 8.3601\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7984 - val_loss: 9.1142\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7994 - val_loss: 8.2153\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7478 - val_loss: 8.1224\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7098 - val_loss: 8.6013\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6691 - val_loss: 8.2782\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8745 - val_loss: 9.0021\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7228 - val_loss: 8.7893\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6154 - val_loss: 8.7484\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6644 - val_loss: 8.4195\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7803 - val_loss: 8.7835\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8110 - val_loss: 8.2177\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0128 - val_loss: 9.0726\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7778 - val_loss: 8.5065\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5754 - val_loss: 9.2079\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8138 - val_loss: 9.0012\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7850 - val_loss: 8.7421\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7891 - val_loss: 8.7509\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0097 - val_loss: 9.5884\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8355 - val_loss: 8.3415\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6288 - val_loss: 8.5346\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6765 - val_loss: 8.9408\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5800 - val_loss: 8.6504\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6026 - val_loss: 8.4360\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6528 - val_loss: 8.1987\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8220 - val_loss: 8.8357\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6526 - val_loss: 8.5419\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6249 - val_loss: 8.6696\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7404 - val_loss: 8.7197\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9408 - val_loss: 8.8865\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6434 - val_loss: 8.3454\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5889 - val_loss: 8.7232\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6149 - val_loss: 8.5898\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6678 - val_loss: 8.3394\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6421 - val_loss: 8.7489\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7619 - val_loss: 9.4308\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6854 - val_loss: 8.2795\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7037 - val_loss: 8.2356\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7297 - val_loss: 8.6000\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5568 - val_loss: 8.6456\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5747 - val_loss: 8.8139\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5859 - val_loss: 8.4825\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6187 - val_loss: 8.2164\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7039 - val_loss: 8.8156\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7072 - val_loss: 8.8015\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5505 - val_loss: 8.0866\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6996 - val_loss: 8.3564\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6190 - val_loss: 8.6330\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6476 - val_loss: 9.0879\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8120 - val_loss: 8.6005\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8157 - val_loss: 8.6258\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5302 - val_loss: 8.2764\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5818 - val_loss: 8.9689\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5895 - val_loss: 8.5243\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5907 - val_loss: 8.9785\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6054 - val_loss: 8.8511\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5842 - val_loss: 8.3863\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7112 - val_loss: 8.4542\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7747 - val_loss: 8.5696\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9364 - val_loss: 9.5517\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4428 - val_loss: 8.8797\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0603 - val_loss: 8.8741\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1617 - val_loss: 8.6276\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5939 - val_loss: 8.6591\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6275 - val_loss: 8.2838\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5989 - val_loss: 8.7050\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6551 - val_loss: 8.5455\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6396 - val_loss: 8.9137\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5563 - val_loss: 8.6741\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8290 - val_loss: 8.6922\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7131 - val_loss: 8.5696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5826 - val_loss: 9.0343\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6554 - val_loss: 8.5340\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6227 - val_loss: 8.7475\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6468 - val_loss: 8.1728\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7054 - val_loss: 8.4064\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8643 - val_loss: 8.4565\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6043 - val_loss: 8.8369\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6617 - val_loss: 8.5499\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5717 - val_loss: 8.3901\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8565 - val_loss: 8.5564\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5826 - val_loss: 8.3449\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6190 - val_loss: 8.7097\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8578 - val_loss: 8.2811\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5733 - val_loss: 8.3306\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5690 - val_loss: 8.5254\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6230 - val_loss: 8.7463\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6330 - val_loss: 8.7334\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6045 - val_loss: 8.4952\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8122 - val_loss: 8.4280\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8168 - val_loss: 8.8737\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8175 - val_loss: 8.3770\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2784 - val_loss: 8.9037\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9267 - val_loss: 8.2724\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5909 - val_loss: 8.6513\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8087 - val_loss: 9.0250\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7337 - val_loss: 8.6102\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0813 - val_loss: 8.5818\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9079 - val_loss: 8.6075\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5806 - val_loss: 8.5910\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5818 - val_loss: 8.4225\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7353 - val_loss: 8.6646\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5299 - val_loss: 8.0941\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5361 - val_loss: 9.0451\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6005 - val_loss: 8.6632\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6099 - val_loss: 8.8849\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5255 - val_loss: 8.7303\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5677 - val_loss: 8.3242\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5693 - val_loss: 8.0700\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7536 - val_loss: 8.7171\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6716 - val_loss: 8.5670\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5381 - val_loss: 8.8651\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5258 - val_loss: 8.6015\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5162 - val_loss: 8.6574\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5620 - val_loss: 8.4738\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6323 - val_loss: 8.3843\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5387 - val_loss: 8.0812\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5096 - val_loss: 8.5428\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5941 - val_loss: 8.7446\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6054 - val_loss: 8.5664\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6226 - val_loss: 8.6154\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7261 - val_loss: 8.4868\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9162 - val_loss: 8.7754\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6447 - val_loss: 8.9328\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6490 - val_loss: 8.5307\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5731 - val_loss: 8.4547\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5289 - val_loss: 8.8468\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5103 - val_loss: 8.7744\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5813 - val_loss: 8.2737\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5667 - val_loss: 8.5402\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7190 - val_loss: 8.4747\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8431 - val_loss: 8.8433\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8931 - val_loss: 8.3819\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6475 - val_loss: 8.6520\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5823 - val_loss: 8.2655\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6123 - val_loss: 8.3977\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7660 - val_loss: 8.4822\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6957 - val_loss: 9.0666\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4797 - val_loss: 8.5205\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5652 - val_loss: 8.8804\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7047 - val_loss: 8.4819\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5431 - val_loss: 8.8918\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4533 - val_loss: 8.7554\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5581 - val_loss: 8.7721\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6429 - val_loss: 8.2184\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4975 - val_loss: 8.5323\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4446 - val_loss: 8.5111\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5079 - val_loss: 8.5898\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5485 - val_loss: 8.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5105 - val_loss: 8.5177\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5142 - val_loss: 8.5313\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5916 - val_loss: 8.4050\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4585 - val_loss: 8.5096\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4951 - val_loss: 8.4994\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4393 - val_loss: 8.5141\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4785 - val_loss: 8.7878\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4951 - val_loss: 8.5963\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6489 - val_loss: 8.5114\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5163 - val_loss: 8.4161\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5396 - val_loss: 8.8151\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5693 - val_loss: 8.4913\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4643 - val_loss: 9.1814\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6953 - val_loss: 8.5630\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7707 - val_loss: 8.5299\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5929 - val_loss: 9.0791\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6859 - val_loss: 8.7047\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6418 - val_loss: 8.5951\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6052 - val_loss: 8.5610\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4716 - val_loss: 8.4814\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7434 - val_loss: 8.5477\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5809 - val_loss: 8.4904\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8782 - val_loss: 8.6582\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7174 - val_loss: 8.3974\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5532 - val_loss: 8.7361\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4786 - val_loss: 9.2048\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5682 - val_loss: 9.0423\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6239 - val_loss: 8.6092\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6830 - val_loss: 8.4372\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7410 - val_loss: 8.8927\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5980 - val_loss: 8.8294\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5836 - val_loss: 8.8891\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4713 - val_loss: 8.5319\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4454 - val_loss: 8.6649\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5360 - val_loss: 8.4051\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4568 - val_loss: 8.6984\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4614 - val_loss: 8.8030\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5373 - val_loss: 8.6929\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5102 - val_loss: 8.6169\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5160 - val_loss: 8.6883\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5985 - val_loss: 8.6610\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5568 - val_loss: 8.7339\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5620 - val_loss: 8.3208\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7672 - val_loss: 8.6282\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4880 - val_loss: 8.8099\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4479 - val_loss: 8.7024\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4649 - val_loss: 8.4928\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4852 - val_loss: 8.4353\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4542 - val_loss: 8.5096\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5756 - val_loss: 8.5929\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5205 - val_loss: 8.4660\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5935 - val_loss: 8.6127\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5912 - val_loss: 8.8424\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5446 - val_loss: 8.5574\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6258 - val_loss: 8.6208\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5610 - val_loss: 8.5398\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5297 - val_loss: 8.8109\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5481 - val_loss: 8.8056\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5659 - val_loss: 8.4646\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4549 - val_loss: 8.3539\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5635 - val_loss: 8.5084\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5882 - val_loss: 8.9316\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6292 - val_loss: 8.8120\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5691 - val_loss: 8.5151\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4385 - val_loss: 8.7811\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4828 - val_loss: 8.5415\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5702 - val_loss: 8.5439\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5188 - val_loss: 8.8058\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5086 - val_loss: 8.5020\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4879 - val_loss: 8.5269\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4466 - val_loss: 8.8774\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4875 - val_loss: 8.6234\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5604 - val_loss: 8.7517\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6395 - val_loss: 8.7716\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5442 - val_loss: 8.5394\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6880 - val_loss: 8.9438\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9864 - val_loss: 8.4437\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7184 - val_loss: 8.9372\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5772 - val_loss: 8.5599\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4998 - val_loss: 8.9865\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5876 - val_loss: 8.5624\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3630 - val_loss: 8.8170\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5943 - val_loss: 8.6383\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6715 - val_loss: 8.8609\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8181 - val_loss: 8.7581\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5608 - val_loss: 8.5453\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3670 - val_loss: 8.6794\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5341 - val_loss: 9.0218\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6184 - val_loss: 8.4522\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7440 - val_loss: 8.8700\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7410 - val_loss: 8.3743\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4193 - val_loss: 8.3526\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4722 - val_loss: 8.4815\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4417 - val_loss: 8.4997\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4015 - val_loss: 8.3814\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4788 - val_loss: 8.7358\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6346 - val_loss: 8.8462\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4538 - val_loss: 8.3732\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5882 - val_loss: 8.6851\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8079 - val_loss: 8.9193\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7864 - val_loss: 8.4320\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4954 - val_loss: 9.0478\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8250 - val_loss: 8.9538\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5716 - val_loss: 8.6375\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5257 - val_loss: 8.4315\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6042 - val_loss: 8.5801\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6437 - val_loss: 8.8536\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5930 - val_loss: 8.2091\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4086 - val_loss: 8.3423\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3959 - val_loss: 8.3883\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4103 - val_loss: 8.5047\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5078 - val_loss: 8.5713\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4323 - val_loss: 8.4208\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8124 - val_loss: 8.9770\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3822 - val_loss: 8.7311\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7099 - val_loss: 8.4834\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4329 - val_loss: 8.6716\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4304 - val_loss: 8.5253\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5164 - val_loss: 8.4645\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4833 - val_loss: 8.5403\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4560 - val_loss: 8.5035\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5538 - val_loss: 8.7112\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4392 - val_loss: 8.8384\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4635 - val_loss: 8.7461\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4127 - val_loss: 8.3529\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4492 - val_loss: 8.3559\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3961 - val_loss: 8.7257\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3622 - val_loss: 8.5090\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5182 - val_loss: 8.7387\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5009 - val_loss: 8.5217\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4741 - val_loss: 8.5103\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4357 - val_loss: 8.3065\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6409 - val_loss: 8.7728\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5750 - val_loss: 8.6605\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5299 - val_loss: 8.4441\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7183 - val_loss: 8.6009\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8005 - val_loss: 9.0336\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5275 - val_loss: 8.7316\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5869 - val_loss: 8.8364\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6560 - val_loss: 8.4165\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6612 - val_loss: 8.3137\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5411 - val_loss: 8.8318\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3661 - val_loss: 8.6584\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4414 - val_loss: 8.5654\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6139 - val_loss: 8.3717\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4447 - val_loss: 8.8314\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4709 - val_loss: 8.6545\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.3793 - val_loss: 8.6151\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3753 - val_loss: 8.5534\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4601 - val_loss: 8.3613\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4433 - val_loss: 8.9578\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3993 - val_loss: 8.5259\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4529 - val_loss: 8.3166\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4867 - val_loss: 8.3994\n",
      "6.668892900822526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.6584237 ,  3.600912  ,  1.0642779 , -1.4646646 , -3.9994962 ],\n",
       "        [-0.55934453, -3.151859  ,  1.2732308 , -1.1256683 ,  1.5035728 ],\n",
       "        [-0.49883747, -0.6132283 ,  0.18551446, -0.21356298, -1.1399486 ],\n",
       "        [-0.2986147 ,  1.943602  , -0.3162826 ,  1.1644708 , -2.184272  ],\n",
       "        [-0.11221903,  1.2907693 ,  0.7853834 , -1.884835  ,  0.00748462],\n",
       "        [ 0.31130916, -1.4160132 , -0.46827623, -1.2205663 ,  0.4667793 ],\n",
       "        [ 0.072436  , -3.4009252 , -0.26400906, -0.47478816, -0.42128587]],\n",
       "       dtype=float32),\n",
       " array([ 1.1896387, -1.6924345, -2.210228 ,  4.021315 , -1.340502 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.5058452 ,  1.0068543 , -0.9291062 ,  1.0465548 , -0.6207959 ,\n",
       "          1.0926247 ,  0.2773367 , -1.0355852 , -1.0305797 ,  0.06563292],\n",
       "        [ 0.20539135, -0.41403428,  0.5349409 ,  0.26193297, -0.44147187,\n",
       "         -0.63234824, -0.1750498 ,  0.06486125,  0.6244549 ,  0.43516093],\n",
       "        [-0.5177047 , -0.79228765,  0.35194433, -0.14061534, -0.36080667,\n",
       "         -0.661197  ,  0.28503188,  0.36311713,  0.7451253 , -0.14842415],\n",
       "        [-0.6165448 , -1.0607452 ,  0.7137452 , -0.07879567,  0.21052544,\n",
       "         -0.05029145, -1.0025972 ,  1.1540128 ,  0.8948438 , -0.18749285],\n",
       "        [ 0.8514653 ,  0.91565156, -0.09111185,  0.6996952 , -0.81359196,\n",
       "          0.73103577,  0.40188384, -0.74131167, -0.7455004 ,  1.0551411 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.8516698,  1.8600798, -1.8342823,  1.8047462, -1.8276535,\n",
       "         1.7696517,  1.4372919, -1.8869073, -1.8314961,  1.809824 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.2503265],\n",
       "        [ 1.0327493],\n",
       "        [-1.3233979],\n",
       "        [ 1.270431 ],\n",
       "        [-1.1596228],\n",
       "        [ 1.3466835],\n",
       "        [ 0.3500212],\n",
       "        [-1.653526 ],\n",
       "        [-1.1513938],\n",
       "        [ 0.997933 ]], dtype=float32),\n",
       " array([1.7689137], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_2(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure2_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 948us/step - loss: 479.4770 - val_loss: 222.7928\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 103.5366 - val_loss: 73.9312\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 47.7805 - val_loss: 28.0329\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 24.3784 - val_loss: 21.6257\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 18.4289 - val_loss: 21.4561\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.8812 - val_loss: 19.3782\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 16.2183 - val_loss: 19.6031\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.7774 - val_loss: 19.0691\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.4675 - val_loss: 19.0905\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.1612 - val_loss: 17.7776\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.0118 - val_loss: 16.6883\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.7688 - val_loss: 15.4767\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.1538 - val_loss: 15.1134\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 11.3605 - val_loss: 13.3261\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 10.1658 - val_loss: 13.4274\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 9.9880 - val_loss: 12.7179\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 9.6300 - val_loss: 12.4526\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.2309 - val_loss: 12.4705\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7964 - val_loss: 11.9435\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 8.7358 - val_loss: 11.5012\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2931 - val_loss: 11.9359\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.8804 - val_loss: 10.8873\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0658 - val_loss: 10.7691\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3080 - val_loss: 12.0754\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0014 - val_loss: 11.2542\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.9680 - val_loss: 11.3975\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4905 - val_loss: 10.8950\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.9294 - val_loss: 10.8273\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5022 - val_loss: 10.7259\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3260 - val_loss: 10.9862\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5147 - val_loss: 10.7862\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1512 - val_loss: 11.3504\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.0452 - val_loss: 10.8547\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5964 - val_loss: 10.6225\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4722 - val_loss: 10.5336\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1539 - val_loss: 11.2370\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3703 - val_loss: 10.9310\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.6481 - val_loss: 11.9439\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3979 - val_loss: 10.4359\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3318 - val_loss: 10.5852\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0268 - val_loss: 10.3932\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2821 - val_loss: 10.7749\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9376 - val_loss: 10.4813\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2669 - val_loss: 10.1976\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1454 - val_loss: 11.0040\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1129 - val_loss: 10.3945\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0552 - val_loss: 10.8609\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3872 - val_loss: 11.6017\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7616 - val_loss: 12.0542\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5255 - val_loss: 10.4352\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.4865 - val_loss: 10.1315\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8085 - val_loss: 11.5309\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4503 - val_loss: 10.2566\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4156 - val_loss: 10.9486\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9995 - val_loss: 10.0666\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9324 - val_loss: 10.3086\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0001 - val_loss: 10.0985\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9373 - val_loss: 10.1887\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8872 - val_loss: 9.9606\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2160 - val_loss: 10.7002\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9635 - val_loss: 10.2916\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5846 - val_loss: 10.0414\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8616 - val_loss: 9.9734\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9654 - val_loss: 9.9636\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8715 - val_loss: 10.6539\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1741 - val_loss: 9.9495\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9391 - val_loss: 10.2669\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9889 - val_loss: 9.6926\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8669 - val_loss: 9.7793\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9484 - val_loss: 10.2102\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0668 - val_loss: 9.6818\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0270 - val_loss: 9.6479\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5022 - val_loss: 10.1834\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2706 - val_loss: 9.5831\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8945 - val_loss: 9.8974\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8803 - val_loss: 9.7053\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9516 - val_loss: 9.7235\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0057 - val_loss: 9.6859\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8624 - val_loss: 9.5352\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7239 - val_loss: 9.6972\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9365 - val_loss: 9.5079\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0761 - val_loss: 9.6540\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8745 - val_loss: 9.3662\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7873 - val_loss: 9.5488\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6940 - val_loss: 9.7171\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7189 - val_loss: 9.2065\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6937 - val_loss: 9.1749\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7497 - val_loss: 9.3618\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8053 - val_loss: 9.4805\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7379 - val_loss: 9.4175\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7888 - val_loss: 9.0943\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8141 - val_loss: 9.2033\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0050 - val_loss: 9.1542\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6645 - val_loss: 8.9958\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6729 - val_loss: 8.9285\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6139 - val_loss: 9.3598\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6993 - val_loss: 8.7464\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.5922 - val_loss: 8.6762\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6124 - val_loss: 8.7386\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7874 - val_loss: 9.2518\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8159 - val_loss: 8.7260\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8522 - val_loss: 8.5076\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4827 - val_loss: 8.5428\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7840 - val_loss: 9.1126\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6044 - val_loss: 8.6099\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5096 - val_loss: 8.6300\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6950 - val_loss: 8.2824\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6433 - val_loss: 8.2129\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8803 - val_loss: 8.8492\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5115 - val_loss: 8.3928\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5869 - val_loss: 9.0434\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5550 - val_loss: 8.2037\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6992 - val_loss: 8.3584\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6233 - val_loss: 8.9002\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7506 - val_loss: 7.8226\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0070 - val_loss: 9.6274\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9358 - val_loss: 8.4599\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9229 - val_loss: 9.7798\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6956 - val_loss: 8.5332\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8863 - val_loss: 9.5959\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4742 - val_loss: 8.1373\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4297 - val_loss: 8.3219\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3444 - val_loss: 7.8334\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.4339 - val_loss: 8.2117\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3383 - val_loss: 8.3442\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6445 - val_loss: 7.9662\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4309 - val_loss: 8.6770\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4461 - val_loss: 8.0907\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4742 - val_loss: 8.1130\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2603 - val_loss: 8.2584\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1711 - val_loss: 8.0572\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5780 - val_loss: 7.6592\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5405 - val_loss: 8.8804\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.3398 - val_loss: 8.0118\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4282 - val_loss: 8.3137\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.667 - 0s 102us/step - loss: 6.4008 - val_loss: 8.2282\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3612 - val_loss: 7.9502\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4192 - val_loss: 8.8040\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4063 - val_loss: 7.8942\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5226 - val_loss: 8.3598\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1964 - val_loss: 7.8335\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4109 - val_loss: 7.7624\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4503 - val_loss: 8.1507\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3296 - val_loss: 8.4512\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3239 - val_loss: 7.9144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3042 - val_loss: 8.0422\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3881 - val_loss: 8.3940\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4413 - val_loss: 7.8944\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6447 - val_loss: 9.3696\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0073 - val_loss: 8.2852\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0863 - val_loss: 8.7905\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1801 - val_loss: 8.1403\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6319 - val_loss: 8.5936\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3525 - val_loss: 8.1524\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5336 - val_loss: 8.0327\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1860 - val_loss: 7.7948\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3229 - val_loss: 7.9581\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2287 - val_loss: 8.3581\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0055 - val_loss: 7.8722\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1034 - val_loss: 8.2636\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6276 - val_loss: 7.7893\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.1087 - val_loss: 8.1083\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0463 - val_loss: 7.9773\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.9145 - val_loss: 8.3891\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9916 - val_loss: 7.9656\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9579 - val_loss: 8.3579\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1082 - val_loss: 8.0152\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0499 - val_loss: 8.2844\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0056 - val_loss: 8.0195\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8640 - val_loss: 8.1204\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9392 - val_loss: 8.2729\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2004 - val_loss: 8.3774\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2082 - val_loss: 8.1835\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1137 - val_loss: 8.1554\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1628 - val_loss: 7.7669\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4718 - val_loss: 8.1587\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9240 - val_loss: 8.2974\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9265 - val_loss: 8.4349\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9204 - val_loss: 8.4456\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7285 - val_loss: 8.1886\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1095 - val_loss: 8.1791\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1864 - val_loss: 8.1294\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9293 - val_loss: 8.2082\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3559 - val_loss: 9.2730\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1708 - val_loss: 8.2855\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9257 - val_loss: 8.6809\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0918 - val_loss: 8.4581\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9959 - val_loss: 8.1357\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1302 - val_loss: 8.3082\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9025 - val_loss: 8.0903\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0305 - val_loss: 8.3565\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8626 - val_loss: 8.5568\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1449 - val_loss: 8.3502\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2830 - val_loss: 8.8443\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0890 - val_loss: 8.1187\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1168 - val_loss: 8.3527\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9539 - val_loss: 8.3445\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1354 - val_loss: 8.5744\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0228 - val_loss: 8.0868\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1761 - val_loss: 8.8662\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8825 - val_loss: 8.2838\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2852 - val_loss: 9.5725\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2751 - val_loss: 8.0935\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9948 - val_loss: 8.2822\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8062 - val_loss: 8.0301\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8607 - val_loss: 8.5234\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9654 - val_loss: 8.5541\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9316 - val_loss: 8.9006\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8201 - val_loss: 8.8125\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9772 - val_loss: 9.2583\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0488 - val_loss: 8.4531\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8604 - val_loss: 8.5015\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0448 - val_loss: 8.6735\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0593 - val_loss: 8.5857\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9047 - val_loss: 9.0870\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8654 - val_loss: 8.5969\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9022 - val_loss: 8.5332\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8629 - val_loss: 8.5603\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8789 - val_loss: 8.2791\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8761 - val_loss: 8.3288\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7968 - val_loss: 9.1106\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8968 - val_loss: 8.6063\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9386 - val_loss: 8.8155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9509 - val_loss: 8.2830\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0493 - val_loss: 9.4845\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1341 - val_loss: 9.1441\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0621 - val_loss: 8.8939\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8597 - val_loss: 9.0665\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7652 - val_loss: 8.4737\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9208 - val_loss: 8.3633\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0212 - val_loss: 8.9237\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8658 - val_loss: 8.5688\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7687 - val_loss: 8.5819\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6872 - val_loss: 8.3409\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8684 - val_loss: 8.6283\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8183 - val_loss: 9.0561\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7503 - val_loss: 8.6641\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8310 - val_loss: 8.5577\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8412 - val_loss: 8.8160\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7018 - val_loss: 8.7287\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8534 - val_loss: 8.5182\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8320 - val_loss: 8.7805\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0737 - val_loss: 8.9146\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8805 - val_loss: 8.6184\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1151 - val_loss: 9.2046\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8548 - val_loss: 8.6633\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8930 - val_loss: 9.2477\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0146 - val_loss: 8.7601\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5780 - val_loss: 8.5865\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0974 - val_loss: 8.9939\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7563 - val_loss: 8.5731\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7419 - val_loss: 8.8160\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7180 - val_loss: 8.7466\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8058 - val_loss: 8.4988\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7299 - val_loss: 8.6117\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8208 - val_loss: 8.5321\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7359 - val_loss: 8.6828\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8129 - val_loss: 9.2807\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8639 - val_loss: 8.8380\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8026 - val_loss: 9.0693\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0625 - val_loss: 9.1358\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9557 - val_loss: 8.7881\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8442 - val_loss: 8.6509\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7589 - val_loss: 8.7775\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6878 - val_loss: 8.9412\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6596 - val_loss: 8.8542\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8216 - val_loss: 9.2443\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2546 - val_loss: 8.9398\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6899 - val_loss: 9.4270\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3512 - val_loss: 9.1152\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9450 - val_loss: 9.1484\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8778 - val_loss: 8.7785\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7739 - val_loss: 8.9539\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6794 - val_loss: 8.9708\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7099 - val_loss: 8.7056\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7115 - val_loss: 8.8096\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7228 - val_loss: 8.9257\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6704 - val_loss: 8.9874\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0701 - val_loss: 9.7552\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0210 - val_loss: 9.6524\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0307 - val_loss: 9.4625\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0959 - val_loss: 9.2649\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9480 - val_loss: 9.3666\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9218 - val_loss: 8.9370\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.8495 - val_loss: 8.8217\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9864 - val_loss: 9.1641\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7088 - val_loss: 8.6212\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6585 - val_loss: 8.8513\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6827 - val_loss: 8.7910\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7007 - val_loss: 9.0080\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7624 - val_loss: 8.9436\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9766 - val_loss: 8.8952\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7775 - val_loss: 9.0711\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6952 - val_loss: 8.9533\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7853 - val_loss: 9.0631\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6732 - val_loss: 8.8837\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8182 - val_loss: 9.1489\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6961 - val_loss: 9.1260\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6745 - val_loss: 8.9693\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6222 - val_loss: 8.9606\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8449 - val_loss: 9.1785\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7693 - val_loss: 8.9758\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8832 - val_loss: 9.0038\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8481 - val_loss: 9.2723\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7212 - val_loss: 9.0765\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6915 - val_loss: 9.0326\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6924 - val_loss: 9.0497\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7991 - val_loss: 9.3012\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7400 - val_loss: 9.0339\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7142 - val_loss: 9.0873\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7313 - val_loss: 8.7727\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6442 - val_loss: 8.9393\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6944 - val_loss: 8.9845\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7650 - val_loss: 8.9413\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7364 - val_loss: 9.3307\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6576 - val_loss: 9.2676\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8210 - val_loss: 9.1967\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6662 - val_loss: 8.8146\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7353 - val_loss: 8.9300\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 5.8862 - val_loss: 8.7595\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6678 - val_loss: 9.1800\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6378 - val_loss: 9.1940\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7469 - val_loss: 9.4884\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1043 - val_loss: 9.3456\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4589 - val_loss: 9.9601\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3334 - val_loss: 9.1093\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3042 - val_loss: 9.3172\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4022 - val_loss: 10.9273\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3244 - val_loss: 9.0698\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8459 - val_loss: 9.3849\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6541 - val_loss: 8.9755\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7281 - val_loss: 9.4971\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5989 - val_loss: 8.9216\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1057 - val_loss: 9.9962\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4910 - val_loss: 8.8951\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6967 - val_loss: 9.0239\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6368 - val_loss: 9.1104\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6662 - val_loss: 9.0177\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7483 - val_loss: 9.0784\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5760 - val_loss: 9.1381\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6599 - val_loss: 8.8937\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7506 - val_loss: 9.5482\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6389 - val_loss: 8.8580\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6289 - val_loss: 9.0475\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7884 - val_loss: 9.4490\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9973 - val_loss: 9.5645\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9577 - val_loss: 9.8962\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6788 - val_loss: 8.9634\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6411 - val_loss: 9.3293\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6131 - val_loss: 8.7144\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5823 - val_loss: 9.0705\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5879 - val_loss: 9.0100\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6914 - val_loss: 8.8348\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8513 - val_loss: 9.2027\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7019 - val_loss: 9.2220\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5981 - val_loss: 9.0361\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6250 - val_loss: 9.0230\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6678 - val_loss: 9.1481\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6284 - val_loss: 9.2091\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1833 - val_loss: 9.4717\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9989 - val_loss: 9.8412\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7210 - val_loss: 8.8260\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6963 - val_loss: 9.4683\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6762 - val_loss: 8.9478\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6665 - val_loss: 9.9005\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7196 - val_loss: 8.9704\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7259 - val_loss: 9.0516\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8336 - val_loss: 9.4504\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6857 - val_loss: 10.1253\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9868 - val_loss: 10.2861\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8261 - val_loss: 9.3510\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6976 - val_loss: 9.5306\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6784 - val_loss: 9.0375\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5434 - val_loss: 9.0029\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8476 - val_loss: 9.4989\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7054 - val_loss: 8.8820\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7380 - val_loss: 9.0970\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6287 - val_loss: 9.1742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6828 - val_loss: 9.1192\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5685 - val_loss: 9.0724\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7468 - val_loss: 8.8775\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7016 - val_loss: 9.3940\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8634 - val_loss: 8.9072\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5683 - val_loss: 9.0496\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6736 - val_loss: 9.1286\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5384 - val_loss: 9.2883\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5845 - val_loss: 9.1878\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6246 - val_loss: 9.0033\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7874 - val_loss: 9.2372\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6750 - val_loss: 9.4731\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6893 - val_loss: 8.8660\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6882 - val_loss: 8.9277\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6855 - val_loss: 9.4905\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5421 - val_loss: 10.2965\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9764 - val_loss: 8.9675\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9447 - val_loss: 9.3988\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8682 - val_loss: 10.3421\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9769 - val_loss: 9.0413\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6160 - val_loss: 10.0943\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9722 - val_loss: 9.3621\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7732 - val_loss: 9.2774\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6521 - val_loss: 9.2872\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7526 - val_loss: 9.3641\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7689 - val_loss: 9.1573\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9455 - val_loss: 8.9782\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7006 - val_loss: 9.1765\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5622 - val_loss: 9.0951\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6306 - val_loss: 9.3372\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5759 - val_loss: 9.1648\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6073 - val_loss: 9.4357\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7694 - val_loss: 9.4014\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8092 - val_loss: 9.4600\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8039 - val_loss: 9.8079\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7753 - val_loss: 9.1403\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.6021 - val_loss: 9.6416\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4930 - val_loss: 9.1548\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7252 - val_loss: 9.1603\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7132 - val_loss: 9.0165\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6097 - val_loss: 9.3332\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5730 - val_loss: 9.2855\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7021 - val_loss: 9.0519\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1564 - val_loss: 9.3495\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8239 - val_loss: 9.0598\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5501 - val_loss: 8.9007\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6166 - val_loss: 9.2764\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6763 - val_loss: 9.1212\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5766 - val_loss: 9.2631\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.5455 - val_loss: 9.0576\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6552 - val_loss: 9.2933\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5994 - val_loss: 9.1731\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5207 - val_loss: 9.9689\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6591 - val_loss: 9.3225\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6346 - val_loss: 9.7708\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8390 - val_loss: 9.8662\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7144 - val_loss: 11.5918\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5985 - val_loss: 9.3739\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1474 - val_loss: 9.3156\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0016 - val_loss: 9.2886\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0036 - val_loss: 8.7944\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6106 - val_loss: 9.0895\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6619 - val_loss: 9.5080\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5718 - val_loss: 9.3897\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6122 - val_loss: 9.2294\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5170 - val_loss: 9.2409\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6376 - val_loss: 9.1962\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7496 - val_loss: 10.2974\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9567 - val_loss: 9.4763\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0108 - val_loss: 10.2306\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8327 - val_loss: 9.2531\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5123 - val_loss: 9.3295\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5467 - val_loss: 8.8878\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6732 - val_loss: 8.9280\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6681 - val_loss: 9.4268\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7301 - val_loss: 9.0187\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6102 - val_loss: 9.0623\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6618 - val_loss: 9.2063\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6371 - val_loss: 9.6995\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8156 - val_loss: 8.9458\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7242 - val_loss: 9.1269\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6942 - val_loss: 8.9354\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5295 - val_loss: 9.5155\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6544 - val_loss: 9.1812\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8711 - val_loss: 9.2231\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8529 - val_loss: 9.0738\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8065 - val_loss: 9.3443\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5699 - val_loss: 8.9720\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7210 - val_loss: 10.1814\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6992 - val_loss: 8.9725\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7254 - val_loss: 9.1504\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8387 - val_loss: 9.8263\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7388 - val_loss: 9.8027\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2206 - val_loss: 10.5055\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8990 - val_loss: 9.2092\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5336 - val_loss: 9.5550\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6695 - val_loss: 9.2637\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5263 - val_loss: 9.1550\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4753 - val_loss: 9.1732\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5713 - val_loss: 9.1361\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6333 - val_loss: 9.3941\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5520 - val_loss: 9.1876\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6222 - val_loss: 9.0669\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5529 - val_loss: 9.2755\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9029 - val_loss: 9.2163\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6733 - val_loss: 9.4197\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4936 - val_loss: 9.1331\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6149 - val_loss: 9.4861\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6481 - val_loss: 9.2119\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5206 - val_loss: 9.5191\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6002 - val_loss: 8.9598\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6237 - val_loss: 9.5639\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5235 - val_loss: 9.1503\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4783 - val_loss: 9.4385\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5351 - val_loss: 9.1971\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6850 - val_loss: 9.3490\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6921 - val_loss: 9.2710\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7795 - val_loss: 9.3319\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6396 - val_loss: 9.1590\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5704 - val_loss: 9.0751\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7367 - val_loss: 8.9886\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6582 - val_loss: 9.1678\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5240 - val_loss: 9.3248\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8242 - val_loss: 9.5487\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9517 - val_loss: 9.3133\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7514 - val_loss: 9.6281\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6448 - val_loss: 9.2817\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7875 - val_loss: 9.3761\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6740 - val_loss: 9.3722\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6529 - val_loss: 9.3512\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6755 - val_loss: 9.6807\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8985 - val_loss: 8.9984\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0696 - val_loss: 9.2642\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3598 - val_loss: 11.3306\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3702 - val_loss: 9.3717\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9673 - val_loss: 9.2686\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6088 - val_loss: 9.7325\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0196 - val_loss: 9.4057\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8589 - val_loss: 9.4074\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6137 - val_loss: 9.6456\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5473 - val_loss: 8.9896\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4796 - val_loss: 9.1084\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5428 - val_loss: 9.1979\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5903 - val_loss: 9.1423\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5987 - val_loss: 9.4546\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6476 - val_loss: 9.1295\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0738 - val_loss: 9.3766\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5909 - val_loss: 9.2796\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5535 - val_loss: 9.2664\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6563 - val_loss: 8.9287\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8531 - val_loss: 9.3821\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8642 - val_loss: 9.6983\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6589 - val_loss: 9.2432\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8657 - val_loss: 9.7944\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4179 - val_loss: 9.5337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5516 - val_loss: 9.5090\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8314 - val_loss: 9.0904\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6296 - val_loss: 9.3880\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7780 - val_loss: 9.9750\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7543 - val_loss: 9.6646\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0473 - val_loss: 9.7126\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7267 - val_loss: 9.3544\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4839 - val_loss: 9.8189\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5549 - val_loss: 9.0899\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5231 - val_loss: 9.5178\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6183 - val_loss: 9.0451\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5395 - val_loss: 9.2009\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7225 - val_loss: 10.1336\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8039 - val_loss: 9.2169\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6296 - val_loss: 9.6474\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4994 - val_loss: 9.3886\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4704 - val_loss: 9.4101\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6476 - val_loss: 8.9426\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7610 - val_loss: 9.2511\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7336 - val_loss: 9.4014\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5853 - val_loss: 9.1416\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7416 - val_loss: 9.2398\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6564 - val_loss: 9.8506\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.6328 - val_loss: 9.2470\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4844 - val_loss: 9.7881\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6807 - val_loss: 9.3379\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7849 - val_loss: 10.4007\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8149 - val_loss: 8.8871\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6540 - val_loss: 9.2779\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6719 - val_loss: 9.6022\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9630 - val_loss: 9.4918\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8875 - val_loss: 8.9500\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1617 - val_loss: 10.0500\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0694 - val_loss: 9.3530\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6734 - val_loss: 9.6483\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6161 - val_loss: 9.0585\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6518 - val_loss: 9.2784\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6601 - val_loss: 9.3709\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5131 - val_loss: 9.6835\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6723 - val_loss: 9.4024\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7808 - val_loss: 8.8111\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8464 - val_loss: 8.8213\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6727 - val_loss: 9.4460\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5068 - val_loss: 9.3052\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5031 - val_loss: 9.6944\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7560 - val_loss: 9.0922\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5175 - val_loss: 9.1760\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5452 - val_loss: 9.1760\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5477 - val_loss: 9.3486\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7178 - val_loss: 9.7679\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9672 - val_loss: 9.1344\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5304 - val_loss: 9.3259\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4390 - val_loss: 9.2809\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7218 - val_loss: 9.4953\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9028 - val_loss: 9.7343\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0329 - val_loss: 9.4153\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9536 - val_loss: 9.9136\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4897 - val_loss: 9.3939\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5674 - val_loss: 9.6891\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5139 - val_loss: 8.9616\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5251 - val_loss: 9.4927\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5074 - val_loss: 9.1298\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5472 - val_loss: 9.6887\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6491 - val_loss: 9.0833\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8107 - val_loss: 9.0161\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6856 - val_loss: 9.3102\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7332 - val_loss: 9.5395\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6079 - val_loss: 9.4495\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5517 - val_loss: 9.4317\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5745 - val_loss: 9.5252\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8767 - val_loss: 9.5550\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8272 - val_loss: 9.3756\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8569 - val_loss: 10.2832\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7294 - val_loss: 9.7979\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0012 - val_loss: 9.6745\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8666 - val_loss: 9.3614\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8134 - val_loss: 9.5657\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7029 - val_loss: 9.3292\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4960 - val_loss: 9.1806\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6258 - val_loss: 9.5810\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7773 - val_loss: 9.3939\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6037 - val_loss: 9.2567\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5014 - val_loss: 9.2138\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5474 - val_loss: 9.1501\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4663 - val_loss: 9.1845\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4849 - val_loss: 8.9646\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4555 - val_loss: 9.1358\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6065 - val_loss: 9.2432\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6902 - val_loss: 10.5539\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3145 - val_loss: 10.7714\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9106 - val_loss: 10.1395\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5558 - val_loss: 9.2234\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3306 - val_loss: 9.4087\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8019 - val_loss: 9.2590\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0443 - val_loss: 9.1869\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7280 - val_loss: 9.2106\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2114 - val_loss: 9.1681\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1626 - val_loss: 10.1982\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7188 - val_loss: 9.3921\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8351 - val_loss: 9.5478\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4006 - val_loss: 9.2753\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5936 - val_loss: 9.9627\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7559 - val_loss: 9.1487\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0920 - val_loss: 9.1251\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7696 - val_loss: 9.6333\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5643 - val_loss: 9.1791\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5362 - val_loss: 9.0350\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6531 - val_loss: 9.1650\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6023 - val_loss: 9.0929\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0908 - val_loss: 9.8213\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7280 - val_loss: 9.4617\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8398 - val_loss: 9.5788\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4825 - val_loss: 9.0467\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6177 - val_loss: 9.2050\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4930 - val_loss: 8.9393\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6461 - val_loss: 8.9940\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5974 - val_loss: 9.1134\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6100 - val_loss: 9.2009\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5925 - val_loss: 9.1299\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6816 - val_loss: 9.7882\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9512 - val_loss: 9.3323\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5444 - val_loss: 9.9688\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0917 - val_loss: 9.7401\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8547 - val_loss: 9.6033\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3909 - val_loss: 9.6685\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7587 - val_loss: 10.0777\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6905 - val_loss: 9.2291\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6918 - val_loss: 10.3625\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1697 - val_loss: 10.0085\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0603 - val_loss: 10.7015\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9504 - val_loss: 9.5730\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7985 - val_loss: 10.0302\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7431 - val_loss: 9.2768\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5558 - val_loss: 9.3894\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4708 - val_loss: 9.3734\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5650 - val_loss: 9.1398\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5660 - val_loss: 9.5750\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5788 - val_loss: 9.4138\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6269 - val_loss: 9.3846\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5280 - val_loss: 9.2411\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5575 - val_loss: 9.8739\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8652 - val_loss: 9.2662\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9552 - val_loss: 9.6528\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6809 - val_loss: 9.3166\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8376 - val_loss: 10.0778\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5110 - val_loss: 9.5635\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0425 - val_loss: 10.3902\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8843 - val_loss: 9.7956\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9653 - val_loss: 9.7369\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5065 - val_loss: 9.4158\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4797 - val_loss: 9.6439\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0267 - val_loss: 9.2551\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5330 - val_loss: 9.1935\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5543 - val_loss: 9.1851\n",
      "Epoch 688/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.5030 - val_loss: 9.2114\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5578 - val_loss: 9.4644\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6272 - val_loss: 9.1553\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5598 - val_loss: 8.9750\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5245 - val_loss: 9.3381\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5146 - val_loss: 9.3581\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6121 - val_loss: 9.4964\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5516 - val_loss: 9.0642\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6120 - val_loss: 9.0865\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5609 - val_loss: 9.4341\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5206 - val_loss: 9.2203\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5096 - val_loss: 9.2825\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7594 - val_loss: 9.6797\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6105 - val_loss: 9.5425\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6044 - val_loss: 9.2606\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6014 - val_loss: 9.2805\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5912 - val_loss: 9.2294\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5138 - val_loss: 9.1768\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5106 - val_loss: 8.8820\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4962 - val_loss: 9.3188\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5718 - val_loss: 9.3807\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4579 - val_loss: 9.1598\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4105 - val_loss: 9.1278\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4843 - val_loss: 9.3757\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5263 - val_loss: 9.3558\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5070 - val_loss: 9.1274\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4426 - val_loss: 9.3525\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6749 - val_loss: 9.3519\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6356 - val_loss: 9.0919\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5756 - val_loss: 9.2448\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4784 - val_loss: 9.3514\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4580 - val_loss: 9.4122\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4212 - val_loss: 9.0510\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6056 - val_loss: 9.3424\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4552 - val_loss: 9.4519\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7703 - val_loss: 10.2761\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9623 - val_loss: 9.9847\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0790 - val_loss: 9.4459\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4532 - val_loss: 9.0908\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4944 - val_loss: 9.2493\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5153 - val_loss: 9.2137\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4460 - val_loss: 9.1611\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5528 - val_loss: 9.5510\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6786 - val_loss: 9.0989\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6834 - val_loss: 9.0860\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5518 - val_loss: 9.6061\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7001 - val_loss: 9.1433\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5033 - val_loss: 9.4635\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.5210 - val_loss: 9.2891\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5588 - val_loss: 8.9941\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4544 - val_loss: 9.5180\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6894 - val_loss: 9.2518\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5670 - val_loss: 9.1658\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4803 - val_loss: 9.4498\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5753 - val_loss: 9.4491\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5002 - val_loss: 9.1341\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4486 - val_loss: 9.5276\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5655 - val_loss: 9.2438\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4642 - val_loss: 9.0895\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5483 - val_loss: 9.3085\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7458 - val_loss: 9.2392\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5894 - val_loss: 9.7217\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5394 - val_loss: 8.9499\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5996 - val_loss: 9.1227\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5197 - val_loss: 9.1454\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4191 - val_loss: 9.2337\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7379 - val_loss: 9.6197\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5098 - val_loss: 9.4007\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5736 - val_loss: 9.2491\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5091 - val_loss: 9.0632\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6177 - val_loss: 8.9971\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6902 - val_loss: 9.5960\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7458 - val_loss: 9.5277\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9912 - val_loss: 9.0562\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5647 - val_loss: 9.4795\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5398 - val_loss: 9.3415\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5517 - val_loss: 9.2641\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4801 - val_loss: 9.1769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4588 - val_loss: 9.0335\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5421 - val_loss: 9.6007\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4234 - val_loss: 9.1499\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6686 - val_loss: 9.5731\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6311 - val_loss: 9.2685\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6894 - val_loss: 9.2863\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5497 - val_loss: 9.4878\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5220 - val_loss: 9.5342\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5667 - val_loss: 9.1968\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4909 - val_loss: 9.4962\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7699 - val_loss: 9.4184\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4961 - val_loss: 9.6615\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6630 - val_loss: 9.2029\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4249 - val_loss: 9.6523\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5816 - val_loss: 9.3156\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7275 - val_loss: 9.0553\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1884 - val_loss: 10.5418\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7312 - val_loss: 9.6054\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3728 - val_loss: 9.9751\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6104 - val_loss: 9.1319\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4656 - val_loss: 9.5728\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6813 - val_loss: 9.4478\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7887 - val_loss: 9.2984\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8528 - val_loss: 9.6115\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5129 - val_loss: 9.4513\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7993 - val_loss: 9.1079\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4016 - val_loss: 9.2303\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5651 - val_loss: 9.2257\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5153 - val_loss: 9.5879\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5651 - val_loss: 9.2549\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6438 - val_loss: 9.2831\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6390 - val_loss: 9.5231\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6668 - val_loss: 9.2599\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7968 - val_loss: 9.4457\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4466 - val_loss: 9.1159\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5144 - val_loss: 9.3972\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4626 - val_loss: 9.1373\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4266 - val_loss: 9.3633\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4231 - val_loss: 9.0790\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4206 - val_loss: 9.1387\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4512 - val_loss: 9.1829\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7688 - val_loss: 9.2726\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2934 - val_loss: 10.5775\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9769 - val_loss: 9.1709\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7085 - val_loss: 9.5693\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6220 - val_loss: 9.1120\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5825 - val_loss: 9.3198\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5126 - val_loss: 9.1911\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7418 - val_loss: 9.9185\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8154 - val_loss: 9.3199\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5997 - val_loss: 9.1489\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9273 - val_loss: 9.4648\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5719 - val_loss: 9.4596\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6729 - val_loss: 9.3046\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4490 - val_loss: 9.2843\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4781 - val_loss: 9.3078\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5153 - val_loss: 9.1417\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6699 - val_loss: 9.5540\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4352 - val_loss: 9.2133\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5538 - val_loss: 9.2070\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5037 - val_loss: 9.3048\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5161 - val_loss: 9.0653\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5074 - val_loss: 9.3456\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5725 - val_loss: 9.2684\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6047 - val_loss: 9.3301\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6752 - val_loss: 9.6239\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5517 - val_loss: 9.4881\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7033 - val_loss: 9.5522\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4729 - val_loss: 9.0078\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5000 - val_loss: 9.5554\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3972 - val_loss: 9.1459\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6065 - val_loss: 9.7970\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4803 - val_loss: 9.2153\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4946 - val_loss: 9.5430\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8263 - val_loss: 9.0194\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4973 - val_loss: 9.2394\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9399 - val_loss: 10.9445\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1552 - val_loss: 9.2748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6165 - val_loss: 9.2997\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4580 - val_loss: 9.1707\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4764 - val_loss: 9.0675\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8806 - val_loss: 9.7701\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9770 - val_loss: 9.1519\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4763 - val_loss: 9.0274\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6616 - val_loss: 9.0353\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7695 - val_loss: 10.0548\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7629 - val_loss: 9.4538\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5166 - val_loss: 9.3250\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4383 - val_loss: 9.0982\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7750 - val_loss: 9.1702\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8565 - val_loss: 9.6796\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8930 - val_loss: 9.2894\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2243 - val_loss: 10.5217\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6841 - val_loss: 9.5290\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4475 - val_loss: 10.5306\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9730 - val_loss: 9.3312\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6732 - val_loss: 9.2007\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5692 - val_loss: 9.1561\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4696 - val_loss: 9.2478\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4334 - val_loss: 9.1977\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5065 - val_loss: 9.6336\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0714 - val_loss: 9.0218\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5825 - val_loss: 9.5474\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3324 - val_loss: 9.3716\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5421 - val_loss: 9.3613\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8115 - val_loss: 9.2125\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9757 - val_loss: 9.2388\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2312 - val_loss: 9.0640\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6680 - val_loss: 9.5715\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5586 - val_loss: 9.1566\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4867 - val_loss: 9.2707\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3916 - val_loss: 9.1041\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3920 - val_loss: 9.1494\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4742 - val_loss: 9.0966\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4168 - val_loss: 9.1437\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4401 - val_loss: 9.4301\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8002 - val_loss: 9.5536\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4484 - val_loss: 9.1426\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4303 - val_loss: 9.1141\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4158 - val_loss: 9.1995\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6756 - val_loss: 9.2359\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5911 - val_loss: 9.1786\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6451 - val_loss: 9.5324\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5467 - val_loss: 9.0349\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4365 - val_loss: 8.9380\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4374 - val_loss: 9.3319\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6170 - val_loss: 9.3999\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4720 - val_loss: 9.3167\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5908 - val_loss: 9.2076\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5463 - val_loss: 9.0369\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4297 - val_loss: 9.1855\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4549 - val_loss: 9.1026\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4614 - val_loss: 8.9394\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5136 - val_loss: 9.2141\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5207 - val_loss: 9.0493\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6587 - val_loss: 8.9040\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5185 - val_loss: 9.1927\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3969 - val_loss: 9.3351\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6189 - val_loss: 9.3441\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8266 - val_loss: 9.2938\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7412 - val_loss: 9.2518\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5719 - val_loss: 9.4023\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5239 - val_loss: 8.9055\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4679 - val_loss: 8.9671\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4570 - val_loss: 9.7544\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6813 - val_loss: 9.0711\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7399 - val_loss: 9.3206\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6012 - val_loss: 9.2090\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4337 - val_loss: 8.9472\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6470 - val_loss: 9.2308\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5310 - val_loss: 9.1841\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6647 - val_loss: 9.4020\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4690 - val_loss: 9.0099\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6846 - val_loss: 9.7740\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6729 - val_loss: 8.8485\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3841 - val_loss: 9.4803\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4905 - val_loss: 9.0696\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5463 - val_loss: 10.2297\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0616 - val_loss: 9.0296\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5744 - val_loss: 9.2360\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7026 - val_loss: 9.6848\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4812 - val_loss: 9.1885\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5288 - val_loss: 9.3248\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5345 - val_loss: 9.2099\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4901 - val_loss: 9.1010\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4774 - val_loss: 9.2617\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4840 - val_loss: 9.1700\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5182 - val_loss: 9.2842\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5588 - val_loss: 9.2404\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7020 - val_loss: 10.3992\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8644 - val_loss: 9.1808\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3860 - val_loss: 9.0619\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3792 - val_loss: 9.1133\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4279 - val_loss: 9.2276\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7414 - val_loss: 9.1378\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7248 - val_loss: 9.1280\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6572 - val_loss: 9.2743\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4922 - val_loss: 9.0582\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4543 - val_loss: 8.9483\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5158 - val_loss: 9.5907\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6814 - val_loss: 9.1946\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5560 - val_loss: 9.2456\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4617 - val_loss: 9.4694\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5126 - val_loss: 9.2191\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.4021 - val_loss: 9.0638\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5818 - val_loss: 9.2261\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5000 - val_loss: 9.8469\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6034 - val_loss: 9.1683\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6443 - val_loss: 9.7281\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5239 - val_loss: 9.5235\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6169 - val_loss: 9.1421\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4844 - val_loss: 9.0561\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4116 - val_loss: 9.0180\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5636 - val_loss: 9.5970\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7256 - val_loss: 9.1030\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6651 - val_loss: 9.3162\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6450 - val_loss: 9.2196\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9765 - val_loss: 10.5009\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9804 - val_loss: 9.1061\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6511 - val_loss: 9.3387\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9089 - val_loss: 9.8856\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3789 - val_loss: 9.5828\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5920 - val_loss: 10.2908\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9885 - val_loss: 9.3954\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1181 - val_loss: 9.2365\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1118 - val_loss: 10.8717\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2417 - val_loss: 9.5217\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5224 - val_loss: 10.0147\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4741 - val_loss: 9.3498\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6466 - val_loss: 9.5012\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5178 - val_loss: 9.0601\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4001 - val_loss: 9.1797\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5120 - val_loss: 9.0643\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7266 - val_loss: 10.8887\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8399 - val_loss: 9.2954\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6956 - val_loss: 9.6708\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3123 - val_loss: 9.6936\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9675 - val_loss: 9.4204\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7494 - val_loss: 9.5803\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5914 - val_loss: 9.2883\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4660 - val_loss: 9.1173\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5357 - val_loss: 8.9882\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4121 - val_loss: 9.0768\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6220 - val_loss: 8.8762\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.5810 - val_loss: 9.3734\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6168 - val_loss: 9.1298\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5358 - val_loss: 9.1300\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6608 - val_loss: 9.0501\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0747 - val_loss: 9.4126\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8878 - val_loss: 9.9746\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7101 - val_loss: 8.9192\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4918 - val_loss: 9.3300\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3818 - val_loss: 9.1614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5458 - val_loss: 9.1686\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4293 - val_loss: 9.2524\n",
      "6.98731241387836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.27501857,  0.00647581, -1.7981249 , -0.25894523, -1.5347608 ],\n",
       "        [ 0.13419281, -0.7983037 , -1.756959  , -0.17998771,  0.98929536],\n",
       "        [-0.0946307 ,  0.2640069 ,  0.41315675,  0.54601234, -0.10241376],\n",
       "        [-0.7360216 ,  1.0029446 ,  1.9121959 , -0.26165012, -1.6212268 ],\n",
       "        [ 0.01639562, -0.56000984, -0.12175646,  0.77160424,  0.2056142 ],\n",
       "        [-0.38294467, -1.2857094 ,  3.834698  , -0.0809181 , -1.7040383 ],\n",
       "        [-0.3256187 , -0.5813387 ,  2.7194846 , -1.7284831 , -0.3302039 ]],\n",
       "       dtype=float32),\n",
       " array([-0.7437551,  1.9427844,  3.4529698, -2.1505299, -1.9501916],\n",
       "       dtype=float32),\n",
       " array([[-0.876621  ,  0.85907936, -0.46372515,  0.40297446, -0.9730287 ,\n",
       "          0.91716117,  0.13793106,  0.96972895,  0.7497994 , -1.0428926 ,\n",
       "         -1.0962548 , -0.40737143,  0.9935972 , -1.0462191 ,  0.7164666 ],\n",
       "        [ 0.23083621, -0.9596442 ,  0.512562  , -0.56063604,  0.3212999 ,\n",
       "         -0.65442467,  0.51854604, -0.44116563, -0.3355713 ,  0.23608859,\n",
       "          0.6775716 ,  0.5466196 , -0.4921334 ,  0.24093081, -0.44896746],\n",
       "        [-0.43864378,  0.05626088, -0.14188491,  0.3551581 ,  0.07468665,\n",
       "          0.5908559 ,  0.4482017 , -0.19956264,  0.17976834,  0.17659327,\n",
       "         -0.7093605 , -0.3548728 ,  0.43711558,  0.2329264 , -0.37661263],\n",
       "        [ 0.38504502, -0.20116237,  0.41254053, -0.5360288 , -0.1535099 ,\n",
       "         -0.44658244, -0.17317966, -0.7289731 ,  0.02583913,  0.56135195,\n",
       "          0.588246  ,  0.4184622 , -0.05206239, -0.20278354, -0.01176273],\n",
       "        [-0.29624152, -0.51823866, -0.10599876, -0.11295766, -0.13203412,\n",
       "         -0.18001574, -0.5317009 , -0.3296484 , -0.51310843,  0.58403337,\n",
       "          0.47335148, -0.2066469 , -0.73832136,  0.2983594 , -0.0682056 ]],\n",
       "       dtype=float32),\n",
       " array([-1.7140219 ,  1.768159  , -1.5786972 ,  1.7083331 , -1.7588683 ,\n",
       "         1.7410622 , -0.92354065,  1.747882  ,  1.6712726 , -1.7155206 ,\n",
       "        -1.7321677 , -1.6743914 ,  1.7326542 , -1.7008505 ,  1.2589265 ],\n",
       "       dtype=float32),\n",
       " array([[-0.8487837 ],\n",
       "        [ 1.0562928 ],\n",
       "        [-0.813394  ],\n",
       "        [ 0.8693717 ],\n",
       "        [-1.1063161 ],\n",
       "        [ 1.0794629 ],\n",
       "        [-0.01423117],\n",
       "        [ 1.485647  ],\n",
       "        [ 1.1352743 ],\n",
       "        [-1.0471647 ],\n",
       "        [-1.2435168 ],\n",
       "        [-1.1232611 ],\n",
       "        [ 1.3974208 ],\n",
       "        [-0.90379363],\n",
       "        [ 0.28708678]], dtype=float32),\n",
       " array([1.7306118], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_3(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure3_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 963us/step - loss: 488.2231 - val_loss: 273.2271\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 165.9502 - val_loss: 62.5673\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 55.4482 - val_loss: 32.5820\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 38.4718 - val_loss: 23.8198\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 22.3734 - val_loss: 21.9976\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 20.4960 - val_loss: 21.3471\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 17.3882 - val_loss: 18.7238\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 16.1656 - val_loss: 17.9056\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.3853 - val_loss: 17.1535\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.1915 - val_loss: 16.8743\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.3446 - val_loss: 16.0111\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.3588 - val_loss: 15.5625\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.9259 - val_loss: 14.6988\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.4541 - val_loss: 14.4998\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.0337 - val_loss: 14.1246\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 9.6893 - val_loss: 13.7021\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.4044 - val_loss: 13.1253\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.1845 - val_loss: 12.9504\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.0387 - val_loss: 12.6732\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.8049 - val_loss: 12.4198\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5764 - val_loss: 11.9877\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 8.3843 - val_loss: 11.6880\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2707 - val_loss: 11.3968\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.2220 - val_loss: 11.2132\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1276 - val_loss: 10.8810\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9385 - val_loss: 10.7581\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0058 - val_loss: 10.8415\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7111 - val_loss: 10.6142\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.6068 - val_loss: 10.5033\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5023 - val_loss: 10.4247\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6398 - val_loss: 10.3354\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.5530 - val_loss: 10.2547\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2614 - val_loss: 10.0094\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2824 - val_loss: 10.0298\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2420 - val_loss: 10.1858\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0182 - val_loss: 10.1819\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0299 - val_loss: 10.3215\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0450 - val_loss: 9.9781\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0874 - val_loss: 10.1213\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0280 - val_loss: 10.3224\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9315 - val_loss: 10.0195\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9332 - val_loss: 9.8343\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8107 - val_loss: 10.0341\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8692 - val_loss: 9.9390\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9372 - val_loss: 10.0565\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9838 - val_loss: 10.0555\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8987 - val_loss: 9.8565\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1003 - val_loss: 9.7205\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0991 - val_loss: 10.1236\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2713 - val_loss: 10.2065\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3662 - val_loss: 10.2170\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8728 - val_loss: 9.9729\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8226 - val_loss: 10.2807\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8303 - val_loss: 10.1377\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.8533 - val_loss: 10.0226\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9198 - val_loss: 10.0547\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0035 - val_loss: 9.8377\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7467 - val_loss: 9.6320\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7746 - val_loss: 9.8109\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6721 - val_loss: 10.1570\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0507 - val_loss: 10.1422\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7036 - val_loss: 9.9429\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6845 - val_loss: 10.0227\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8071 - val_loss: 9.9900\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9869 - val_loss: 9.7596\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8108 - val_loss: 9.9284\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6024 - val_loss: 10.2186\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7404 - val_loss: 10.0275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6693 - val_loss: 9.8223\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6120 - val_loss: 9.9789\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5831 - val_loss: 10.1454\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6086 - val_loss: 9.9002\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5332 - val_loss: 9.7211\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6703 - val_loss: 9.6867\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 6.6127 - val_loss: 9.9490\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6256 - val_loss: 10.1970\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5375 - val_loss: 9.8546\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.8779 - val_loss: 9.8129\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7814 - val_loss: 9.8782\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6554 - val_loss: 9.7671\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.6126 - val_loss: 9.8236\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6102 - val_loss: 10.0588\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2427 - val_loss: 10.1686\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8041 - val_loss: 10.0533\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 7.7047 - val_loss: 10.1138\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7830 - val_loss: 10.1207\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7748 - val_loss: 9.9027\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9185 - val_loss: 10.0676\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5539 - val_loss: 9.6912\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5827 - val_loss: 9.9080\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5127 - val_loss: 9.8375\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5109 - val_loss: 9.8424\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6196 - val_loss: 10.0607\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5708 - val_loss: 9.9840\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9486 - val_loss: 9.8329\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6173 - val_loss: 10.3020\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4295 - val_loss: 9.8332\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4387 - val_loss: 9.9044\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5218 - val_loss: 9.5440\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4486 - val_loss: 9.7422\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4120 - val_loss: 9.8001\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4845 - val_loss: 9.8366\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5717 - val_loss: 10.1761\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4848 - val_loss: 9.8169\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4352 - val_loss: 9.9326\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5204 - val_loss: 10.1263\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3696 - val_loss: 9.8155\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3025 - val_loss: 9.8175\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4213 - val_loss: 9.9702\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.5665 - val_loss: 9.7582\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.4266 - val_loss: 9.9252\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3676 - val_loss: 9.8390\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3824 - val_loss: 9.6456\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6421 - val_loss: 9.6811\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6360 - val_loss: 9.9077\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3707 - val_loss: 10.1416\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8015 - val_loss: 10.1124\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5643 - val_loss: 9.8159\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4632 - val_loss: 9.9167\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4258 - val_loss: 9.7212\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4550 - val_loss: 9.8997\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4569 - val_loss: 9.9194\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.4428 - val_loss: 9.9264\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4229 - val_loss: 9.8413\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3398 - val_loss: 9.5491\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3591 - val_loss: 9.6586\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2984 - val_loss: 9.6795\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4376 - val_loss: 9.9016\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2307 - val_loss: 9.9707\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3008 - val_loss: 10.1561\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6575 - val_loss: 9.7966\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3310 - val_loss: 9.9803\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2619 - val_loss: 9.9052\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4351 - val_loss: 9.9807\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3814 - val_loss: 9.7578\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5224 - val_loss: 9.7750\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3851 - val_loss: 9.6110\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2010 - val_loss: 9.7642\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2656 - val_loss: 9.8043\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.2691 - val_loss: 9.7200\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.3774 - val_loss: 9.8080\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1690 - val_loss: 9.7766\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1569 - val_loss: 9.6491\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2747 - val_loss: 9.6544\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2088 - val_loss: 9.6658\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1511 - val_loss: 9.8658\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1310 - val_loss: 9.6141\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0982 - val_loss: 9.4858\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1952 - val_loss: 9.8301\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1599 - val_loss: 9.7780\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1059 - val_loss: 9.6358\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1788 - val_loss: 9.5486\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1415 - val_loss: 9.6881\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3275 - val_loss: 9.7152\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5649 - val_loss: 9.9543\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4323 - val_loss: 9.4551\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3897 - val_loss: 9.6460\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1362 - val_loss: 9.5230\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1252 - val_loss: 9.6515\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0712 - val_loss: 9.3903\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9829 - val_loss: 9.2609\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0650 - val_loss: 9.1844\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1594 - val_loss: 9.5262\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1628 - val_loss: 9.4170\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.9406 - val_loss: 9.8353\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1383 - val_loss: 9.6486\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9384 - val_loss: 9.4821\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0172 - val_loss: 9.3545\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9435 - val_loss: 9.5419\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0750 - val_loss: 9.2619\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 6.1120 - val_loss: 9.5114\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4911 - val_loss: 9.6579\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5198 - val_loss: 9.6522\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.5832 - val_loss: 9.5933\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0150 - val_loss: 9.1147\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0030 - val_loss: 9.2622\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0661 - val_loss: 9.0087\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8769 - val_loss: 9.1846\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9151 - val_loss: 9.1589\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9560 - val_loss: 9.3935\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8686 - val_loss: 9.3481\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8889 - val_loss: 9.1883\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9885 - val_loss: 9.2826\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3332 - val_loss: 9.2848\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9974 - val_loss: 9.0636\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8641 - val_loss: 9.1535\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0836 - val_loss: 9.0675\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8097 - val_loss: 9.0443\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7906 - val_loss: 8.7491\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8039 - val_loss: 8.9628\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7441 - val_loss: 9.3583\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6968 - val_loss: 9.0493\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7046 - val_loss: 8.8022\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7582 - val_loss: 8.9338\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7177 - val_loss: 9.0667\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6125 - val_loss: 9.0524\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7094 - val_loss: 9.0846\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6642 - val_loss: 8.7513\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6404 - val_loss: 8.9509\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8148 - val_loss: 8.7147\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8012 - val_loss: 8.9967\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5941 - val_loss: 8.9714\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7652 - val_loss: 8.9224\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6374 - val_loss: 8.9217\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5915 - val_loss: 8.8950\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6680 - val_loss: 8.6626\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.6016 - val_loss: 8.8545\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6763 - val_loss: 9.0312\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6788 - val_loss: 8.7678\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5404 - val_loss: 8.9896\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7069 - val_loss: 8.6869\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7965 - val_loss: 9.3623\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7215 - val_loss: 8.7012\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5808 - val_loss: 8.8179\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5792 - val_loss: 8.9952\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.5784 - val_loss: 8.6952\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 130us/step - loss: 5.5696 - val_loss: 8.8876\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.6546 - val_loss: 8.8085\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.6911 - val_loss: 9.1602\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.7153 - val_loss: 8.8757\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.0326 - val_loss: 9.0795\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5711 - val_loss: 8.9040\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.4319 - val_loss: 8.6407\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4240 - val_loss: 8.5830\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4726 - val_loss: 8.6315\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.4913 - val_loss: 9.0857\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4123 - val_loss: 8.7764\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5273 - val_loss: 8.8630\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9388 - val_loss: 8.7012\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6022 - val_loss: 9.6993\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.2796 - val_loss: 8.9992\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5846 - val_loss: 9.0797\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5510 - val_loss: 8.9208\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5019 - val_loss: 8.8779\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4910 - val_loss: 8.8597\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7868 - val_loss: 8.7469\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1783 - val_loss: 9.1402\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7229 - val_loss: 8.6473\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4141 - val_loss: 8.8982\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5827 - val_loss: 8.7661\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5135 - val_loss: 8.8503\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 134us/step - loss: 5.5015 - val_loss: 8.5437\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9730 - val_loss: 9.1950\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1926 - val_loss: 8.7301\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.5895 - val_loss: 8.6871\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4219 - val_loss: 8.6039\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4609 - val_loss: 8.6534\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4004 - val_loss: 8.6848\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4689 - val_loss: 9.0073\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4038 - val_loss: 8.8028\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3334 - val_loss: 8.7349\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3367 - val_loss: 9.0555\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3641 - val_loss: 8.8576\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3146 - val_loss: 8.8517\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3650 - val_loss: 9.0663\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3723 - val_loss: 8.6566\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6499 - val_loss: 9.8634\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8051 - val_loss: 8.7202\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5866 - val_loss: 8.8917\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3928 - val_loss: 8.9475\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3715 - val_loss: 8.7805\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2818 - val_loss: 8.7007\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4666 - val_loss: 8.8442\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3835 - val_loss: 8.8919\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2634 - val_loss: 8.7658\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2786 - val_loss: 8.6656\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3487 - val_loss: 8.6869\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3603 - val_loss: 8.9805\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3466 - val_loss: 8.7371\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2966 - val_loss: 8.8936\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2836 - val_loss: 8.7547\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4003 - val_loss: 8.7834\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3260 - val_loss: 8.7043\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3569 - val_loss: 8.4873\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3707 - val_loss: 9.1018\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3526 - val_loss: 8.8941\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2331 - val_loss: 8.8401\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2352 - val_loss: 8.5870\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4238 - val_loss: 8.8790\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5038 - val_loss: 8.8324\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4345 - val_loss: 8.9216\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3279 - val_loss: 8.6883\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3267 - val_loss: 8.7124\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2492 - val_loss: 8.8423\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3599 - val_loss: 8.6255\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2994 - val_loss: 8.8936\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3999 - val_loss: 8.5925\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3743 - val_loss: 8.8612\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3641 - val_loss: 8.7866\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2232 - val_loss: 8.7806\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1899 - val_loss: 8.6535\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2519 - val_loss: 8.7508\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1722 - val_loss: 8.6857\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2601 - val_loss: 8.8478\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1391 - val_loss: 8.8282\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2209 - val_loss: 8.8328\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1715 - val_loss: 8.8275\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1771 - val_loss: 8.9222\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1915 - val_loss: 8.9338\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1872 - val_loss: 8.7434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1859 - val_loss: 8.9376\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6016 - val_loss: 8.9243\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5169 - val_loss: 9.1779\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3494 - val_loss: 8.6621\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3918 - val_loss: 8.6900\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2350 - val_loss: 8.8340\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2331 - val_loss: 9.1243\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1740 - val_loss: 8.8797\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1826 - val_loss: 8.6074\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1346 - val_loss: 9.0350\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2841 - val_loss: 9.4990\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3580 - val_loss: 8.7690\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2770 - val_loss: 8.7395\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2018 - val_loss: 8.7981\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1758 - val_loss: 8.9059\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2069 - val_loss: 8.7926\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2000 - val_loss: 8.7548\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1731 - val_loss: 8.6327\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1191 - val_loss: 8.6233\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2057 - val_loss: 8.8446\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1999 - val_loss: 8.9308\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1797 - val_loss: 8.6578\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0327 - val_loss: 8.7431\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1940 - val_loss: 8.7086\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.2209 - val_loss: 9.0366\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.0923 - val_loss: 8.7418\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0993 - val_loss: 8.3837\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 125us/step - loss: 5.0882 - val_loss: 8.5471\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0503 - val_loss: 8.4797\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1267 - val_loss: 8.8255\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1681 - val_loss: 8.8303\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0223 - val_loss: 8.5216\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1229 - val_loss: 9.1928\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6212 - val_loss: 8.7676\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4113 - val_loss: 8.8890\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1045 - val_loss: 8.7899\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1396 - val_loss: 9.6176\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3471 - val_loss: 8.9890\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0812 - val_loss: 9.2960\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0117 - val_loss: 8.6447\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8669 - val_loss: 9.5923\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6334 - val_loss: 8.7182\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0905 - val_loss: 9.1872\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0033 - val_loss: 8.6486\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1116 - val_loss: 8.6055\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0582 - val_loss: 8.3978\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0224 - val_loss: 8.9129\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1973 - val_loss: 8.6013\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0751 - val_loss: 8.9964\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1495 - val_loss: 8.6280\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1144 - val_loss: 8.6630\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0026 - val_loss: 8.7369\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0863 - val_loss: 8.9799\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.9880 - val_loss: 8.8941\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0544 - val_loss: 8.8033\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3347 - val_loss: 8.9544\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3905 - val_loss: 8.9243\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0177 - val_loss: 8.9513\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0154 - val_loss: 8.6837\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9673 - val_loss: 9.1473\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3940 - val_loss: 8.5419\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0945 - val_loss: 8.8622\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1294 - val_loss: 8.7044\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9125 - val_loss: 8.8322\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9565 - val_loss: 8.6237\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1466 - val_loss: 9.3778\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1642 - val_loss: 8.9411\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1376 - val_loss: 9.0448\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5478 - val_loss: 9.1483\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5713 - val_loss: 8.8613\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0500 - val_loss: 8.9087\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0473 - val_loss: 8.6008\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0529 - val_loss: 8.7161\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0002 - val_loss: 8.6084\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0346 - val_loss: 8.9590\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9057 - val_loss: 8.8548\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9002 - val_loss: 8.9563\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8815 - val_loss: 8.6371\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9184 - val_loss: 8.5810\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8866 - val_loss: 8.6475\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9815 - val_loss: 9.1154\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9773 - val_loss: 8.8146\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.8812 - val_loss: 8.4877\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9275 - val_loss: 8.6877\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1455 - val_loss: 8.8212\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.8896 - val_loss: 8.8199\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8874 - val_loss: 8.8869\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9056 - val_loss: 8.8298\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1006 - val_loss: 8.5191\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0221 - val_loss: 8.9595\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9428 - val_loss: 8.5846\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1324 - val_loss: 8.5589\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1406 - val_loss: 9.1350\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2827 - val_loss: 8.6414\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1079 - val_loss: 9.5286\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1991 - val_loss: 9.1766\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0505 - val_loss: 9.5579\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1006 - val_loss: 8.4086\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9530 - val_loss: 8.8252\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8390 - val_loss: 8.5619\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8645 - val_loss: 8.7389\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1246 - val_loss: 8.8640\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2472 - val_loss: 8.7987\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2973 - val_loss: 8.8957\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9824 - val_loss: 8.5900\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8138 - val_loss: 8.6069\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7723 - val_loss: 8.5306\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8709 - val_loss: 9.0385\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9071 - val_loss: 8.3645\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7920 - val_loss: 8.7534\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8774 - val_loss: 8.5111\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7444 - val_loss: 8.7372\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7856 - val_loss: 8.3663\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.7255 - val_loss: 9.1426\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0338 - val_loss: 8.9497\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3216 - val_loss: 9.5105\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1775 - val_loss: 8.7364\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8111 - val_loss: 8.8361\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7654 - val_loss: 8.4956\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7272 - val_loss: 8.6619\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9834 - val_loss: 8.3604\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8848 - val_loss: 8.9786\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8383 - val_loss: 8.4771\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7844 - val_loss: 9.4304\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0803 - val_loss: 8.6124\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6930 - val_loss: 8.4032\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6854 - val_loss: 8.4255\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6435 - val_loss: 8.5371\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7096 - val_loss: 8.5719\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6315 - val_loss: 8.4181\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6966 - val_loss: 8.6007\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9761 - val_loss: 8.4415\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1499 - val_loss: 9.9398\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4131 - val_loss: 8.7329\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.8863 - val_loss: 8.8202\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8721 - val_loss: 8.8273\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6147 - val_loss: 8.7473\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6311 - val_loss: 8.3958\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6808 - val_loss: 8.2473\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6516 - val_loss: 8.2646\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7876 - val_loss: 8.4192\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6966 - val_loss: 8.6621\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9474 - val_loss: 8.1458\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6957 - val_loss: 8.5074\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5542 - val_loss: 8.4324\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6644 - val_loss: 8.6066\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8167 - val_loss: 8.2523\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5983 - val_loss: 8.6584\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7406 - val_loss: 8.2865\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5741 - val_loss: 8.6247\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5968 - val_loss: 8.1973\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7675 - val_loss: 8.2520\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6897 - val_loss: 8.3857\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7892 - val_loss: 8.5288\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6391 - val_loss: 8.1649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5772 - val_loss: 8.3102\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5726 - val_loss: 8.1749\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5530 - val_loss: 8.2962\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6079 - val_loss: 8.5377\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6006 - val_loss: 8.2637\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6644 - val_loss: 8.8640\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7857 - val_loss: 8.0354\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5057 - val_loss: 8.0610\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7606 - val_loss: 8.4042\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7236 - val_loss: 8.5260\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4987 - val_loss: 8.1303\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5635 - val_loss: 8.2329\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5248 - val_loss: 8.2440\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5219 - val_loss: 8.3237\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4178 - val_loss: 8.1252\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6079 - val_loss: 8.1032\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6687 - val_loss: 8.0662\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7067 - val_loss: 8.2145\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5261 - val_loss: 8.0730\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7463 - val_loss: 8.1498\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7972 - val_loss: 8.1564\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9089 - val_loss: 8.8668\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4064 - val_loss: 8.2371\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7001 - val_loss: 8.9959\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.7831 - val_loss: 8.1227\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7730 - val_loss: 8.3604\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4762 - val_loss: 8.1041\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3376 - val_loss: 8.2326\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4435 - val_loss: 7.8858\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4739 - val_loss: 8.1295\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4476 - val_loss: 8.0231\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4936 - val_loss: 8.9330\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4440 - val_loss: 8.2442\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9978 - val_loss: 9.0483\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0072 - val_loss: 8.3361\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7786 - val_loss: 8.9930\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5037 - val_loss: 8.0247\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4904 - val_loss: 8.3760\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4486 - val_loss: 8.2113\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6754 - val_loss: 8.0063\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6542 - val_loss: 8.3263\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7192 - val_loss: 7.6188\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4843 - val_loss: 8.0556\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3672 - val_loss: 7.7833\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5859 - val_loss: 8.3955\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5239 - val_loss: 7.8932\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5495 - val_loss: 8.1197\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5016 - val_loss: 7.8508\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5171 - val_loss: 7.9397\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3952 - val_loss: 7.9544\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.4231 - val_loss: 8.0111\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4946 - val_loss: 8.5045\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4621 - val_loss: 8.1085\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3884 - val_loss: 8.2505\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3092 - val_loss: 7.7477\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4520 - val_loss: 7.8440\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4636 - val_loss: 7.8931\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6488 - val_loss: 7.9551\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4726 - val_loss: 8.2902\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3424 - val_loss: 7.7455\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2452 - val_loss: 7.8599\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3857 - val_loss: 8.1132\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2772 - val_loss: 7.6608\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2502 - val_loss: 7.9583\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4554 - val_loss: 7.8714\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2736 - val_loss: 7.9966\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8933 - val_loss: 8.0290\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8350 - val_loss: 7.9545\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0168 - val_loss: 8.3933\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4368 - val_loss: 8.0639\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3186 - val_loss: 8.2920\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3166 - val_loss: 7.9438\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2465 - val_loss: 7.8851\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2886 - val_loss: 7.6293\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2766 - val_loss: 7.8605\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3691 - val_loss: 7.9023\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3345 - val_loss: 7.6196\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3903 - val_loss: 8.2089\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.2626 - val_loss: 7.5091\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4267 - val_loss: 7.6138\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3345 - val_loss: 7.7412\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2925 - val_loss: 8.0471\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3409 - val_loss: 7.7003\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2015 - val_loss: 7.5931\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2974 - val_loss: 7.9040\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2707 - val_loss: 7.7860\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3601 - val_loss: 7.5861\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3488 - val_loss: 7.8947\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3442 - val_loss: 7.8141\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4797 - val_loss: 7.6589\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3465 - val_loss: 7.5075\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4379 - val_loss: 7.8423\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2444 - val_loss: 7.7509\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3004 - val_loss: 7.5277\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3643 - val_loss: 8.6531\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.5086 - val_loss: 7.4711\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4821 - val_loss: 8.2795\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9344 - val_loss: 7.9715\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5101 - val_loss: 8.1023\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2657 - val_loss: 7.6144\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2103 - val_loss: 7.7594\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2149 - val_loss: 7.7315\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6463 - val_loss: 7.8802\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4832 - val_loss: 8.2044\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4541 - val_loss: 7.8199\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1655 - val_loss: 7.9477\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2789 - val_loss: 7.3733\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3580 - val_loss: 8.2812\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3997 - val_loss: 7.6670\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2919 - val_loss: 8.0945\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5828 - val_loss: 7.4076\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4158 - val_loss: 7.8010\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2468 - val_loss: 7.3756\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2612 - val_loss: 8.2513\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3404 - val_loss: 7.5664\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1477 - val_loss: 7.9172\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1611 - val_loss: 7.5316\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1204 - val_loss: 7.7813\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2786 - val_loss: 7.4907\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2752 - val_loss: 8.0351\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2431 - val_loss: 7.3477\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.0818 - val_loss: 7.6686\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1539 - val_loss: 7.5369\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1819 - val_loss: 7.6659\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1516 - val_loss: 7.3523\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.2186 - val_loss: 7.7135\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.2513 - val_loss: 7.5821\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2514 - val_loss: 7.9205\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2006 - val_loss: 7.5308\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1366 - val_loss: 7.8147\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2448 - val_loss: 7.6158\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.2298 - val_loss: 7.2592\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4584 - val_loss: 7.9545\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2258 - val_loss: 7.5773\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3322 - val_loss: 7.7168\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1847 - val_loss: 7.4770\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1313 - val_loss: 7.8182\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1746 - val_loss: 7.4241\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0441 - val_loss: 7.6592\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2935 - val_loss: 7.8524\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4592 - val_loss: 8.4296\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5049 - val_loss: 7.5800\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0886 - val_loss: 7.8869\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0567 - val_loss: 7.3330\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2200 - val_loss: 7.6192\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1895 - val_loss: 7.7606\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1221 - val_loss: 7.6842\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0357 - val_loss: 7.6141\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0844 - val_loss: 7.3628\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1428 - val_loss: 7.8183\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5435 - val_loss: 7.5440\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1784 - val_loss: 7.9292\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1248 - val_loss: 7.4132\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3447 - val_loss: 8.0597\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2869 - val_loss: 7.5878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0133 - val_loss: 7.5551\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0788 - val_loss: 7.6348\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1148 - val_loss: 7.4295\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1005 - val_loss: 7.2918\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2004 - val_loss: 7.8070\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.1892 - val_loss: 7.2778\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2518 - val_loss: 7.8173\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.1191 - val_loss: 7.5672\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1287 - val_loss: 7.6330\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0622 - val_loss: 7.5091\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1393 - val_loss: 7.4628\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0441 - val_loss: 7.3338\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2559 - val_loss: 7.9248\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1154 - val_loss: 7.3897\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2428 - val_loss: 7.8670\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1411 - val_loss: 7.3174\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2778 - val_loss: 7.5713\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2471 - val_loss: 7.8799\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3739 - val_loss: 7.6637\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3703 - val_loss: 7.2986\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0735 - val_loss: 7.5148\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1593 - val_loss: 7.5863\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0644 - val_loss: 7.6077\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3371 - val_loss: 7.5450\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5546 - val_loss: 7.9241\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 4.1403 - val_loss: 7.7204\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0727 - val_loss: 7.6160\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0296 - val_loss: 7.5720\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0354 - val_loss: 7.5159\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9735 - val_loss: 7.5610\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0499 - val_loss: 7.6872\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0065 - val_loss: 7.5640\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1388 - val_loss: 7.2785\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1094 - val_loss: 7.7724\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3370 - val_loss: 7.5201\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9507 - val_loss: 7.8175\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2305 - val_loss: 7.8783\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1835 - val_loss: 7.5376\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0961 - val_loss: 7.3615\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0367 - val_loss: 7.5193\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1032 - val_loss: 7.7284\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1152 - val_loss: 7.2795\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9833 - val_loss: 7.3488\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0080 - val_loss: 7.5663\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9178 - val_loss: 7.4270\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9476 - val_loss: 7.4746\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0490 - val_loss: 7.4042\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9796 - val_loss: 7.3731\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0281 - val_loss: 7.5482\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9135 - val_loss: 7.4166\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9549 - val_loss: 7.5016\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0268 - val_loss: 7.6384\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2400 - val_loss: 7.3866\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9884 - val_loss: 7.5376\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0001 - val_loss: 7.3796\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0940 - val_loss: 7.6709\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2936 - val_loss: 7.6792\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9811 - val_loss: 7.5640\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0447 - val_loss: 7.5789\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9148 - val_loss: 7.4736\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2957 - val_loss: 7.4905\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6908 - val_loss: 8.0918\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1657 - val_loss: 7.6422\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9684 - val_loss: 7.9294\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9979 - val_loss: 7.4240\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9254 - val_loss: 7.4795\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.9359 - val_loss: 7.2708\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9994 - val_loss: 7.5048\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3066 - val_loss: 7.8574\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0262 - val_loss: 7.5590\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1296 - val_loss: 8.0695\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1486 - val_loss: 7.4702\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0060 - val_loss: 7.8937\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 121us/step - loss: 3.9781 - val_loss: 7.2562\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0479 - val_loss: 7.7583\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1556 - val_loss: 7.7674\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1265 - val_loss: 7.3111\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0407 - val_loss: 7.4046\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9921 - val_loss: 7.6615\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9627 - val_loss: 7.6279\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9417 - val_loss: 7.2965\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0503 - val_loss: 7.4407\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7973 - val_loss: 7.7176\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1482 - val_loss: 7.9409\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.9882 - val_loss: 7.3662\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9975 - val_loss: 7.7878\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9674 - val_loss: 7.6299\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9755 - val_loss: 7.4803\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9900 - val_loss: 7.6576\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 3.8584 - val_loss: 7.5418\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 3.9275 - val_loss: 7.6273\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.8625 - val_loss: 7.5165\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2450 - val_loss: 7.5736\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0506 - val_loss: 7.9591\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9657 - val_loss: 7.3917\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9937 - val_loss: 7.8182\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8472 - val_loss: 7.6889\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9077 - val_loss: 7.7964\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9606 - val_loss: 7.3417\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9702 - val_loss: 7.5108\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8287 - val_loss: 7.7585\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9848 - val_loss: 7.5427\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.9262 - val_loss: 7.6392\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0451 - val_loss: 7.4982\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9595 - val_loss: 7.6364\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9052 - val_loss: 7.2804\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8824 - val_loss: 7.4787\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9238 - val_loss: 7.8331\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 3.9304 - val_loss: 7.6762\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.8992 - val_loss: 7.3677\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8911 - val_loss: 7.5131\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8453 - val_loss: 7.9525\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 3.9303 - val_loss: 7.5367\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 3.8839 - val_loss: 7.4001\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9725 - val_loss: 7.2980\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0244 - val_loss: 7.8063\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9220 - val_loss: 7.2790\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8925 - val_loss: 7.7387\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9787 - val_loss: 7.7044\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9546 - val_loss: 7.4825\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8877 - val_loss: 7.4384\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8974 - val_loss: 7.6640\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8223 - val_loss: 7.5386\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8949 - val_loss: 7.8708\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8370 - val_loss: 7.3292\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9204 - val_loss: 7.5779\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0286 - val_loss: 7.6984\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9054 - val_loss: 7.6181\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 4.0024 - val_loss: 7.3057\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8594 - val_loss: 7.5941\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9372 - val_loss: 7.5178\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7972 - val_loss: 7.3738\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9848 - val_loss: 7.7436\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 3.9702 - val_loss: 7.5895\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.9550 - val_loss: 7.1603\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9697 - val_loss: 8.0774\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9209 - val_loss: 7.4247\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0798 - val_loss: 7.7122\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9433 - val_loss: 7.4666\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2564 - val_loss: 8.1096\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4469 - val_loss: 7.2421\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8030 - val_loss: 7.6721\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8524 - val_loss: 7.4628\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7684 - val_loss: 7.7291\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8570 - val_loss: 7.3709\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7874 - val_loss: 7.6358\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 3.7924 - val_loss: 7.4364\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.7721 - val_loss: 7.4187\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8707 - val_loss: 7.5554\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8226 - val_loss: 7.5196\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 3.7773 - val_loss: 7.4038\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.8300 - val_loss: 7.4733\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8565 - val_loss: 7.3780\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8280 - val_loss: 7.5310\n",
      "Epoch 765/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 100us/step - loss: 3.7869 - val_loss: 7.3469\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0242 - val_loss: 7.4108\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9241 - val_loss: 7.3580\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7637 - val_loss: 7.5442\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7848 - val_loss: 7.5673\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 3.8265 - val_loss: 7.5101\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8131 - val_loss: 7.2731\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9448 - val_loss: 7.3341\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9795 - val_loss: 7.4957\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8102 - val_loss: 7.5127\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8018 - val_loss: 7.2885\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8234 - val_loss: 7.5783\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9391 - val_loss: 7.4245\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8761 - val_loss: 7.9568\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8405 - val_loss: 7.4869\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8879 - val_loss: 7.6163\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 3.8730 - val_loss: 7.0898\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8555 - val_loss: 7.7001\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8316 - val_loss: 7.4629\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9055 - val_loss: 7.4871\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.8594 - val_loss: 7.6076\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7725 - val_loss: 7.4332\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.8796 - val_loss: 7.2453\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9081 - val_loss: 7.1445\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7896 - val_loss: 7.5877\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7634 - val_loss: 7.5181\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9550 - val_loss: 7.3110\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7865 - val_loss: 7.6318\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 130us/step - loss: 3.7602 - val_loss: 7.4354\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8202 - val_loss: 7.7905\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7552 - val_loss: 7.3392\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.2346 - val_loss: 7.5279\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8169 - val_loss: 7.5473\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8393 - val_loss: 7.4488\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7621 - val_loss: 7.4618\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8428 - val_loss: 7.3236\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8648 - val_loss: 7.9292\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8635 - val_loss: 7.4511\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.8177 - val_loss: 7.6710\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7656 - val_loss: 7.4728\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9482 - val_loss: 7.6149\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7604 - val_loss: 7.5776\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7538 - val_loss: 7.2931\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 3.8180 - val_loss: 7.5673\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8299 - val_loss: 7.6326\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.8811 - val_loss: 7.6995\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7482 - val_loss: 7.3733\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.8678 - val_loss: 7.5837\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.7877 - val_loss: 7.4581\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9760 - val_loss: 7.4257\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8954 - val_loss: 7.4338\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8927 - val_loss: 8.0182\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.8102 - val_loss: 7.4742\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7231 - val_loss: 7.4629\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7377 - val_loss: 7.4440\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6954 - val_loss: 7.4784\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6954 - val_loss: 7.5292\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8473 - val_loss: 7.5556\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1381 - val_loss: 8.0846\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.9605 - val_loss: 7.8700\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7904 - val_loss: 7.8507\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7106 - val_loss: 7.3440\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7884 - val_loss: 7.9454\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.8439 - val_loss: 7.4370\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8052 - val_loss: 7.7534\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.6764 - val_loss: 7.8101\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8125 - val_loss: 7.6978\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6649 - val_loss: 7.4379\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.7729 - val_loss: 7.6153\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 3.7493 - val_loss: 7.6144\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8468 - val_loss: 7.6239\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1231 - val_loss: 7.9811\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7188 - val_loss: 7.6822\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.7925 - val_loss: 7.6818\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7278 - val_loss: 7.8768\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6652 - val_loss: 8.1297\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8018 - val_loss: 7.6915\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8178 - val_loss: 7.6836\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6490 - val_loss: 7.5324\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7609 - val_loss: 7.8836\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7224 - val_loss: 7.4297\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6372 - val_loss: 7.7909\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6423 - val_loss: 7.8501\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7783 - val_loss: 7.9581\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.7147 - val_loss: 7.5268\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6855 - val_loss: 7.6825\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7048 - val_loss: 7.7227\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8353 - val_loss: 7.5853\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8654 - val_loss: 7.8765\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7602 - val_loss: 7.9348\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7021 - val_loss: 8.0138\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9462 - val_loss: 7.6678\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6174 - val_loss: 7.6931\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6293 - val_loss: 7.5485\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6293 - val_loss: 7.7255\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.6171 - val_loss: 7.6698\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.5810 - val_loss: 7.8167\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6306 - val_loss: 7.8307\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6308 - val_loss: 7.5784\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7120 - val_loss: 7.6602\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7550 - val_loss: 7.8822\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 3.8124 - val_loss: 7.8139\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.7170 - val_loss: 8.1024\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6833 - val_loss: 7.6295\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.7559 - val_loss: 7.8868\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7190 - val_loss: 7.6385\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7268 - val_loss: 8.2156\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6539 - val_loss: 7.6787\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6693 - val_loss: 7.7045\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7803 - val_loss: 7.7623\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6647 - val_loss: 7.8441\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7285 - val_loss: 7.9319\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7525 - val_loss: 8.1506\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0390 - val_loss: 8.1485\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6259 - val_loss: 7.6723\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 3.6370 - val_loss: 7.8323\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5801 - val_loss: 7.9269\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7708 - val_loss: 7.6519\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6959 - val_loss: 8.2326\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.7589 - val_loss: 7.7138\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.5955 - val_loss: 8.0658\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.7454 - val_loss: 7.6954\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6313 - val_loss: 7.9879\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6887 - val_loss: 7.6577\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6188 - val_loss: 7.7789\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6798 - val_loss: 7.6937\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8152 - val_loss: 8.1615\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7072 - val_loss: 7.8881\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5586 - val_loss: 7.8861\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6649 - val_loss: 7.6897\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6921 - val_loss: 7.7369\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.5564 - val_loss: 8.0851\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7694 - val_loss: 8.0540\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8463 - val_loss: 7.4637\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.6276 - val_loss: 7.8785\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 3.5784 - val_loss: 7.9919\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5869 - val_loss: 7.6762\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6316 - val_loss: 8.1430\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5581 - val_loss: 7.5833\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.6133 - val_loss: 7.8677\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7338 - val_loss: 7.7427\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7343 - val_loss: 8.0739\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5262 - val_loss: 7.9382\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5150 - val_loss: 7.9372\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6210 - val_loss: 7.9442\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.7310 - val_loss: 8.2279\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7292 - val_loss: 7.8154\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7945 - val_loss: 7.8601\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.4777 - val_loss: 7.9231\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.5727 - val_loss: 7.9013\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6800 - val_loss: 7.9676\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7252 - val_loss: 7.8231\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6891 - val_loss: 8.1211\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6947 - val_loss: 8.2964\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 3.7454 - val_loss: 7.8913\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7238 - val_loss: 7.8811\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6043 - val_loss: 7.6127\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6456 - val_loss: 7.7524\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.5490 - val_loss: 7.9838\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6964 - val_loss: 7.9559\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8322 - val_loss: 8.1030\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 3.5935 - val_loss: 7.8680\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7905 - val_loss: 8.2328\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6398 - val_loss: 7.7562\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 182us/step - loss: 3.5729 - val_loss: 8.1388\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 3.5574 - val_loss: 7.8809\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7277 - val_loss: 7.6431\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 3.7356 - val_loss: 8.3102\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.6599 - val_loss: 7.9765\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5481 - val_loss: 8.2862\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7514 - val_loss: 7.9105\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9660 - val_loss: 9.2041\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6232 - val_loss: 8.2971\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8078 - val_loss: 8.5176\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5914 - val_loss: 7.8879\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8077 - val_loss: 8.1431\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7449 - val_loss: 7.6604\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.4480 - val_loss: 8.1192\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5046 - val_loss: 8.1584\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5189 - val_loss: 7.7558\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6715 - val_loss: 8.0131\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5623 - val_loss: 8.0502\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.4904 - val_loss: 7.9481\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5749 - val_loss: 8.0065\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5771 - val_loss: 7.7890\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5854 - val_loss: 7.9007\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5754 - val_loss: 8.2464\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5435 - val_loss: 8.0735\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1985 - val_loss: 8.4627\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5608 - val_loss: 8.1471\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6863 - val_loss: 8.0171\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5750 - val_loss: 7.9807\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5132 - val_loss: 7.9582\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6020 - val_loss: 8.5567\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7812 - val_loss: 7.8952\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5581 - val_loss: 7.8464\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5952 - val_loss: 8.1067\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6668 - val_loss: 7.9604\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.5400 - val_loss: 7.9318\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.4977 - val_loss: 7.8745\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5332 - val_loss: 7.9998\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5629 - val_loss: 8.1051\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6383 - val_loss: 8.0571\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5578 - val_loss: 8.0176\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5904 - val_loss: 7.9243\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.4605 - val_loss: 8.0453\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.5312 - val_loss: 7.9824\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.4874 - val_loss: 7.8203\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5046 - val_loss: 8.2477\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6280 - val_loss: 7.9901\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5635 - val_loss: 8.2608\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 3.6087 - val_loss: 7.8079\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.7413 - val_loss: 7.9992\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9622 - val_loss: 8.3389\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8780 - val_loss: 7.9728\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7292 - val_loss: 8.1489\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.4536 - val_loss: 8.1876\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 3.5925 - val_loss: 7.9831\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5904 - val_loss: 8.1391\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6504 - val_loss: 8.0047\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6629 - val_loss: 8.1063\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5869 - val_loss: 7.9090\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.4839 - val_loss: 7.9942\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.4909 - val_loss: 7.9902\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5081 - val_loss: 8.0633\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9069 - val_loss: 8.4584\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9020 - val_loss: 8.0495\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.5250 - val_loss: 7.8331\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6088 - val_loss: 8.2375\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7148 - val_loss: 8.2883\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.4939 - val_loss: 8.2622\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6600 - val_loss: 8.3681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7287 - val_loss: 8.1999\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5821 - val_loss: 8.9222\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6396 - val_loss: 8.0143\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.4320 - val_loss: 7.9626\n",
      "5.531032740059546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04545702, -2.511662  ,  3.762047  , -0.17416118,  3.2291272 ,\n",
       "         -2.6302717 ,  3.9915245 , -7.318204  , -0.82214326, -1.0902684 ],\n",
       "        [-0.5517557 ,  0.9220406 ,  0.8571945 , -1.1297529 , -0.5887715 ,\n",
       "         -1.1524109 , -3.4047036 ,  4.364822  ,  0.44232997,  1.7254438 ],\n",
       "        [-1.1246996 , -0.45825884, -0.7950726 , -0.77377963, -0.882725  ,\n",
       "          2.3346918 , -0.56510377, -2.187164  ,  1.6658965 , -1.2665586 ],\n",
       "        [-0.5957374 , -0.25802156, -0.6191043 ,  2.0048451 , -1.3560736 ,\n",
       "          5.347828  ,  2.4444008 , -2.6487172 , -0.2875823 ,  0.38301754],\n",
       "        [-1.6832465 ,  0.11433085, -0.20251735, -1.1141636 , -0.33357382,\n",
       "         -0.29563668, -1.0002967 , -0.51464176, -0.7839633 ,  0.38977957],\n",
       "        [ 1.0633119 ,  0.13517897,  2.013581  ,  0.60491997, -0.8806438 ,\n",
       "         -0.24715768, -0.6073789 ,  1.1115314 ,  0.8893951 , -0.84443676],\n",
       "        [ 0.29118034, -0.50261205, -0.24787265,  1.7554169 ,  1.6885302 ,\n",
       "          2.2992573 , -0.27163017,  0.458901  , -0.4176286 ,  0.90261346]],\n",
       "       dtype=float32),\n",
       " array([ 3.3426821 , -0.23841675,  2.2793555 ,  2.827074  ,  3.4101396 ,\n",
       "        -0.13817684, -2.3672223 , -1.866132  ,  2.025288  , -1.8055254 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.25889722, -0.4037308 ,  0.40967703,  0.11732051,  0.28199306],\n",
       "        [-1.0348529 ,  1.2147099 , -1.6250434 ,  1.4805171 , -1.9730874 ],\n",
       "        [ 0.98891914, -0.19562656,  0.99353033, -1.1090219 ,  0.29173428],\n",
       "        [ 0.676984  , -0.9496748 ,  1.2813505 , -0.3682077 ,  0.8619993 ],\n",
       "        [ 0.6578513 , -0.19603612,  1.0343928 , -0.28052726,  0.7423796 ],\n",
       "        [-0.4587659 ,  0.20897983, -0.49695325, -0.00815166, -0.08902176],\n",
       "        [-0.24813613,  0.73065084, -1.188133  ,  0.7137287 , -1.0997171 ],\n",
       "        [ 1.608869  , -1.9563065 ,  2.264545  , -2.1023314 ,  1.4879382 ],\n",
       "        [-0.72457314,  0.9575441 , -1.2057633 ,  0.6366979 , -0.9564414 ],\n",
       "        [-0.80201334,  0.23931181, -0.7634616 ,  0.8431799 , -0.48937753]],\n",
       "       dtype=float32),\n",
       " array([ 1.2720758, -1.3384957,  1.3756126, -1.356005 ,  1.3567696],\n",
       "       dtype=float32),\n",
       " array([[ 1.1104835],\n",
       "        [-0.9162189],\n",
       "        [ 1.6339409],\n",
       "        [-1.6556954],\n",
       "        [ 1.3168961]], dtype=float32),\n",
       " array([1.4115847], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_4(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure4_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 509.7514 - val_loss: 293.7673\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 171.2571 - val_loss: 94.8609\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 51.9852 - val_loss: 28.5903\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 22.4122 - val_loss: 19.5599\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 17.5339 - val_loss: 18.3763\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.3152 - val_loss: 18.1917\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 11.9829 - val_loss: 16.1711\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.6396 - val_loss: 14.8902\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.1179 - val_loss: 14.0682\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 8.4240 - val_loss: 12.7527\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8055 - val_loss: 12.3492\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0003 - val_loss: 11.6346\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0167 - val_loss: 11.9025\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4085 - val_loss: 11.0081\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.3818 - val_loss: 10.8121\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2823 - val_loss: 10.9795\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2106 - val_loss: 10.8651\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1620 - val_loss: 10.8006\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1748 - val_loss: 10.4302\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.3195 - val_loss: 10.9010\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2903 - val_loss: 10.8929\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.3242 - val_loss: 10.5928\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.5288 - val_loss: 10.4974\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2062 - val_loss: 11.9449\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.4568 - val_loss: 10.6764\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5147 - val_loss: 10.5143\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3785 - val_loss: 10.5882\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1189 - val_loss: 10.6467\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2847 - val_loss: 10.5130\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5262 - val_loss: 10.5113\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1936 - val_loss: 11.9125\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5365 - val_loss: 10.7158\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1350 - val_loss: 10.6050\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1467 - val_loss: 11.2598\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9679 - val_loss: 10.6594\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4328 - val_loss: 11.9270\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5296 - val_loss: 10.9462\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.0995 - val_loss: 12.3285\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 9.3365 - val_loss: 12.2978\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.4200 - val_loss: 11.1790\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6309 - val_loss: 11.0705\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5203 - val_loss: 10.7497\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2276 - val_loss: 10.9989\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0219 - val_loss: 10.8693\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.3707 - val_loss: 10.5853\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0330 - val_loss: 10.9255\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0085 - val_loss: 10.6369\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9180 - val_loss: 10.7414\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9562 - val_loss: 11.0175\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0540 - val_loss: 10.3022\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.4460 - val_loss: 11.0243\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3476 - val_loss: 10.7697\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1888 - val_loss: 10.8622\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0483 - val_loss: 10.9007\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8132 - val_loss: 10.3606\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1501 - val_loss: 10.6470\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0540 - val_loss: 11.2121\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8860 - val_loss: 10.4358\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0715 - val_loss: 10.5924\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9127 - val_loss: 10.7078\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8429 - val_loss: 10.8504\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9016 - val_loss: 10.9187\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0068 - val_loss: 11.9204\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8300 - val_loss: 10.7218\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1804 - val_loss: 11.2483\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7452 - val_loss: 10.5757\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0102 - val_loss: 11.1431\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7750 - val_loss: 10.5794\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8969 - val_loss: 11.7744\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0799 - val_loss: 11.1212\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9729 - val_loss: 10.8668\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8768 - val_loss: 10.9980\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8781 - val_loss: 10.8672\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9787 - val_loss: 11.0125\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7017 - val_loss: 10.8787\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7870 - val_loss: 10.6584\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8962 - val_loss: 10.3708\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6975 - val_loss: 10.5329\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7359 - val_loss: 11.1294\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8081 - val_loss: 10.8988\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5904 - val_loss: 10.7437\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5841 - val_loss: 10.7798\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7982 - val_loss: 10.9265\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6612 - val_loss: 11.0086\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6351 - val_loss: 10.8591\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5098 - val_loss: 10.5830\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6689 - val_loss: 11.5514\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8466 - val_loss: 10.8686\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3321 - val_loss: 11.9111\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0324 - val_loss: 10.7152\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4597 - val_loss: 11.2817\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5071 - val_loss: 10.7612\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4776 - val_loss: 10.4730\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4512 - val_loss: 10.8469\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6410 - val_loss: 10.7476\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4975 - val_loss: 10.5550\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4269 - val_loss: 10.3394\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4275 - val_loss: 10.3034\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3496 - val_loss: 10.6753\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3368 - val_loss: 10.5775\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2507 - val_loss: 10.2684\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4272 - val_loss: 10.1223\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2866 - val_loss: 10.1989\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2534 - val_loss: 10.2882\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4354 - val_loss: 10.5434\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3070 - val_loss: 10.2607\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4636 - val_loss: 10.5811\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7764 - val_loss: 10.2775\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4248 - val_loss: 10.5251\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4180 - val_loss: 10.0408\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1013 - val_loss: 9.7389\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1332 - val_loss: 9.7956\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2192 - val_loss: 9.8211\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0848 - val_loss: 9.8102\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2557 - val_loss: 10.0346\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4374 - val_loss: 10.5104\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0646 - val_loss: 9.5013\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1020 - val_loss: 9.7281\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0963 - val_loss: 9.7147\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9865 - val_loss: 9.2118\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9748 - val_loss: 9.6017\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8790 - val_loss: 10.0632\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9142 - val_loss: 9.8876\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1270 - val_loss: 10.1225\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9941 - val_loss: 9.2860\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7519 - val_loss: 9.2817\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9935 - val_loss: 9.5236\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7556 - val_loss: 9.5700\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7376 - val_loss: 9.4895\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9225 - val_loss: 9.1327\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9690 - val_loss: 9.7668\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1358 - val_loss: 9.5628\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9594 - val_loss: 9.4666\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7721 - val_loss: 9.3860\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7251 - val_loss: 9.7842\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8454 - val_loss: 9.5896\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9532 - val_loss: 9.6557\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6673 - val_loss: 9.4798\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7501 - val_loss: 9.5620\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6948 - val_loss: 9.3646\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7594 - val_loss: 9.4430\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6228 - val_loss: 9.3068\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8187 - val_loss: 9.4909\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3567 - val_loss: 9.9008\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.8255 - val_loss: 9.5496\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5659 - val_loss: 9.3731\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9967 - val_loss: 9.0754\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8555 - val_loss: 8.8210\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1195 - val_loss: 8.9670\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9019 - val_loss: 9.5477\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8813 - val_loss: 8.9837\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2581 - val_loss: 8.9939\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0094 - val_loss: 8.9180\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6135 - val_loss: 9.0406\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8437 - val_loss: 9.6164\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8327 - val_loss: 8.9376\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6551 - val_loss: 8.9788\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5956 - val_loss: 9.2820\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5308 - val_loss: 9.2508\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9503 - val_loss: 9.0198\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7762 - val_loss: 8.8743\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9535 - val_loss: 9.1366\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6245 - val_loss: 9.5585\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8004 - val_loss: 9.6020\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8468 - val_loss: 9.2315\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6402 - val_loss: 9.2435\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5533 - val_loss: 9.0405\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7908 - val_loss: 8.9943\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5508 - val_loss: 8.8726\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8310 - val_loss: 8.7348\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8885 - val_loss: 8.7578\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7112 - val_loss: 9.3616\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9881 - val_loss: 9.1657\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5981 - val_loss: 8.8856\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4946 - val_loss: 8.7214\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4230 - val_loss: 8.7237\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4994 - val_loss: 8.6521\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4801 - val_loss: 8.6795\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5341 - val_loss: 8.8690\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7894 - val_loss: 8.8074\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6278 - val_loss: 8.8997\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7274 - val_loss: 8.7875\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6086 - val_loss: 8.8148\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5070 - val_loss: 8.9153\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4388 - val_loss: 8.7458\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4741 - val_loss: 8.7915\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4366 - val_loss: 8.6787\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4219 - val_loss: 8.8177\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4710 - val_loss: 8.7296\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4740 - val_loss: 8.5030\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5535 - val_loss: 8.5797\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4110 - val_loss: 8.7408\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3532 - val_loss: 8.6397\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4026 - val_loss: 8.5696\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3665 - val_loss: 8.7174\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4229 - val_loss: 8.6130\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4596 - val_loss: 8.8643\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6205 - val_loss: 8.4853\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4966 - val_loss: 8.8691\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6147 - val_loss: 8.7108\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4489 - val_loss: 8.9010\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4519 - val_loss: 8.8657\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4054 - val_loss: 8.6420\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4892 - val_loss: 8.4486\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4138 - val_loss: 8.5672\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4760 - val_loss: 8.7173\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5926 - val_loss: 8.6429\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3599 - val_loss: 8.4162\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3654 - val_loss: 8.6284\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3595 - val_loss: 8.5630\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3279 - val_loss: 8.6976\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3778 - val_loss: 8.7340\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4051 - val_loss: 8.4123\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3413 - val_loss: 8.4964\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3395 - val_loss: 8.5244\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3986 - val_loss: 8.4935\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3274 - val_loss: 8.5887\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3088 - val_loss: 8.6627\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4461 - val_loss: 8.6469\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3925 - val_loss: 8.6116\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3384 - val_loss: 8.4387\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5611 - val_loss: 8.6749\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5752 - val_loss: 8.7793\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5413 - val_loss: 8.9064\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5023 - val_loss: 8.4476\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3148 - val_loss: 8.7333\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5872 - val_loss: 8.5298\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3099 - val_loss: 8.6963\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5867 - val_loss: 9.8538\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9569 - val_loss: 9.1708\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6963 - val_loss: 9.6495\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6474 - val_loss: 9.0366\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6793 - val_loss: 8.9290\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4358 - val_loss: 8.4747\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3533 - val_loss: 8.2845\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.3412 - val_loss: 8.5830\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2845 - val_loss: 8.6883\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3886 - val_loss: 8.5341\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4924 - val_loss: 8.7468\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4585 - val_loss: 8.5646\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2083 - val_loss: 8.7281\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4549 - val_loss: 8.5629\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3167 - val_loss: 8.6735\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2725 - val_loss: 8.6122\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3863 - val_loss: 8.3547\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4283 - val_loss: 8.4649\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4357 - val_loss: 8.7088\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2835 - val_loss: 8.7086\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4450 - val_loss: 8.6344\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4586 - val_loss: 8.8158\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4389 - val_loss: 8.5292\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3279 - val_loss: 8.6281\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2821 - val_loss: 8.5188\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3271 - val_loss: 8.5639\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3165 - val_loss: 8.5555\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3056 - val_loss: 8.5480\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2646 - val_loss: 8.5693\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4037 - val_loss: 8.4946\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2901 - val_loss: 8.6069\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4060 - val_loss: 8.7786\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6053 - val_loss: 9.1926\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5880 - val_loss: 8.6288\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6903 - val_loss: 8.5887\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5433 - val_loss: 8.5533\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3939 - val_loss: 8.6099\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2405 - val_loss: 8.7647\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2386 - val_loss: 8.5800\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2405 - val_loss: 8.6521\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2325 - val_loss: 8.5035\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5257 - val_loss: 8.5044\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2716 - val_loss: 9.1319\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4604 - val_loss: 8.6529\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7791 - val_loss: 9.3551\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6410 - val_loss: 8.7361\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2432 - val_loss: 8.7310\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2746 - val_loss: 8.5330\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3896 - val_loss: 8.9543\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4487 - val_loss: 8.7516\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6109 - val_loss: 9.0938\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1591 - val_loss: 8.6794\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3990 - val_loss: 9.2293\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7342 - val_loss: 8.7094\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 5.3924 - val_loss: 8.8157\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 128us/step - loss: 5.6229 - val_loss: 8.6915\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8329 - val_loss: 9.0972\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7501 - val_loss: 9.3295\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4874 - val_loss: 8.9880\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3794 - val_loss: 8.7535\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2098 - val_loss: 8.4876\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.2814 - val_loss: 8.8443\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3608 - val_loss: 8.9714\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3095 - val_loss: 8.8439\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3253 - val_loss: 8.5046\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2558 - val_loss: 8.4230\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2959 - val_loss: 8.5946\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3588 - val_loss: 8.3890\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2252 - val_loss: 8.4032\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1255 - val_loss: 8.8280\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.2704 - val_loss: 8.6838\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2349 - val_loss: 8.6283\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2338 - val_loss: 8.5189\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1907 - val_loss: 8.4384\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5670 - val_loss: 8.7658\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8402 - val_loss: 8.9564\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4961 - val_loss: 8.8410\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2879 - val_loss: 8.5619\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1612 - val_loss: 8.6637\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4296 - val_loss: 8.4836\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2761 - val_loss: 8.6389\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1860 - val_loss: 8.6936\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.2037 - val_loss: 8.9269\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2550 - val_loss: 8.6162\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1969 - val_loss: 8.5839\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3860 - val_loss: 8.8035\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4718 - val_loss: 8.7057\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2655 - val_loss: 8.8553\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1928 - val_loss: 8.7900\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1689 - val_loss: 8.7045\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2009 - val_loss: 8.8276\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2368 - val_loss: 9.0350\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3885 - val_loss: 8.7214\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2070 - val_loss: 8.5500\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2228 - val_loss: 8.4132\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1947 - val_loss: 8.7416\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1991 - val_loss: 8.6705\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1688 - val_loss: 8.6001\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2646 - val_loss: 8.5107\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1465 - val_loss: 8.8438\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4162 - val_loss: 8.8640\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5409 - val_loss: 9.6445\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6643 - val_loss: 8.6872\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2622 - val_loss: 8.9792\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2477 - val_loss: 8.7312\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2583 - val_loss: 8.7325\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.4546 - val_loss: 8.7922\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3081 - val_loss: 8.6701\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1633 - val_loss: 8.9706\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2939 - val_loss: 8.9182\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1360 - val_loss: 8.7730\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1825 - val_loss: 8.6134\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0978 - val_loss: 8.8596\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3454 - val_loss: 8.7565\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3171 - val_loss: 9.2861\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6004 - val_loss: 9.0223\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5680 - val_loss: 8.9993\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2794 - val_loss: 8.5517\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2933 - val_loss: 8.8093\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 470us/step - loss: 5.1479 - val_loss: 8.6928\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1232 - val_loss: 8.7493\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0524 - val_loss: 8.8101\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1003 - val_loss: 9.0317\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4038 - val_loss: 8.7524\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2373 - val_loss: 9.0070\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1252 - val_loss: 8.7067\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1439 - val_loss: 8.8519\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1102 - val_loss: 8.5137\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0905 - val_loss: 8.7678\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1468 - val_loss: 8.6193\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1677 - val_loss: 8.8061\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0276 - val_loss: 8.5469\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0149 - val_loss: 8.9363\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0797 - val_loss: 8.8288\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9883 - val_loss: 8.6394\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0265 - val_loss: 8.6437\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9996 - val_loss: 8.6976\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0054 - val_loss: 9.0011\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0350 - val_loss: 8.7740\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9458 - val_loss: 8.7394\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0800 - val_loss: 8.6832\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0280 - val_loss: 8.7440\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0154 - val_loss: 8.8056\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9761 - val_loss: 8.5978\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1512 - val_loss: 8.9299\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1195 - val_loss: 8.9139\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2496 - val_loss: 8.7399\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0476 - val_loss: 8.6480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1561 - val_loss: 8.9644\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2456 - val_loss: 9.2892\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9201 - val_loss: 8.8100\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0610 - val_loss: 9.5258\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2874 - val_loss: 8.6354\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9103 - val_loss: 9.1938\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2319 - val_loss: 9.2695\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7969 - val_loss: 10.7642\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5361 - val_loss: 8.8056\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2217 - val_loss: 8.7771\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9257 - val_loss: 8.7337\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9686 - val_loss: 8.7484\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1038 - val_loss: 9.1230\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3248 - val_loss: 8.6744\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8658 - val_loss: 9.2812\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0223 - val_loss: 8.6995\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0240 - val_loss: 8.9109\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8829 - val_loss: 8.8214\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9543 - val_loss: 8.7828\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8138 - val_loss: 8.6945\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8850 - val_loss: 8.6844\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7411 - val_loss: 8.6934\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8597 - val_loss: 8.6145\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8417 - val_loss: 8.6286\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.810 - 0s 102us/step - loss: 4.8296 - val_loss: 8.6689\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8278 - val_loss: 8.5054\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7491 - val_loss: 8.7577\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7412 - val_loss: 8.7355\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7539 - val_loss: 8.8942\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8591 - val_loss: 8.9191\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8037 - val_loss: 8.7456\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.8079 - val_loss: 8.8657\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8042 - val_loss: 8.7255\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8116 - val_loss: 8.5509\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8449 - val_loss: 8.8130\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9089 - val_loss: 8.8634\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8995 - val_loss: 9.0893\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8542 - val_loss: 8.6851\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7987 - val_loss: 9.1610\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7474 - val_loss: 8.8034\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0692 - val_loss: 8.6131\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7851 - val_loss: 8.7356\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7805 - val_loss: 8.7400\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6643 - val_loss: 8.8654\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8377 - val_loss: 9.0964\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8321 - val_loss: 8.8395\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6644 - val_loss: 8.7769\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6871 - val_loss: 8.8998\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7966 - val_loss: 8.7877\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6774 - val_loss: 9.0858\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7838 - val_loss: 9.1780\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0745 - val_loss: 8.7158\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9902 - val_loss: 8.9270\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8167 - val_loss: 9.0746\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4266 - val_loss: 9.2728\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9243 - val_loss: 9.5342\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9539 - val_loss: 8.5322\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7929 - val_loss: 8.5256\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8080 - val_loss: 9.2343\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9113 - val_loss: 8.8269\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8955 - val_loss: 8.7145\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8603 - val_loss: 8.9839\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7364 - val_loss: 8.7011\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6909 - val_loss: 8.9458\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5990 - val_loss: 8.9891\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6609 - val_loss: 9.1698\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.6555 - val_loss: 8.8604\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7075 - val_loss: 9.1514\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.5940 - val_loss: 9.0518\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6800 - val_loss: 9.1061\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7452 - val_loss: 8.8882\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6042 - val_loss: 9.0647\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6230 - val_loss: 8.9260\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6065 - val_loss: 8.7215\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6397 - val_loss: 8.6572\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5743 - val_loss: 9.5845\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8208 - val_loss: 8.8151\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9278 - val_loss: 9.0048\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6015 - val_loss: 9.3128\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9456 - val_loss: 8.8885\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6902 - val_loss: 9.3869\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5787 - val_loss: 8.6479\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5770 - val_loss: 9.1070\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5787 - val_loss: 8.7700\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7991 - val_loss: 9.3262\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7923 - val_loss: 8.7440\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5412 - val_loss: 9.2477\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6832 - val_loss: 8.7984\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7206 - val_loss: 9.1513\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6196 - val_loss: 8.8858\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7689 - val_loss: 9.0490\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5366 - val_loss: 8.8991\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5619 - val_loss: 8.6491\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5329 - val_loss: 9.0223\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6037 - val_loss: 9.0492\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4820 - val_loss: 9.0162\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7148 - val_loss: 8.9626\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6132 - val_loss: 9.2418\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6996 - val_loss: 8.9098\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6050 - val_loss: 9.8547\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0457 - val_loss: 8.8546\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6878 - val_loss: 9.2464\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6740 - val_loss: 8.8599\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3956 - val_loss: 9.3977\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6158 - val_loss: 9.1034\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9543 - val_loss: 9.5261\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4479 - val_loss: 8.7441\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5678 - val_loss: 8.9594\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4725 - val_loss: 8.8684\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5073 - val_loss: 8.9096\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4748 - val_loss: 9.0330\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5014 - val_loss: 8.7645\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9861 - val_loss: 9.8045\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7816 - val_loss: 8.7572\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5476 - val_loss: 9.0911\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.8760 - val_loss: 9.5278\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1858 - val_loss: 8.9990\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9202 - val_loss: 8.8969\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4641 - val_loss: 8.7145\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5566 - val_loss: 8.8364\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7074 - val_loss: 9.5531\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6610 - val_loss: 8.8249\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8687 - val_loss: 9.2318\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4660 - val_loss: 8.7162\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5825 - val_loss: 9.3216\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.5875 - val_loss: 8.5202\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4406 - val_loss: 8.9613\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6827 - val_loss: 9.1221\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3954 - val_loss: 9.4183\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8592 - val_loss: 8.8255\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4430 - val_loss: 9.2203\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8205 - val_loss: 9.3787\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6154 - val_loss: 9.0792\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4951 - val_loss: 9.6090\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5645 - val_loss: 9.2003\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5398 - val_loss: 9.0744\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4249 - val_loss: 8.8930\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5021 - val_loss: 8.8171\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5017 - val_loss: 8.7162\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6353 - val_loss: 8.8203\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4671 - val_loss: 8.8681\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6215 - val_loss: 9.2595\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5976 - val_loss: 8.9485\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3978 - val_loss: 9.1243\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3396 - val_loss: 8.8584\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3933 - val_loss: 8.9784\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3824 - val_loss: 8.7806\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4921 - val_loss: 8.8284\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5910 - val_loss: 8.9198\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3831 - val_loss: 9.0514\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4295 - val_loss: 9.3009\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4589 - val_loss: 9.0161\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4616 - val_loss: 9.3510\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3662 - val_loss: 8.9011\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3714 - val_loss: 9.3837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4399 - val_loss: 8.9371\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3482 - val_loss: 9.1442\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4128 - val_loss: 9.0763\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4010 - val_loss: 8.9970\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4058 - val_loss: 9.6554\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4039 - val_loss: 9.0180\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5730 - val_loss: 9.1350\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 4.6047 - val_loss: 8.7054\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.3387 - val_loss: 9.0380\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 4.4112 - val_loss: 9.1133\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4337 - val_loss: 9.4378\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4961 - val_loss: 9.4954\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5129 - val_loss: 9.0227\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3220 - val_loss: 9.5426\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3428 - val_loss: 9.2799\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.5951 - val_loss: 9.3355\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4720 - val_loss: 9.0924\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4621 - val_loss: 9.5950\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6090 - val_loss: 9.4987\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6283 - val_loss: 10.0058\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5209 - val_loss: 9.2963\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4972 - val_loss: 9.8904\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3172 - val_loss: 8.9640\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3038 - val_loss: 9.2506\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4142 - val_loss: 9.5932\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5709 - val_loss: 10.4018\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6835 - val_loss: 9.6248\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5979 - val_loss: 10.5722\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4567 - val_loss: 9.7956\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4199 - val_loss: 10.1544\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0317 - val_loss: 9.7309\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7199 - val_loss: 10.0525\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4929 - val_loss: 9.4175\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5411 - val_loss: 9.6812\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3912 - val_loss: 9.2492\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3326 - val_loss: 9.5942\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4390 - val_loss: 9.3335\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3407 - val_loss: 9.6871\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2470 - val_loss: 9.5462\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4504 - val_loss: 9.4032\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4181 - val_loss: 9.2875\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5109 - val_loss: 9.3628\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2001 - val_loss: 9.7714\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2528 - val_loss: 9.3467\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3084 - val_loss: 9.4081\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2823 - val_loss: 9.5377\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3317 - val_loss: 9.6632\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2890 - val_loss: 9.5342\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3605 - val_loss: 9.4494\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3322 - val_loss: 9.3194\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3045 - val_loss: 9.4713\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3785 - val_loss: 9.1453\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3591 - val_loss: 9.2172\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3984 - val_loss: 9.6205\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3840 - val_loss: 9.9270\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3638 - val_loss: 9.7257\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2500 - val_loss: 9.6420\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1956 - val_loss: 9.7987\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2829 - val_loss: 9.5821\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3154 - val_loss: 9.7125\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4534 - val_loss: 10.0425\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3595 - val_loss: 9.6775\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4860 - val_loss: 9.4589\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3461 - val_loss: 9.2451\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2213 - val_loss: 9.5719\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2777 - val_loss: 9.6130\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5609 - val_loss: 9.8720\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6856 - val_loss: 9.8095\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2250 - val_loss: 9.6331\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.2048 - val_loss: 9.4304\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3132 - val_loss: 9.6542\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2739 - val_loss: 9.5259\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4556 - val_loss: 10.1131\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2922 - val_loss: 9.5059\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2620 - val_loss: 9.3913\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2958 - val_loss: 9.6974\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4810 - val_loss: 10.1791\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3330 - val_loss: 9.9327\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3155 - val_loss: 10.0783\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2323 - val_loss: 9.4278\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2382 - val_loss: 9.7277\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2740 - val_loss: 9.7543\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.5993 - val_loss: 9.7546\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2830 - val_loss: 10.2750\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2132 - val_loss: 10.2165\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2537 - val_loss: 10.2136\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1253 - val_loss: 9.5976\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2135 - val_loss: 9.6393\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1880 - val_loss: 9.9044\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3341 - val_loss: 10.0172\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2698 - val_loss: 9.8792\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1891 - val_loss: 9.5917\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1530 - val_loss: 9.9241\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1362 - val_loss: 9.9320\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1875 - val_loss: 10.1396\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3732 - val_loss: 9.8817\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3962 - val_loss: 9.8739\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3592 - val_loss: 10.2928\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1227 - val_loss: 9.6572\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2112 - val_loss: 10.1606\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2535 - val_loss: 9.7366\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2925 - val_loss: 10.0244\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1512 - val_loss: 9.6940\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1233 - val_loss: 9.6421\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1124 - val_loss: 10.1802\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1702 - val_loss: 10.0208\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1945 - val_loss: 9.9497\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0814 - val_loss: 9.7893\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2520 - val_loss: 10.1469\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1193 - val_loss: 10.3642\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0774 - val_loss: 10.2740\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2376 - val_loss: 9.6881\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1319 - val_loss: 9.9179\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1078 - val_loss: 9.8838\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2490 - val_loss: 9.8572\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2381 - val_loss: 9.8932\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3224 - val_loss: 10.4531\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2959 - val_loss: 9.8464\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2705 - val_loss: 9.7876\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1599 - val_loss: 10.0009\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1718 - val_loss: 9.9721\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2110 - val_loss: 10.0570\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1178 - val_loss: 10.0306\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1712 - val_loss: 10.1936\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3178 - val_loss: 10.4682\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1996 - val_loss: 10.1293\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0538 - val_loss: 10.6437\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3746 - val_loss: 10.0640\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1981 - val_loss: 9.7467\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1520 - val_loss: 10.0212\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3123 - val_loss: 10.3418\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1777 - val_loss: 10.5746\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3257 - val_loss: 10.5565\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5887 - val_loss: 10.4749\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2442 - val_loss: 10.4774\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0183 - val_loss: 10.4687\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1198 - val_loss: 10.0006\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1330 - val_loss: 9.6757\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1760 - val_loss: 10.3533\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0455 - val_loss: 10.1300\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1949 - val_loss: 10.1344\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0697 - val_loss: 10.1160\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0470 - val_loss: 10.1337\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2152 - val_loss: 10.2308\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1451 - val_loss: 9.9596\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1343 - val_loss: 10.0339\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0676 - val_loss: 10.1315\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0360 - val_loss: 10.2837\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1922 - val_loss: 10.1867\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1172 - val_loss: 10.1869\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1723 - val_loss: 10.0897\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1189 - val_loss: 10.3790\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3388 - val_loss: 10.4064\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3426 - val_loss: 10.1948\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 99us/step - loss: 4.2964 - val_loss: 10.6548\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4882 - val_loss: 10.4320\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2310 - val_loss: 10.1101\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2551 - val_loss: 10.3886\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0900 - val_loss: 10.1500\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2248 - val_loss: 10.2949\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.1160 - val_loss: 10.4158\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0153 - val_loss: 10.7943\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1269 - val_loss: 10.3195\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0517 - val_loss: 10.3871\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0452 - val_loss: 10.4295\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0770 - val_loss: 10.3372\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0660 - val_loss: 10.1436\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1044 - val_loss: 10.3934\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3347 - val_loss: 10.4873\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1291 - val_loss: 10.3697\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0108 - val_loss: 10.0588\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9916 - val_loss: 10.2600\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0538 - val_loss: 10.1526\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9754 - val_loss: 10.4234\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0329 - val_loss: 10.4220\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0108 - val_loss: 10.4533\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0366 - val_loss: 10.2179\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0753 - val_loss: 10.2374\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9880 - val_loss: 10.4267\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0608 - val_loss: 10.6329\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3990 - val_loss: 11.4127\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3338 - val_loss: 10.1635\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3370 - val_loss: 10.1939\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6370 - val_loss: 11.2134\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7718 - val_loss: 11.8904\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6478 - val_loss: 12.2106\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5697 - val_loss: 10.7428\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1425 - val_loss: 10.6246\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2586 - val_loss: 10.4726\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0318 - val_loss: 10.3185\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0596 - val_loss: 10.0726\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0373 - val_loss: 10.1469\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0860 - val_loss: 10.1781\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9836 - val_loss: 10.1323\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9604 - val_loss: 10.3425\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9897 - val_loss: 10.2102\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9650 - val_loss: 10.3751\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9634 - val_loss: 10.3241\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9929 - val_loss: 10.3162\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9943 - val_loss: 10.4435\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.1416 - val_loss: 10.4531\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9509 - val_loss: 10.5226\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1221 - val_loss: 10.5345\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0824 - val_loss: 10.2889\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9948 - val_loss: 10.3571\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0945 - val_loss: 10.2676\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1825 - val_loss: 10.8407\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0917 - val_loss: 10.6735\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1978 - val_loss: 11.2603\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3202 - val_loss: 10.3423\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1536 - val_loss: 10.0977\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0365 - val_loss: 10.3572\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9879 - val_loss: 10.4645\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0194 - val_loss: 10.4718\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2337 - val_loss: 10.7910\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1213 - val_loss: 10.6625\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1096 - val_loss: 10.5862\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3532 - val_loss: 10.4730\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9993 - val_loss: 10.5991\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9901 - val_loss: 10.6371\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0279 - val_loss: 10.4849\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0300 - val_loss: 10.6544\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4201 - val_loss: 10.8405\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0466 - val_loss: 10.4502\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1070 - val_loss: 10.6300\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9159 - val_loss: 10.4339\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9551 - val_loss: 10.4330\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9291 - val_loss: 10.5560\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0283 - val_loss: 10.4961\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9838 - val_loss: 10.5396\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1673 - val_loss: 11.0035\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 100us/step - loss: 3.9596 - val_loss: 10.5487\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9825 - val_loss: 10.4311\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0018 - val_loss: 10.3198\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9364 - val_loss: 10.6699\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1773 - val_loss: 10.5603\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6772 - val_loss: 11.7385\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.3667 - val_loss: 11.1301\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2853 - val_loss: 11.1078\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1061 - val_loss: 10.7172\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9418 - val_loss: 10.5784\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9790 - val_loss: 10.7676\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9818 - val_loss: 10.4599\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9393 - val_loss: 10.3894\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9226 - val_loss: 10.5322\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9198 - val_loss: 10.5248\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0189 - val_loss: 10.6862\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8953 - val_loss: 10.8077\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9362 - val_loss: 10.4966\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0165 - val_loss: 10.8406\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2735 - val_loss: 10.9555\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1101 - val_loss: 11.1575\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0739 - val_loss: 10.8824\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0367 - val_loss: 10.4258\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0383 - val_loss: 10.7064\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9533 - val_loss: 11.0666\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0349 - val_loss: 10.7414\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0025 - val_loss: 10.6242\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2549 - val_loss: 10.9428\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4396 - val_loss: 11.2275\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3888 - val_loss: 10.9897\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0807 - val_loss: 10.7118\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0266 - val_loss: 10.4139\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.9635 - val_loss: 10.8618\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0942 - val_loss: 11.1632\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4837 - val_loss: 12.2813\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4036 - val_loss: 11.1729\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4259 - val_loss: 11.1069\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9818 - val_loss: 10.9410\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9416 - val_loss: 10.9998\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2261 - val_loss: 10.8857\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0288 - val_loss: 11.0515\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1259 - val_loss: 10.7827\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0887 - val_loss: 10.4364\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9927 - val_loss: 11.0486\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0453 - val_loss: 10.6787\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8879 - val_loss: 11.1176\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0621 - val_loss: 11.2748\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0349 - val_loss: 10.9288\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1725 - val_loss: 10.7122\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9961 - val_loss: 11.0995\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0701 - val_loss: 10.8996\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9978 - val_loss: 10.7099\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9777 - val_loss: 10.9768\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9730 - val_loss: 10.6805\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0076 - val_loss: 10.7977\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0327 - val_loss: 10.8663\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9201 - val_loss: 10.9004\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9472 - val_loss: 10.8978\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1159 - val_loss: 10.9969\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0107 - val_loss: 10.8026\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0663 - val_loss: 10.7379\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9127 - val_loss: 10.7895\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9476 - val_loss: 11.1481\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0390 - val_loss: 11.1824\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4416 - val_loss: 11.7428\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2613 - val_loss: 10.3594\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0120 - val_loss: 10.5185\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9844 - val_loss: 10.7452\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9938 - val_loss: 10.9751\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9771 - val_loss: 10.7863\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9998 - val_loss: 11.1428\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2305 - val_loss: 11.1510\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0663 - val_loss: 11.0274\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8981 - val_loss: 10.6941\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8694 - val_loss: 10.7572\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9674 - val_loss: 11.0585\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0242 - val_loss: 10.9637\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.1776 - val_loss: 10.9921\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1452 - val_loss: 10.9293\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.9378 - val_loss: 10.9285\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.9324 - val_loss: 10.8874\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0852 - val_loss: 11.3629\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.8441 - val_loss: 10.9106\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0601 - val_loss: 10.7395\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0264 - val_loss: 10.4928\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 3.8326 - val_loss: 10.7362\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.8438 - val_loss: 10.8763\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8542 - val_loss: 10.7143\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 3.9796 - val_loss: 10.7341\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0350 - val_loss: 10.8836\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 3.9188 - val_loss: 10.7061\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.8864 - val_loss: 10.8449\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9111 - val_loss: 11.0306\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9399 - val_loss: 10.8393\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9412 - val_loss: 10.5683\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8591 - val_loss: 10.7755\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8612 - val_loss: 11.1793\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 3.8733 - val_loss: 10.8688\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8805 - val_loss: 10.6366\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8883 - val_loss: 10.9171\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0726 - val_loss: 10.9825\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.0066 - val_loss: 11.1119\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0499 - val_loss: 11.4635\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0986 - val_loss: 11.4901\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 121us/step - loss: 4.1796 - val_loss: 11.3112\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.1839 - val_loss: 10.9148\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3872 - val_loss: 10.9391\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9924 - val_loss: 11.3057\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.0703 - val_loss: 11.7176\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0673 - val_loss: 11.5369\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0566 - val_loss: 11.0920\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0601 - val_loss: 10.8687\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2772 - val_loss: 11.2108\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0228 - val_loss: 11.3647\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1671 - val_loss: 11.6537\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9492 - val_loss: 11.2898\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0692 - val_loss: 11.2098\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0600 - val_loss: 10.8934\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8371 - val_loss: 11.2533\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8740 - val_loss: 11.1350\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9852 - val_loss: 10.9498\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0345 - val_loss: 10.6699\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9525 - val_loss: 10.9866\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8390 - val_loss: 11.0316\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8476 - val_loss: 11.0164\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9256 - val_loss: 11.0919\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0119 - val_loss: 11.1741\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9592 - val_loss: 11.0930\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8803 - val_loss: 10.5574\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9040 - val_loss: 10.5283\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0296 - val_loss: 10.8846\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2636 - val_loss: 11.2297\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9655 - val_loss: 11.0306\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9359 - val_loss: 10.6573\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9847 - val_loss: 10.6004\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9663 - val_loss: 11.2161\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8988 - val_loss: 11.2077\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1875 - val_loss: 11.3776\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1803 - val_loss: 11.1018\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9742 - val_loss: 11.1480\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0486 - val_loss: 11.0486\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9090 - val_loss: 10.8622\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0797 - val_loss: 10.9756\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1406 - val_loss: 10.8844\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9160 - val_loss: 10.9677\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9107 - val_loss: 11.1196\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7551 - val_loss: 10.9708\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9305 - val_loss: 10.9737\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9990 - val_loss: 10.8650\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8685 - val_loss: 11.1193\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8288 - val_loss: 11.0154\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9169 - val_loss: 11.3447\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0957 - val_loss: 10.9000\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0751 - val_loss: 11.2035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0515 - val_loss: 11.3256\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3801 - val_loss: 11.3889\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1810 - val_loss: 11.5525\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0436 - val_loss: 11.1889\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8888 - val_loss: 11.2211\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8534 - val_loss: 10.9472\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0277 - val_loss: 11.1284\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9411 - val_loss: 11.1117\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8441 - val_loss: 11.1721\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8662 - val_loss: 11.1818\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8374 - val_loss: 10.9285\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8213 - val_loss: 10.9605\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8687 - val_loss: 11.2542\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8146 - val_loss: 11.0198\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9333 - val_loss: 11.2707\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9519 - val_loss: 11.1032\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9020 - val_loss: 11.0426\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8519 - val_loss: 11.1168\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9146 - val_loss: 11.2376\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0075 - val_loss: 11.1848\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9828 - val_loss: 10.8933\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8533 - val_loss: 10.9667\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9178 - val_loss: 11.6892\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9882 - val_loss: 11.1735\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8573 - val_loss: 11.2842\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0673 - val_loss: 11.7840\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9719 - val_loss: 11.4297\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0678 - val_loss: 11.0998\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9392 - val_loss: 10.8520\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8835 - val_loss: 11.3267\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0719 - val_loss: 11.7169\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3137 - val_loss: 12.3627\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4226 - val_loss: 11.8261\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3747 - val_loss: 11.2538\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3320 - val_loss: 11.2834\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1470 - val_loss: 11.2169\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9487 - val_loss: 10.8275\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8540 - val_loss: 11.1512\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8129 - val_loss: 11.3717\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9584 - val_loss: 11.5315\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0666 - val_loss: 11.6998\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9111 - val_loss: 11.2483\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0660 - val_loss: 11.4229\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9134 - val_loss: 11.5727\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9751 - val_loss: 11.3894\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9842 - val_loss: 11.4607\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0605 - val_loss: 11.7761\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9011 - val_loss: 11.1309\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3261 - val_loss: 11.5370\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0263 - val_loss: 12.1341\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1046 - val_loss: 11.5866\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7988 - val_loss: 11.3313\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9444 - val_loss: 11.1344\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.8054 - val_loss: 11.1464\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8912 - val_loss: 11.4734\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9327 - val_loss: 11.3486\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2163 - val_loss: 11.5267\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0455 - val_loss: 11.4110\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8739 - val_loss: 11.0089\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8904 - val_loss: 11.1394\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7719 - val_loss: 11.1899\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7852 - val_loss: 11.3216\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8797 - val_loss: 11.3547\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8903 - val_loss: 11.2380\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9009 - val_loss: 11.3271\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0197 - val_loss: 11.3461\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0206 - val_loss: 11.2418\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8069 - val_loss: 11.1028\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8212 - val_loss: 11.4396\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9010 - val_loss: 11.5465\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8288 - val_loss: 11.5815\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7876 - val_loss: 11.0983\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9317 - val_loss: 11.6887\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9208 - val_loss: 11.3807\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0168 - val_loss: 11.1829\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9583 - val_loss: 11.2265\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8346 - val_loss: 11.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8443 - val_loss: 11.3694\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8624 - val_loss: 11.5985\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8490 - val_loss: 11.4366\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8170 - val_loss: 11.3329\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7863 - val_loss: 11.3269\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8335 - val_loss: 11.4319\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9774 - val_loss: 11.7863\n",
      "7.638522034984524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.3485718 ,  3.437333  , -1.0346681 , -1.11541   , -0.39312732,\n",
       "         -0.4332369 ,  1.2525725 , -2.305369  ,  0.29607502,  1.1767436 ],\n",
       "        [-2.8701944 , -1.1326944 ,  1.3748207 ,  0.8238783 ,  0.25929376,\n",
       "         -0.62357056,  2.1771872 ,  1.0054055 , -2.0650096 ,  1.9648839 ],\n",
       "        [ 0.35068494, -2.829381  , -0.8547602 ,  0.27258775,  2.0103989 ,\n",
       "          0.55739146,  0.11665559, -0.56137866, -1.226192  , -0.8768354 ],\n",
       "        [ 2.9578562 , -1.196214  ,  0.64882755, -0.99563617,  1.0634879 ,\n",
       "          1.1656897 , -0.6445601 , -0.4994563 ,  2.0238454 , -1.9855816 ],\n",
       "        [-1.48828   , -0.2082753 ,  0.38139126, -0.31505525,  0.1825463 ,\n",
       "          0.00885664,  0.5097318 , -0.14638576, -0.12460362,  0.19514143],\n",
       "        [-1.2721285 ,  0.11190529, -0.20485285,  1.4725543 , -3.2043078 ,\n",
       "         -1.7638916 , -2.9814444 ,  1.3098832 ,  1.773347  ,  0.52337813],\n",
       "        [ 0.20947824, -0.7044808 , -0.63588274,  1.6007673 ,  1.722647  ,\n",
       "         -1.0264131 , -0.44186702,  0.6157399 , -1.6883347 , -0.36790484]],\n",
       "       dtype=float32),\n",
       " array([-1.7928839 , -0.34946346, -2.6489387 , -2.7085807 , -1.9592679 ,\n",
       "         2.4896789 , -3.636838  , -1.9293121 , -3.6054022 ,  2.8671076 ],\n",
       "       dtype=float32),\n",
       " array([[-0.0667    , -0.32810333,  0.5470393 , -0.79445887, -0.19878711,\n",
       "         -0.05124215,  0.15830597, -0.8500063 ,  0.15626183, -0.16159973],\n",
       "        [ 0.00328202,  0.05128068,  0.29500526,  0.02284895, -0.12905172,\n",
       "          0.5878156 ,  0.17624529,  0.62511045, -0.526461  , -0.628566  ],\n",
       "        [-0.54165477, -0.865547  , -0.52166235, -0.79120785,  0.5399539 ,\n",
       "         -0.3747064 ,  0.1995626 , -1.0511333 ,  1.1187688 ,  0.39044514],\n",
       "        [-1.4956169 , -0.75524235, -0.47345972, -1.628753  ,  1.0502714 ,\n",
       "         -0.6988928 , -0.72571826, -1.2079921 ,  1.3249004 ,  0.6363848 ],\n",
       "        [ 0.29472712,  0.38729754,  1.0191323 ,  0.27490532, -0.7304267 ,\n",
       "          0.5894938 ,  0.2805529 ,  0.7470119 , -0.9244178 , -1.1693736 ],\n",
       "        [-0.67679936, -0.8537454 , -1.1588688 , -1.1065645 ,  1.4489453 ,\n",
       "         -1.6433363 , -0.85737985, -1.6232597 ,  1.5993615 ,  1.5209233 ],\n",
       "        [-0.48358274, -0.10225753,  0.4922244 , -0.8601    ,  0.69951105,\n",
       "         -0.74563545, -0.03173164, -0.787975  ,  0.5740128 , -0.13069558],\n",
       "        [ 1.085702  ,  0.83317417,  0.33065   ,  1.2169445 , -0.4446378 ,\n",
       "          1.0265621 ,  0.10193486,  0.6889824 , -1.1440878 ,  0.1169877 ],\n",
       "        [-0.65120304, -0.18827365,  0.16528137, -0.5927282 ,  0.48486775,\n",
       "         -0.7929574 , -0.04554199, -0.9219886 ,  0.29724592,  0.197169  ],\n",
       "        [ 1.0215331 ,  0.68977946,  0.0022937 ,  0.15098752, -0.70212144,\n",
       "          0.91337055, -0.72565615,  0.9668969 , -0.8545949 ,  0.6461616 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.3831478,  1.3791628,  1.3202124,  1.4041364, -1.3337815,\n",
       "         1.4108173,  1.1485226,  1.4666204, -1.4665344, -1.3272821],\n",
       "       dtype=float32),\n",
       " array([[ 8.9560360e-01],\n",
       "        [ 6.7779511e-01],\n",
       "        [ 1.1938925e-02],\n",
       "        [ 1.1228292e+00],\n",
       "        [-8.0935705e-01],\n",
       "        [ 8.1635022e-01],\n",
       "        [ 1.0888668e-03],\n",
       "        [ 1.2823679e+00],\n",
       "        [-1.0877315e+00],\n",
       "        [-1.1851584e-02]], dtype=float32),\n",
       " array([1.4513278], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_5(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure5_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 427.6391 - val_loss: 164.3104\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 90.5694 - val_loss: 47.8081\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 43.2862 - val_loss: 27.7094\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 21.6398 - val_loss: 25.1714\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 18.4639 - val_loss: 18.7556\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 12.5254 - val_loss: 16.3490\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 10.8801 - val_loss: 15.1364\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 9.3737 - val_loss: 13.4334\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.8980 - val_loss: 12.5833\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.1714 - val_loss: 13.2593\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.9960 - val_loss: 12.6858\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.4139 - val_loss: 14.1395\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.7560 - val_loss: 12.7224\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.4731 - val_loss: 13.8866\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.7228 - val_loss: 11.8181\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3425 - val_loss: 11.3056\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3840 - val_loss: 11.6315\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6485 - val_loss: 11.1366\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9041 - val_loss: 11.2467\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9260 - val_loss: 10.6161\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6837 - val_loss: 10.6409\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6481 - val_loss: 10.6200\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1714 - val_loss: 10.8719\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.6780 - val_loss: 9.9567\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4437 - val_loss: 10.0601\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5573 - val_loss: 10.2825\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5136 - val_loss: 10.7618\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5232 - val_loss: 10.3116\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.5454 - val_loss: 10.0936\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4719 - val_loss: 10.1995\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4468 - val_loss: 10.8198\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7762 - val_loss: 10.8477\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6979 - val_loss: 11.9587\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9004 - val_loss: 9.9789\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4611 - val_loss: 10.2092\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1431 - val_loss: 10.4096\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3029 - val_loss: 10.4460\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.3407 - val_loss: 10.8795\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4591 - val_loss: 10.5192\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1596 - val_loss: 10.1240\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3703 - val_loss: 11.2271\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6396 - val_loss: 10.0931\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2771 - val_loss: 10.4927\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0534 - val_loss: 10.6646\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3328 - val_loss: 10.3072\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9220 - val_loss: 10.1877\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2406 - val_loss: 10.7542\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1304 - val_loss: 10.4013\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9683 - val_loss: 10.4241\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9576 - val_loss: 10.5164\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1858 - val_loss: 10.2170\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7949 - val_loss: 10.3893\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8070 - val_loss: 10.4153\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8508 - val_loss: 10.5774\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8943 - val_loss: 9.9205\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7849 - val_loss: 10.1402\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8188 - val_loss: 10.3972\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8306 - val_loss: 11.1929\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8945 - val_loss: 10.8129\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2091 - val_loss: 10.8204\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.360 - 0s 97us/step - loss: 5.4761 - val_loss: 10.1933\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0760 - val_loss: 10.1389\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5894 - val_loss: 10.0292\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6286 - val_loss: 10.6961\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7339 - val_loss: 10.2237\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6032 - val_loss: 10.4652\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8621 - val_loss: 10.3502\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8428 - val_loss: 11.2467\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5079 - val_loss: 10.2087\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9300 - val_loss: 10.7586\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6748 - val_loss: 9.8027\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8477 - val_loss: 9.8383\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8625 - val_loss: 10.3587\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3475 - val_loss: 9.7108\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9830 - val_loss: 9.6810\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9924 - val_loss: 10.2441\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5644 - val_loss: 9.9076\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7097 - val_loss: 10.8570\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7757 - val_loss: 9.9092\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7150 - val_loss: 9.4979\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3923 - val_loss: 9.7654\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6181 - val_loss: 9.7933\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4736 - val_loss: 9.8625\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 5.3316 - val_loss: 9.6370\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3680 - val_loss: 9.9508\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3008 - val_loss: 10.0725\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4992 - val_loss: 11.0277\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5875 - val_loss: 10.8366\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2662 - val_loss: 10.0522\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8860 - val_loss: 10.4744\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5466 - val_loss: 9.6509\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3392 - val_loss: 10.2617\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1488 - val_loss: 9.6705\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3163 - val_loss: 10.1363\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5855 - val_loss: 9.8357\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1806 - val_loss: 10.1805\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2267 - val_loss: 9.7038\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4596 - val_loss: 9.3812\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6824 - val_loss: 10.4805\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8123 - val_loss: 9.7654\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4751 - val_loss: 10.2179\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5816 - val_loss: 10.2210\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3484 - val_loss: 9.1721\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1588 - val_loss: 9.0757\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5653 - val_loss: 9.5849\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6954 - val_loss: 10.6036\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6913 - val_loss: 10.0020\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1453 - val_loss: 9.4408\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1519 - val_loss: 9.3411\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1710 - val_loss: 9.3382\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2866 - val_loss: 10.5396\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1558 - val_loss: 10.0282\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 232us/step - loss: 5.1334 - val_loss: 10.5218\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 130us/step - loss: 5.7294 - val_loss: 9.9717\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8219 - val_loss: 11.6784\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.8320 - val_loss: 9.2841\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4912 - val_loss: 9.7801\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1776 - val_loss: 9.9529\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1549 - val_loss: 9.4762\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3311 - val_loss: 9.5472\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0545 - val_loss: 9.4321\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0844 - val_loss: 9.6585\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9541 - val_loss: 9.7336\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3047 - val_loss: 9.5339\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5017 - val_loss: 10.0499\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7424 - val_loss: 11.7314\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5785 - val_loss: 9.1590\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5644 - val_loss: 9.1188\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1513 - val_loss: 10.5983\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9403 - val_loss: 9.9854\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3610 - val_loss: 10.9498\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8949 - val_loss: 9.3536\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2372 - val_loss: 9.7133\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3273 - val_loss: 9.4844\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9378 - val_loss: 10.3227\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3087 - val_loss: 10.3465\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8961 - val_loss: 9.4845\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0777 - val_loss: 10.7483\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5608 - val_loss: 9.8118\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8614 - val_loss: 9.7423\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9751 - val_loss: 9.4240\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9353 - val_loss: 9.5710\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9168 - val_loss: 10.0577\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0942 - val_loss: 9.3835\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8037 - val_loss: 9.9056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0340 - val_loss: 9.1894\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9609 - val_loss: 9.2438\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9536 - val_loss: 10.0652\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9702 - val_loss: 9.6150\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0117 - val_loss: 10.3622\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0213 - val_loss: 9.4448\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2346 - val_loss: 9.5990\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9507 - val_loss: 9.3637\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8615 - val_loss: 9.7265\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0018 - val_loss: 9.3610\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8370 - val_loss: 9.2560\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9097 - val_loss: 9.7455\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9281 - val_loss: 9.3800\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0246 - val_loss: 9.3816\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0350 - val_loss: 11.1459\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2058 - val_loss: 9.6334\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1391 - val_loss: 11.7831\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1326 - val_loss: 11.6013\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3389 - val_loss: 11.8087\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9460 - val_loss: 9.9014\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9598 - val_loss: 10.5305\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1621 - val_loss: 9.8286\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3169 - val_loss: 9.6553\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7471 - val_loss: 9.6259\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9979 - val_loss: 9.5063\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9128 - val_loss: 9.9023\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9599 - val_loss: 9.2910\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1753 - val_loss: 9.5503\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0645 - val_loss: 10.5889\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0608 - val_loss: 10.1141\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0358 - val_loss: 9.8392\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7043 - val_loss: 9.3323\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9705 - val_loss: 9.3723\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0438 - val_loss: 9.9000\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8335 - val_loss: 9.5881\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.8286 - val_loss: 9.1733\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8965 - val_loss: 9.7538\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6912 - val_loss: 9.6760\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7299 - val_loss: 10.1990\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9530 - val_loss: 9.8520\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6576 - val_loss: 9.6678\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8811 - val_loss: 9.5233\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8120 - val_loss: 9.8043\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8169 - val_loss: 11.0834\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9174 - val_loss: 9.8061\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7027 - val_loss: 9.8435\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7417 - val_loss: 9.6701\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6858 - val_loss: 9.9518\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6715 - val_loss: 9.6445\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8362 - val_loss: 9.7002\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1633 - val_loss: 10.1987\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7062 - val_loss: 9.7671\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0183 - val_loss: 9.2858\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9486 - val_loss: 13.4279\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8460 - val_loss: 10.8595\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0713 - val_loss: 10.3365\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6931 - val_loss: 9.4610\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8358 - val_loss: 9.6253\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8873 - val_loss: 9.9215\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7877 - val_loss: 9.8664\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6316 - val_loss: 9.6883\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6859 - val_loss: 10.0434\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6428 - val_loss: 9.4145\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6026 - val_loss: 9.6761\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5983 - val_loss: 9.9075\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6465 - val_loss: 9.4867\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8074 - val_loss: 9.5768\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8909 - val_loss: 11.4057\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2007 - val_loss: 10.2632\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7181 - val_loss: 10.1368\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6360 - val_loss: 9.2552\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6313 - val_loss: 9.9174\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5804 - val_loss: 9.5679\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7074 - val_loss: 9.7669\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5738 - val_loss: 9.6487\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5272 - val_loss: 9.9875\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7010 - val_loss: 9.5441\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9010 - val_loss: 10.7586\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6349 - val_loss: 10.1435\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1221 - val_loss: 11.7277\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9138 - val_loss: 10.3446\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8651 - val_loss: 9.6881\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5445 - val_loss: 9.5150\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6014 - val_loss: 9.4839\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7403 - val_loss: 10.0769\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7178 - val_loss: 9.6021\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7457 - val_loss: 10.1566\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7634 - val_loss: 9.9279\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0955 - val_loss: 9.5070\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5399 - val_loss: 10.0612\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 4.5785 - val_loss: 10.4282\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5438 - val_loss: 9.8041\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8235 - val_loss: 10.3042\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5639 - val_loss: 9.6093\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4456 - val_loss: 10.0629\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6363 - val_loss: 9.9557\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7628 - val_loss: 9.4563\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6487 - val_loss: 9.5462\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5742 - val_loss: 10.1134\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4925 - val_loss: 9.8942\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4841 - val_loss: 9.9813\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4611 - val_loss: 9.8040\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3689 - val_loss: 9.4889\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5384 - val_loss: 9.7647\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5941 - val_loss: 10.2429\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4213 - val_loss: 9.6355\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5057 - val_loss: 10.5848\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7298 - val_loss: 9.9466\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8510 - val_loss: 11.1682\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5132 - val_loss: 9.7032\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7968 - val_loss: 9.3246\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8453 - val_loss: 11.3976\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9261 - val_loss: 10.1053\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4617 - val_loss: 9.7358\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3082 - val_loss: 9.6125\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5737 - val_loss: 11.0300\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5518 - val_loss: 9.7739\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0652 - val_loss: 9.5345\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3779 - val_loss: 10.2965\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5762 - val_loss: 10.0705\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8437 - val_loss: 9.7304\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4720 - val_loss: 9.7665\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4560 - val_loss: 9.6380\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4095 - val_loss: 9.7946\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4733 - val_loss: 10.1572\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5421 - val_loss: 9.8810\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3910 - val_loss: 9.8861\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.3666 - val_loss: 9.7884\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3751 - val_loss: 9.8138\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8799 - val_loss: 11.2666\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5249 - val_loss: 9.5583\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5478 - val_loss: 9.8348\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2926 - val_loss: 9.6745\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3490 - val_loss: 9.8063\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4485 - val_loss: 10.0933\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4489 - val_loss: 9.8218\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6533 - val_loss: 9.9871\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4805 - val_loss: 10.0521\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8530 - val_loss: 9.7532\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9364 - val_loss: 11.9469\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8491 - val_loss: 10.0740\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1897 - val_loss: 10.5856\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6076 - val_loss: 9.7818\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2710 - val_loss: 9.7365\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2831 - val_loss: 9.5799\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3281 - val_loss: 10.2754\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6405 - val_loss: 9.9836\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6330 - val_loss: 10.3313\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4001 - val_loss: 9.7847\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3127 - val_loss: 9.5920\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5547 - val_loss: 9.7517\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5931 - val_loss: 9.6021\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2827 - val_loss: 9.6977\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3484 - val_loss: 10.0460\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.6093 - val_loss: 10.2927\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9127 - val_loss: 9.6568\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9229 - val_loss: 10.1451\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6673 - val_loss: 9.6211\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3005 - val_loss: 10.3397\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3368 - val_loss: 9.7183\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2903 - val_loss: 9.7470\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2156 - val_loss: 10.0457\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1904 - val_loss: 9.8168\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1905 - val_loss: 9.9408\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2524 - val_loss: 9.8280\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2871 - val_loss: 9.4199\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2860 - val_loss: 10.6173\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.9165 - val_loss: 10.7436\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3168 - val_loss: 9.9275\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2151 - val_loss: 10.3999\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3187 - val_loss: 9.8802\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1821 - val_loss: 10.0780\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2973 - val_loss: 9.4897\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3100 - val_loss: 9.8788\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3143 - val_loss: 10.2931\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1997 - val_loss: 9.5932\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2316 - val_loss: 10.2192\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3185 - val_loss: 9.6056\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1552 - val_loss: 12.0318\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5582 - val_loss: 10.2808\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6293 - val_loss: 11.4722\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9815 - val_loss: 10.5307\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5633 - val_loss: 10.2759\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1048 - val_loss: 11.8229\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0108 - val_loss: 10.1796\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4167 - val_loss: 9.6951\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4471 - val_loss: 10.5974\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5067 - val_loss: 9.6214\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4034 - val_loss: 9.8056\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3912 - val_loss: 9.9111\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5792 - val_loss: 11.1586\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3689 - val_loss: 9.7429\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1685 - val_loss: 10.0981\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2027 - val_loss: 9.6279\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1478 - val_loss: 10.0724\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3379 - val_loss: 10.1392\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2284 - val_loss: 10.4791\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4751 - val_loss: 9.6347\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1306 - val_loss: 10.1390\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2900 - val_loss: 9.8942\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6176 - val_loss: 11.1885\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1811 - val_loss: 9.8790\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 145us/step - loss: 4.2079 - val_loss: 9.9582\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.0652 - val_loss: 9.8475\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.2456 - val_loss: 11.1722\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.7301 - val_loss: 9.9710\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4010 - val_loss: 9.5685\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.1342 - val_loss: 9.8110\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1662 - val_loss: 9.9188\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3489 - val_loss: 10.9862\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1712 - val_loss: 9.7517\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.1718 - val_loss: 10.0630\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1482 - val_loss: 9.9419\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.0560 - val_loss: 9.8537\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 4.5787 - val_loss: 9.8797\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.1167 - val_loss: 10.1790\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0970 - val_loss: 9.8856\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.0686 - val_loss: 10.0754\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1301 - val_loss: 9.7254\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.2746 - val_loss: 9.7682\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.1102 - val_loss: 10.5673\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2962 - val_loss: 10.0480\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2421 - val_loss: 9.6485\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1876 - val_loss: 10.2386\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1253 - val_loss: 10.4330\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1068 - val_loss: 10.0673\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.6086 - val_loss: 10.7837\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9008 - val_loss: 10.4553\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.3603 - val_loss: 10.1616\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.3304 - val_loss: 11.0749\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1556 - val_loss: 9.7962\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1462 - val_loss: 9.9789\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 4.3529 - val_loss: 10.5133\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0364 - val_loss: 9.9673\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1681 - val_loss: 9.9321\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9675 - val_loss: 10.1803\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0654 - val_loss: 10.1958\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0953 - val_loss: 9.7782\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2630 - val_loss: 10.5812\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2567 - val_loss: 10.1718\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1634 - val_loss: 10.7998\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0048 - val_loss: 9.6925\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2779 - val_loss: 10.2930\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1885 - val_loss: 12.3224\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9157 - val_loss: 10.1262\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1231 - val_loss: 10.3268\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1518 - val_loss: 10.8924\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3709 - val_loss: 10.0904\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3061 - val_loss: 10.0448\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0759 - val_loss: 10.2685\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0496 - val_loss: 10.6947\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0109 - val_loss: 10.0663\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0081 - val_loss: 10.2003\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 4.0054 - val_loss: 10.4644\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0851 - val_loss: 9.9930\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0571 - val_loss: 10.8330\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2350 - val_loss: 10.1384\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0299 - val_loss: 10.0183\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1615 - val_loss: 11.0584\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2608 - val_loss: 10.2647\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0355 - val_loss: 10.2628\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0237 - val_loss: 10.6498\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9651 - val_loss: 10.1419\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9340 - val_loss: 10.1706\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9067 - val_loss: 10.7072\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9755 - val_loss: 10.2464\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6010 - val_loss: 10.8182\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1430 - val_loss: 10.5649\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0239 - val_loss: 10.1472\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1604 - val_loss: 10.5295\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9933 - val_loss: 10.2966\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0869 - val_loss: 10.6162\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1147 - val_loss: 11.2712\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4187 - val_loss: 10.2798\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0177 - val_loss: 9.8956\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0554 - val_loss: 11.3586\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3829 - val_loss: 10.5874\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2881 - val_loss: 10.1993\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0184 - val_loss: 10.2988\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4901 - val_loss: 12.1426\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3579 - val_loss: 10.5787\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3293 - val_loss: 10.4810\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.2704 - val_loss: 12.3102\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6294 - val_loss: 10.9985\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3817 - val_loss: 10.3847\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9162 - val_loss: 10.6100\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4008 - val_loss: 12.6799\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3329 - val_loss: 10.7533\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2645 - val_loss: 10.0751\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9530 - val_loss: 11.2046\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3330 - val_loss: 10.9099\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1424 - val_loss: 10.7468\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0768 - val_loss: 10.4582\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9695 - val_loss: 10.7009\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2571 - val_loss: 11.7462\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2460 - val_loss: 9.9580\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0826 - val_loss: 10.6809\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0914 - val_loss: 10.4574\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1036 - val_loss: 10.3723\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0144 - val_loss: 10.5630\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9070 - val_loss: 10.4737\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9431 - val_loss: 10.6330\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9693 - val_loss: 10.5182\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9860 - val_loss: 11.5297\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2131 - val_loss: 10.3738\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0030 - val_loss: 10.3741\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8304 - val_loss: 10.4943\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9250 - val_loss: 11.1143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8758 - val_loss: 10.2558\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1210 - val_loss: 10.3487\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0374 - val_loss: 10.9622\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3973 - val_loss: 9.8555\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0488 - val_loss: 10.4038\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1209 - val_loss: 11.2876\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9448 - val_loss: 10.8651\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4078 - val_loss: 12.8986\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4373 - val_loss: 10.6714\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9911 - val_loss: 10.4940\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9087 - val_loss: 10.2541\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8522 - val_loss: 10.3249\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9176 - val_loss: 10.4802\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9559 - val_loss: 11.6058\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0346 - val_loss: 10.2538\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7316 - val_loss: 12.3020\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8839 - val_loss: 10.7733\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3568 - val_loss: 11.3924\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1967 - val_loss: 10.5540\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1313 - val_loss: 10.5050\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2656 - val_loss: 10.8937\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9519 - val_loss: 10.8009\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9399 - val_loss: 10.2157\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9533 - val_loss: 10.5792\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8980 - val_loss: 10.5437\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1368 - val_loss: 11.9587\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2720 - val_loss: 10.6074\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0370 - val_loss: 10.2530\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7593 - val_loss: 10.1508\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2880 - val_loss: 11.8075\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2907 - val_loss: 10.9438\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4027 - val_loss: 10.4494\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9625 - val_loss: 10.9008\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7988 - val_loss: 10.2353\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9388 - val_loss: 11.2613\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8830 - val_loss: 10.5293\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9100 - val_loss: 10.3205\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9378 - val_loss: 10.6877\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9348 - val_loss: 10.8019\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.2210 - val_loss: 10.3408\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9813 - val_loss: 11.0586\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8998 - val_loss: 10.4606\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8206 - val_loss: 11.4497\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0410 - val_loss: 10.1431\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9856 - val_loss: 10.7906\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1228 - val_loss: 10.8729\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1479 - val_loss: 10.8478\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 3.9412 - val_loss: 10.8644\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9221 - val_loss: 10.9691\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0568 - val_loss: 10.3335\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9775 - val_loss: 11.2910\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8679 - val_loss: 10.4791\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8553 - val_loss: 10.9972\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9734 - val_loss: 11.6646\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0088 - val_loss: 11.4188\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3781 - val_loss: 11.4702\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9678 - val_loss: 10.6159\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8768 - val_loss: 10.4003\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8882 - val_loss: 10.9925\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8351 - val_loss: 10.7903\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8408 - val_loss: 10.8700\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8151 - val_loss: 10.4736\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8246 - val_loss: 10.9177\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0202 - val_loss: 11.2291\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4146 - val_loss: 10.8691\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.1534 - val_loss: 10.7016\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7888 - val_loss: 11.6596\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.0523 - val_loss: 10.9495\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0731 - val_loss: 10.7088\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8574 - val_loss: 11.0842\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0463 - val_loss: 10.9162\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1711 - val_loss: 11.4830\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0188 - val_loss: 10.8494\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8368 - val_loss: 10.6836\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7936 - val_loss: 10.2174\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.7878 - val_loss: 10.8253\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8799 - val_loss: 11.8355\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7752 - val_loss: 10.4420\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 152us/step - loss: 3.7395 - val_loss: 10.9934\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.7667 - val_loss: 10.7201\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0862 - val_loss: 12.0594\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8926 - val_loss: 10.7922\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1124 - val_loss: 11.7035\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1567 - val_loss: 11.2899\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7057 - val_loss: 11.5192\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1421 - val_loss: 12.4898\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9591 - val_loss: 10.4008\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0330 - val_loss: 11.0019\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.0554 - val_loss: 12.0551\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.1314 - val_loss: 10.3648\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.0123 - val_loss: 10.7337\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0046 - val_loss: 10.8394\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7370 - val_loss: 11.4543\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 130us/step - loss: 3.9159 - val_loss: 10.9840\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.8560 - val_loss: 10.8799\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 3.7853 - val_loss: 11.1218\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7190 - val_loss: 10.4926\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7185 - val_loss: 10.9717\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7143 - val_loss: 10.6125\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8725 - val_loss: 11.3326\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.8580 - val_loss: 10.5824\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.8015 - val_loss: 10.6574\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 3.7996 - val_loss: 10.7274\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 137us/step - loss: 3.7615 - val_loss: 11.0311\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8328 - val_loss: 10.9677\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8005 - val_loss: 10.7372\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7914 - val_loss: 10.9784\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8621 - val_loss: 10.7493\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.8223 - val_loss: 11.5248\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.7370 - val_loss: 10.4147\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.7801 - val_loss: 11.2418\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 3.7365 - val_loss: 10.7481\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 3.8080 - val_loss: 10.6690\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.8218 - val_loss: 11.3229\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7699 - val_loss: 11.4051\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2677 - val_loss: 11.6981\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7162 - val_loss: 10.4712\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6802 - val_loss: 10.7007\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0115 - val_loss: 13.1427\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7517 - val_loss: 10.8066\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1335 - val_loss: 10.6547\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.1040 - val_loss: 11.2404\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8754 - val_loss: 11.2323\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8201 - val_loss: 10.9723\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7683 - val_loss: 11.1532\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7566 - val_loss: 10.4362\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.6668 - val_loss: 13.4361\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8788 - val_loss: 11.6768\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6423 - val_loss: 11.2135\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9637 - val_loss: 10.7355\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9268 - val_loss: 12.6032\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9057 - val_loss: 10.4773\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9707 - val_loss: 10.8322\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7077 - val_loss: 10.8746\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7440 - val_loss: 11.0367\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7515 - val_loss: 10.8645\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7352 - val_loss: 10.5060\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9519 - val_loss: 11.5901\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6763 - val_loss: 10.4089\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7942 - val_loss: 11.2424\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8230 - val_loss: 11.5378\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9868 - val_loss: 10.6837\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7720 - val_loss: 11.5631\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6958 - val_loss: 11.1076\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6858 - val_loss: 10.7877\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6595 - val_loss: 11.0767\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.7522 - val_loss: 11.7587\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0767 - val_loss: 10.7573\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7109 - val_loss: 11.8467\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8048 - val_loss: 10.8756\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7410 - val_loss: 12.4045\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0083 - val_loss: 10.9995\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7898 - val_loss: 10.9678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1432 - val_loss: 12.3640\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0119 - val_loss: 10.6758\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.6846 - val_loss: 10.9994\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8513 - val_loss: 11.5600\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0204 - val_loss: 11.9968\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2423 - val_loss: 10.6691\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1389 - val_loss: 10.6382\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7621 - val_loss: 11.7662\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7341 - val_loss: 10.6983\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2075 - val_loss: 11.0039\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8590 - val_loss: 11.9893\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8718 - val_loss: 11.3898\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7818 - val_loss: 10.6230\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6817 - val_loss: 10.5036\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6551 - val_loss: 10.7005\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8222 - val_loss: 10.9323\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7622 - val_loss: 11.2433\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8835 - val_loss: 10.5942\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.7143 - val_loss: 11.1032\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7737 - val_loss: 10.9720\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6361 - val_loss: 11.5851\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7662 - val_loss: 11.0552\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8003 - val_loss: 10.6213\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5982 - val_loss: 11.0689\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6372 - val_loss: 10.7709\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7164 - val_loss: 10.6666\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6693 - val_loss: 11.3536\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9342 - val_loss: 10.6990\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9570 - val_loss: 11.0421\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5712 - val_loss: 11.2639\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0635 - val_loss: 11.1803\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6534 - val_loss: 10.8849\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6461 - val_loss: 11.2232\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6210 - val_loss: 11.2930\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6184 - val_loss: 11.2978\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7509 - val_loss: 10.6723\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8771 - val_loss: 11.4804\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7338 - val_loss: 11.0563\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7106 - val_loss: 10.7556\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6397 - val_loss: 10.9869\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7173 - val_loss: 11.5297\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7055 - val_loss: 10.9330\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7720 - val_loss: 10.5328\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9888 - val_loss: 12.3654\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8159 - val_loss: 11.1243\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7420 - val_loss: 11.3337\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6464 - val_loss: 10.6120\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5816 - val_loss: 11.9223\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7003 - val_loss: 10.7960\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8018 - val_loss: 11.6224\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6636 - val_loss: 10.8684\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.7981 - val_loss: 11.1262\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6985 - val_loss: 12.0251\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7252 - val_loss: 10.7191\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6461 - val_loss: 11.4735\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6921 - val_loss: 11.3468\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7502 - val_loss: 11.0600\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7601 - val_loss: 11.5397\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8043 - val_loss: 10.5680\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6575 - val_loss: 11.7852\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7541 - val_loss: 11.5307\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7578 - val_loss: 11.6310\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7829 - val_loss: 10.6096\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.5830 - val_loss: 11.0443\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7408 - val_loss: 11.6540\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6333 - val_loss: 10.5073\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7403 - val_loss: 11.3841\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6375 - val_loss: 10.7660\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7476 - val_loss: 11.8654\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.5506 - val_loss: 10.8255\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8349 - val_loss: 11.3791\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5952 - val_loss: 11.4316\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6851 - val_loss: 11.5607\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5430 - val_loss: 10.9987\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6637 - val_loss: 11.0555\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6886 - val_loss: 11.4162\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6591 - val_loss: 11.0381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9320 - val_loss: 10.8083\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8308 - val_loss: 13.4431\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4885 - val_loss: 10.8176\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1774 - val_loss: 11.0359\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8579 - val_loss: 10.9697\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7351 - val_loss: 11.1712\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6363 - val_loss: 11.6623\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7531 - val_loss: 11.2172\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8164 - val_loss: 10.8230\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7011 - val_loss: 11.1349\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6186 - val_loss: 11.1930\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6951 - val_loss: 11.3513\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7732 - val_loss: 11.7035\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7153 - val_loss: 11.5704\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8419 - val_loss: 10.9819\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9709 - val_loss: 11.1226\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8621 - val_loss: 13.1009\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0555 - val_loss: 11.2103\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6210 - val_loss: 10.6755\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6532 - val_loss: 12.9787\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0160 - val_loss: 10.7673\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2382 - val_loss: 11.1323\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8966 - val_loss: 11.4788\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5094 - val_loss: 10.8866\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9660 - val_loss: 10.8865\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2885 - val_loss: 14.8381\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2557 - val_loss: 11.5372\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8455 - val_loss: 12.9462\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0821 - val_loss: 11.2554\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9185 - val_loss: 10.9302\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9520 - val_loss: 11.2161\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7395 - val_loss: 11.9137\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8776 - val_loss: 12.5739\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2825 - val_loss: 11.2297\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9837 - val_loss: 10.8676\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6744 - val_loss: 11.3222\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6664 - val_loss: 11.1443\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7508 - val_loss: 11.2608\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.5567 - val_loss: 11.3610\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6139 - val_loss: 11.0861\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.5403 - val_loss: 11.2746\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5961 - val_loss: 11.1625\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6066 - val_loss: 10.7190\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8825 - val_loss: 11.0021\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7542 - val_loss: 10.9052\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6890 - val_loss: 11.5540\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7281 - val_loss: 10.9962\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7603 - val_loss: 11.1945\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6109 - val_loss: 11.7608\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.912 - 0s 97us/step - loss: 3.7120 - val_loss: 11.4328\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7033 - val_loss: 10.7790\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9139 - val_loss: 13.7301\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0092 - val_loss: 10.7645\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.7287 - val_loss: 10.7715\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8339 - val_loss: 11.3938\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6500 - val_loss: 11.4311\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.5699 - val_loss: 11.2956\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6301 - val_loss: 10.8743\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5940 - val_loss: 11.9973\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.6633 - val_loss: 11.0827\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5993 - val_loss: 11.7145\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5430 - val_loss: 10.7891\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.5484 - val_loss: 11.2865\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.5413 - val_loss: 11.8617\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9699 - val_loss: 11.2261\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9096 - val_loss: 11.4487\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7954 - val_loss: 12.0560\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7769 - val_loss: 11.0470\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6261 - val_loss: 11.4304\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6576 - val_loss: 10.7425\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.6213 - val_loss: 11.4644\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6553 - val_loss: 11.2260\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5932 - val_loss: 11.2831\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.8788 - val_loss: 12.7353\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7889 - val_loss: 11.0641\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6410 - val_loss: 11.0980\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6865 - val_loss: 11.6716\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7965 - val_loss: 11.2237\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5826 - val_loss: 11.1670\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7368 - val_loss: 12.4268\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0424 - val_loss: 11.2745\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7211 - val_loss: 11.6840\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.5770 - val_loss: 11.3440\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6256 - val_loss: 11.9769\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7855 - val_loss: 11.6286\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5386 - val_loss: 11.2617\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5333 - val_loss: 11.2090\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6648 - val_loss: 11.2699\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.7330 - val_loss: 10.8138\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5864 - val_loss: 11.0492\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5136 - val_loss: 11.7667\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6897 - val_loss: 11.9628\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6860 - val_loss: 11.0594\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5596 - val_loss: 11.0965\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6293 - val_loss: 11.5889\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5751 - val_loss: 11.0577\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5767 - val_loss: 12.3493\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7907 - val_loss: 10.8682\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0112 - val_loss: 10.9221\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6642 - val_loss: 12.1356\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8351 - val_loss: 11.8732\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0461 - val_loss: 11.0966\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0674 - val_loss: 13.7425\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0323 - val_loss: 11.2983\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7680 - val_loss: 11.6911\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6398 - val_loss: 11.6030\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5508 - val_loss: 11.5100\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6599 - val_loss: 10.6488\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5624 - val_loss: 12.1248\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6230 - val_loss: 11.2943\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8466 - val_loss: 11.4631\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9213 - val_loss: 12.9146\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6630 - val_loss: 11.0224\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5763 - val_loss: 10.8462\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.6206 - val_loss: 12.0117\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7759 - val_loss: 11.0867\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.4834 - val_loss: 11.6352\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5478 - val_loss: 10.7070\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5715 - val_loss: 11.6888\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6256 - val_loss: 11.9525\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5908 - val_loss: 10.8454\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 121us/step - loss: 3.7062 - val_loss: 11.6496\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7201 - val_loss: 12.2828\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5573 - val_loss: 10.6251\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5704 - val_loss: 11.6854\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.8722 - val_loss: 10.6080\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6733 - val_loss: 11.2918\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4804 - val_loss: 10.9290\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6222 - val_loss: 11.9170\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6373 - val_loss: 11.1729\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5916 - val_loss: 11.8743\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6245 - val_loss: 10.7565\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6032 - val_loss: 11.3389\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6163 - val_loss: 11.4855\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6255 - val_loss: 10.5558\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6419 - val_loss: 11.7046\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5457 - val_loss: 11.1098\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8272 - val_loss: 12.8829\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8897 - val_loss: 11.5448\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7136 - val_loss: 10.5100\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6146 - val_loss: 11.1287\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.4955 - val_loss: 12.0390\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7270 - val_loss: 11.4477\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5222 - val_loss: 11.1644\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.5296 - val_loss: 11.4462\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6183 - val_loss: 10.6189\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8475 - val_loss: 11.3526\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8785 - val_loss: 12.8151\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4731 - val_loss: 11.2170\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6680 - val_loss: 11.1864\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6089 - val_loss: 11.4488\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5565 - val_loss: 11.2506\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1774 - val_loss: 14.2120\n",
      "Epoch 837/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.1515 - val_loss: 10.4842\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8572 - val_loss: 11.2537\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7744 - val_loss: 12.8360\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9729 - val_loss: 10.9312\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5291 - val_loss: 11.5649\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5626 - val_loss: 11.0101\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 3.6645 - val_loss: 11.3338\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6323 - val_loss: 11.2983\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5609 - val_loss: 11.8530\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8363 - val_loss: 11.3832\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5662 - val_loss: 10.9571\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6226 - val_loss: 13.1665\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3131 - val_loss: 10.7223\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8920 - val_loss: 11.0984\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5959 - val_loss: 11.6220\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5044 - val_loss: 10.7498\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6531 - val_loss: 10.7669\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6685 - val_loss: 11.4649\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7334 - val_loss: 11.7666\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5012 - val_loss: 11.0193\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5343 - val_loss: 11.2779\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7654 - val_loss: 12.8982\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4578 - val_loss: 10.8086\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.5473 - val_loss: 11.3046\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.4599 - val_loss: 10.9014\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.6401 - val_loss: 11.2367\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.4625 - val_loss: 11.2483\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7009 - val_loss: 10.8818\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5029 - val_loss: 11.1645\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.4902 - val_loss: 11.2708\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8038 - val_loss: 10.8627\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5828 - val_loss: 14.6870\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5275 - val_loss: 11.1065\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9243 - val_loss: 11.4880\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7593 - val_loss: 12.4637\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9020 - val_loss: 10.7262\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1132 - val_loss: 12.1710\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6615 - val_loss: 10.9232\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6891 - val_loss: 10.7218\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5977 - val_loss: 11.5663\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5915 - val_loss: 11.7022\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6944 - val_loss: 11.0982\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8132 - val_loss: 13.2726\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7076 - val_loss: 11.0908\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.7831 - val_loss: 11.8708\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8260 - val_loss: 11.1398\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1770 - val_loss: 11.0724\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0519 - val_loss: 11.8907\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5415 - val_loss: 11.2436\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5113 - val_loss: 11.0007\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7015 - val_loss: 11.1400\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8162 - val_loss: 12.0841\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7537 - val_loss: 10.9300\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.5846 - val_loss: 11.7210\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6105 - val_loss: 11.3302\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6859 - val_loss: 12.0105\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9855 - val_loss: 12.3599\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9205 - val_loss: 10.7667\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7491 - val_loss: 11.0742\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6596 - val_loss: 11.4683\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.5504 - val_loss: 11.3729\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8669 - val_loss: 10.9751\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1018 - val_loss: 13.7854\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2276 - val_loss: 11.3101\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9685 - val_loss: 12.7593\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.6749 - val_loss: 10.5969\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.6036 - val_loss: 11.8716\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 3.6761 - val_loss: 11.6528\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 3.6415 - val_loss: 10.9879\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.4747 - val_loss: 11.6918\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.6728 - val_loss: 11.2134\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6525 - val_loss: 11.9872\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5432 - val_loss: 10.7590\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6602 - val_loss: 11.8049\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.6453 - val_loss: 10.5357\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 3.7011 - val_loss: 13.3453\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0982 - val_loss: 10.9425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.5228 - val_loss: 11.6186\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7746 - val_loss: 11.1980\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9242 - val_loss: 10.6387\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8344 - val_loss: 14.0475\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0842 - val_loss: 10.9821\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6502 - val_loss: 11.0763\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5723 - val_loss: 11.1523\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5980 - val_loss: 12.3213\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5960 - val_loss: 10.6400\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5794 - val_loss: 13.0282\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6944 - val_loss: 11.0331\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6508 - val_loss: 11.5370\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5218 - val_loss: 11.1809\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5480 - val_loss: 11.0621\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.5477 - val_loss: 11.3317\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.8293 - val_loss: 10.9446\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7086 - val_loss: 12.0502\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.5935 - val_loss: 10.8474\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8113 - val_loss: 11.0010\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8920 - val_loss: 10.8979\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5702 - val_loss: 11.0750\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.5192 - val_loss: 11.1944\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5372 - val_loss: 11.4237\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.4626 - val_loss: 11.7186\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5673 - val_loss: 10.5317\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6012 - val_loss: 11.6874\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.4534 - val_loss: 11.0936\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8012 - val_loss: 12.5060\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8163 - val_loss: 10.5498\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9706 - val_loss: 10.8914\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6239 - val_loss: 11.0929\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.5469 - val_loss: 11.0925\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6092 - val_loss: 11.7265\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6620 - val_loss: 10.7838\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7129 - val_loss: 11.8127\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8326 - val_loss: 11.7472\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8284 - val_loss: 10.8309\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7001 - val_loss: 11.4061\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9817 - val_loss: 12.2615\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7514 - val_loss: 10.6908\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7949 - val_loss: 10.9406\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.3582 - val_loss: 12.0772\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7561 - val_loss: 10.7188\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8650 - val_loss: 11.2543\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7417 - val_loss: 11.3853\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7611 - val_loss: 12.1948\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5329 - val_loss: 10.8014\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8229 - val_loss: 12.4617\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8900 - val_loss: 11.3256\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5429 - val_loss: 10.8056\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.5513 - val_loss: 11.3574\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4803 - val_loss: 10.9866\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6801 - val_loss: 11.4306\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5417 - val_loss: 11.1023\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6110 - val_loss: 10.9187\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4804 - val_loss: 11.4222\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5021 - val_loss: 11.0833\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4569 - val_loss: 11.0730\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5065 - val_loss: 11.4839\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5109 - val_loss: 11.2343\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.5195 - val_loss: 11.3227\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.4473 - val_loss: 11.9411\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9407 - val_loss: 10.5782\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9611 - val_loss: 10.4766\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.5461 - val_loss: 11.9602\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7328 - val_loss: 11.0333\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.8651 - val_loss: 11.4555\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5375 - val_loss: 10.3684\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5067 - val_loss: 11.5984\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.6173 - val_loss: 11.4059\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7073 - val_loss: 10.3658\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7115 - val_loss: 12.3577\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8591 - val_loss: 11.5882\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.5210 - val_loss: 10.7636\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5998 - val_loss: 11.2773\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6000 - val_loss: 10.7764\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6921 - val_loss: 13.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2650 - val_loss: 11.2564\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1977 - val_loss: 12.5269\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4979 - val_loss: 10.8023\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1876 - val_loss: 10.3173\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8070 - val_loss: 11.1629\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.4901 - val_loss: 11.1088\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5817 - val_loss: 10.6880\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7846 - val_loss: 11.0440\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5008 - val_loss: 10.8611\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5810 - val_loss: 10.5445\n",
      "10.415479821673895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.1809119 ,  0.05248419, -0.4461234 , -0.48930568, -1.6214685 ,\n",
       "          1.8095565 ,  1.7396572 , -5.5524507 , -0.23961815,  0.2033678 ],\n",
       "        [-0.8258639 ,  1.1540966 ,  0.55125743, -0.83661705,  0.14821894,\n",
       "         -1.2706293 ,  1.3272252 ,  1.2854592 , -1.9795737 ,  2.422064  ],\n",
       "        [ 0.6645644 ,  0.28592727, -0.6108597 ,  0.80949426,  0.27631927,\n",
       "          0.5237329 , -0.43020216, -4.579145  , -2.84042   ,  1.2264276 ],\n",
       "        [ 1.6136824 , -1.1411405 , -0.7480782 ,  0.6712501 ,  0.7271336 ,\n",
       "          0.12609679, -1.7450751 , -1.4833832 ,  0.50500077, -1.4211518 ],\n",
       "        [-0.8509135 ,  0.84900045,  0.13964376,  0.8328872 ,  0.07463697,\n",
       "         -0.13533783,  0.28014556,  0.6807951 , -0.29070285,  0.58345723],\n",
       "        [-1.5723346 , -0.42963967,  1.6803507 ,  0.50648135, -0.32829776,\n",
       "         -0.5607675 , -2.9704347 , -0.33758435, -0.22591737,  0.8456348 ],\n",
       "        [-0.8142687 , -1.2406414 ,  0.12384932, -2.5659118 ,  0.4395675 ,\n",
       "          0.7164058 , -1.9186012 , -0.7447423 ,  2.442979  , -0.30387682]],\n",
       "       dtype=float32),\n",
       " array([-1.6393754 ,  0.33294594, -2.0561907 , -2.041324  , -1.8350377 ,\n",
       "        -0.09779418, -2.668892  , -1.5559926 ,  1.1289778 , -0.18773952],\n",
       "       dtype=float32),\n",
       " array([[ 0.9074361 ,  0.4050903 , -0.5748892 , -0.58655757, -0.8944321 ,\n",
       "         -0.05975629,  0.13306049, -1.021638  , -0.2919678 , -0.96848756,\n",
       "          0.24796788, -0.38242945, -0.8602867 , -0.14730956, -0.8907028 ],\n",
       "        [-0.7822537 , -0.47670457,  0.24753135,  0.6231862 ,  0.950184  ,\n",
       "          0.23225883, -0.6460228 ,  0.00565613,  0.2246867 ,  0.23225531,\n",
       "         -0.4623871 ,  0.1621854 ,  0.4083618 , -0.1942853 ,  0.509567  ],\n",
       "        [-0.6275865 , -0.10396803,  0.6534913 ,  0.60149306,  0.8503087 ,\n",
       "          0.38084126, -0.8781163 ,  0.41411272,  0.96722096,  1.0805793 ,\n",
       "         -0.49027073,  0.83086187,  0.75173175, -0.32088453,  0.64309305],\n",
       "        [ 0.44659242, -0.01677688,  0.00469145, -0.7622278 , -0.44122425,\n",
       "         -0.05300905,  0.03286337, -0.71212095, -0.385471  , -0.2304203 ,\n",
       "         -0.09268339, -0.61981404, -0.6061955 , -0.0814525 ,  0.04991111],\n",
       "        [ 0.34784365,  0.19465823,  0.12520893, -0.92097723, -0.7998019 ,\n",
       "         -0.24600627,  0.87021923, -0.94216496, -0.6414635 , -0.88227665,\n",
       "          0.46892428, -0.33895278, -1.2497962 , -0.24239583, -1.0106428 ],\n",
       "        [-0.71832997, -0.16249393,  0.12774491,  0.7777369 ,  0.5358773 ,\n",
       "          0.69550496, -0.4579367 ,  0.5118035 ,  0.7765033 ,  0.5094016 ,\n",
       "         -0.28186798,  0.9331177 ,  0.38522732,  0.07438587,  1.0119207 ],\n",
       "        [ 0.34150583,  0.11185578,  0.4692039 , -0.3186318 , -0.16794321,\n",
       "         -0.2295564 ,  0.58241457, -0.75513667, -0.44991723,  0.12188659,\n",
       "         -0.51800674, -0.31218106, -0.27854902, -0.20280562, -0.693959  ],\n",
       "        [-0.3949074 , -0.09728982,  0.19339234,  0.52233636,  1.0565063 ,\n",
       "         -0.00357922, -0.9825155 ,  0.2010831 ,  0.5280978 ,  0.64987046,\n",
       "         -0.5880282 ,  0.38380253,  0.5170219 , -0.07929392,  0.31853732],\n",
       "        [ 1.3012305 ,  0.49722332, -1.4715675 , -0.8452346 , -0.8885424 ,\n",
       "         -0.7150143 ,  0.424647  , -1.042119  , -1.0088224 , -0.90739125,\n",
       "          0.7065312 , -0.9020907 , -0.90603465,  0.5683656 , -1.1667258 ],\n",
       "        [ 1.2408159 ,  0.1891005 , -0.679179  , -0.9101362 , -0.8946671 ,\n",
       "         -0.8454793 ,  0.59696084, -0.3990371 , -0.9239548 , -0.94803524,\n",
       "          0.37241438, -0.9428806 , -0.6725664 ,  0.7188039 , -0.91992366]],\n",
       "       dtype=float32),\n",
       " array([-1.3876425 ,  0.2676916 ,  0.9612524 ,  1.3722656 ,  1.4088937 ,\n",
       "         1.0847526 , -1.3568829 ,  1.3901552 ,  1.3889753 ,  1.4075798 ,\n",
       "        -1.0417621 ,  1.2647961 ,  1.4138077 , -0.45492864,  1.3978235 ],\n",
       "       dtype=float32),\n",
       " array([[-0.92169774],\n",
       "        [-0.01232267],\n",
       "        [ 0.05810685],\n",
       "        [ 0.78051865],\n",
       "        [ 1.1567321 ],\n",
       "        [ 0.18273981],\n",
       "        [-0.8180923 ],\n",
       "        [ 0.97678363],\n",
       "        [ 0.8065165 ],\n",
       "        [ 0.946462  ],\n",
       "        [-0.17399578],\n",
       "        [ 0.47348925],\n",
       "        [ 1.1071335 ],\n",
       "        [-0.00336278],\n",
       "        [ 0.96521693]], dtype=float32),\n",
       " array([1.496985], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_6(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure6_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.6855 - val_loss: 0.0506\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.1256 - val_loss: 0.0778\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0642 - val_loss: 0.0955\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0826 - val_loss: 0.0293\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0318 - val_loss: 0.0295\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0449 - val_loss: 0.0172\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0244 - val_loss: 0.0202\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0190\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0206 - val_loss: 0.0100\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0177 - val_loss: 0.0104\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0161 - val_loss: 0.0087\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0152 - val_loss: 0.0086\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0145 - val_loss: 0.0093\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0141 - val_loss: 0.0083\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0131 - val_loss: 0.0084\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0109 - val_loss: 0.0085\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 117us/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 116us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 133us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0083\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "0.011725426651537418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.0138961 , -0.23617822,  0.6278258 ,  0.22500198,  0.46470216],\n",
       "        [-0.59554577,  0.3107354 , -0.7839685 ,  0.1192729 ,  0.6189596 ],\n",
       "        [-0.44013596,  0.31653598, -0.85171247,  0.01691079, -0.2820443 ],\n",
       "        [-0.5190926 , -0.02201221, -0.11430769,  0.37365848,  1.2335027 ],\n",
       "        [-0.22187409,  0.03705249, -0.34099478, -0.02803409, -0.09494247],\n",
       "        [-0.7632476 , -0.02111059,  0.5061534 ,  0.14301753,  0.45890406],\n",
       "        [-0.3176996 , -0.1022935 , -0.3648605 , -0.7576992 , -0.15210307],\n",
       "        [-0.1030855 ,  0.01438237,  0.05054303,  0.33922064,  0.20812123],\n",
       "        [-0.5256499 ,  0.18947607,  0.33318004, -0.11476175, -0.3557342 ],\n",
       "        [-0.9234985 , -0.4002752 ,  0.13668562, -0.50796765,  0.48396426],\n",
       "        [-0.45526153,  0.16595559, -0.38524875, -0.93099993, -0.06124977],\n",
       "        [-0.25857064,  0.29217872, -0.42656755,  0.17636001,  0.47156373],\n",
       "        [-0.71443075,  0.14756984, -0.33939964, -0.05902457,  0.13912672],\n",
       "        [-0.77061903,  1.0129212 ,  2.2035487 ,  0.08198307,  0.12836596],\n",
       "        [-0.4835968 ,  0.08205664,  0.09755014, -0.04068154, -0.05605176],\n",
       "        [-0.21269174, -0.36111277,  0.20279782, -0.21542427, -0.02448533],\n",
       "        [-0.34772426, -0.37081832, -0.4555372 ,  0.28066334,  0.74312973],\n",
       "        [-0.0983966 ,  0.32751384,  0.3593361 ,  0.01133342,  0.34229472],\n",
       "        [-0.7146934 ,  0.25503427, -0.519357  , -1.032146  , -1.4158094 ],\n",
       "        [-0.37978002,  0.12283815,  1.2247708 , -0.02094229, -0.17148535],\n",
       "        [-0.34882125, -0.30636644, -2.5138037 ,  0.31431222,  0.42386577],\n",
       "        [-0.5086598 ,  0.4353968 , -0.7281891 , -0.42425886,  0.12103619]],\n",
       "       dtype=float32),\n",
       " array([-0.5808581 ,  0.0231861 , -0.64163727, -0.01680216,  0.07815159],\n",
       "       dtype=float32),\n",
       " array([[ 0.3061449 ,  0.13853917,  0.44775313,  0.13269883,  0.06676134],\n",
       "        [ 0.0495161 , -0.04740262, -0.00546479,  0.9590199 , -0.3809424 ],\n",
       "        [ 0.6181028 ,  0.37643132, -0.5398054 ,  0.76935506, -0.7868742 ],\n",
       "        [-0.47359547, -0.53982055, -0.22948997,  0.08835634,  0.15089339],\n",
       "        [ 0.6762919 ,  0.43621802, -0.36553833,  0.4599372 , -0.14508311]],\n",
       "       dtype=float32),\n",
       " array([ 0.0419329 , -0.14865471,  0.13328701,  0.06011446, -0.18475768],\n",
       "       dtype=float32),\n",
       " array([[ 0.3593782 ],\n",
       "        [ 0.11856681],\n",
       "        [-0.1164479 ],\n",
       "        [ 0.21360834],\n",
       "        [-0.28504   ]], dtype=float32),\n",
       " array([0.21878944], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_1(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure1_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1913 - val_loss: 0.0462\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.1555 - val_loss: 0.1547\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1012 - val_loss: 0.0202\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0579 - val_loss: 0.0261\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0381 - val_loss: 0.0179\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0274 - val_loss: 0.0245\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0270 - val_loss: 0.0115\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0209 - val_loss: 0.0097\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0205 - val_loss: 0.0082\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0185 - val_loss: 0.0083\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0174 - val_loss: 0.0074\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0162 - val_loss: 0.0070\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0156 - val_loss: 0.0066\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0150 - val_loss: 0.0064\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0146 - val_loss: 0.0061\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0141 - val_loss: 0.0061\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0138 - val_loss: 0.0060\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0138 - val_loss: 0.0058\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0132 - val_loss: 0.0059\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0130 - val_loss: 0.0057\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0127 - val_loss: 0.0056\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0133 - val_loss: 0.0060\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0147 - val_loss: 0.0061\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0150 - val_loss: 0.0057\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0148 - val_loss: 0.0056\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0127 - val_loss: 0.0060\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0119 - val_loss: 0.0058\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0111 - val_loss: 0.0066\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0109 - val_loss: 0.0066\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0117 - val_loss: 0.0059\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0116 - val_loss: 0.0054\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0105 - val_loss: 0.0056\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0104 - val_loss: 0.0054\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0098 - val_loss: 0.0063\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0091 - val_loss: 0.0056\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0108 - val_loss: 0.0062\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0114 - val_loss: 0.0061\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0076 - val_loss: 0.0045\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0074 - val_loss: 0.0048\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 141us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 131us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0083\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0052 - val_loss: 0.0079\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0094\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0058 - val_loss: 0.0097\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0073\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0077\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0083\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0044 - val_loss: 0.0073\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0101\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0081\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0062\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0087\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0070\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0062\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0065\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0063\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0036 - val_loss: 0.0088\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0082\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0039 - val_loss: 0.0073\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0066\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0081\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0071\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0093\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0083\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0082\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0066\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0095\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0101\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0069\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0073\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0075\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 104us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0077\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0084\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0079\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0072\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 112us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0070\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0072\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0084\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0084\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 138us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0077\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0073\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0082\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0070\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0071\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0019 - val_loss: 0.0074\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0077\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0076\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0069\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0063\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 193us/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 209us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0073\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0064\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0074\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0070\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0075\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0077\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0074\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0075\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0071\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0080\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0018 - val_loss: 0.0083\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0072\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0070\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0071\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0069\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0070\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "0.015014992095530033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.5736573 ,  0.1265544 , -0.47902927,  0.61840904, -0.50585866],\n",
       "        [-0.683833  ,  0.8060595 , -0.021943  , -0.3240458 ,  0.05592718],\n",
       "        [ 0.45083618, -1.0342698 ,  0.706376  , -0.13129845,  0.15516737],\n",
       "        [-1.6272156 , -0.06322861,  0.3655931 ,  0.0433594 ,  0.0223134 ],\n",
       "        [-0.00631125, -1.6157868 ,  0.56717384, -0.25213358, -0.28233984],\n",
       "        [ 0.25117785, -0.553465  , -0.6082802 ,  0.11214534, -1.6101968 ],\n",
       "        [ 0.3234074 , -0.05128997,  0.25775555,  0.05939157,  0.78603673],\n",
       "        [ 0.29637182,  0.30213124, -0.07114127, -0.3336933 , -0.15259276],\n",
       "        [ 0.37869915, -1.1231941 ,  0.29945993,  0.21226929,  0.00956837],\n",
       "        [-0.33944264,  0.96623266, -0.68134356,  0.03110527, -0.02534997],\n",
       "        [ 0.15359375,  0.5271991 ,  0.20085715, -1.0992467 ,  0.55244654],\n",
       "        [-0.58744514,  1.060027  , -0.18913722, -0.07728682, -0.52706   ],\n",
       "        [-0.00441534,  0.7454373 , -0.0794742 ,  0.06878286, -0.90017486],\n",
       "        [-0.6685028 , -0.26604718, -1.4728286 , -0.79731834, -0.37058985],\n",
       "        [-0.27975604, -0.0863082 , -0.05056025,  0.0205504 , -0.24544145],\n",
       "        [-0.2035595 ,  0.5810493 , -0.25099653, -0.09704525,  0.14966218],\n",
       "        [-0.58709043, -0.12986025,  0.42405868,  0.4872471 ,  0.03225977],\n",
       "        [-0.02658141, -0.22344574, -0.30015543, -0.6609705 , -0.34099317],\n",
       "        [ 0.13128285, -1.1899023 ,  0.53046656, -0.48384953, -0.22071123],\n",
       "        [ 0.17763622, -0.1371058 , -0.18496592, -0.25658995,  0.17791867],\n",
       "        [-0.44191533, -0.9371424 ,  1.7428814 ,  0.43320554,  1.1916986 ],\n",
       "        [-0.7677615 , -1.3055671 ,  0.5935543 ,  0.55980307, -0.43185267]],\n",
       "       dtype=float32),\n",
       " array([-0.03988929, -0.23203297,  0.4539083 ,  0.19100873,  0.03226028],\n",
       "       dtype=float32),\n",
       " array([[-0.11738371, -0.39946952, -0.30214694,  0.3882857 ,  0.38418484,\n",
       "          0.45786902,  0.19279878, -0.5935365 , -0.07218165,  0.2888732 ],\n",
       "        [-0.19253373,  0.21214978,  0.47087067, -0.15754883, -0.4262431 ,\n",
       "         -0.16352622,  0.34728855, -0.9414049 , -0.27543244, -0.27008373],\n",
       "        [-0.33931372,  0.49229875,  0.15319133,  0.02424873, -0.21075997,\n",
       "         -0.44446415,  0.35292774, -1.0119416 ,  0.02689753, -0.04583825],\n",
       "        [ 0.24123082, -0.34793642, -0.07243906,  0.258405  , -0.17762257,\n",
       "         -0.05085802,  0.10390195, -0.29248545,  0.06951474, -0.31471384],\n",
       "        [ 0.03692501,  0.43052146, -0.21882002, -0.118288  ,  0.06929844,\n",
       "         -0.35650387, -0.27323082,  0.7357972 ,  0.46829548, -0.09073602]],\n",
       "       dtype=float32),\n",
       " array([ 0.02166478, -0.1484433 , -0.12430915,  0.00273576,  0.13041353,\n",
       "         0.21903193, -0.00742533,  0.11514766,  0.0773981 , -0.06291012],\n",
       "       dtype=float32),\n",
       " array([[ 0.02040899],\n",
       "        [-0.06856612],\n",
       "        [-0.0057252 ],\n",
       "        [-0.02356692],\n",
       "        [ 0.01604661],\n",
       "        [ 0.05978444],\n",
       "        [-0.01567956],\n",
       "        [ 0.6134339 ],\n",
       "        [-0.00062575],\n",
       "        [ 0.00867734]], dtype=float32),\n",
       " array([0.16679868], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_2(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure2_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.3056 - val_loss: 0.0829\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0766 - val_loss: 0.0461\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0642 - val_loss: 0.0207\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0407 - val_loss: 0.0164\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0334 - val_loss: 0.0126\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0231 - val_loss: 0.0140\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0194 - val_loss: 0.0060\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0161 - val_loss: 0.0060\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0135 - val_loss: 0.0044\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0127 - val_loss: 0.0040\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0127 - val_loss: 0.0038\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0134 - val_loss: 0.0041\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0123 - val_loss: 0.0039\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0118 - val_loss: 0.0042\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0112 - val_loss: 0.0038\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0110 - val_loss: 0.0042\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0107 - val_loss: 0.0037\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0109 - val_loss: 0.0042\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0112 - val_loss: 0.0042\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0101 - val_loss: 0.0035\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0095 - val_loss: 0.0043\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0037\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0092 - val_loss: 0.0040\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0097 - val_loss: 0.0039\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0091 - val_loss: 0.0040\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0101 - val_loss: 0.0046\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0091 - val_loss: 0.0040\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0082 - val_loss: 0.0052\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0088 - val_loss: 0.0038\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0083 - val_loss: 0.0051\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0047\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0054\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 146us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0074 - val_loss: 0.0048\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0075\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0072\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 141us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0070\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0100\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 163us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0074\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "0.009791904129087925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.5255522 , -0.09260228, -0.49330962, -0.9216876 , -0.5651125 ],\n",
       "        [-0.03541639,  0.40660682,  1.1710927 , -0.17194907, -0.1852446 ],\n",
       "        [ 0.36717063, -0.9793008 ,  0.3815718 , -0.07199725, -0.2897665 ],\n",
       "        [ 0.12579791, -0.557407  ,  0.3072762 , -1.109443  ,  0.31677562],\n",
       "        [ 0.1355897 , -0.25938445, -0.1403504 ,  0.04746757, -0.03559031],\n",
       "        [-0.7056149 ,  0.806231  ,  0.31346   , -0.34633514, -0.40193793],\n",
       "        [-0.38638026,  0.17395428,  0.35183176,  0.02083181,  0.02005108],\n",
       "        [-0.3674216 , -0.37435734, -0.06876706, -0.6989836 ,  0.5061537 ],\n",
       "        [ 0.17992376, -0.10178285, -0.7727435 ,  0.5489126 ,  0.8463981 ],\n",
       "        [-0.16879638,  0.19843319, -0.07119418, -0.27431184, -0.1200474 ],\n",
       "        [ 0.814577  ,  0.14653325,  0.15072307,  0.8478684 ,  0.61418843],\n",
       "        [ 1.1191216 ,  0.295338  ,  0.6228138 ,  0.4253674 ,  0.19461577],\n",
       "        [ 0.5305401 ,  0.54548115,  1.1093385 , -0.06105691, -0.4524011 ],\n",
       "        [ 0.41338006,  2.045965  , -1.1120446 ,  0.6962345 ,  0.4818994 ],\n",
       "        [ 0.24017014,  0.43618494,  0.19060339,  0.0453372 , -0.69108605],\n",
       "        [-0.08169162, -0.18693519, -0.782328  ,  0.18919204, -0.04999233],\n",
       "        [-0.39274082, -0.73793566,  0.7197112 , -1.2543002 ,  0.10511784],\n",
       "        [-0.42645773, -0.46101606, -0.30397698,  0.14856996,  0.0215523 ],\n",
       "        [ 0.8320196 , -0.62625134, -1.4057757 ,  0.88302404, -0.7831534 ],\n",
       "        [ 0.35850343, -0.03814184, -1.4525986 ,  0.19003409, -0.01937152],\n",
       "        [-0.15021367, -0.223025  ,  1.893398  , -0.7436361 , -0.55794525],\n",
       "        [ 0.97733957,  0.06774307,  0.8568746 , -0.3756608 , -0.49170256]],\n",
       "       dtype=float32),\n",
       " array([ 0.06058024, -0.6309538 ,  0.43027586,  0.01210605, -0.18303835],\n",
       "       dtype=float32),\n",
       " array([[ 0.46942464,  0.10273793,  0.4288476 ,  0.18916495,  0.15361758,\n",
       "         -0.4882831 , -0.53772813,  0.10155802,  0.08371238, -0.00993496,\n",
       "         -0.52428126,  0.08092023, -0.2201881 , -0.33064955, -0.34595525],\n",
       "        [ 0.16721605, -0.40006033,  0.40320262, -0.6688756 ,  0.41346228,\n",
       "          0.08116784, -0.07268585,  0.50059694, -0.2754802 , -0.0353749 ,\n",
       "         -0.54491377,  0.48934472, -0.00760149,  0.41380548, -0.20950767],\n",
       "        [ 0.04833458,  0.05516015, -0.30670217,  0.44206384, -0.20056492,\n",
       "          0.2601474 ,  0.11877931,  0.22836038, -0.16143438, -0.24740392,\n",
       "          0.33861127,  0.33436543,  0.01897942,  0.199103  , -0.1334018 ],\n",
       "        [ 0.12046853,  0.25690022, -0.48090744,  0.6673398 , -0.5801651 ,\n",
       "          0.07125659,  0.21525687, -0.06731996, -0.1382542 , -0.4366191 ,\n",
       "          0.05676833,  0.09926277,  0.34276295, -0.15447363,  0.14459601],\n",
       "        [ 0.17016   ,  0.151587  ,  0.5656323 ,  0.05955929,  0.03994661,\n",
       "         -0.3474783 , -0.33202115,  0.17203785,  0.05166041, -0.00936212,\n",
       "         -0.07282437, -0.10485044, -0.38851672, -0.08784586, -0.19325778]],\n",
       "       dtype=float32),\n",
       " array([-0.02100936, -0.03160683,  0.20669067, -0.18919893, -0.14201409,\n",
       "        -0.03317845, -0.05942174,  0.13713871, -0.17397717, -0.19051632,\n",
       "        -0.19169323, -0.0030807 ,  0.11766146,  0.12835659,  0.16087931],\n",
       "       dtype=float32),\n",
       " array([[ 0.01096723],\n",
       "        [-0.00435861],\n",
       "        [ 0.2782968 ],\n",
       "        [-0.40622127],\n",
       "        [ 0.02224807],\n",
       "        [-0.07190224],\n",
       "        [-0.2555986 ],\n",
       "        [ 0.00590728],\n",
       "        [-0.00207481],\n",
       "        [ 0.00541473],\n",
       "        [-0.14787781],\n",
       "        [ 0.00546924],\n",
       "        [-0.00566188],\n",
       "        [ 0.01036398],\n",
       "        [-0.0022871 ]], dtype=float32),\n",
       " array([0.19661674], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_3(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure3_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 291\n",
      "Trainable params: 291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1790 - val_loss: 0.0158\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0718 - val_loss: 0.0454\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0593 - val_loss: 0.0306\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0414 - val_loss: 0.0213\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0412 - val_loss: 0.0192\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0343 - val_loss: 0.0248\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0300 - val_loss: 0.0149\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0232 - val_loss: 0.0136\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0184 - val_loss: 0.0061\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0150 - val_loss: 0.0046\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0128 - val_loss: 0.0042\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0119 - val_loss: 0.0044\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0106 - val_loss: 0.0051\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0100 - val_loss: 0.0056\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0083 - val_loss: 0.0050\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0051\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0077\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 119us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0064\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 119us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "0.007169807329773903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.14152452, -0.18154316, -0.5027929 , -1.0379568 , -0.33447295,\n",
       "         -0.359882  ,  0.31829327, -0.59946203, -0.73631847, -0.12072644],\n",
       "        [ 0.09193673,  0.41734576, -0.57767457, -1.3535154 , -0.34632316,\n",
       "          0.2547017 , -0.30201617, -0.43302813,  1.0867004 ,  0.12813191],\n",
       "        [ 0.00857275, -0.4601806 , -0.6179865 ,  0.20987892, -0.4366662 ,\n",
       "         -0.07716192, -0.01325955, -0.0600386 ,  0.57893157, -0.43296665],\n",
       "        [-0.01223801,  0.45243114, -0.26250425,  1.3320085 , -0.19800974,\n",
       "         -0.3582311 ,  0.8764556 ,  0.26378852,  0.39583528, -0.25944135],\n",
       "        [ 0.03666883, -0.07855121, -0.33102754, -0.4455303 , -0.12275294,\n",
       "          0.27266353, -0.14822869, -0.02552002, -0.02837286,  0.35114753],\n",
       "        [ 0.38372484,  0.6373168 , -0.655392  ,  0.12057621, -0.8310448 ,\n",
       "          0.3079887 , -0.9029526 , -1.1841974 ,  0.1852856 , -0.18111914],\n",
       "        [-0.07108203,  0.33087465, -0.28488982,  0.4797545 , -0.30858007,\n",
       "          0.17835045,  0.52791625, -0.04049763,  0.11498543,  0.10405946],\n",
       "        [-0.46292022,  0.34407535, -0.8068597 , -0.12634218, -0.73104846,\n",
       "         -0.16673797,  0.04680958,  0.06778242, -0.05339946,  0.6245353 ],\n",
       "        [ 0.46232295,  0.3427617 , -0.680129  , -0.00562206, -0.31527525,\n",
       "          0.9493663 ,  0.6391568 ,  0.24991222, -1.2675896 ,  0.3188373 ],\n",
       "        [ 0.1004706 ,  0.04596506, -0.0596639 , -0.01110584, -0.77892005,\n",
       "         -0.9537604 , -0.1939584 ,  0.38249433,  0.6913928 ,  1.1367283 ],\n",
       "        [-0.05974066, -0.05994999, -0.3190131 , -0.3643556 , -0.7312723 ,\n",
       "          0.2122312 ,  0.13080746,  1.1488321 , -0.27128622, -0.47591168],\n",
       "        [-0.64760345, -0.03128536, -0.06536029,  1.1194466 , -0.3614165 ,\n",
       "         -1.4181335 ,  0.34334153, -0.5286782 ,  1.2178382 , -1.1326733 ],\n",
       "        [-0.24733485,  0.188     , -0.07183602,  0.2644141 , -0.38103807,\n",
       "         -0.71165806, -1.0750319 ,  0.9261069 ,  1.2011484 , -0.96815914],\n",
       "        [-0.8435611 ,  0.25820193, -0.16350275, -1.2317773 , -0.27484238,\n",
       "          0.0687803 ,  0.34152502,  0.3899064 , -1.9775487 , -1.2522275 ],\n",
       "        [-0.04697473,  0.16912231, -0.39624634,  0.1122434 , -0.416111  ,\n",
       "          0.17343798,  0.60933536,  0.8726521 ,  0.52369905,  0.3489653 ],\n",
       "        [-0.15443921, -0.14550057, -0.28276172,  0.18349122, -0.25210682,\n",
       "         -0.29817435,  0.3724775 , -0.25184256, -0.86576396,  0.31346008],\n",
       "        [ 0.5138181 , -0.36279348, -0.4501115 ,  0.43820322, -0.26088247,\n",
       "         -0.39029044,  0.24604136, -0.66225797,  0.5057579 , -0.7771484 ],\n",
       "        [-0.17848733, -0.29559812, -0.8878579 ,  0.301777  , -0.32248062,\n",
       "          0.18055953, -0.4032373 ,  1.6185132 , -0.5994606 ,  0.8166294 ],\n",
       "        [-0.07436053, -0.95171064,  0.00326493, -0.88427436, -0.85048246,\n",
       "          0.61488324,  1.178886  ,  2.3335896 , -0.51922774, -1.865146  ],\n",
       "        [ 0.21231292, -0.62843364,  0.06890859,  0.35884392, -0.30657327,\n",
       "          0.1663905 , -0.3049219 ,  0.70235234, -1.6426071 , -0.54465497],\n",
       "        [-0.02648706,  0.04383206, -0.23756655,  0.3678033 , -0.46819296,\n",
       "         -0.5657739 , -0.436717  ,  0.4362329 ,  1.8825893 ,  0.46110943],\n",
       "        [-0.25544313, -0.3921914 , -0.00923184, -0.2863733 , -0.07966452,\n",
       "          0.12011625, -0.39295033,  0.09141312,  0.78842723, -0.4483593 ]],\n",
       "       dtype=float32),\n",
       " array([-0.00279642, -0.21060167, -0.3153038 ,  0.17142288, -0.3810201 ,\n",
       "        -0.17230174,  0.00227562,  0.09676977,  0.39425296, -0.05761505],\n",
       "       dtype=float32),\n",
       " array([[ 0.1432557 ,  0.0241359 ,  0.5849637 , -0.24698076, -0.1266375 ],\n",
       "        [-0.9462722 , -0.4055623 ,  0.46780288,  0.31737846,  0.14841108],\n",
       "        [-0.26757905, -0.28498846, -0.19822025, -0.68439335,  0.27371675],\n",
       "        [ 0.2057004 ,  0.23255043, -0.5732241 , -0.3431849 ,  0.27318102],\n",
       "        [-0.2884563 ,  0.29593936,  0.12379403, -0.03310727,  0.6647072 ],\n",
       "        [ 0.6699466 ,  0.62823594, -1.1107649 ,  0.20287852, -0.9788438 ],\n",
       "        [ 0.65343416,  0.17531621, -0.05131287,  0.11679526,  0.15284666],\n",
       "        [-0.86118144, -0.27579913, -0.09231795,  0.0459039 ,  0.39352405],\n",
       "        [ 0.02911955,  0.803597  , -0.15939906,  0.22317578, -0.58362347],\n",
       "        [ 0.10892699,  0.5709321 ,  0.33559293,  0.602527  , -0.26898587]],\n",
       "       dtype=float32),\n",
       " array([ 0.03393387,  0.02839977, -0.1279866 , -0.15374358,  0.12171164],\n",
       "       dtype=float32),\n",
       " array([[-0.12205514],\n",
       "        [-0.42820725],\n",
       "        [ 0.03158391],\n",
       "        [-0.00507557],\n",
       "        [ 0.07107482]], dtype=float32),\n",
       " array([0.08657429], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_4(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure4_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 351\n",
      "Trainable params: 351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.5124 - val_loss: 0.1206\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.1896 - val_loss: 0.1825\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.1003 - val_loss: 0.0662\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0493 - val_loss: 0.0566\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0326 - val_loss: 0.0369\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0294 - val_loss: 0.0158\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0221 - val_loss: 0.0049\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0144 - val_loss: 0.0083\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0124 - val_loss: 0.0049\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0114 - val_loss: 0.0055\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0122 - val_loss: 0.0055\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0103 - val_loss: 0.0041\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0110 - val_loss: 0.0041\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0104 - val_loss: 0.0051\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0100 - val_loss: 0.0038\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0099 - val_loss: 0.0039\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0099 - val_loss: 0.0044\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0096 - val_loss: 0.0037\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0095 - val_loss: 0.0043\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0096 - val_loss: 0.0044\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0089 - val_loss: 0.0038\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0039\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0037\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0039\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0080 - val_loss: 0.0038\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0081 - val_loss: 0.0041\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0039\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0043\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0081 - val_loss: 0.0038\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0042\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0075\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0077\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0069\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0068\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0069\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0095\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0071\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0077\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0068\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0068\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0074\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0092\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0065\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0080\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0070\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0062\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0075\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0070\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0062\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0075\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0067\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 145us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0029 - val_loss: 0.0101\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0065\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0028 - val_loss: 0.0084\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 126us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 130us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 161us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 148us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 148us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 202us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 126us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0064\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 141us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 163us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 9.2512e-0 - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "0.006033340003341436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.63109416e-01,  2.87394315e-01,  3.36530685e-01,\n",
       "         -8.23357403e-02, -5.12385607e-01, -8.40016007e-01,\n",
       "         -2.13714793e-01,  4.58041936e-01, -1.85280755e-01,\n",
       "         -5.73321342e-01],\n",
       "        [ 1.58114403e-01, -1.79817379e-01, -2.11871684e-01,\n",
       "         -1.42843321e-01,  6.22609677e-03,  1.04388809e+00,\n",
       "         -9.76363122e-01,  4.71190929e-01,  1.05771244e-01,\n",
       "         -7.43597224e-02],\n",
       "        [ 9.66557190e-02,  5.15188277e-01,  3.80168408e-01,\n",
       "          2.27735594e-01,  6.14834189e-01,  5.43149054e-01,\n",
       "          4.82464641e-01,  6.44063577e-02, -3.87285680e-01,\n",
       "          3.48457456e-01],\n",
       "        [-4.35258180e-01,  2.93920785e-01,  2.14602843e-01,\n",
       "         -1.26953751e-01, -7.18626678e-01,  5.65966487e-01,\n",
       "         -2.13499808e+00,  3.77359218e-03, -4.30591673e-01,\n",
       "         -1.43307462e-01],\n",
       "        [ 1.02253094e-01,  1.74734235e-01, -4.65976119e-01,\n",
       "          2.96346936e-02, -1.39747381e-01, -1.68274596e-01,\n",
       "          1.23926312e-01, -1.20168231e-01,  9.25486013e-02,\n",
       "          7.91943893e-02],\n",
       "        [ 4.25149679e-01, -8.56372774e-01,  2.45106220e-01,\n",
       "         -1.30387828e-01, -1.53024808e-01, -1.12677917e-01,\n",
       "         -1.36127189e-01, -2.98247755e-01, -3.35858315e-01,\n",
       "          2.98883557e-01],\n",
       "        [-4.34978902e-01,  1.29756588e-03, -2.53390986e-03,\n",
       "         -1.14089832e-01, -3.19512963e-01,  5.39655149e-01,\n",
       "          6.86772615e-02,  4.27698821e-01, -5.23213390e-03,\n",
       "         -6.57286048e-02],\n",
       "        [-3.27296615e-01,  6.56589344e-02, -1.17408663e-01,\n",
       "          2.83899844e-01,  5.41148424e-01,  1.00925282e-01,\n",
       "          6.05011582e-01,  1.77659374e-02,  1.13299049e-01,\n",
       "         -3.61097991e-01],\n",
       "        [ 7.40461349e-01, -5.21348834e-01, -1.90296248e-01,\n",
       "          9.34984758e-02,  5.91273904e-01, -1.25089121e+00,\n",
       "          1.50346339e-01, -6.25709370e-02,  4.18599062e-02,\n",
       "         -2.64553547e-01],\n",
       "        [-1.38400578e+00,  2.90939569e-01, -2.44425058e-01,\n",
       "          2.15687975e-02, -3.57659310e-01,  5.94026864e-01,\n",
       "          6.91136003e-01,  2.50466257e-01, -3.80086690e-01,\n",
       "          5.05809247e-01],\n",
       "        [-3.27164590e-01,  5.43858670e-02,  4.67868179e-01,\n",
       "         -3.25722009e-01,  7.84319401e-01, -6.76055551e-01,\n",
       "         -1.33301541e-01, -5.72708488e-01, -5.88013530e-02,\n",
       "          2.48246476e-01],\n",
       "        [-1.19163179e+00, -3.54448289e-01,  2.15085298e-01,\n",
       "         -2.01059386e-01,  1.75562203e-01,  7.87222981e-01,\n",
       "          8.26483130e-01,  3.10831144e-02, -2.08308443e-01,\n",
       "         -4.57243353e-01],\n",
       "        [-4.83674705e-01, -6.63466573e-01, -4.25132990e-01,\n",
       "          3.52477431e-01,  8.18840787e-02,  4.80150938e-01,\n",
       "         -2.42765546e-02, -2.09218934e-01,  6.83119819e-02,\n",
       "         -2.90680200e-01],\n",
       "        [ 5.04612923e-01, -8.24309289e-01, -2.05427647e-01,\n",
       "          1.64761692e-01,  2.86653936e-01, -1.32909024e+00,\n",
       "         -7.95398653e-01, -9.39444780e-01, -1.71626568e-01,\n",
       "          1.21198967e-01],\n",
       "        [-1.58751160e-01,  3.99433225e-02,  1.16060451e-01,\n",
       "         -2.72404015e-01,  2.40293384e-01,  5.01857162e-01,\n",
       "         -6.75404847e-01,  3.14582288e-01,  4.00329903e-02,\n",
       "         -4.21360165e-01],\n",
       "        [-3.25062126e-01,  9.20806170e-01, -4.60330814e-01,\n",
       "          2.35755637e-01, -5.36117852e-01, -1.82153717e-01,\n",
       "          1.12194885e-02, -1.58715606e-01, -2.74702489e-01,\n",
       "          4.92053956e-01],\n",
       "        [ 4.89884198e-01, -3.47932428e-01, -4.30561960e-01,\n",
       "          7.64949322e-02, -1.30936518e-01,  1.02906220e-01,\n",
       "          3.82513225e-01,  1.70268506e-01, -4.21181560e-01,\n",
       "         -5.45521438e-01],\n",
       "        [ 3.35381866e-01,  4.09401774e-01, -3.01082768e-02,\n",
       "          2.12927699e-01,  5.45608737e-02,  3.16168189e-01,\n",
       "          9.22734141e-02,  1.15287468e-01, -2.17831910e-01,\n",
       "          3.96739274e-01],\n",
       "        [ 1.11020195e+00,  4.21658397e-01,  6.86173201e-01,\n",
       "         -1.18630692e-01,  1.88104678e-02, -8.15776944e-01,\n",
       "         -8.51828933e-01, -3.39533120e-01,  6.04374297e-02,\n",
       "          4.47742088e-04],\n",
       "        [ 1.20336771e-01,  2.35049558e+00, -4.23604220e-01,\n",
       "          1.09586909e-01,  6.14979029e-01, -7.36441076e-01,\n",
       "         -7.28837729e-01, -2.43901774e-01,  2.25722045e-01,\n",
       "          5.96306264e-01],\n",
       "        [-6.13795035e-02,  3.89100671e-01, -3.40759516e-01,\n",
       "         -3.83753300e-01, -8.56100321e-02,  1.09375072e+00,\n",
       "         -7.74674788e-02, -2.28163511e-01,  3.16384643e-01,\n",
       "         -1.22027166e-01],\n",
       "        [-2.15071067e-01,  1.79500967e-01, -1.79057851e-01,\n",
       "         -1.00875452e-01,  5.00284374e-01,  8.03485990e-01,\n",
       "         -5.67288578e-01, -2.32237000e-02, -1.72004849e-01,\n",
       "          3.18803102e-01]], dtype=float32),\n",
       " array([-0.20849362,  0.3690852 , -0.02374649, -0.03469928,  0.18910307,\n",
       "         0.13205682,  0.16502337,  0.05768082,  0.01459994, -0.02488949],\n",
       "       dtype=float32),\n",
       " array([[ 8.06644559e-01,  8.36050212e-02,  2.35463306e-01,\n",
       "         -5.01340568e-01, -1.47147238e-01,  7.32412457e-01,\n",
       "          8.46144333e-02, -3.76255572e-01,  2.41739582e-02,\n",
       "         -1.21763311e-02],\n",
       "        [ 3.44696254e-01, -4.61230092e-02,  2.64683902e-01,\n",
       "         -2.06623167e-01, -2.06543893e-01,  5.77939332e-01,\n",
       "          2.29954347e-02, -1.73319146e-01,  8.95364210e-02,\n",
       "         -3.04914385e-01],\n",
       "        [ 4.22308147e-01, -2.98984468e-01,  3.39802682e-01,\n",
       "         -1.97610810e-01, -3.34106326e-01,  3.17612179e-02,\n",
       "         -1.52502999e-01,  1.07928053e-01, -1.88784525e-01,\n",
       "         -5.06092682e-02],\n",
       "        [-1.53485402e-01, -2.99907207e-01, -1.82863608e-01,\n",
       "          2.32072741e-01, -3.43364239e-01, -3.15170214e-02,\n",
       "          5.33674836e-01, -1.60131350e-01,  1.91682279e-01,\n",
       "         -2.71184891e-01],\n",
       "        [-1.59951821e-01, -1.12957038e-01,  1.57297537e-01,\n",
       "          6.43597245e-02,  3.18412364e-01, -3.34392935e-01,\n",
       "         -7.01018721e-02,  5.29324114e-01, -4.58114952e-01,\n",
       "         -8.80074576e-02],\n",
       "        [ 2.23291084e-01, -2.43144765e-01, -1.46192312e-01,\n",
       "         -3.73461336e-01, -2.80192316e-01,  4.45418030e-01,\n",
       "         -1.71808004e-01, -2.62584448e-01,  5.82422376e-01,\n",
       "         -4.19098884e-03],\n",
       "        [-2.21967772e-01,  3.76793683e-01,  1.04156464e-01,\n",
       "          6.40878603e-02, -1.40711606e-01,  3.46070647e-01,\n",
       "         -1.47518978e-01, -9.77761373e-02,  4.11352873e-01,\n",
       "         -2.72528499e-01],\n",
       "        [ 1.72916174e-01,  1.94522128e-01, -2.46811379e-02,\n",
       "          3.68095368e-01,  3.21291924e-01,  1.60832450e-01,\n",
       "          4.04219568e-01,  4.34604645e-01, -8.83892849e-02,\n",
       "          4.65485603e-01],\n",
       "        [ 3.02828521e-01, -8.07301924e-02, -2.31459171e-01,\n",
       "         -1.08389128e-02,  2.33179162e-04, -1.82085320e-01,\n",
       "         -1.20157734e-01,  2.43368819e-01,  2.13732436e-01,\n",
       "         -1.57997981e-01],\n",
       "        [-1.35094717e-01,  2.95504659e-01, -8.34746435e-02,\n",
       "         -2.48063907e-01,  1.31515935e-01, -3.11425269e-01,\n",
       "          9.30499658e-02, -1.06924325e-01,  1.68077901e-01,\n",
       "          3.70968133e-02]], dtype=float32),\n",
       " array([ 0.10058939,  0.17562637, -0.1366504 , -0.07438143, -0.11002741,\n",
       "        -0.16103649,  0.05000467, -0.12172215,  0.01526164,  0.1244563 ],\n",
       "       dtype=float32),\n",
       " array([[-0.25864434],\n",
       "        [ 0.00073778],\n",
       "        [-0.01445004],\n",
       "        [ 0.06739312],\n",
       "        [ 0.05801789],\n",
       "        [-0.447927  ],\n",
       "        [ 0.00499782],\n",
       "        [ 0.04968252],\n",
       "        [-0.2191279 ],\n",
       "        [ 0.01523416]], dtype=float32),\n",
       " array([0.04582349], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_5(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure5_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.5370 - val_loss: 0.6039\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.2946 - val_loss: 0.0534\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1009 - val_loss: 0.0320\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0728 - val_loss: 0.0236\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0482 - val_loss: 0.0111\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0422 - val_loss: 0.0130\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0237 - val_loss: 0.0226\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0207 - val_loss: 0.0131\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0208 - val_loss: 0.0096\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0159 - val_loss: 0.0105\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0162 - val_loss: 0.0095\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0145 - val_loss: 0.0092\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0139 - val_loss: 0.0085\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0135 - val_loss: 0.0083\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0131 - val_loss: 0.0083\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0124 - val_loss: 0.0082\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0119 - val_loss: 0.0078\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0118 - val_loss: 0.0073\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0115 - val_loss: 0.0071\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0106 - val_loss: 0.0065\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0100 - val_loss: 0.0063\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0102 - val_loss: 0.0055\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0082 - val_loss: 0.0052\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0048\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 125us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0083\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0063\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 141us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0084\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0072\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 195us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0068\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0071\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0067\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0070\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0072\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0075\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0079\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0077\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0067\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0083\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0081\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0064\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 143us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0076\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0081\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0015 - val_loss: 0.0075\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0075\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0066\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 195us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0061\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0070\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0079\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0079\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0066\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 6.9166e-0 - 0s 126us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.9761e-04 - val_loss: 0.0046\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9762e-04 - val_loss: 0.0059\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 9.7770e-04 - val_loss: 0.0047\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0062\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0059\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "0.007517980877310038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 4.12755638e-01,  6.52505178e-03,  4.21901822e-01,\n",
       "          1.46211982e-01, -3.81319821e-01, -1.37775600e+00,\n",
       "          1.46873429e-01,  1.14680924e-01,  1.31995782e-01,\n",
       "          6.77955866e-01],\n",
       "        [-1.28790671e-02,  2.45136186e-01,  2.63380051e-01,\n",
       "          5.30252904e-02,  1.34121314e-01,  8.77678454e-01,\n",
       "         -3.93621117e-01,  5.17267108e-01, -1.04674518e+00,\n",
       "          4.00007218e-02],\n",
       "        [ 3.46141875e-01, -2.21463859e-01,  1.51258543e-01,\n",
       "         -8.30499381e-02, -1.51601970e-01,  6.03372991e-01,\n",
       "         -2.98534900e-01,  3.31560105e-01,  4.47529763e-01,\n",
       "          7.84211606e-02],\n",
       "        [ 7.01330602e-02,  3.73776019e-01,  3.14476192e-02,\n",
       "          8.66234973e-02,  4.37999755e-01,  2.95698792e-01,\n",
       "         -2.07813993e-01,  4.18076575e-01, -1.23005152e+00,\n",
       "          3.77705514e-01],\n",
       "        [ 2.88788885e-01, -2.98465610e-01, -3.87324840e-01,\n",
       "         -6.02497041e-01,  2.54160553e-01,  2.54337251e-01,\n",
       "         -4.44469064e-01,  1.66325003e-01, -2.18206927e-01,\n",
       "          5.31575739e-01],\n",
       "        [-8.11304972e-02,  2.60732651e-01, -1.65076610e-02,\n",
       "         -8.79994094e-01,  3.61944467e-01, -2.47494519e-01,\n",
       "         -4.13911074e-01, -2.15065747e-01,  4.07341033e-01,\n",
       "          5.23675740e-01],\n",
       "        [ 8.10454190e-01,  6.07841909e-01, -2.44372830e-01,\n",
       "          3.11953425e-02, -2.79899538e-01,  4.38073575e-01,\n",
       "         -2.50913829e-01,  3.97846192e-01,  1.51384383e-01,\n",
       "          2.01475844e-01],\n",
       "        [ 4.72902060e-01, -3.09014529e-01, -2.21942306e-01,\n",
       "          3.96606594e-01,  2.11409882e-01, -1.27776563e-01,\n",
       "         -3.36303353e-01,  4.59404349e-01, -1.13287359e-01,\n",
       "          2.08124518e-01],\n",
       "        [ 3.35002039e-03,  2.16762319e-01,  4.95322086e-02,\n",
       "         -8.02371562e-01,  4.35144193e-02, -3.65207344e-01,\n",
       "         -2.95521677e-01,  3.63398731e-01,  5.94396412e-01,\n",
       "          6.72841311e-01],\n",
       "        [ 8.96421313e-01,  3.51173222e-01, -5.42876683e-02,\n",
       "          9.07773316e-01, -7.12356269e-02,  1.27709031e-01,\n",
       "         -1.81835592e-01, -4.68712538e-01, -3.84653568e-01,\n",
       "         -4.91507977e-01],\n",
       "        [-1.04507856e-01,  2.94179350e-01,  9.53389481e-02,\n",
       "         -5.01510920e-04, -1.46701664e-01, -1.75188527e-01,\n",
       "          7.39403814e-02,  6.88015670e-02,  2.43405327e-01,\n",
       "         -5.21020055e-01],\n",
       "        [-2.10315973e-01, -3.20582420e-01,  8.07371065e-02,\n",
       "          1.00657737e+00, -1.80575326e-01,  5.47470748e-01,\n",
       "          6.10866360e-02,  3.79361868e-01,  4.45956111e-01,\n",
       "         -1.72136521e+00],\n",
       "        [-1.40415207e-01,  1.32892858e-02,  2.43457437e-01,\n",
       "          3.87719601e-01,  6.55117556e-02,  3.89703572e-01,\n",
       "         -2.97446638e-01,  4.34975028e-02,  3.53758633e-02,\n",
       "         -7.76965082e-01],\n",
       "        [-4.14210588e-01,  9.25616547e-02,  8.25713933e-01,\n",
       "         -9.82220769e-01,  1.81879491e-01, -1.22698712e+00,\n",
       "         -2.61865884e-01,  5.03432564e-02,  5.57910763e-02,\n",
       "         -1.18731380e+00],\n",
       "        [-4.18551415e-01,  2.01137513e-01, -1.50525346e-01,\n",
       "         -6.18806720e-01, -3.29180181e-01,  6.77663386e-02,\n",
       "          1.18485563e-01, -6.14528283e-02,  2.82557786e-01,\n",
       "          1.05913118e-01],\n",
       "        [ 2.80496869e-02,  3.26667517e-01, -3.23502570e-01,\n",
       "          5.28038919e-01, -2.08072454e-01, -3.17745805e-01,\n",
       "         -3.78265023e-01, -4.80708450e-01, -9.54049006e-02,\n",
       "         -3.21231961e-01],\n",
       "        [-5.72255731e-01, -6.84559464e-01, -3.35126072e-01,\n",
       "          1.07637785e-01,  2.98248708e-01,  9.71541926e-02,\n",
       "         -4.28549983e-02,  5.96935689e-01, -3.18586290e-01,\n",
       "          8.70365128e-02],\n",
       "        [ 5.96989512e-01,  2.20969066e-01,  3.61906618e-01,\n",
       "          2.18696728e-01,  3.50814722e-02, -2.48063177e-01,\n",
       "         -5.45827389e-01, -2.76432782e-01, -1.10415781e+00,\n",
       "          7.06416368e-02],\n",
       "        [-1.26349866e+00,  5.09117067e-01, -4.03590441e-01,\n",
       "         -1.42914236e+00,  3.93292606e-02,  1.34250343e-01,\n",
       "         -6.88597038e-02,  6.07855856e-01,  1.18115973e+00,\n",
       "          8.37404132e-02],\n",
       "        [-9.72771347e-02,  1.84743538e-01,  2.98879981e-01,\n",
       "          4.26254392e-01,  2.04782650e-01, -7.05149114e-01,\n",
       "          5.33558190e-01,  3.32111508e-01, -3.64580512e-01,\n",
       "         -2.09477276e-01],\n",
       "        [-7.41248764e-03,  2.73163221e-03, -2.39841864e-01,\n",
       "         -4.73016679e-01,  2.44918719e-01,  2.01542926e+00,\n",
       "          3.79738770e-02, -1.61295176e-01, -4.51429546e-01,\n",
       "          8.26633334e-01],\n",
       "        [ 2.77252346e-01, -2.75990367e-01,  2.07399756e-01,\n",
       "         -2.57637277e-02, -2.04716444e-01,  1.04318070e+00,\n",
       "         -7.71839321e-02,  1.59210548e-01, -6.02242291e-01,\n",
       "         -5.95605791e-01]], dtype=float32),\n",
       " array([ 0.08632284,  0.05729124,  0.03485694,  0.11829862, -0.01257372,\n",
       "         0.3469734 , -0.07689847,  0.06779459, -0.15419719,  0.01018766],\n",
       "       dtype=float32),\n",
       " array([[ 0.27097386, -0.13678537, -0.00987607, -0.2050169 ,  0.24835473,\n",
       "          0.6804422 ,  0.2858292 , -0.17979746,  0.02117592, -0.11197746,\n",
       "          0.1493688 ,  0.08450423, -0.14242823, -0.7468539 , -0.5815113 ],\n",
       "        [-0.24406908,  0.20310667,  0.21093644, -0.03787255, -0.2774527 ,\n",
       "          0.05728162, -0.20085287,  0.14887428,  0.18343817, -0.4752347 ,\n",
       "          0.2415654 ,  0.12759751,  0.11932502, -0.1721932 ,  0.01411937],\n",
       "        [ 0.18839322,  0.18433623,  0.41717592,  0.2570324 ,  0.58378   ,\n",
       "          0.34138864, -0.14620218, -0.08352054,  0.17030607, -0.33519003,\n",
       "         -0.05482768,  0.2696557 ,  0.5697057 , -0.00989614, -0.09469441],\n",
       "        [-0.17716113,  0.18143822, -0.03631823,  0.11587816, -0.39288685,\n",
       "         -0.09765616, -0.06097034,  0.1940896 ,  0.2830768 ,  0.07525806,\n",
       "          0.04835483, -0.6067905 , -0.2395807 ,  0.49967563, -0.11102126],\n",
       "        [ 0.00265514, -0.16744244, -0.01803599,  0.03794752,  0.4789963 ,\n",
       "          0.22052479,  0.32069224, -0.1593295 , -0.10367732, -0.3051012 ,\n",
       "         -0.09525051,  0.25510493,  0.4405873 ,  0.20278606,  0.01939167],\n",
       "        [-0.33810008, -0.24726759, -0.5456542 ,  0.48104978, -0.04181981,\n",
       "         -0.0573354 , -0.21983   ,  0.13269566,  0.40698576, -0.14603823,\n",
       "         -0.6019854 , -0.7581767 , -0.02862131, -0.04194311, -0.1626793 ],\n",
       "        [-0.03617006, -0.2896509 , -0.24092065, -0.00396302, -0.0966415 ,\n",
       "          0.29901204, -0.1332368 ,  0.06995764,  0.22324361,  0.10284868,\n",
       "         -0.00283901,  0.24106732,  0.25343388, -0.35558912, -0.3184661 ],\n",
       "        [-0.29486787, -0.14628716,  0.27916682, -0.3217279 , -0.22837293,\n",
       "         -0.02307238, -0.2502909 , -0.30178902, -0.08295144,  0.22875127,\n",
       "          0.27629504,  0.49836046,  0.43041447, -0.09500984,  0.09562201],\n",
       "        [ 0.12212295, -0.35060117, -0.04934445,  0.3518494 ,  0.01288757,\n",
       "          0.24067228,  0.17219546, -0.090726  ,  0.13630281, -0.10849904,\n",
       "          0.2968831 , -0.56356525, -0.12779173,  0.23644866, -0.14630963],\n",
       "        [-0.5150046 ,  0.29247308,  0.02120371, -0.25076592, -0.35383126,\n",
       "          0.02012025, -0.15506378, -0.3572067 ,  0.38879776, -0.20676357,\n",
       "         -0.5322273 , -0.39235306, -0.00903989,  0.49837548, -0.2277842 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.23560515,  0.08362017, -0.1343171 ,  0.06644347, -0.09250231,\n",
       "        -0.08640318,  0.13903904,  0.17974643,  0.02807006,  0.17344274,\n",
       "        -0.02476734,  0.03998603, -0.13911605,  0.0656894 ,  0.04508149],\n",
       "       dtype=float32),\n",
       " array([[ 0.01742122],\n",
       "        [-0.01658252],\n",
       "        [ 0.04401017],\n",
       "        [-0.03866604],\n",
       "        [ 0.00772338],\n",
       "        [ 0.00075548],\n",
       "        [ 0.00506335],\n",
       "        [-0.02746736],\n",
       "        [-0.17246617],\n",
       "        [ 0.00663978],\n",
       "        [ 0.18928154],\n",
       "        [ 0.21922134],\n",
       "        [ 0.020463  ],\n",
       "        [-0.32702056],\n",
       "        [ 0.02106819]], dtype=float32),\n",
       " array([0.03805264], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_6(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure6_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 36.6579 - val_loss: 32.9557\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.6021 - val_loss: 31.6688\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.2603 - val_loss: 29.3158\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.4852 - val_loss: 25.8053\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 26.0483 - val_loss: 21.2272\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 21.9375 - val_loss: 15.8787\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.2868 - val_loss: 10.3674\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 12.3473 - val_loss: 5.6999\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6245 - val_loss: 3.1019\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8903 - val_loss: 2.7281\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7931 - val_loss: 3.3545\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7573 - val_loss: 3.3596\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1446 - val_loss: 2.2943\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1772 - val_loss: 1.0976\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1332 - val_loss: 0.7201\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5745 - val_loss: 1.1794\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9943 - val_loss: 1.8662\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4694 - val_loss: 2.3044\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9743 - val_loss: 2.3708\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5329 - val_loss: 2.1425\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1839 - val_loss: 1.7496\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.9415 - val_loss: 1.3126\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7943 - val_loss: 0.9254\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7186 - val_loss: 0.6490\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 0.6879 - val_loss: 0.5076\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6781 - val_loss: 0.4885\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6689 - val_loss: 0.5519\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6475 - val_loss: 0.6463\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6107 - val_loss: 0.7245\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5636 - val_loss: 0.7550\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5146 - val_loss: 0.7260\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4707 - val_loss: 0.6440\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4343 - val_loss: 0.5280\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4025 - val_loss: 0.4013\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3697 - val_loss: 0.2837\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3302 - val_loss: 0.1878\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2813 - val_loss: 0.1179\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2243 - val_loss: 0.0726\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1646 - val_loss: 0.0472\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1101 - val_loss: 0.0367\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0685 - val_loss: 0.0366\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 0.0452 - val_loss: 0.0434\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0414 - val_loss: 0.0540\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0540 - val_loss: 0.0654\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0761 - val_loss: 0.0750\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0995 - val_loss: 0.0805\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1164 - val_loss: 0.0805\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1220 - val_loss: 0.0750\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1153 - val_loss: 0.0652\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0987 - val_loss: 0.0532\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0769 - val_loss: 0.0411\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0550 - val_loss: 0.0303\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0219\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0245 - val_loss: 0.0160\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0182 - val_loss: 0.0123\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0166 - val_loss: 0.0105\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0177 - val_loss: 0.0103\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0115\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0215 - val_loss: 0.0139\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0222 - val_loss: 0.0173\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0220 - val_loss: 0.0213\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0213 - val_loss: 0.0250\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0204 - val_loss: 0.0278\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0196 - val_loss: 0.0291\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0189 - val_loss: 0.0285\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0262\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0176 - val_loss: 0.0225\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0165 - val_loss: 0.0183\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.0142\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0071 - val_loss: 0.0028\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0026\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0024\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0023\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0019\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0018\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 9.9548e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 9.9093e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 9.8644e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.8203e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.7763e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 9.7321e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.6867e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.6406e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0029 - val_loss: 9.5933e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0029 - val_loss: 9.5452e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 9.4960e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 9.4464e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 9.3963e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 9.3463e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 9.2967e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 9.2478e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 9.1996e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 9.1526e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 9.1066e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 9.0616e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 9.0174e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.9740e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.9311e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.8884e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.8460e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.8037e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0027 - val_loss: 8.7611e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.7185e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.6757e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.6332e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.5905e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.5480e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.5057e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 8.4638e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 8.4223e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 8.3815e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 8.3408e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 8.3005e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 8.2606e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 8.2209e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 8.1816e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 8.1424e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 8.1031e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 8.0642e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 8.0250e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.9859e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0026 - val_loss: 7.9469e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 7.9078e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 7.8690e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.8301e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 7.7916e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 7.7534e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.7153e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.6777e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.6403e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.6031e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.5662e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.5297e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.4936e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0025 - val_loss: 7.4573e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.4214e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.3855e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 7.3499e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 7.3145e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 7.2790e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.2437e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 7.2085e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 7.1738e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.1389e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 7.1043e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.0698e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 7.0356e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 7.0014e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 6.9677e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 6.9339e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0023 - val_loss: 6.9005e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.8672e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.8341e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.8011e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 6.7683e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.7357e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0023 - val_loss: 6.7030e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0023 - val_loss: 6.6705e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.6383e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 6.6060e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.5740e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.5421e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0023 - val_loss: 6.5105e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.4789e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.4475e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.4164e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.3854e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.3546e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.3239e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.2934e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 6.2632e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0022 - val_loss: 6.2329e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.2028e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.1729e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 6.1432e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 6.1135e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 6.0839e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 6.0545e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.0253e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.9961e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.9671e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.9385e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.9099e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 5.8813e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 5.8528e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.8248e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 5.7969e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 5.7690e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.7410e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.7134e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.6858e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.6584e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.6311e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.6040e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.5769e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.5500e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.5232e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 5.4967e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 5.4703e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.4440e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.4177e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.3916e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 5.3657e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 5.3400e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.3142e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.2887e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.2633e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.2380e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.2128e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.1879e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.1628e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.1380e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.1134e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.0887e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.0644e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 5.0402e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.0159e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.9919e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 4.9680e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 4.9441e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.9203e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.8967e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.8734e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.8501e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.8267e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.8037e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.7807e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 4.7579e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.7351e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.7126e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 4.6900e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.6677e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.6453e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 4.6232e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6011e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.5792e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.5574e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 4.5357e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.5140e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 4.4925e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.4712e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.4499e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.4286e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.4076e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.3866e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0018 - val_loss: 4.3659e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.3451e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.3246e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 4.3041e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 4.2837e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.2634e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 4.2431e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.2230e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.2030e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.1832e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.1634e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 4.1437e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 4.1242e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.1045e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 4.0852e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0659e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0468e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0278e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0090e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 3.9901e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 3.9713e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0017 - val_loss: 3.9526e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 3.9341e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 3.9156e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 3.8972e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 3.8790e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 3.8606e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 3.8427e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 3.8246e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 3.8068e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 3.7889e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 3.7713e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 3.7537e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.7362e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 3.7187e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.7015e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.6843e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 3.6671e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.6501e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.6332e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.6163e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.5994e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.5827e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 3.5662e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.5496e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.5332e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.5171e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 3.5008e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.4847e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 3.4687e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 3.4527e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.4368e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.4209e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.4052e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.3897e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 3.3742e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0016 - val_loss: 3.3586e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.3433e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.3278e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.3127e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.2976e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 3.2825e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.2677e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.2527e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.2379e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.2233e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.2086e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.1940e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.1796e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.1653e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.1509e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.1367e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.1225e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.1084e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.0943e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.0804e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.0666e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.0528e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.0392e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.0255e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.0120e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.9985e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.9851e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.9717e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 2.9586e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 2.9453e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 2.9322e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.9192e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.9063e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.8934e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.8805e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.8679e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.8552e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.8426e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.8299e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.8175e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.8051e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.7928e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.7805e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.7685e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.7563e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.7442e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.7322e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.7202e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.7084e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.6965e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.6849e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.6733e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0014 - val_loss: 2.6617e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.6502e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 2.6387e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.6272e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.6159e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.6047e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.5935e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.5823e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.5713e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.5604e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.5494e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.5385e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.5277e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.5168e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.5062e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.4955e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.4848e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0013 - val_loss: 2.4743e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.4639e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.4535e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.4431e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.4327e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.4225e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.4124e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.4022e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.3922e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3823e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3722e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.3624e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3525e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3426e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3329e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3232e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.3136e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.3040e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.2945e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.2851e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.2756e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.2663e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.2569e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.2477e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.2385e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.2293e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.2203e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 2.2112e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.2023e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1932e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.1843e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1756e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1668e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 2.1581e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.1494e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1407e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1321e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1236e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1151e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1066e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.0982e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0899e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.0816e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0733e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.0650e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.0570e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0488e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.0407e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.0327e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.0246e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.0167e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.0088e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.0009e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9931e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9852e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9776e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9699e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 1.9623e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 1.9547e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.9471e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9397e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9321e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9248e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.9174e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.9100e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.9027e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.8955e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8883e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8811e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.8739e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8668e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8598e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.8527e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.8458e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8389e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8320e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8250e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8183e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8114e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8047e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.7980e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.7913e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.7846e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.7780e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.7713e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.7649e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.7584e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.7519e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.7455e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.7391e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.7327e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.7265e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.7202e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0010 - val_loss: 1.7139e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.7078e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.7015e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.6954e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 1.6893e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.6832e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.6772e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.6711e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 1.6652e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.6592e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.6533e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9780e-04 - val_loss: 1.6475e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9523e-04 - val_loss: 1.6416e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9267e-04 - val_loss: 1.6358e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9012e-04 - val_loss: 1.6300e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8757e-04 - val_loss: 1.6241e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8502e-04 - val_loss: 1.6185e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8248e-04 - val_loss: 1.6127e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.7994e-04 - val_loss: 1.6071e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7742e-04 - val_loss: 1.6015e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7489e-04 - val_loss: 1.5958e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7238e-04 - val_loss: 1.5903e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6987e-04 - val_loss: 1.5848e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6737e-04 - val_loss: 1.5792e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6487e-04 - val_loss: 1.5738e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6238e-04 - val_loss: 1.5684e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5990e-04 - val_loss: 1.5629e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5742e-04 - val_loss: 1.5575e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5494e-04 - val_loss: 1.5521e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5247e-04 - val_loss: 1.5468e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5001e-04 - val_loss: 1.5415e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4755e-04 - val_loss: 1.5362e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4509e-04 - val_loss: 1.5309e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4265e-04 - val_loss: 1.5257e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4021e-04 - val_loss: 1.5206e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3778e-04 - val_loss: 1.5154e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3536e-04 - val_loss: 1.5104e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3293e-04 - val_loss: 1.5052e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3052e-04 - val_loss: 1.5001e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2811e-04 - val_loss: 1.4950e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2570e-04 - val_loss: 1.4900e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2331e-04 - val_loss: 1.4850e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2090e-04 - val_loss: 1.4800e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1852e-04 - val_loss: 1.4751e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1614e-04 - val_loss: 1.4701e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1376e-04 - val_loss: 1.4652e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1139e-04 - val_loss: 1.4603e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0903e-04 - val_loss: 1.4555e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0667e-04 - val_loss: 1.4507e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0432e-04 - val_loss: 1.4459e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0196e-04 - val_loss: 1.4411e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9963e-04 - val_loss: 1.4364e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9728e-04 - val_loss: 1.4316e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9496e-04 - val_loss: 1.4269e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9262e-04 - val_loss: 1.4222e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 8.9031e-04 - val_loss: 1.4176e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.8799e-04 - val_loss: 1.4130e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 404us/step - loss: 8.8568e-04 - val_loss: 1.4084e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.8338e-04 - val_loss: 1.4038e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8108e-04 - val_loss: 1.3993e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7879e-04 - val_loss: 1.3948e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7650e-04 - val_loss: 1.3904e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7422e-04 - val_loss: 1.3858e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7195e-04 - val_loss: 1.3814e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6967e-04 - val_loss: 1.3770e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6741e-04 - val_loss: 1.3725e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6514e-04 - val_loss: 1.3682e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6288e-04 - val_loss: 1.3639e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 8.6064e-04 - val_loss: 1.3595e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5840e-04 - val_loss: 1.3551e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5615e-04 - val_loss: 1.3508e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5392e-04 - val_loss: 1.3465e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5169e-04 - val_loss: 1.3422e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4947e-04 - val_loss: 1.3380e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4726e-04 - val_loss: 1.3338e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4504e-04 - val_loss: 1.3296e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4283e-04 - val_loss: 1.3255e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 8.4063e-04 - val_loss: 1.3213e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3844e-04 - val_loss: 1.3172e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3624e-04 - val_loss: 1.3131e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 8.3406e-04 - val_loss: 1.3089e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3187e-04 - val_loss: 1.3049e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2970e-04 - val_loss: 1.3008e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2753e-04 - val_loss: 1.2968e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2536e-04 - val_loss: 1.2928e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2320e-04 - val_loss: 1.2889e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2105e-04 - val_loss: 1.2850e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1890e-04 - val_loss: 1.2809e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1675e-04 - val_loss: 1.2771e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1462e-04 - val_loss: 1.2732e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1248e-04 - val_loss: 1.2693e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1035e-04 - val_loss: 1.2655e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0822e-04 - val_loss: 1.2616e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0611e-04 - val_loss: 1.2577e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 8.0399e-04 - val_loss: 1.2540e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0188e-04 - val_loss: 1.2502e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9978e-04 - val_loss: 1.2464e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9768e-04 - val_loss: 1.2425e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9558e-04 - val_loss: 1.2388e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9350e-04 - val_loss: 1.2351e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9141e-04 - val_loss: 1.2314e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8934e-04 - val_loss: 1.2277e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8726e-04 - val_loss: 1.2240e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8520e-04 - val_loss: 1.2204e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8313e-04 - val_loss: 1.2168e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8107e-04 - val_loss: 1.2132e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7902e-04 - val_loss: 1.2096e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7696e-04 - val_loss: 1.2060e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7492e-04 - val_loss: 1.2025e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7289e-04 - val_loss: 1.1989e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7085e-04 - val_loss: 1.1954e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6882e-04 - val_loss: 1.1919e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6679e-04 - val_loss: 1.1884e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6477e-04 - val_loss: 1.1849e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6276e-04 - val_loss: 1.1815e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6075e-04 - val_loss: 1.1781e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5875e-04 - val_loss: 1.1746e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5675e-04 - val_loss: 1.1712e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5475e-04 - val_loss: 1.1678e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5276e-04 - val_loss: 1.1645e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5077e-04 - val_loss: 1.1611e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4880e-04 - val_loss: 1.1577e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4682e-04 - val_loss: 1.1544e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4484e-04 - val_loss: 1.1511e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4287e-04 - val_loss: 1.1478e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4091e-04 - val_loss: 1.1445e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3896e-04 - val_loss: 1.1412e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.3701e-04 - val_loss: 1.1380e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3506e-04 - val_loss: 1.1347e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3312e-04 - val_loss: 1.1315e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3118e-04 - val_loss: 1.1283e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2925e-04 - val_loss: 1.1250e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2732e-04 - val_loss: 1.1219e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 7.2539e-04 - val_loss: 1.1187e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 7.2347e-04 - val_loss: 1.1155e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2156e-04 - val_loss: 1.1124e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1965e-04 - val_loss: 1.1093e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1774e-04 - val_loss: 1.1062e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1585e-04 - val_loss: 1.1031e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1395e-04 - val_loss: 1.1000e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1205e-04 - val_loss: 1.0970e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1017e-04 - val_loss: 1.0939e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.0830e-04 - val_loss: 1.0909e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0640e-04 - val_loss: 1.0878e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0453e-04 - val_loss: 1.0848e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0266e-04 - val_loss: 1.0818e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0080e-04 - val_loss: 1.0788e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9894e-04 - val_loss: 1.0758e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9709e-04 - val_loss: 1.0729e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 6.9524e-04 - val_loss: 1.0699e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9340e-04 - val_loss: 1.0670e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9155e-04 - val_loss: 1.0641e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8972e-04 - val_loss: 1.0612e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8789e-04 - val_loss: 1.0583e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8606e-04 - val_loss: 1.0554e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8424e-04 - val_loss: 1.0525e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8242e-04 - val_loss: 1.0496e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8061e-04 - val_loss: 1.0468e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7880e-04 - val_loss: 1.0439e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7699e-04 - val_loss: 1.0412e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7519e-04 - val_loss: 1.0383e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7339e-04 - val_loss: 1.0355e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7160e-04 - val_loss: 1.0327e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6981e-04 - val_loss: 1.0299e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6803e-04 - val_loss: 1.0272e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6625e-04 - val_loss: 1.0244e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.6447e-04 - val_loss: 1.0217e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6271e-04 - val_loss: 1.0189e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6095e-04 - val_loss: 1.0162e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5918e-04 - val_loss: 1.0135e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5743e-04 - val_loss: 1.0107e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5568e-04 - val_loss: 1.0081e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5393e-04 - val_loss: 1.0054e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5218e-04 - val_loss: 1.0027e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5045e-04 - val_loss: 1.0000e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4871e-04 - val_loss: 9.9740e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4698e-04 - val_loss: 9.9486e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4525e-04 - val_loss: 9.9219e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4353e-04 - val_loss: 9.8960e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4182e-04 - val_loss: 9.8701e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4011e-04 - val_loss: 9.8438e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3840e-04 - val_loss: 9.8183e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3669e-04 - val_loss: 9.7925e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 6.3498e-04 - val_loss: 9.7667e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3328e-04 - val_loss: 9.7415e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3160e-04 - val_loss: 9.7159e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2991e-04 - val_loss: 9.6905e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2823e-04 - val_loss: 9.6651e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2655e-04 - val_loss: 9.6398e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2488e-04 - val_loss: 9.6152e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2320e-04 - val_loss: 9.5900e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2154e-04 - val_loss: 9.5652e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1988e-04 - val_loss: 9.5403e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1822e-04 - val_loss: 9.5161e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1656e-04 - val_loss: 9.4917e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1492e-04 - val_loss: 9.4671e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1327e-04 - val_loss: 9.4424e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.1163e-04 - val_loss: 9.4184e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0999e-04 - val_loss: 9.3941e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0836e-04 - val_loss: 9.3697e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0672e-04 - val_loss: 9.3455e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0510e-04 - val_loss: 9.3218e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0348e-04 - val_loss: 9.2974e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.0187e-04 - val_loss: 9.2739e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0025e-04 - val_loss: 9.2508e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9864e-04 - val_loss: 9.2273e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9704e-04 - val_loss: 9.2034e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9543e-04 - val_loss: 9.1800e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9384e-04 - val_loss: 9.1569e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.9225e-04 - val_loss: 9.1337e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9066e-04 - val_loss: 9.1108e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8908e-04 - val_loss: 9.0875e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8749e-04 - val_loss: 9.0646e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8592e-04 - val_loss: 9.0416e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8435e-04 - val_loss: 9.0184e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8278e-04 - val_loss: 8.9956e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8121e-04 - val_loss: 8.9733e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7966e-04 - val_loss: 8.9509e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 5.7810e-04 - val_loss: 8.9284e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7655e-04 - val_loss: 8.9058e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7499e-04 - val_loss: 8.8835e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7345e-04 - val_loss: 8.8614e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7191e-04 - val_loss: 8.8389e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7038e-04 - val_loss: 8.8173e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6885e-04 - val_loss: 8.7949e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6732e-04 - val_loss: 8.7727e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6579e-04 - val_loss: 8.7511e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6427e-04 - val_loss: 8.7291e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6275e-04 - val_loss: 8.7076e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6125e-04 - val_loss: 8.6862e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5973e-04 - val_loss: 8.6642e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5823e-04 - val_loss: 8.6427e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5672e-04 - val_loss: 8.6217e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5523e-04 - val_loss: 8.6000e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5374e-04 - val_loss: 8.5789e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5224e-04 - val_loss: 8.5576e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5076e-04 - val_loss: 8.5363e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4928e-04 - val_loss: 8.5149e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4780e-04 - val_loss: 8.4937e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4632e-04 - val_loss: 8.4732e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4485e-04 - val_loss: 8.4524e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4339e-04 - val_loss: 8.4320e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4192e-04 - val_loss: 8.4110e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4046e-04 - val_loss: 8.3906e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3901e-04 - val_loss: 8.3694e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3756e-04 - val_loss: 8.3491e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3611e-04 - val_loss: 8.3281e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3466e-04 - val_loss: 8.3075e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3322e-04 - val_loss: 8.2870e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3179e-04 - val_loss: 8.2671e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.3036e-04 - val_loss: 8.2468e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2893e-04 - val_loss: 8.2267e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2751e-04 - val_loss: 8.2063e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2608e-04 - val_loss: 8.1863e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2467e-04 - val_loss: 8.1665e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2326e-04 - val_loss: 8.1467e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2184e-04 - val_loss: 8.1265e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2044e-04 - val_loss: 8.1064e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1904e-04 - val_loss: 8.0871e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1763e-04 - val_loss: 8.0673e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1624e-04 - val_loss: 8.0474e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1485e-04 - val_loss: 8.0282e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1346e-04 - val_loss: 8.0087e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1208e-04 - val_loss: 7.9891e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1069e-04 - val_loss: 7.9701e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0931e-04 - val_loss: 7.9505e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0794e-04 - val_loss: 7.9317e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0657e-04 - val_loss: 7.9118e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0520e-04 - val_loss: 7.8932e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0384e-04 - val_loss: 7.8735e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0248e-04 - val_loss: 7.8549e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0113e-04 - val_loss: 7.8360e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9978e-04 - val_loss: 7.8167e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9843e-04 - val_loss: 7.7984e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9708e-04 - val_loss: 7.7791e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9574e-04 - val_loss: 7.7604e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9440e-04 - val_loss: 7.7419e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9307e-04 - val_loss: 7.7229e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9174e-04 - val_loss: 7.7041e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 4.9041e-04 - val_loss: 7.6861e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8908e-04 - val_loss: 7.6672e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8776e-04 - val_loss: 7.6485e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8645e-04 - val_loss: 7.6299e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8514e-04 - val_loss: 7.6117e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8383e-04 - val_loss: 7.5933e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8252e-04 - val_loss: 7.5755e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8122e-04 - val_loss: 7.5570e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.7992e-04 - val_loss: 7.5386e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7863e-04 - val_loss: 7.5208e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7733e-04 - val_loss: 7.5027e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7604e-04 - val_loss: 7.4845e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7475e-04 - val_loss: 7.4664e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7348e-04 - val_loss: 7.4487e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7220e-04 - val_loss: 7.4307e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7093e-04 - val_loss: 7.4131e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6965e-04 - val_loss: 7.3953e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6838e-04 - val_loss: 7.3777e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6712e-04 - val_loss: 7.3598e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6586e-04 - val_loss: 7.3422e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6460e-04 - val_loss: 7.3247e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6335e-04 - val_loss: 7.3071e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6210e-04 - val_loss: 7.2894e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6085e-04 - val_loss: 7.2715e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5961e-04 - val_loss: 7.2545e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5836e-04 - val_loss: 7.2372e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5713e-04 - val_loss: 7.2198e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5589e-04 - val_loss: 7.2024e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5466e-04 - val_loss: 7.1855e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5344e-04 - val_loss: 7.1679e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5221e-04 - val_loss: 7.1509e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5099e-04 - val_loss: 7.1339e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4977e-04 - val_loss: 7.1168e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4856e-04 - val_loss: 7.0999e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4735e-04 - val_loss: 7.0826e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4614e-04 - val_loss: 7.0659e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4493e-04 - val_loss: 7.0489e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4373e-04 - val_loss: 7.0320e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4254e-04 - val_loss: 7.0151e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4134e-04 - val_loss: 6.9983e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4015e-04 - val_loss: 6.9814e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3896e-04 - val_loss: 6.9651e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3778e-04 - val_loss: 6.9486e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3660e-04 - val_loss: 6.9315e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3542e-04 - val_loss: 6.9151e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3424e-04 - val_loss: 6.8986e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3308e-04 - val_loss: 6.8820e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3190e-04 - val_loss: 6.8655e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3074e-04 - val_loss: 6.8490e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2958e-04 - val_loss: 6.8328e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2842e-04 - val_loss: 6.8162e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2726e-04 - val_loss: 6.7998e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2611e-04 - val_loss: 6.7836e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 4.2496e-04 - val_loss: 6.7673e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2382e-04 - val_loss: 6.7516e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2268e-04 - val_loss: 6.7353e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2153e-04 - val_loss: 6.7193e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2039e-04 - val_loss: 6.7029e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1926e-04 - val_loss: 6.6869e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.1813e-04 - val_loss: 6.6709e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1700e-04 - val_loss: 6.6552e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1588e-04 - val_loss: 6.6391e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1476e-04 - val_loss: 6.6238e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1364e-04 - val_loss: 6.6076e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1253e-04 - val_loss: 6.5915e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1142e-04 - val_loss: 6.5759e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1031e-04 - val_loss: 6.5597e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0920e-04 - val_loss: 6.5442e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0810e-04 - val_loss: 6.5285e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0700e-04 - val_loss: 6.5125e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0590e-04 - val_loss: 6.4972e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0481e-04 - val_loss: 6.4815e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0372e-04 - val_loss: 6.4660e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0263e-04 - val_loss: 6.4507e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0155e-04 - val_loss: 6.4352e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0047e-04 - val_loss: 6.4200e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9939e-04 - val_loss: 6.4046e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9831e-04 - val_loss: 6.3890e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9724e-04 - val_loss: 6.3737e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9617e-04 - val_loss: 6.3581e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9510e-04 - val_loss: 6.3432e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9404e-04 - val_loss: 6.3280e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9298e-04 - val_loss: 6.3121e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9193e-04 - val_loss: 6.2975e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9087e-04 - val_loss: 6.2822e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8982e-04 - val_loss: 6.2671e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8878e-04 - val_loss: 6.2521e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8773e-04 - val_loss: 6.2373e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8669e-04 - val_loss: 6.2222e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8564e-04 - val_loss: 6.2071e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8461e-04 - val_loss: 6.1921e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8358e-04 - val_loss: 6.1774e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8254e-04 - val_loss: 6.1626e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8152e-04 - val_loss: 6.1477e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8049e-04 - val_loss: 6.1329e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7947e-04 - val_loss: 6.1177e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7846e-04 - val_loss: 6.1030e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7743e-04 - val_loss: 6.0884e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7642e-04 - val_loss: 6.0734e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7541e-04 - val_loss: 6.0591e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7441e-04 - val_loss: 6.0444e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7340e-04 - val_loss: 6.0299e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7240e-04 - val_loss: 6.0153e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7140e-04 - val_loss: 6.0007e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7041e-04 - val_loss: 5.9864e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6942e-04 - val_loss: 5.9717e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6842e-04 - val_loss: 5.9574e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6744e-04 - val_loss: 5.9432e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6645e-04 - val_loss: 5.9288e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6547e-04 - val_loss: 5.9139e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6449e-04 - val_loss: 5.9000e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6351e-04 - val_loss: 5.8853e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6254e-04 - val_loss: 5.8714e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6157e-04 - val_loss: 5.8568e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6060e-04 - val_loss: 5.8425e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5963e-04 - val_loss: 5.8284e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5867e-04 - val_loss: 5.8141e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5771e-04 - val_loss: 5.8003e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5676e-04 - val_loss: 5.7862e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5581e-04 - val_loss: 5.7720e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5485e-04 - val_loss: 5.7581e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5391e-04 - val_loss: 5.7440e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5296e-04 - val_loss: 5.7303e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5202e-04 - val_loss: 5.7161e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5108e-04 - val_loss: 5.7020e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5014e-04 - val_loss: 5.6881e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4920e-04 - val_loss: 5.6742e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4827e-04 - val_loss: 5.6603e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4734e-04 - val_loss: 5.6464e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4641e-04 - val_loss: 5.6331e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4549e-04 - val_loss: 5.6191e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4457e-04 - val_loss: 5.6054e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4366e-04 - val_loss: 5.5920e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4274e-04 - val_loss: 5.5781e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4182e-04 - val_loss: 5.5647e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4092e-04 - val_loss: 5.5507e-05\n",
      "2.90303687506821e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.89171654, -0.76205015,  0.08254873,  0.6707255 ,  0.2554909 ],\n",
       "        [-0.48835367,  0.5092173 , -0.33163166,  0.36471644, -0.01312719],\n",
       "        [ 0.66100895,  0.8473332 , -0.54665524,  1.4670547 ,  1.1479717 ]],\n",
       "       dtype=float32),\n",
       " array([-0.51324785, -0.6671838 , -0.81470305,  0.6924536 ,  0.5144541 ],\n",
       "       dtype=float32),\n",
       " array([[-0.47093776, -0.23187377,  0.01583179, -0.95371944,  0.71973705],\n",
       "        [-0.9090844 , -0.17508113,  0.40705237, -0.72806317, -0.1065243 ],\n",
       "        [-0.44984707, -0.30987573, -0.5420416 , -0.08325931,  0.06469244],\n",
       "        [ 0.49054736, -0.17894533, -0.32699907,  0.78325397,  0.21815884],\n",
       "        [-0.6837565 , -0.7079664 , -0.46730724,  0.42671806,  0.02811091]],\n",
       "       dtype=float32),\n",
       " array([ 0.9575484 , -0.92973846, -0.8974282 ,  0.9691136 , -0.8821732 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.0957047 ],\n",
       "        [-0.42902774],\n",
       "        [-0.5003522 ],\n",
       "        [ 0.98112893],\n",
       "        [-0.5037892 ]], dtype=float32),\n",
       " array([0.9872191], dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_1(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure1_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 36.1776 - val_loss: 34.7250\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.0812 - val_loss: 31.7998\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.1923 - val_loss: 28.9888\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.4729 - val_loss: 25.5723\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 22.8418 - val_loss: 20.9814\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 17.5884 - val_loss: 14.1268\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12.0672 - val_loss: 6.8419\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9477 - val_loss: 1.9793\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1226 - val_loss: 0.8190\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.5438 - val_loss: 2.5025\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3333 - val_loss: 4.9333\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6533 - val_loss: 5.8203\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0022 - val_loss: 4.6393\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9601 - val_loss: 2.5021\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3870 - val_loss: 0.8358\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3856 - val_loss: 0.4604\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4320 - val_loss: 0.9772\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9755 - val_loss: 1.3420\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2265 - val_loss: 1.2237\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0693 - val_loss: 0.8577\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.7466 - val_loss: 0.4974\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4554 - val_loss: 0.2639\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2706 - val_loss: 0.1690\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1876 - val_loss: 0.1605\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1690 - val_loss: 0.1785\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.1841 - val_loss: 0.1919\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2143 - val_loss: 0.1918\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2376 - val_loss: 0.1802\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2413 - val_loss: 0.1627\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2321 - val_loss: 0.1404\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2131 - val_loss: 0.1182\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1805 - val_loss: 0.1104\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1410 - val_loss: 0.1226\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1067 - val_loss: 0.1422\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0824 - val_loss: 0.1558\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0700 - val_loss: 0.1635\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0707 - val_loss: 0.1711\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0797 - val_loss: 0.1802\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0879 - val_loss: 0.1867\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0903 - val_loss: 0.1832\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0858 - val_loss: 0.1639\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0745 - val_loss: 0.1309\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0577 - val_loss: 0.0947\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0404 - val_loss: 0.0657\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0472\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0187 - val_loss: 0.0374\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0161 - val_loss: 0.0335\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0189 - val_loss: 0.0323\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0244 - val_loss: 0.0315\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0292 - val_loss: 0.0306\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0315 - val_loss: 0.0288\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0306 - val_loss: 0.0259\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0265 - val_loss: 0.0228\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0201\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0200\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0202\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0059 - val_loss: 0.0213\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0071 - val_loss: 0.0232\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0254\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0269\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0265\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0107 - val_loss: 0.0237\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0093 - val_loss: 0.0195\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0153\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 0.0122\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0102\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0091\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0082\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0067\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9880e-04 - val_loss: 0.0017\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9926e-04 - val_loss: 0.0016\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9523e-04 - val_loss: 0.0016\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8406e-04 - val_loss: 0.0015\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6415e-04 - val_loss: 0.0014\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3676e-04 - val_loss: 0.0014\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0718e-04 - val_loss: 0.0013\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8015e-04 - val_loss: 0.0012\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5786e-04 - val_loss: 0.0012\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4161e-04 - val_loss: 0.0011\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 8.3131e-04 - val_loss: 0.0011\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2433e-04 - val_loss: 0.0010\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1755e-04 - val_loss: 0.0010\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0930e-04 - val_loss: 9.8024e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9864e-04 - val_loss: 9.5926e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8512e-04 - val_loss: 9.3834e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6982e-04 - val_loss: 9.2081e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5449e-04 - val_loss: 9.0959e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4020e-04 - val_loss: 9.0517e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2751e-04 - val_loss: 9.0472e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1683e-04 - val_loss: 9.0312e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0786e-04 - val_loss: 8.9598e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9968e-04 - val_loss: 8.8276e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9165e-04 - val_loss: 8.6606e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8341e-04 - val_loss: 8.4875e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7463e-04 - val_loss: 8.3177e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6528e-04 - val_loss: 8.1395e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5573e-04 - val_loss: 7.9371e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4631e-04 - val_loss: 7.7085e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3719e-04 - val_loss: 7.4717e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2857e-04 - val_loss: 7.2526e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2054e-04 - val_loss: 7.0677e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1302e-04 - val_loss: 6.9171e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0583e-04 - val_loss: 6.7916e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9887e-04 - val_loss: 6.6786e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9205e-04 - val_loss: 6.5710e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8521e-04 - val_loss: 6.4699e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.7835e-04 - val_loss: 6.3809e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7153e-04 - val_loss: 6.3075e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.6476e-04 - val_loss: 6.2478e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5810e-04 - val_loss: 6.1946e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5162e-04 - val_loss: 6.1381e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4539e-04 - val_loss: 6.0733e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3937e-04 - val_loss: 6.0002e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3356e-04 - val_loss: 5.9241e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2796e-04 - val_loss: 5.8483e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2247e-04 - val_loss: 5.7735e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1708e-04 - val_loss: 5.6958e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1174e-04 - val_loss: 5.6128e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0644e-04 - val_loss: 5.5239e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0120e-04 - val_loss: 5.4333e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9604e-04 - val_loss: 5.3452e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9099e-04 - val_loss: 5.2632e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8608e-04 - val_loss: 5.1877e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8130e-04 - val_loss: 5.1169e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7666e-04 - val_loss: 5.0493e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.7214e-04 - val_loss: 4.9839e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6771e-04 - val_loss: 4.9218e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6335e-04 - val_loss: 4.8641e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5906e-04 - val_loss: 4.8113e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5482e-04 - val_loss: 4.7627e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5063e-04 - val_loss: 4.7163e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4652e-04 - val_loss: 4.6715e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4249e-04 - val_loss: 4.6271e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3854e-04 - val_loss: 4.5832e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3470e-04 - val_loss: 4.5403e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3093e-04 - val_loss: 4.4983e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2724e-04 - val_loss: 4.4572e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2361e-04 - val_loss: 4.4157e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2005e-04 - val_loss: 4.3732e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1654e-04 - val_loss: 4.3300e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1308e-04 - val_loss: 4.2865e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0968e-04 - val_loss: 4.2432e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0634e-04 - val_loss: 4.2007e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0306e-04 - val_loss: 4.1590e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9984e-04 - val_loss: 4.1179e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9668e-04 - val_loss: 4.0779e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9358e-04 - val_loss: 4.0392e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9053e-04 - val_loss: 4.0019e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8753e-04 - val_loss: 3.9662e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8459e-04 - val_loss: 3.9324e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8168e-04 - val_loss: 3.9002e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7884e-04 - val_loss: 3.8697e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7602e-04 - val_loss: 3.8407e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7325e-04 - val_loss: 3.8130e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7054e-04 - val_loss: 3.7862e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6787e-04 - val_loss: 3.7605e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6524e-04 - val_loss: 3.7354e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.6266e-04 - val_loss: 3.7105e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6011e-04 - val_loss: 3.6861e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5761e-04 - val_loss: 3.6618e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5514e-04 - val_loss: 3.6375e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5272e-04 - val_loss: 3.6132e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5033e-04 - val_loss: 3.5890e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.4798e-04 - val_loss: 3.5647e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4565e-04 - val_loss: 3.5405e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4338e-04 - val_loss: 3.5168e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4113e-04 - val_loss: 3.4934e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3892e-04 - val_loss: 3.4709e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3674e-04 - val_loss: 3.4490e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.3459e-04 - val_loss: 3.4277e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3248e-04 - val_loss: 3.4074e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3040e-04 - val_loss: 3.3878e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2835e-04 - val_loss: 3.3691e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2632e-04 - val_loss: 3.3511e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2433e-04 - val_loss: 3.3340e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2237e-04 - val_loss: 3.3176e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2043e-04 - val_loss: 3.3015e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1851e-04 - val_loss: 3.2860e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1663e-04 - val_loss: 3.2704e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1478e-04 - val_loss: 3.2553e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.1295e-04 - val_loss: 3.2403e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1114e-04 - val_loss: 3.2256e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0936e-04 - val_loss: 3.2109e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0760e-04 - val_loss: 3.1962e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0587e-04 - val_loss: 3.1817e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0416e-04 - val_loss: 3.1671e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0248e-04 - val_loss: 3.1530e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0081e-04 - val_loss: 3.1390e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9917e-04 - val_loss: 3.1254e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9756e-04 - val_loss: 3.1122e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9595e-04 - val_loss: 3.0995e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9438e-04 - val_loss: 3.0869e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9282e-04 - val_loss: 3.0749e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9128e-04 - val_loss: 3.0631e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8976e-04 - val_loss: 3.0519e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8826e-04 - val_loss: 3.0409e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8679e-04 - val_loss: 3.0304e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8532e-04 - val_loss: 3.0199e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8388e-04 - val_loss: 3.0095e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8246e-04 - val_loss: 2.9995e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8105e-04 - val_loss: 2.9896e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7966e-04 - val_loss: 2.9798e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7829e-04 - val_loss: 2.9701e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7693e-04 - val_loss: 2.9607e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7560e-04 - val_loss: 2.9512e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7427e-04 - val_loss: 2.9418e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7296e-04 - val_loss: 2.9326e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7167e-04 - val_loss: 2.9235e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7039e-04 - val_loss: 2.9146e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.6913e-04 - val_loss: 2.9059e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6788e-04 - val_loss: 2.8975e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6665e-04 - val_loss: 2.8889e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6543e-04 - val_loss: 2.8808e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6422e-04 - val_loss: 2.8727e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 2.6303e-04 - val_loss: 2.8649e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6185e-04 - val_loss: 2.8573e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6069e-04 - val_loss: 2.8498e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.5954e-04 - val_loss: 2.8423e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5839e-04 - val_loss: 2.8352e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5727e-04 - val_loss: 2.8280e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5616e-04 - val_loss: 2.8209e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5505e-04 - val_loss: 2.8139e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5396e-04 - val_loss: 2.8072e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5289e-04 - val_loss: 2.8003e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5181e-04 - val_loss: 2.7936e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5076e-04 - val_loss: 2.7869e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 2.4972e-04 - val_loss: 2.7805e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4868e-04 - val_loss: 2.7740e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4766e-04 - val_loss: 2.7677e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4664e-04 - val_loss: 2.7615e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4564e-04 - val_loss: 2.7553e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4465e-04 - val_loss: 2.7491e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.4366e-04 - val_loss: 2.7430e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4270e-04 - val_loss: 2.7371e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4173e-04 - val_loss: 2.7313e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4078e-04 - val_loss: 2.7256e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3984e-04 - val_loss: 2.7198e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3891e-04 - val_loss: 2.7142e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3798e-04 - val_loss: 2.7087e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3707e-04 - val_loss: 2.7031e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3616e-04 - val_loss: 2.6979e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 2.3526e-04 - val_loss: 2.6925e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3437e-04 - val_loss: 2.6871e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 2.3349e-04 - val_loss: 2.6819e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3261e-04 - val_loss: 2.6768e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3176e-04 - val_loss: 2.6715e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3089e-04 - val_loss: 2.6666e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3005e-04 - val_loss: 2.6615e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2920e-04 - val_loss: 2.6566e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2837e-04 - val_loss: 2.6516e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2755e-04 - val_loss: 2.6468e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2673e-04 - val_loss: 2.6418e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2592e-04 - val_loss: 2.6370e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2512e-04 - val_loss: 2.6324e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2432e-04 - val_loss: 2.6276e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.2353e-04 - val_loss: 2.6229e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2275e-04 - val_loss: 2.6183e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2197e-04 - val_loss: 2.6138e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2120e-04 - val_loss: 2.6092e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2045e-04 - val_loss: 2.6047e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.1969e-04 - val_loss: 2.6003e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1894e-04 - val_loss: 2.5958e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1820e-04 - val_loss: 2.5914e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1746e-04 - val_loss: 2.5870e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1673e-04 - val_loss: 2.5827e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1601e-04 - val_loss: 2.5785e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.1529e-04 - val_loss: 2.5742e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1458e-04 - val_loss: 2.5699e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1387e-04 - val_loss: 2.5657e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1317e-04 - val_loss: 2.5616e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1248e-04 - val_loss: 2.5574e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1178e-04 - val_loss: 2.5534e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1111e-04 - val_loss: 2.5493e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1043e-04 - val_loss: 2.5451e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0976e-04 - val_loss: 2.5410e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0909e-04 - val_loss: 2.5370e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0843e-04 - val_loss: 2.5331e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0776e-04 - val_loss: 2.5291e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0711e-04 - val_loss: 2.5252e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0647e-04 - val_loss: 2.5212e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0583e-04 - val_loss: 2.5173e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0519e-04 - val_loss: 2.5135e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0456e-04 - val_loss: 2.5096e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0393e-04 - val_loss: 2.5057e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0331e-04 - val_loss: 2.5018e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0269e-04 - val_loss: 2.4981e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0208e-04 - val_loss: 2.4942e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0147e-04 - val_loss: 2.4907e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0087e-04 - val_loss: 2.4868e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0027e-04 - val_loss: 2.4830e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9967e-04 - val_loss: 2.4793e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9908e-04 - val_loss: 2.4757e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9849e-04 - val_loss: 2.4720e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9791e-04 - val_loss: 2.4682e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9733e-04 - val_loss: 2.4646e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9675e-04 - val_loss: 2.4610e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9619e-04 - val_loss: 2.4572e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9562e-04 - val_loss: 2.4537e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9506e-04 - val_loss: 2.4502e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9450e-04 - val_loss: 2.4465e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9394e-04 - val_loss: 2.4430e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9339e-04 - val_loss: 2.4394e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9285e-04 - val_loss: 2.4359e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9230e-04 - val_loss: 2.4324e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9177e-04 - val_loss: 2.4288e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9123e-04 - val_loss: 2.4253e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9069e-04 - val_loss: 2.4218e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9017e-04 - val_loss: 2.4184e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8964e-04 - val_loss: 2.4149e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8912e-04 - val_loss: 2.4114e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8860e-04 - val_loss: 2.4081e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8809e-04 - val_loss: 2.4046e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8757e-04 - val_loss: 2.4012e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8707e-04 - val_loss: 2.3977e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8656e-04 - val_loss: 2.3943e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8606e-04 - val_loss: 2.3909e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8556e-04 - val_loss: 2.3875e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8506e-04 - val_loss: 2.3841e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8457e-04 - val_loss: 2.3808e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8409e-04 - val_loss: 2.3773e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8360e-04 - val_loss: 2.3740e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8311e-04 - val_loss: 2.3708e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8263e-04 - val_loss: 2.3673e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8215e-04 - val_loss: 2.3641e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8168e-04 - val_loss: 2.3607e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8121e-04 - val_loss: 2.3575e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8074e-04 - val_loss: 2.3541e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8027e-04 - val_loss: 2.3508e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7981e-04 - val_loss: 2.3475e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7935e-04 - val_loss: 2.3442e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7889e-04 - val_loss: 2.3410e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.7843e-04 - val_loss: 2.3377e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7798e-04 - val_loss: 2.3345e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7753e-04 - val_loss: 2.3312e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7709e-04 - val_loss: 2.3279e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7664e-04 - val_loss: 2.3247e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7620e-04 - val_loss: 2.3215e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7576e-04 - val_loss: 2.3182e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7532e-04 - val_loss: 2.3150e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.7489e-04 - val_loss: 2.3119e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7446e-04 - val_loss: 2.3086e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.7403e-04 - val_loss: 2.3053e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7360e-04 - val_loss: 2.3022e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7317e-04 - val_loss: 2.2990e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7276e-04 - val_loss: 2.2958e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7233e-04 - val_loss: 2.2926e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7192e-04 - val_loss: 2.2895e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7150e-04 - val_loss: 2.2863e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7109e-04 - val_loss: 2.2832e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7068e-04 - val_loss: 2.2801e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7027e-04 - val_loss: 2.2768e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6986e-04 - val_loss: 2.2737e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6946e-04 - val_loss: 2.2706e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6906e-04 - val_loss: 2.2674e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6865e-04 - val_loss: 2.2643e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6826e-04 - val_loss: 2.2612e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6786e-04 - val_loss: 2.2580e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6747e-04 - val_loss: 2.2549e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6708e-04 - val_loss: 2.2518e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6669e-04 - val_loss: 2.2487e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6630e-04 - val_loss: 2.2457e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6591e-04 - val_loss: 2.2425e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6553e-04 - val_loss: 2.2395e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.6514e-04 - val_loss: 2.2364e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6477e-04 - val_loss: 2.2333e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6439e-04 - val_loss: 2.2301e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6401e-04 - val_loss: 2.2272e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.6364e-04 - val_loss: 2.2240e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6327e-04 - val_loss: 2.2210e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.6289e-04 - val_loss: 2.2180e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6253e-04 - val_loss: 2.2149e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6216e-04 - val_loss: 2.2118e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6179e-04 - val_loss: 2.2089e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6143e-04 - val_loss: 2.2057e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6107e-04 - val_loss: 2.2028e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6071e-04 - val_loss: 2.1997e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6035e-04 - val_loss: 2.1967e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6000e-04 - val_loss: 2.1936e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5964e-04 - val_loss: 2.1906e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5929e-04 - val_loss: 2.1876e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 1.5893e-04 - val_loss: 2.1846e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5859e-04 - val_loss: 2.1815e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5823e-04 - val_loss: 2.1787e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5789e-04 - val_loss: 2.1756e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5755e-04 - val_loss: 2.1727e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5721e-04 - val_loss: 2.1696e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5686e-04 - val_loss: 2.1666e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5652e-04 - val_loss: 2.1636e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5618e-04 - val_loss: 2.1608e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5585e-04 - val_loss: 2.1577e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5551e-04 - val_loss: 2.1548e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5518e-04 - val_loss: 2.1517e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5484e-04 - val_loss: 2.1489e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5452e-04 - val_loss: 2.1458e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5419e-04 - val_loss: 2.1428e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5386e-04 - val_loss: 2.1400e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5353e-04 - val_loss: 2.1370e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5321e-04 - val_loss: 2.1339e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5288e-04 - val_loss: 2.1311e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5256e-04 - val_loss: 2.1281e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5224e-04 - val_loss: 2.1252e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5192e-04 - val_loss: 2.1222e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5160e-04 - val_loss: 2.1193e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5128e-04 - val_loss: 2.1164e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5097e-04 - val_loss: 2.1136e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5066e-04 - val_loss: 2.1106e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5035e-04 - val_loss: 2.1078e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5003e-04 - val_loss: 2.1048e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 1.4972e-04 - val_loss: 2.1018e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4941e-04 - val_loss: 2.0989e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4910e-04 - val_loss: 2.0961e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4880e-04 - val_loss: 2.0933e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4850e-04 - val_loss: 2.0904e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4819e-04 - val_loss: 2.0874e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4789e-04 - val_loss: 2.0844e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4759e-04 - val_loss: 2.0817e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4729e-04 - val_loss: 2.0788e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4699e-04 - val_loss: 2.0760e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4669e-04 - val_loss: 2.0731e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4640e-04 - val_loss: 2.0701e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4610e-04 - val_loss: 2.0674e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4581e-04 - val_loss: 2.0645e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4552e-04 - val_loss: 2.0616e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4522e-04 - val_loss: 2.0588e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4494e-04 - val_loss: 2.0559e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4465e-04 - val_loss: 2.0532e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4436e-04 - val_loss: 2.0503e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4407e-04 - val_loss: 2.0473e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4379e-04 - val_loss: 2.0445e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4350e-04 - val_loss: 2.0418e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4322e-04 - val_loss: 2.0389e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4293e-04 - val_loss: 2.0361e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4265e-04 - val_loss: 2.0333e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4237e-04 - val_loss: 2.0304e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4209e-04 - val_loss: 2.0276e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4181e-04 - val_loss: 2.0248e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4154e-04 - val_loss: 2.0221e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4126e-04 - val_loss: 2.0191e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4099e-04 - val_loss: 2.0164e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4071e-04 - val_loss: 2.0136e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4044e-04 - val_loss: 2.0109e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4017e-04 - val_loss: 2.0081e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3990e-04 - val_loss: 2.0052e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3963e-04 - val_loss: 2.0025e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3936e-04 - val_loss: 1.9997e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3909e-04 - val_loss: 1.9970e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3883e-04 - val_loss: 1.9941e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3856e-04 - val_loss: 1.9914e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3829e-04 - val_loss: 1.9885e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3803e-04 - val_loss: 1.9858e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3777e-04 - val_loss: 1.9830e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3751e-04 - val_loss: 1.9802e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3724e-04 - val_loss: 1.9775e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3698e-04 - val_loss: 1.9748e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3673e-04 - val_loss: 1.9720e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3647e-04 - val_loss: 1.9692e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3621e-04 - val_loss: 1.9666e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3596e-04 - val_loss: 1.9638e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3570e-04 - val_loss: 1.9611e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3544e-04 - val_loss: 1.9583e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3519e-04 - val_loss: 1.9557e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3494e-04 - val_loss: 1.9529e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3469e-04 - val_loss: 1.9502e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3444e-04 - val_loss: 1.9475e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3419e-04 - val_loss: 1.9449e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3394e-04 - val_loss: 1.9420e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3369e-04 - val_loss: 1.9394e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3344e-04 - val_loss: 1.9366e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3319e-04 - val_loss: 1.9339e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.3295e-04 - val_loss: 1.9312e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3270e-04 - val_loss: 1.9285e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3246e-04 - val_loss: 1.9258e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3222e-04 - val_loss: 1.9232e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3198e-04 - val_loss: 1.9205e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3173e-04 - val_loss: 1.9178e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3149e-04 - val_loss: 1.9151e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.3125e-04 - val_loss: 1.9124e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3101e-04 - val_loss: 1.9098e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3077e-04 - val_loss: 1.9072e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3054e-04 - val_loss: 1.9045e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3029e-04 - val_loss: 1.9018e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3006e-04 - val_loss: 1.8991e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2982e-04 - val_loss: 1.8965e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2959e-04 - val_loss: 1.8938e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2935e-04 - val_loss: 1.8911e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2912e-04 - val_loss: 1.8885e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2889e-04 - val_loss: 1.8859e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2866e-04 - val_loss: 1.8833e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2843e-04 - val_loss: 1.8805e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2820e-04 - val_loss: 1.8780e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2797e-04 - val_loss: 1.8754e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2774e-04 - val_loss: 1.8728e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2751e-04 - val_loss: 1.8701e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2728e-04 - val_loss: 1.8674e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.2706e-04 - val_loss: 1.8649e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2683e-04 - val_loss: 1.8622e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2660e-04 - val_loss: 1.8596e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2638e-04 - val_loss: 1.8570e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2616e-04 - val_loss: 1.8544e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2594e-04 - val_loss: 1.8519e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2572e-04 - val_loss: 1.8492e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2549e-04 - val_loss: 1.8466e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2527e-04 - val_loss: 1.8441e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2505e-04 - val_loss: 1.8414e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2483e-04 - val_loss: 1.8388e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2461e-04 - val_loss: 1.8363e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2439e-04 - val_loss: 1.8337e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2418e-04 - val_loss: 1.8312e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2396e-04 - val_loss: 1.8287e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.2374e-04 - val_loss: 1.8260e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2353e-04 - val_loss: 1.8234e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2331e-04 - val_loss: 1.8208e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2310e-04 - val_loss: 1.8183e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2289e-04 - val_loss: 1.8158e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2267e-04 - val_loss: 1.8132e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2246e-04 - val_loss: 1.8107e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2225e-04 - val_loss: 1.8081e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2203e-04 - val_loss: 1.8057e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2183e-04 - val_loss: 1.8030e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2161e-04 - val_loss: 1.8006e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.2141e-04 - val_loss: 1.7980e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.2120e-04 - val_loss: 1.7955e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2099e-04 - val_loss: 1.7929e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2078e-04 - val_loss: 1.7905e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2058e-04 - val_loss: 1.7879e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2037e-04 - val_loss: 1.7854e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2016e-04 - val_loss: 1.7828e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1995e-04 - val_loss: 1.7804e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1975e-04 - val_loss: 1.7778e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1954e-04 - val_loss: 1.7754e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.1934e-04 - val_loss: 1.7728e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1914e-04 - val_loss: 1.7703e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1894e-04 - val_loss: 1.7678e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1874e-04 - val_loss: 1.7653e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1854e-04 - val_loss: 1.7628e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1834e-04 - val_loss: 1.7602e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1813e-04 - val_loss: 1.7578e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1794e-04 - val_loss: 1.7553e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1774e-04 - val_loss: 1.7529e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1754e-04 - val_loss: 1.7504e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1734e-04 - val_loss: 1.7479e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1715e-04 - val_loss: 1.7454e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1695e-04 - val_loss: 1.7430e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1675e-04 - val_loss: 1.7405e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1655e-04 - val_loss: 1.7381e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1636e-04 - val_loss: 1.7356e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1616e-04 - val_loss: 1.7332e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.1597e-04 - val_loss: 1.7307e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1578e-04 - val_loss: 1.7283e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1559e-04 - val_loss: 1.7258e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1539e-04 - val_loss: 1.7234e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1520e-04 - val_loss: 1.7210e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1501e-04 - val_loss: 1.7185e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1482e-04 - val_loss: 1.7161e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1463e-04 - val_loss: 1.7137e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1444e-04 - val_loss: 1.7113e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1425e-04 - val_loss: 1.7088e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1405e-04 - val_loss: 1.7063e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1387e-04 - val_loss: 1.7040e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1368e-04 - val_loss: 1.7016e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1349e-04 - val_loss: 1.6991e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1331e-04 - val_loss: 1.6967e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1312e-04 - val_loss: 1.6944e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1294e-04 - val_loss: 1.6919e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1275e-04 - val_loss: 1.6896e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1256e-04 - val_loss: 1.6871e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1237e-04 - val_loss: 1.6847e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1220e-04 - val_loss: 1.6824e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1201e-04 - val_loss: 1.6800e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1183e-04 - val_loss: 1.6776e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1164e-04 - val_loss: 1.6752e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1146e-04 - val_loss: 1.6728e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1128e-04 - val_loss: 1.6704e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1110e-04 - val_loss: 1.6681e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1092e-04 - val_loss: 1.6658e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1074e-04 - val_loss: 1.6633e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1056e-04 - val_loss: 1.6609e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1038e-04 - val_loss: 1.6586e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1020e-04 - val_loss: 1.6563e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1002e-04 - val_loss: 1.6539e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0984e-04 - val_loss: 1.6515e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0966e-04 - val_loss: 1.6491e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0949e-04 - val_loss: 1.6468e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0931e-04 - val_loss: 1.6445e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0913e-04 - val_loss: 1.6422e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0896e-04 - val_loss: 1.6399e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0878e-04 - val_loss: 1.6375e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0861e-04 - val_loss: 1.6351e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0843e-04 - val_loss: 1.6328e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0826e-04 - val_loss: 1.6305e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0808e-04 - val_loss: 1.6283e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0791e-04 - val_loss: 1.6258e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0774e-04 - val_loss: 1.6235e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0756e-04 - val_loss: 1.6212e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0740e-04 - val_loss: 1.6189e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0722e-04 - val_loss: 1.6166e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0705e-04 - val_loss: 1.6143e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0688e-04 - val_loss: 1.6120e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0671e-04 - val_loss: 1.6097e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.0654e-04 - val_loss: 1.6074e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0637e-04 - val_loss: 1.6051e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0620e-04 - val_loss: 1.6029e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0603e-04 - val_loss: 1.6005e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0586e-04 - val_loss: 1.5982e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0569e-04 - val_loss: 1.5959e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0552e-04 - val_loss: 1.5936e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0535e-04 - val_loss: 1.5913e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.0519e-04 - val_loss: 1.5890e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0502e-04 - val_loss: 1.5868e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0486e-04 - val_loss: 1.5846e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0469e-04 - val_loss: 1.5822e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0452e-04 - val_loss: 1.5800e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0436e-04 - val_loss: 1.5778e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0420e-04 - val_loss: 1.5755e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0403e-04 - val_loss: 1.5733e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0387e-04 - val_loss: 1.5710e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0370e-04 - val_loss: 1.5686e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0354e-04 - val_loss: 1.5665e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0338e-04 - val_loss: 1.5643e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0322e-04 - val_loss: 1.5620e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0305e-04 - val_loss: 1.5598e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0289e-04 - val_loss: 1.5576e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0273e-04 - val_loss: 1.5553e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0257e-04 - val_loss: 1.5531e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0241e-04 - val_loss: 1.5508e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0225e-04 - val_loss: 1.5486e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0209e-04 - val_loss: 1.5463e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0192e-04 - val_loss: 1.5441e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0177e-04 - val_loss: 1.5419e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0161e-04 - val_loss: 1.5397e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0145e-04 - val_loss: 1.5375e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0129e-04 - val_loss: 1.5353e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0113e-04 - val_loss: 1.5331e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0098e-04 - val_loss: 1.5308e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0082e-04 - val_loss: 1.5287e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0066e-04 - val_loss: 1.5264e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0051e-04 - val_loss: 1.5242e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0035e-04 - val_loss: 1.5221e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0019e-04 - val_loss: 1.5199e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0004e-04 - val_loss: 1.5177e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9882e-05 - val_loss: 1.5155e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9729e-05 - val_loss: 1.5133e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9575e-05 - val_loss: 1.5111e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 9.9417e-05 - val_loss: 1.5090e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.9265e-05 - val_loss: 1.5068e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9112e-05 - val_loss: 1.5047e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8957e-05 - val_loss: 1.5024e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8805e-05 - val_loss: 1.5002e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8652e-05 - val_loss: 1.4981e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8502e-05 - val_loss: 1.4960e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8349e-05 - val_loss: 1.4938e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8198e-05 - val_loss: 1.4916e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8044e-05 - val_loss: 1.4894e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7894e-05 - val_loss: 1.4873e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7741e-05 - val_loss: 1.4851e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7592e-05 - val_loss: 1.4830e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7442e-05 - val_loss: 1.4809e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7293e-05 - val_loss: 1.4787e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7142e-05 - val_loss: 1.4766e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6996e-05 - val_loss: 1.4744e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6849e-05 - val_loss: 1.4723e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6698e-05 - val_loss: 1.4702e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6547e-05 - val_loss: 1.4680e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6400e-05 - val_loss: 1.4659e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6251e-05 - val_loss: 1.4637e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6103e-05 - val_loss: 1.4617e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5956e-05 - val_loss: 1.4595e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5809e-05 - val_loss: 1.4575e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5663e-05 - val_loss: 1.4553e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5521e-05 - val_loss: 1.4532e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5372e-05 - val_loss: 1.4511e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5229e-05 - val_loss: 1.4490e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5084e-05 - val_loss: 1.4469e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4939e-05 - val_loss: 1.4447e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4791e-05 - val_loss: 1.4427e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4647e-05 - val_loss: 1.4405e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4503e-05 - val_loss: 1.4385e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4361e-05 - val_loss: 1.4364e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4217e-05 - val_loss: 1.4344e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4071e-05 - val_loss: 1.4322e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3928e-05 - val_loss: 1.4302e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3788e-05 - val_loss: 1.4280e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3644e-05 - val_loss: 1.4260e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3503e-05 - val_loss: 1.4239e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3360e-05 - val_loss: 1.4218e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3219e-05 - val_loss: 1.4197e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3078e-05 - val_loss: 1.4177e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2939e-05 - val_loss: 1.4155e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2796e-05 - val_loss: 1.4135e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2655e-05 - val_loss: 1.4114e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2517e-05 - val_loss: 1.4094e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2376e-05 - val_loss: 1.4073e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2235e-05 - val_loss: 1.4053e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2095e-05 - val_loss: 1.4032e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1954e-05 - val_loss: 1.4013e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1815e-05 - val_loss: 1.3991e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1680e-05 - val_loss: 1.3971e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1540e-05 - val_loss: 1.3951e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1402e-05 - val_loss: 1.3931e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1266e-05 - val_loss: 1.3910e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.1128e-05 - val_loss: 1.3889e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0988e-05 - val_loss: 1.3869e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0850e-05 - val_loss: 1.3848e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0715e-05 - val_loss: 1.3828e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0577e-05 - val_loss: 1.3808e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0444e-05 - val_loss: 1.3788e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0304e-05 - val_loss: 1.3768e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0168e-05 - val_loss: 1.3748e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.0036e-05 - val_loss: 1.3727e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9897e-05 - val_loss: 1.3707e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9763e-05 - val_loss: 1.3686e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9628e-05 - val_loss: 1.3667e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9493e-05 - val_loss: 1.3647e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9358e-05 - val_loss: 1.3627e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9225e-05 - val_loss: 1.3606e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9094e-05 - val_loss: 1.3587e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8959e-05 - val_loss: 1.3567e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.8826e-05 - val_loss: 1.3546e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8692e-05 - val_loss: 1.3527e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8559e-05 - val_loss: 1.3507e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8428e-05 - val_loss: 1.3487e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8295e-05 - val_loss: 1.3467e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8160e-05 - val_loss: 1.3447e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8029e-05 - val_loss: 1.3428e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7902e-05 - val_loss: 1.3407e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.7769e-05 - val_loss: 1.3387e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7633e-05 - val_loss: 1.3368e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7506e-05 - val_loss: 1.3348e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7375e-05 - val_loss: 1.3328e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7240e-05 - val_loss: 1.3309e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7112e-05 - val_loss: 1.3289e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6982e-05 - val_loss: 1.3268e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6853e-05 - val_loss: 1.3249e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6725e-05 - val_loss: 1.3231e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6597e-05 - val_loss: 1.3210e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6464e-05 - val_loss: 1.3191e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6335e-05 - val_loss: 1.3171e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6207e-05 - val_loss: 1.3151e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.6078e-05 - val_loss: 1.3132e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5950e-05 - val_loss: 1.3113e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5823e-05 - val_loss: 1.3093e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5695e-05 - val_loss: 1.3074e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5566e-05 - val_loss: 1.3055e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5438e-05 - val_loss: 1.3035e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5313e-05 - val_loss: 1.3016e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5185e-05 - val_loss: 1.2997e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5062e-05 - val_loss: 1.2977e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4933e-05 - val_loss: 1.2957e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4808e-05 - val_loss: 1.2938e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4680e-05 - val_loss: 1.2919e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4557e-05 - val_loss: 1.2900e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4429e-05 - val_loss: 1.2880e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4302e-05 - val_loss: 1.2861e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4179e-05 - val_loss: 1.2842e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4054e-05 - val_loss: 1.2824e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3929e-05 - val_loss: 1.2804e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3804e-05 - val_loss: 1.2784e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3678e-05 - val_loss: 1.2764e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3553e-05 - val_loss: 1.2747e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3433e-05 - val_loss: 1.2728e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3311e-05 - val_loss: 1.2709e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.3183e-05 - val_loss: 1.2690e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3060e-05 - val_loss: 1.2671e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2938e-05 - val_loss: 1.2651e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2815e-05 - val_loss: 1.2633e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2692e-05 - val_loss: 1.2614e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2571e-05 - val_loss: 1.2595e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2451e-05 - val_loss: 1.2576e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.2324e-05 - val_loss: 1.2557e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2203e-05 - val_loss: 1.2538e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2082e-05 - val_loss: 1.2520e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.1963e-05 - val_loss: 1.2501e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1840e-05 - val_loss: 1.2482e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1718e-05 - val_loss: 1.2463e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1596e-05 - val_loss: 1.2444e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1474e-05 - val_loss: 1.2426e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.1356e-05 - val_loss: 1.2408e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.1238e-05 - val_loss: 1.2389e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.1120e-05 - val_loss: 1.2370e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0997e-05 - val_loss: 1.2352e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 8.0878e-05 - val_loss: 1.2333e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0759e-05 - val_loss: 1.2314e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0638e-05 - val_loss: 1.2295e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0516e-05 - val_loss: 1.2277e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0402e-05 - val_loss: 1.2259e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0281e-05 - val_loss: 1.2240e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0162e-05 - val_loss: 1.2221e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 8.0045e-05 - val_loss: 1.2203e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9928e-05 - val_loss: 1.2185e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9808e-05 - val_loss: 1.2167e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.9695e-05 - val_loss: 1.2148e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9579e-05 - val_loss: 1.2129e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9455e-05 - val_loss: 1.2111e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9339e-05 - val_loss: 1.2093e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9225e-05 - val_loss: 1.2074e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9107e-05 - val_loss: 1.2057e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8989e-05 - val_loss: 1.2038e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8872e-05 - val_loss: 1.2021e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8760e-05 - val_loss: 1.2002e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8642e-05 - val_loss: 1.1984e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8524e-05 - val_loss: 1.1965e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8409e-05 - val_loss: 1.1947e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8293e-05 - val_loss: 1.1929e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8181e-05 - val_loss: 1.1912e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8065e-05 - val_loss: 1.1892e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7948e-05 - val_loss: 1.1875e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.7835e-05 - val_loss: 1.1857e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 7.7720e-05 - val_loss: 1.1839e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 7.7604e-05 - val_loss: 1.1820e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 7.7490e-05 - val_loss: 1.1802e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7377e-05 - val_loss: 1.1784e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7264e-05 - val_loss: 1.1766e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7149e-05 - val_loss: 1.1748e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7033e-05 - val_loss: 1.1731e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6923e-05 - val_loss: 1.1713e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6809e-05 - val_loss: 1.1696e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.6697e-05 - val_loss: 1.1678e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6584e-05 - val_loss: 1.1659e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6471e-05 - val_loss: 1.1642e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6357e-05 - val_loss: 1.1624e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6248e-05 - val_loss: 1.1606e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6133e-05 - val_loss: 1.1588e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6020e-05 - val_loss: 1.1570e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5912e-05 - val_loss: 1.1553e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5802e-05 - val_loss: 1.1535e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5687e-05 - val_loss: 1.1517e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5575e-05 - val_loss: 1.1500e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5464e-05 - val_loss: 1.1482e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5353e-05 - val_loss: 1.1465e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5243e-05 - val_loss: 1.1447e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 7.5129e-05 - val_loss: 1.1429e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5021e-05 - val_loss: 1.1412e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4912e-05 - val_loss: 1.1395e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4804e-05 - val_loss: 1.1377e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4691e-05 - val_loss: 1.1359e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4585e-05 - val_loss: 1.1342e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4474e-05 - val_loss: 1.1325e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4364e-05 - val_loss: 1.1308e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4256e-05 - val_loss: 1.1289e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4145e-05 - val_loss: 1.1271e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4036e-05 - val_loss: 1.1255e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3928e-05 - val_loss: 1.1237e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3820e-05 - val_loss: 1.1220e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3710e-05 - val_loss: 1.1202e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3601e-05 - val_loss: 1.1185e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3494e-05 - val_loss: 1.1168e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3388e-05 - val_loss: 1.1151e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3279e-05 - val_loss: 1.1134e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3172e-05 - val_loss: 1.1116e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 7.3065e-05 - val_loss: 1.1099e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2956e-05 - val_loss: 1.1082e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2849e-05 - val_loss: 1.1065e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2745e-05 - val_loss: 1.1048e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.2637e-05 - val_loss: 1.1030e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2532e-05 - val_loss: 1.1013e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 7.2425e-05 - val_loss: 1.0997e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2318e-05 - val_loss: 1.0979e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2210e-05 - val_loss: 1.0963e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2107e-05 - val_loss: 1.0945e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1999e-05 - val_loss: 1.0928e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1895e-05 - val_loss: 1.0911e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1789e-05 - val_loss: 1.0894e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1684e-05 - val_loss: 1.0877e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1580e-05 - val_loss: 1.0861e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1473e-05 - val_loss: 1.0844e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1366e-05 - val_loss: 1.0827e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1265e-05 - val_loss: 1.0810e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1160e-05 - val_loss: 1.0793e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1054e-05 - val_loss: 1.0776e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0952e-05 - val_loss: 1.0759e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0846e-05 - val_loss: 1.0743e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.0742e-05 - val_loss: 1.0726e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.0639e-05 - val_loss: 1.0709e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0534e-05 - val_loss: 1.0692e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0431e-05 - val_loss: 1.0676e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.0327e-05 - val_loss: 1.0659e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 7.0222e-05 - val_loss: 1.0642e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0124e-05 - val_loss: 1.0626e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 7.0018e-05 - val_loss: 1.0608e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9915e-05 - val_loss: 1.0592e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9815e-05 - val_loss: 1.0576e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9712e-05 - val_loss: 1.0559e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.9608e-05 - val_loss: 1.0543e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9507e-05 - val_loss: 1.0526e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.9404e-05 - val_loss: 1.0509e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9302e-05 - val_loss: 1.0493e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9201e-05 - val_loss: 1.0477e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9100e-05 - val_loss: 1.0459e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8999e-05 - val_loss: 1.0443e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8894e-05 - val_loss: 1.0427e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8796e-05 - val_loss: 1.0411e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8695e-05 - val_loss: 1.0395e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8592e-05 - val_loss: 1.0378e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.8495e-05 - val_loss: 1.0362e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8391e-05 - val_loss: 1.0346e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8294e-05 - val_loss: 1.0329e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8194e-05 - val_loss: 1.0313e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8089e-05 - val_loss: 1.0296e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.7989e-05 - val_loss: 1.0280e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7890e-05 - val_loss: 1.0263e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7791e-05 - val_loss: 1.0247e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7692e-05 - val_loss: 1.0231e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 6.7592e-05 - val_loss: 1.0215e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.7495e-05 - val_loss: 1.0199e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7395e-05 - val_loss: 1.0183e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7296e-05 - val_loss: 1.0166e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7196e-05 - val_loss: 1.0151e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7100e-05 - val_loss: 1.0134e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7001e-05 - val_loss: 1.0118e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6901e-05 - val_loss: 1.0102e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6803e-05 - val_loss: 1.0086e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 6.6704e-05 - val_loss: 1.0070e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6606e-05 - val_loss: 1.0054e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6510e-05 - val_loss: 1.0038e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6411e-05 - val_loss: 1.0022e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.6314e-05 - val_loss: 1.0007e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6218e-05 - val_loss: 9.9910e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6122e-05 - val_loss: 9.9745e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6022e-05 - val_loss: 9.9593e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5928e-05 - val_loss: 9.9428e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.5828e-05 - val_loss: 9.9271e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5732e-05 - val_loss: 9.9112e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5633e-05 - val_loss: 9.8959e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5537e-05 - val_loss: 9.8795e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5441e-05 - val_loss: 9.8637e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5346e-05 - val_loss: 9.8486e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5251e-05 - val_loss: 9.8323e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.5154e-05 - val_loss: 9.8166e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 6.5058e-05 - val_loss: 9.8009e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4962e-05 - val_loss: 9.7843e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4865e-05 - val_loss: 9.7701e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4772e-05 - val_loss: 9.7544e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4675e-05 - val_loss: 9.7384e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4580e-05 - val_loss: 9.7228e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4487e-05 - val_loss: 9.7068e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4393e-05 - val_loss: 9.6917e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4298e-05 - val_loss: 9.6762e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4204e-05 - val_loss: 9.6596e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4106e-05 - val_loss: 9.6445e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4012e-05 - val_loss: 9.6287e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3919e-05 - val_loss: 9.6132e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3826e-05 - val_loss: 9.5983e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3731e-05 - val_loss: 9.5831e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3638e-05 - val_loss: 9.5677e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3545e-05 - val_loss: 9.5517e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3449e-05 - val_loss: 9.5359e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3353e-05 - val_loss: 9.5208e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3263e-05 - val_loss: 9.5058e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3171e-05 - val_loss: 9.4908e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3076e-05 - val_loss: 9.4750e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 6.2985e-05 - val_loss: 9.4596e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2891e-05 - val_loss: 9.4442e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2799e-05 - val_loss: 9.4291e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2706e-05 - val_loss: 9.4142e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2615e-05 - val_loss: 9.3992e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.2523e-05 - val_loss: 9.3835e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2427e-05 - val_loss: 9.3686e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2337e-05 - val_loss: 9.3530e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2244e-05 - val_loss: 9.3380e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2152e-05 - val_loss: 9.3229e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2059e-05 - val_loss: 9.3083e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1969e-05 - val_loss: 9.2932e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1880e-05 - val_loss: 9.2771e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1785e-05 - val_loss: 9.2622e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1696e-05 - val_loss: 9.2470e-05\n",
      "6.111321272328496e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.06182549, -0.38713577,  0.06759677, -0.0458573 , -0.41453752],\n",
       "        [ 1.2679622 , -0.39310175,  0.3822536 ,  1.3825084 , -0.3998088 ],\n",
       "        [ 0.7199374 , -1.7513487 ,  1.7682974 ,  0.76659495, -1.4130423 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.33862007,  0.55749637, -0.47889024,  0.37576637,  0.28218088],\n",
       "       dtype=float32),\n",
       " array([[ 0.43243444,  0.22042912, -0.22639693, -0.35370985,  0.7066437 ,\n",
       "          0.10902827,  0.45573014, -0.27942678, -0.42391744, -0.19043551],\n",
       "        [-0.4396294 , -0.0880951 , -0.4899491 ,  0.48285547,  0.39852217,\n",
       "         -0.10564619, -0.68857837, -0.3855749 ,  0.17675224, -0.48042095],\n",
       "        [ 0.0415375 ,  0.26459557, -0.02249081,  0.20196736, -0.23938161,\n",
       "          0.23885371, -0.11045036,  0.459829  , -0.42828596,  0.23675881],\n",
       "        [-0.5428275 , -0.04239545,  0.00960112, -0.494626  , -0.35884798,\n",
       "         -0.22439824, -0.16406092, -0.39249632, -0.629626  , -0.72096425],\n",
       "        [ 0.37810072, -0.33490768, -0.25408244,  0.4455541 , -0.20622884,\n",
       "         -0.34588408,  0.29729235, -0.1337449 , -0.55038023,  0.02836009]],\n",
       "       dtype=float32),\n",
       " array([ 0.81801766, -0.7192674 , -0.8299313 , -0.82391024,  0.812424  ,\n",
       "         0.712721  , -0.8278015 ,  0.7707819 ,  0.4655734 ,  0.65383345],\n",
       "       dtype=float32),\n",
       " array([[ 0.85333526],\n",
       "        [-0.4197418 ],\n",
       "        [-1.0554655 ],\n",
       "        [-0.9433827 ],\n",
       "        [ 0.8007239 ],\n",
       "        [ 0.3915414 ],\n",
       "        [-1.1024351 ],\n",
       "        [ 0.5162078 ],\n",
       "        [ 0.17819396],\n",
       "        [ 0.24164966]], dtype=float32),\n",
       " array([0.8564107], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_2(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure2_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 35.2446 - val_loss: 32.7967\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 32.2130 - val_loss: 28.8856\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5590 - val_loss: 22.3274\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 21.2212 - val_loss: 14.2421\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 13.7850 - val_loss: 6.2455\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5282 - val_loss: 1.1105\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4919 - val_loss: 0.6635\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 1.1670 - val_loss: 3.8979\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4647 - val_loss: 6.2364\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8935 - val_loss: 5.6618\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.4691 - val_loss: 3.6433\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6517 - val_loss: 1.6443\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4367 - val_loss: 0.4653\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4365 - val_loss: 0.2791\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.4494 - val_loss: 0.7437\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.9960 - val_loss: 1.3510\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6216 - val_loss: 1.7557\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.0469 - val_loss: 1.8443\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1711 - val_loss: 1.6593\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0127 - val_loss: 1.3110\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6504 - val_loss: 0.9141\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1861 - val_loss: 0.5550\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.7256 - val_loss: 0.2864\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.3628 - val_loss: 0.1360\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.1587 - val_loss: 0.1150\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1242 - val_loss: 0.2169\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.2226 - val_loss: 0.4017\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3863 - val_loss: 0.5854\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.5365 - val_loss: 0.6738\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.6066 - val_loss: 0.6252\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.5709 - val_loss: 0.4754\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4528 - val_loss: 0.2977\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.3030 - val_loss: 0.1505\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1707 - val_loss: 0.0592\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0887 - val_loss: 0.0253\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0667 - val_loss: 0.0375\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0929 - val_loss: 0.0784\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.1427 - val_loss: 0.1273\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1914 - val_loss: 0.1642\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2217 - val_loss: 0.1747\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2253 - val_loss: 0.1555\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.2027 - val_loss: 0.1154\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1614 - val_loss: 0.0698\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1132 - val_loss: 0.0333\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0698 - val_loss: 0.0137\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 215us/step - loss: 0.0396 - val_loss: 0.0116\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0263 - val_loss: 0.0230\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0288 - val_loss: 0.0418\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0414 - val_loss: 0.0617\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0563 - val_loss: 0.0773\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0670 - val_loss: 0.0844\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0696 - val_loss: 0.0810\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0641 - val_loss: 0.0682\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0527 - val_loss: 0.0502\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0394 - val_loss: 0.0324\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0279 - val_loss: 0.0188\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0205 - val_loss: 0.0105\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0180 - val_loss: 0.0068\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0193 - val_loss: 0.0058\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0229 - val_loss: 0.0059\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0270 - val_loss: 0.0062\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0301 - val_loss: 0.0061\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0311 - val_loss: 0.0055\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0300 - val_loss: 0.0043\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0271 - val_loss: 0.0030\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0233 - val_loss: 0.0021\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.0023\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0163 - val_loss: 0.0040\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0144 - val_loss: 0.0072\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0151 - val_loss: 0.0170\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0184\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0143 - val_loss: 0.0130\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0103\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0078\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0058\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0103 - val_loss: 0.0045\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 0.0037\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0033\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0031\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0110 - val_loss: 0.0030\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0109 - val_loss: 0.0031\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0033\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0097 - val_loss: 0.0041\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0059\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0074 - val_loss: 0.0036\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0071 - val_loss: 0.0034\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0068 - val_loss: 0.0036\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0037\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0028\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0028 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.9943e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.9512e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.9084e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.8662e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 9.8242e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.7821e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0020 - val_loss: 9.7408e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.6996e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 9.6586e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0020 - val_loss: 9.6182e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 9.5778e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 9.5380e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 9.4984e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0019 - val_loss: 9.4589e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0019 - val_loss: 9.4198e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0019 - val_loss: 9.3812e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 9.3426e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0019 - val_loss: 9.3047e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0019 - val_loss: 9.2668e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 9.2292e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 9.1919e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 9.1548e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.1180e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 9.0814e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.0453e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 9.0091e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.9739e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.9384e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 8.9032e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 8.8682e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.8335e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.7991e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.7650e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0018 - val_loss: 8.7312e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0018 - val_loss: 8.6973e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 8.6640e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0018 - val_loss: 8.6308e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 8.5980e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.5653e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.5330e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 8.5007e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 8.4688e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 8.4368e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.4055e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.3743e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 8.3432e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 8.3123e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 8.2819e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 8.2514e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 8.2212e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 8.1911e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 8.1614e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 8.1316e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0017 - val_loss: 8.1023e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0017 - val_loss: 8.0731e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0017 - val_loss: 8.0445e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0017 - val_loss: 8.0157e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 7.9870e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.9587e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0017 - val_loss: 7.9305e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.9028e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.8750e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.8474e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0017 - val_loss: 7.8200e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.7927e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 7.7659e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.7392e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 7.7127e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0016 - val_loss: 7.6861e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.6600e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0016 - val_loss: 7.6339e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.6080e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.0016 - val_loss: 7.5826e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 7.5569e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 7.5317e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.5065e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 7.4814e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.4568e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0016 - val_loss: 7.4320e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 7.4073e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0016 - val_loss: 7.3832e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 7.3588e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.3349e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 7.3111e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.2874e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.2639e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.2406e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 7.2175e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 7.1944e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 7.1718e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.1489e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0015 - val_loss: 7.1264e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.1041e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0015 - val_loss: 7.0817e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.0596e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 7.0378e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 7.0160e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 6.9942e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0015 - val_loss: 6.9727e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 6.9511e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0015 - val_loss: 6.9300e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0015 - val_loss: 6.9090e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0015 - val_loss: 6.8879e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 6.8671e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 6.8462e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 6.8257e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.8054e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.7851e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0015 - val_loss: 6.7650e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0015 - val_loss: 6.7448e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 6.7252e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 6.7053e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.6857e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0015 - val_loss: 6.6660e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.6466e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.6277e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 6.6085e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.5893e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 6.5706e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 6.5518e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0014 - val_loss: 6.5330e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0014 - val_loss: 6.5146e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0014 - val_loss: 6.4963e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 6.4780e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.4597e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 6.4417e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.4239e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.4059e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.3882e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 6.3707e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 6.3532e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.3360e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 6.3186e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 6.3015e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.2844e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 6.2674e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.2507e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0014 - val_loss: 6.2340e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0014 - val_loss: 6.2176e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.2009e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0014 - val_loss: 6.1845e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 6.1681e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.1518e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 6.1358e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 6.1197e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 6.1038e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.0881e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 6.0727e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 6.0568e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0013 - val_loss: 6.0414e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 6.0259e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 6.0105e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.9952e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.9801e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0013 - val_loss: 5.9651e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0013 - val_loss: 5.9501e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.9352e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 5.9205e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0013 - val_loss: 5.9058e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 5.8912e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.8769e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.8624e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.8483e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 5.8340e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0013 - val_loss: 5.8198e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0013 - val_loss: 5.8058e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.7917e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.7779e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.7639e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.7502e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.7365e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.7231e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.7097e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.6963e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.6828e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 5.6696e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 5.6565e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.6434e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 5.6306e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0012 - val_loss: 5.6174e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.6045e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 5.5919e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.5791e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.5663e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0012 - val_loss: 5.5539e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0012 - val_loss: 5.5414e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.5290e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.5167e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 5.5045e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 5.4923e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 5.4801e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.4682e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.4563e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.4442e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.4323e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.4204e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 5.4087e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.3970e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.3854e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.3741e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 5.3627e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0012 - val_loss: 5.3512e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.3400e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.3287e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.3176e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 5.3064e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 5.2952e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0012 - val_loss: 5.2842e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 5.2732e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.2625e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.2516e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 5.2409e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 5.2304e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 5.2196e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.2089e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 5.1985e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0011 - val_loss: 5.1880e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 5.1777e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0011 - val_loss: 5.1673e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.1572e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 5.1466e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 5.1366e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.1264e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.0011 - val_loss: 5.1165e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.1065e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 5.0964e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 5.0865e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 5.0767e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 5.0668e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.0571e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.0476e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.0378e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.0283e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 5.0187e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 5.0092e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.9999e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 4.9904e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 190us/step - loss: 0.0011 - val_loss: 4.9810e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0011 - val_loss: 4.9719e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.9625e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.9533e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.9442e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.9351e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.9260e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.9171e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.9082e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.8992e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.8904e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.8816e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0011 - val_loss: 4.8727e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.8641e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.8554e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.8468e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.8382e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.8298e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.8212e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 4.8128e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 4.8044e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0010 - val_loss: 4.7961e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.7876e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.7793e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.7710e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.7628e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 4.7546e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.7466e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.7385e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 4.7306e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 4.7227e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.7147e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.7066e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.6988e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 4.6910e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.6831e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0010 - val_loss: 4.6754e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0010 - val_loss: 4.6679e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.6600e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 4.6524e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 4.6448e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 4.6372e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 4.6297e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9858e-04 - val_loss: 4.6219e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 9.9654e-04 - val_loss: 4.6145e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9455e-04 - val_loss: 4.6071e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9253e-04 - val_loss: 4.5997e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 9.9054e-04 - val_loss: 4.5924e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 9.8855e-04 - val_loss: 4.5851e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8656e-04 - val_loss: 4.5779e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 9.8458e-04 - val_loss: 4.5706e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 9.8260e-04 - val_loss: 4.5635e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 9.8064e-04 - val_loss: 4.5563e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7867e-04 - val_loss: 4.5491e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7671e-04 - val_loss: 4.5419e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7477e-04 - val_loss: 4.5348e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7282e-04 - val_loss: 4.5277e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7088e-04 - val_loss: 4.5207e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6894e-04 - val_loss: 4.5138e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 9.6703e-04 - val_loss: 4.5068e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 9.6509e-04 - val_loss: 4.4999e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6320e-04 - val_loss: 4.4932e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6127e-04 - val_loss: 4.4862e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 9.5937e-04 - val_loss: 4.4795e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5747e-04 - val_loss: 4.4726e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5557e-04 - val_loss: 4.4659e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 9.5369e-04 - val_loss: 4.4591e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5181e-04 - val_loss: 4.4523e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 9.4994e-04 - val_loss: 4.4457e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 9.4806e-04 - val_loss: 4.4391e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4619e-04 - val_loss: 4.4325e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4434e-04 - val_loss: 4.4259e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4248e-04 - val_loss: 4.4194e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4064e-04 - val_loss: 4.4128e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3879e-04 - val_loss: 4.4064e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3696e-04 - val_loss: 4.3999e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3511e-04 - val_loss: 4.3935e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.3330e-04 - val_loss: 4.3871e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3147e-04 - val_loss: 4.3808e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2965e-04 - val_loss: 4.3745e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2785e-04 - val_loss: 4.3680e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2603e-04 - val_loss: 4.3618e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2424e-04 - val_loss: 4.3553e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2243e-04 - val_loss: 4.3491e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2065e-04 - val_loss: 4.3428e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 9.1887e-04 - val_loss: 4.3367e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 9.1708e-04 - val_loss: 4.3306e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1530e-04 - val_loss: 4.3246e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1354e-04 - val_loss: 4.3184e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9.1178e-04 - val_loss: 4.3122e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1001e-04 - val_loss: 4.3062e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0825e-04 - val_loss: 4.3003e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0651e-04 - val_loss: 4.2942e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0475e-04 - val_loss: 4.2885e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0304e-04 - val_loss: 4.2824e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0129e-04 - val_loss: 4.2765e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 8.9956e-04 - val_loss: 4.2706e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9784e-04 - val_loss: 4.2646e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9612e-04 - val_loss: 4.2587e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9441e-04 - val_loss: 4.2528e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9268e-04 - val_loss: 4.2470e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9099e-04 - val_loss: 4.2414e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8929e-04 - val_loss: 4.2356e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 8.8759e-04 - val_loss: 4.2299e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8590e-04 - val_loss: 4.2239e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8421e-04 - val_loss: 4.2184e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8254e-04 - val_loss: 4.2129e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8086e-04 - val_loss: 4.2073e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7919e-04 - val_loss: 4.2018e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7751e-04 - val_loss: 4.1962e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 8.7585e-04 - val_loss: 4.1905e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7421e-04 - val_loss: 4.1849e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7255e-04 - val_loss: 4.1795e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 8.7090e-04 - val_loss: 4.1739e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6925e-04 - val_loss: 4.1683e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6762e-04 - val_loss: 4.1630e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6598e-04 - val_loss: 4.1575e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6435e-04 - val_loss: 4.1519e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6273e-04 - val_loss: 4.1465e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6110e-04 - val_loss: 4.1412e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5949e-04 - val_loss: 4.1358e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5787e-04 - val_loss: 4.1307e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 8.5628e-04 - val_loss: 4.1253e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5466e-04 - val_loss: 4.1200e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 8.5307e-04 - val_loss: 4.1145e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5147e-04 - val_loss: 4.1095e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4990e-04 - val_loss: 4.1043e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4830e-04 - val_loss: 4.0990e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.4672e-04 - val_loss: 4.0937e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4513e-04 - val_loss: 4.0885e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4358e-04 - val_loss: 4.0834e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 8.4200e-04 - val_loss: 4.0784e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4044e-04 - val_loss: 4.0733e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3887e-04 - val_loss: 4.0683e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3732e-04 - val_loss: 4.0632e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 8.3576e-04 - val_loss: 4.0581e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 8.3422e-04 - val_loss: 4.0530e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 8.3268e-04 - val_loss: 4.0480e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3115e-04 - val_loss: 4.0432e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2961e-04 - val_loss: 4.0380e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 8.2808e-04 - val_loss: 4.0331e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.2654e-04 - val_loss: 4.0281e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 8.2504e-04 - val_loss: 4.0232e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2352e-04 - val_loss: 4.0183e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2200e-04 - val_loss: 4.0134e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 8.2050e-04 - val_loss: 4.0084e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1898e-04 - val_loss: 4.0036e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1748e-04 - val_loss: 3.9989e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 8.1600e-04 - val_loss: 3.9940e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 8.1449e-04 - val_loss: 3.9892e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1301e-04 - val_loss: 3.9843e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 8.1153e-04 - val_loss: 3.9795e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1004e-04 - val_loss: 3.9748e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0856e-04 - val_loss: 3.9702e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0708e-04 - val_loss: 3.9655e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0561e-04 - val_loss: 3.9608e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0415e-04 - val_loss: 3.9562e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0269e-04 - val_loss: 3.9514e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0124e-04 - val_loss: 3.9466e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9978e-04 - val_loss: 3.9420e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9833e-04 - val_loss: 3.9374e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9687e-04 - val_loss: 3.9329e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9544e-04 - val_loss: 3.9282e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 7.9399e-04 - val_loss: 3.9238e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9256e-04 - val_loss: 3.9190e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9115e-04 - val_loss: 3.9145e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 7.8971e-04 - val_loss: 3.9100e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 7.8829e-04 - val_loss: 3.9055e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 7.8687e-04 - val_loss: 3.9010e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8546e-04 - val_loss: 3.8967e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8405e-04 - val_loss: 3.8922e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8264e-04 - val_loss: 3.8877e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8124e-04 - val_loss: 3.8833e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7983e-04 - val_loss: 3.8787e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7844e-04 - val_loss: 3.8742e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7704e-04 - val_loss: 3.8698e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7565e-04 - val_loss: 3.8654e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7425e-04 - val_loss: 3.8612e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7288e-04 - val_loss: 3.8568e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7150e-04 - val_loss: 3.8525e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7012e-04 - val_loss: 3.8480e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6875e-04 - val_loss: 3.8438e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 7.6738e-04 - val_loss: 3.8396e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6600e-04 - val_loss: 3.8353e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6465e-04 - val_loss: 3.8310e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6329e-04 - val_loss: 3.8266e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 7.6195e-04 - val_loss: 3.8226e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6061e-04 - val_loss: 3.8181e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5924e-04 - val_loss: 3.8138e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5789e-04 - val_loss: 3.8097e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5656e-04 - val_loss: 3.8054e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.5522e-04 - val_loss: 3.8013e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 7.5388e-04 - val_loss: 3.7972e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5255e-04 - val_loss: 3.7931e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5124e-04 - val_loss: 3.7889e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 7.4991e-04 - val_loss: 3.7849e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.4859e-04 - val_loss: 3.7807e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.4727e-04 - val_loss: 3.7768e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4596e-04 - val_loss: 3.7725e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 7.4464e-04 - val_loss: 3.7685e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 7.4334e-04 - val_loss: 3.7642e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4204e-04 - val_loss: 3.7602e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.4074e-04 - val_loss: 3.7562e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3944e-04 - val_loss: 3.7521e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3814e-04 - val_loss: 3.7482e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 7.3685e-04 - val_loss: 3.7441e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 7.3557e-04 - val_loss: 3.7400e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.3428e-04 - val_loss: 3.7360e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3301e-04 - val_loss: 3.7321e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3173e-04 - val_loss: 3.7282e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3045e-04 - val_loss: 3.7242e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2919e-04 - val_loss: 3.7202e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2791e-04 - val_loss: 3.7163e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 7.2665e-04 - val_loss: 3.7122e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2538e-04 - val_loss: 3.7084e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2413e-04 - val_loss: 3.7047e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2288e-04 - val_loss: 3.7007e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2163e-04 - val_loss: 3.6968e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2038e-04 - val_loss: 3.6929e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1913e-04 - val_loss: 3.6890e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1788e-04 - val_loss: 3.6851e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 7.1664e-04 - val_loss: 3.6814e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1541e-04 - val_loss: 3.6775e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 7.1417e-04 - val_loss: 3.6736e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1294e-04 - val_loss: 3.6700e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 7.1173e-04 - val_loss: 3.6659e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1050e-04 - val_loss: 3.6624e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0928e-04 - val_loss: 3.6586e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7.0806e-04 - val_loss: 3.6547e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0684e-04 - val_loss: 3.6510e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 7.0562e-04 - val_loss: 3.6472e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0443e-04 - val_loss: 3.6434e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0322e-04 - val_loss: 3.6396e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0201e-04 - val_loss: 3.6360e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.0082e-04 - val_loss: 3.6323e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9962e-04 - val_loss: 3.6284e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 6.9842e-04 - val_loss: 3.6249e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9723e-04 - val_loss: 3.6212e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9605e-04 - val_loss: 3.6174e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9486e-04 - val_loss: 3.6138e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9368e-04 - val_loss: 3.6104e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9250e-04 - val_loss: 3.6067e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9131e-04 - val_loss: 3.6030e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9014e-04 - val_loss: 3.5994e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8897e-04 - val_loss: 3.5957e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8781e-04 - val_loss: 3.5920e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 6.8665e-04 - val_loss: 3.5884e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8548e-04 - val_loss: 3.5848e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 6.8432e-04 - val_loss: 3.5813e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8316e-04 - val_loss: 3.5776e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.8201e-04 - val_loss: 3.5739e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8086e-04 - val_loss: 3.5704e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7970e-04 - val_loss: 3.5668e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.7856e-04 - val_loss: 3.5634e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.7742e-04 - val_loss: 3.5599e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 6.7627e-04 - val_loss: 3.5563e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 6.7514e-04 - val_loss: 3.5529e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7401e-04 - val_loss: 3.5492e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7288e-04 - val_loss: 3.5457e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7176e-04 - val_loss: 3.5423e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7062e-04 - val_loss: 3.5388e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6950e-04 - val_loss: 3.5354e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6838e-04 - val_loss: 3.5319e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6726e-04 - val_loss: 3.5284e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6615e-04 - val_loss: 3.5251e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6503e-04 - val_loss: 3.5215e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.6393e-04 - val_loss: 3.5180e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 6.6281e-04 - val_loss: 3.5147e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.6171e-04 - val_loss: 3.5112e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6061e-04 - val_loss: 3.5078e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5951e-04 - val_loss: 3.5044e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.5842e-04 - val_loss: 3.5010e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5732e-04 - val_loss: 3.4976e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5621e-04 - val_loss: 3.4941e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5513e-04 - val_loss: 3.4908e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5405e-04 - val_loss: 3.4875e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5297e-04 - val_loss: 3.4839e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5189e-04 - val_loss: 3.4807e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5080e-04 - val_loss: 3.4773e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4972e-04 - val_loss: 3.4738e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4865e-04 - val_loss: 3.4706e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4758e-04 - val_loss: 3.4674e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 6.4651e-04 - val_loss: 3.4640e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.4544e-04 - val_loss: 3.4607e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 6.4439e-04 - val_loss: 3.4574e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 6.4332e-04 - val_loss: 3.4540e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4226e-04 - val_loss: 3.4506e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 6.4120e-04 - val_loss: 3.4473e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4016e-04 - val_loss: 3.4441e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3910e-04 - val_loss: 3.4409e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3806e-04 - val_loss: 3.4375e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3700e-04 - val_loss: 3.4343e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3596e-04 - val_loss: 3.4308e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3492e-04 - val_loss: 3.4276e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3388e-04 - val_loss: 3.4244e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3284e-04 - val_loss: 3.4212e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3181e-04 - val_loss: 3.4179e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3078e-04 - val_loss: 3.4148e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 6.2975e-04 - val_loss: 3.4116e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2872e-04 - val_loss: 3.4083e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 6.2770e-04 - val_loss: 3.4051e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 6.2668e-04 - val_loss: 3.4019e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2566e-04 - val_loss: 3.3987e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2464e-04 - val_loss: 3.3956e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.2362e-04 - val_loss: 3.3923e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 6.2261e-04 - val_loss: 3.3892e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2161e-04 - val_loss: 3.3859e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2060e-04 - val_loss: 3.3828e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1959e-04 - val_loss: 3.3796e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1858e-04 - val_loss: 3.3764e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1758e-04 - val_loss: 3.3733e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.1658e-04 - val_loss: 3.3701e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1559e-04 - val_loss: 3.3670e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1459e-04 - val_loss: 3.3638e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1360e-04 - val_loss: 3.3607e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1261e-04 - val_loss: 3.3577e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1162e-04 - val_loss: 3.3545e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1064e-04 - val_loss: 3.3515e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 6.0965e-04 - val_loss: 3.3483e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0867e-04 - val_loss: 3.3451e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.0770e-04 - val_loss: 3.3419e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0672e-04 - val_loss: 3.3389e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0575e-04 - val_loss: 3.3358e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0478e-04 - val_loss: 3.3326e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0380e-04 - val_loss: 3.3297e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0284e-04 - val_loss: 3.3266e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0187e-04 - val_loss: 3.3237e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0091e-04 - val_loss: 3.3206e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9994e-04 - val_loss: 3.3175e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9899e-04 - val_loss: 3.3144e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9803e-04 - val_loss: 3.3113e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 5.9708e-04 - val_loss: 3.3081e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 5.9611e-04 - val_loss: 3.3050e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9518e-04 - val_loss: 3.3021e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9422e-04 - val_loss: 3.2992e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.9328e-04 - val_loss: 3.2960e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9234e-04 - val_loss: 3.2929e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9140e-04 - val_loss: 3.2900e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9045e-04 - val_loss: 3.2871e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8953e-04 - val_loss: 3.2840e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8859e-04 - val_loss: 3.2812e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8765e-04 - val_loss: 3.2781e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8673e-04 - val_loss: 3.2750e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8579e-04 - val_loss: 3.2721e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8487e-04 - val_loss: 3.2691e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8394e-04 - val_loss: 3.2661e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8302e-04 - val_loss: 3.2632e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.8210e-04 - val_loss: 3.2601e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8119e-04 - val_loss: 3.2571e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8027e-04 - val_loss: 3.2541e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7934e-04 - val_loss: 3.2511e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7843e-04 - val_loss: 3.2481e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7752e-04 - val_loss: 3.2452e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7662e-04 - val_loss: 3.2423e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7571e-04 - val_loss: 3.2395e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 5.7481e-04 - val_loss: 3.2366e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7390e-04 - val_loss: 3.2337e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7301e-04 - val_loss: 3.2306e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7211e-04 - val_loss: 3.2277e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7121e-04 - val_loss: 3.2250e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7032e-04 - val_loss: 3.2221e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6943e-04 - val_loss: 3.2190e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 5.6854e-04 - val_loss: 3.2161e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.6764e-04 - val_loss: 3.2130e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6675e-04 - val_loss: 3.2102e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6587e-04 - val_loss: 3.2073e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6500e-04 - val_loss: 3.2045e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6412e-04 - val_loss: 3.2016e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6323e-04 - val_loss: 3.1987e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6235e-04 - val_loss: 3.1959e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6148e-04 - val_loss: 3.1930e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6061e-04 - val_loss: 3.1900e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5973e-04 - val_loss: 3.1873e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5887e-04 - val_loss: 3.1843e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5800e-04 - val_loss: 3.1814e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5713e-04 - val_loss: 3.1786e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5627e-04 - val_loss: 3.1757e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5541e-04 - val_loss: 3.1729e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5455e-04 - val_loss: 3.1699e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5369e-04 - val_loss: 3.1671e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5284e-04 - val_loss: 3.1644e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.5199e-04 - val_loss: 3.1616e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5113e-04 - val_loss: 3.1587e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5028e-04 - val_loss: 3.1558e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4944e-04 - val_loss: 3.1531e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.4858e-04 - val_loss: 3.1501e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 5.4774e-04 - val_loss: 3.1474e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4690e-04 - val_loss: 3.1446e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4606e-04 - val_loss: 3.1417e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4522e-04 - val_loss: 3.1390e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4438e-04 - val_loss: 3.1361e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 5.4354e-04 - val_loss: 3.1334e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4272e-04 - val_loss: 3.1305e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4188e-04 - val_loss: 3.1278e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4105e-04 - val_loss: 3.1250e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4021e-04 - val_loss: 3.1222e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 5.3940e-04 - val_loss: 3.1193e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3856e-04 - val_loss: 3.1166e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3775e-04 - val_loss: 3.1137e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3693e-04 - val_loss: 3.1111e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3611e-04 - val_loss: 3.1083e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3529e-04 - val_loss: 3.1056e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3447e-04 - val_loss: 3.1027e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.3365e-04 - val_loss: 3.1001e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3284e-04 - val_loss: 3.0971e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3203e-04 - val_loss: 3.0944e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3122e-04 - val_loss: 3.0918e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 5.3042e-04 - val_loss: 3.0890e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2961e-04 - val_loss: 3.0862e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2881e-04 - val_loss: 3.0835e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2801e-04 - val_loss: 3.0806e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2721e-04 - val_loss: 3.0779e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 5.2641e-04 - val_loss: 3.0751e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2561e-04 - val_loss: 3.0725e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2481e-04 - val_loss: 3.0698e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2402e-04 - val_loss: 3.0671e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.2323e-04 - val_loss: 3.0644e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2244e-04 - val_loss: 3.0615e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2165e-04 - val_loss: 3.0588e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 5.2086e-04 - val_loss: 3.0561e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2008e-04 - val_loss: 3.0535e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1929e-04 - val_loss: 3.0508e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.1851e-04 - val_loss: 3.0481e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1772e-04 - val_loss: 3.0455e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1695e-04 - val_loss: 3.0426e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1618e-04 - val_loss: 3.0399e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1540e-04 - val_loss: 3.0372e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1463e-04 - val_loss: 3.0345e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1386e-04 - val_loss: 3.0317e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1308e-04 - val_loss: 3.0292e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1231e-04 - val_loss: 3.0265e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1155e-04 - val_loss: 3.0239e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1079e-04 - val_loss: 3.0211e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.1002e-04 - val_loss: 3.0184e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0925e-04 - val_loss: 3.0158e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0849e-04 - val_loss: 3.0132e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0773e-04 - val_loss: 3.0105e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.0698e-04 - val_loss: 3.0077e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0622e-04 - val_loss: 3.0052e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.0546e-04 - val_loss: 3.0025e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0471e-04 - val_loss: 2.9998e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0396e-04 - val_loss: 2.9972e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0322e-04 - val_loss: 2.9945e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0246e-04 - val_loss: 2.9918e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0172e-04 - val_loss: 2.9890e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 5.0097e-04 - val_loss: 2.9864e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0023e-04 - val_loss: 2.9839e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9948e-04 - val_loss: 2.9813e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9875e-04 - val_loss: 2.9787e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9801e-04 - val_loss: 2.9760e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9726e-04 - val_loss: 2.9734e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9653e-04 - val_loss: 2.9708e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9580e-04 - val_loss: 2.9680e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9507e-04 - val_loss: 2.9656e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9433e-04 - val_loss: 2.9629e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9361e-04 - val_loss: 2.9603e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9286e-04 - val_loss: 2.9577e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9215e-04 - val_loss: 2.9549e-04\n",
      "0.000265808601398021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.47976074, -0.36353016, -0.01851191,  0.23863232,  0.03646738],\n",
       "        [ 0.5874555 ,  0.64983755, -1.0630714 ,  0.5912907 ,  1.0239949 ],\n",
       "        [ 1.5246214 ,  1.4286333 ,  0.75188553,  1.7786391 ,  0.8043896 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.08185434, -0.16567197, -0.6640233 ,  0.44877312, -0.48303416],\n",
       "       dtype=float32),\n",
       " array([[ 0.30607936, -0.4592974 ,  0.08266341,  0.1851418 , -0.40322548,\n",
       "         -0.03020122,  0.11569655,  0.47172412, -0.7517093 , -0.5368275 ,\n",
       "         -0.2260384 ,  0.04775874, -0.29997924, -0.19782972, -0.02385323],\n",
       "        [ 0.4642896 ,  0.36660776,  0.03975499, -0.46183714,  0.34478793,\n",
       "         -0.23975322,  0.39313942,  0.32522342, -0.2305253 , -0.49788794,\n",
       "         -0.2551308 ,  0.1320612 , -0.5311148 , -0.34472758, -0.30377263],\n",
       "        [-0.5869909 ,  0.26495343, -0.5037383 , -0.6367936 , -0.4689473 ,\n",
       "          0.0987145 , -0.23745602, -0.34936252, -0.33994085,  0.29732886,\n",
       "         -0.25864533,  0.05623841, -0.07872384,  0.5858796 ,  0.12419484],\n",
       "        [ 0.36713436,  0.24079406,  0.24050218,  0.64841354,  0.17460304,\n",
       "         -0.68205726,  0.33881113,  0.25233203, -0.0546426 ,  0.6004972 ,\n",
       "         -0.05491138, -0.3208465 ,  0.5400909 , -0.646306  , -0.14579365],\n",
       "        [ 0.19979906, -0.6053214 , -0.6410449 , -0.5853606 ,  0.33119944,\n",
       "         -0.06382266,  0.5282957 , -0.23812768, -0.10446741, -0.75421244,\n",
       "          0.2416598 ,  0.4938889 ,  0.15140751,  0.7230525 , -0.12490189]],\n",
       "       dtype=float32),\n",
       " array([ 0.59412485,  0.5371871 ,  0.623861  ,  0.64234173,  0.584436  ,\n",
       "        -0.5416621 , -0.36636898, -0.42307228,  0.37145245,  0.6376215 ,\n",
       "        -0.00337938, -0.4563566 ,  0.59968746, -0.5903722 , -0.5560534 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.5878904 ],\n",
       "        [ 0.32256156],\n",
       "        [ 0.7005408 ],\n",
       "        [ 0.8373124 ],\n",
       "        [ 0.57031894],\n",
       "        [-0.38933954],\n",
       "        [-0.13746305],\n",
       "        [-0.09442665],\n",
       "        [ 0.23841235],\n",
       "        [ 0.6693473 ],\n",
       "        [ 0.08462234],\n",
       "        [-0.26614517],\n",
       "        [ 0.5677516 ],\n",
       "        [-0.54561347],\n",
       "        [-0.40411335]], dtype=float32),\n",
       " array([0.7147649], dtype=float32)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_3(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure3_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 37.0772 - val_loss: 31.1626\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 33.6676 - val_loss: 26.4921\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5026 - val_loss: 21.4023\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 24.5614 - val_loss: 15.7473\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 18.7987 - val_loss: 9.7287\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12.5003 - val_loss: 4.3001\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4622 - val_loss: 1.1545\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9411 - val_loss: 2.1398\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9237 - val_loss: 6.5216\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9780 - val_loss: 8.4625\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2261 - val_loss: 6.9651\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3348 - val_loss: 4.4482\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.9800 - val_loss: 2.7280\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1463 - val_loss: 2.2611\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.7379 - val_loss: 2.4600\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3808 - val_loss: 2.5826\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1147 - val_loss: 2.3816\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4352 - val_loss: 1.9329\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3211 - val_loss: 1.3870\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9107 - val_loss: 0.8848\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3601 - val_loss: 0.5330\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8152 - val_loss: 0.3884\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.4019 - val_loss: 0.4423\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1997 - val_loss: 0.6202\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.2076 - val_loss: 0.8133\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3428 - val_loss: 0.9308\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.4890 - val_loss: 0.9337\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.5625 - val_loss: 0.8309\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.5410 - val_loss: 0.6572\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4458 - val_loss: 0.4561\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.3147 - val_loss: 0.2695\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.1875 - val_loss: 0.1291\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0974 - val_loss: 0.0493\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0618 - val_loss: 0.0253\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0777 - val_loss: 0.0380\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.1245 - val_loss: 0.0635\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1742 - val_loss: 0.0826\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.2037 - val_loss: 0.0863\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.2031 - val_loss: 0.0758\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1762 - val_loss: 0.0575\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1345 - val_loss: 0.0384\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0905 - val_loss: 0.0232\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0538 - val_loss: 0.0141\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0114\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0203 - val_loss: 0.0144\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0246 - val_loss: 0.0213\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0384 - val_loss: 0.0290\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0544 - val_loss: 0.0338\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0651 - val_loss: 0.0333\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 199us/step - loss: 0.0657 - val_loss: 0.0275\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0565 - val_loss: 0.0192\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0421 - val_loss: 0.0121\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0279 - val_loss: 0.0089\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0180 - val_loss: 0.0107\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 0.0135 - val_loss: 0.0166\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0135 - val_loss: 0.0248\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0332\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0205 - val_loss: 0.0397\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0241 - val_loss: 0.0430\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0259 - val_loss: 0.0425\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0252 - val_loss: 0.0386\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0220 - val_loss: 0.0323\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0173 - val_loss: 0.0251\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0126 - val_loss: 0.0183\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0128\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0101 - val_loss: 0.0041\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0111 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0036\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0112 - val_loss: 0.0032\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0101 - val_loss: 0.0028\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0026\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0073\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0043 - val_loss: 0.0076\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0072\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0042 - val_loss: 0.0069\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 200us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9856e-04 - val_loss: 0.0015\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.9600e-04 - val_loss: 0.0015\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 9.9345e-04 - val_loss: 0.0015\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9093e-04 - val_loss: 0.0015\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8840e-04 - val_loss: 0.0015\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8591e-04 - val_loss: 0.0015\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8341e-04 - val_loss: 0.0015\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8093e-04 - val_loss: 0.0014\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 9.7846e-04 - val_loss: 0.0014\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7601e-04 - val_loss: 0.0014\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7356e-04 - val_loss: 0.0014\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 9.7113e-04 - val_loss: 0.0014\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6870e-04 - val_loss: 0.0014\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6630e-04 - val_loss: 0.0014\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 9.6388e-04 - val_loss: 0.0014\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 9.6149e-04 - val_loss: 0.0014\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 9.5911e-04 - val_loss: 0.0014\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5673e-04 - val_loss: 0.0014\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5438e-04 - val_loss: 0.0014\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5203e-04 - val_loss: 0.0014\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4968e-04 - val_loss: 0.0014\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4736e-04 - val_loss: 0.0014\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 9.4504e-04 - val_loss: 0.0014\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4273e-04 - val_loss: 0.0014\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 9.4044e-04 - val_loss: 0.0014\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 9.3815e-04 - val_loss: 0.0014\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 9.3587e-04 - val_loss: 0.0014\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3360e-04 - val_loss: 0.0014\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3133e-04 - val_loss: 0.0014\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2909e-04 - val_loss: 0.0014\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.2685e-04 - val_loss: 0.0014\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2461e-04 - val_loss: 0.0014\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 9.2240e-04 - val_loss: 0.0014\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2018e-04 - val_loss: 0.0014\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1798e-04 - val_loss: 0.0014\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1579e-04 - val_loss: 0.0013\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1361e-04 - val_loss: 0.0013\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1143e-04 - val_loss: 0.0013\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0927e-04 - val_loss: 0.0013\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0710e-04 - val_loss: 0.0013\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.0495e-04 - val_loss: 0.0013\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.0281e-04 - val_loss: 0.0013\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0069e-04 - val_loss: 0.0013\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.9856e-04 - val_loss: 0.0013\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9645e-04 - val_loss: 0.0013\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9434e-04 - val_loss: 0.0013\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9225e-04 - val_loss: 0.0013\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9015e-04 - val_loss: 0.0013\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8808e-04 - val_loss: 0.0013\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.8600e-04 - val_loss: 0.0013\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8394e-04 - val_loss: 0.0013\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.8188e-04 - val_loss: 0.0013\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7982e-04 - val_loss: 0.0013\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7779e-04 - val_loss: 0.0013\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.7576e-04 - val_loss: 0.0013\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7373e-04 - val_loss: 0.0013\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.7171e-04 - val_loss: 0.0013\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6970e-04 - val_loss: 0.0013\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6771e-04 - val_loss: 0.0013\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 8.6571e-04 - val_loss: 0.0013\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6372e-04 - val_loss: 0.0013\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.6175e-04 - val_loss: 0.0013\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.5977e-04 - val_loss: 0.0013\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5782e-04 - val_loss: 0.0013\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5586e-04 - val_loss: 0.0013\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5390e-04 - val_loss: 0.0013\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5196e-04 - val_loss: 0.0013\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5003e-04 - val_loss: 0.0012\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4809e-04 - val_loss: 0.0012\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4618e-04 - val_loss: 0.0012\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.4426e-04 - val_loss: 0.0012\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4236e-04 - val_loss: 0.0012\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4045e-04 - val_loss: 0.0012\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3857e-04 - val_loss: 0.0012\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3667e-04 - val_loss: 0.0012\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3479e-04 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3292e-04 - val_loss: 0.0012\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3106e-04 - val_loss: 0.0012\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2920e-04 - val_loss: 0.0012\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2735e-04 - val_loss: 0.0012\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2550e-04 - val_loss: 0.0012\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2366e-04 - val_loss: 0.0012\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2182e-04 - val_loss: 0.0012\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.2000e-04 - val_loss: 0.0012\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1818e-04 - val_loss: 0.0012\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1636e-04 - val_loss: 0.0012\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1455e-04 - val_loss: 0.0012\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1276e-04 - val_loss: 0.0012\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1095e-04 - val_loss: 0.0012\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0916e-04 - val_loss: 0.0012\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0738e-04 - val_loss: 0.0012\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0560e-04 - val_loss: 0.0012\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0384e-04 - val_loss: 0.0012\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0208e-04 - val_loss: 0.0012\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0031e-04 - val_loss: 0.0012\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9856e-04 - val_loss: 0.0012\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9680e-04 - val_loss: 0.0012\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9507e-04 - val_loss: 0.0012\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9333e-04 - val_loss: 0.0012\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9159e-04 - val_loss: 0.0012\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8987e-04 - val_loss: 0.0012\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8815e-04 - val_loss: 0.0012\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8644e-04 - val_loss: 0.0012\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8473e-04 - val_loss: 0.0012\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8303e-04 - val_loss: 0.0011\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8133e-04 - val_loss: 0.0011\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7965e-04 - val_loss: 0.0011\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7795e-04 - val_loss: 0.0011\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7629e-04 - val_loss: 0.0011\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7460e-04 - val_loss: 0.0011\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7293e-04 - val_loss: 0.0011\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7126e-04 - val_loss: 0.0011\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6961e-04 - val_loss: 0.0011\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6796e-04 - val_loss: 0.0011\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6631e-04 - val_loss: 0.0011\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6466e-04 - val_loss: 0.0011\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6302e-04 - val_loss: 0.0011\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6139e-04 - val_loss: 0.0011\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5976e-04 - val_loss: 0.0011\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5813e-04 - val_loss: 0.0011\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5652e-04 - val_loss: 0.0011\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5490e-04 - val_loss: 0.0011\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5330e-04 - val_loss: 0.0011\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5170e-04 - val_loss: 0.0011\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5010e-04 - val_loss: 0.0011\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4851e-04 - val_loss: 0.0011\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4692e-04 - val_loss: 0.0011\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4534e-04 - val_loss: 0.0011\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4375e-04 - val_loss: 0.0011\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4218e-04 - val_loss: 0.0011\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4061e-04 - val_loss: 0.0011\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3905e-04 - val_loss: 0.0011\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3749e-04 - val_loss: 0.0011\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3594e-04 - val_loss: 0.0011\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3439e-04 - val_loss: 0.0011\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 7.3285e-04 - val_loss: 0.0011\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3131e-04 - val_loss: 0.0011\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2977e-04 - val_loss: 0.0011\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2824e-04 - val_loss: 0.0011\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2671e-04 - val_loss: 0.0011\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2518e-04 - val_loss: 0.0011\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2367e-04 - val_loss: 0.0011\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2215e-04 - val_loss: 0.0011\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2065e-04 - val_loss: 0.0011\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1914e-04 - val_loss: 0.0011\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1764e-04 - val_loss: 0.0011\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1615e-04 - val_loss: 0.0010\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1465e-04 - val_loss: 0.0010\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1317e-04 - val_loss: 0.0010\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.1168e-04 - val_loss: 0.0010\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1022e-04 - val_loss: 0.0010\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0873e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0727e-04 - val_loss: 0.0010\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0580e-04 - val_loss: 0.0010\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0434e-04 - val_loss: 0.0010\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0288e-04 - val_loss: 0.0010\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 7.0143e-04 - val_loss: 0.0010\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9998e-04 - val_loss: 0.0010\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9852e-04 - val_loss: 0.0010\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9709e-04 - val_loss: 0.0010\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9565e-04 - val_loss: 0.0010\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9422e-04 - val_loss: 0.0010\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9279e-04 - val_loss: 0.0010\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9137e-04 - val_loss: 0.0010\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8995e-04 - val_loss: 0.0010\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8853e-04 - val_loss: 0.0010\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8712e-04 - val_loss: 0.0010\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8570e-04 - val_loss: 0.0010\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8430e-04 - val_loss: 0.0010\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8290e-04 - val_loss: 9.9970e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8151e-04 - val_loss: 9.9767e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8011e-04 - val_loss: 9.9561e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7872e-04 - val_loss: 9.9356e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7734e-04 - val_loss: 9.9154e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7596e-04 - val_loss: 9.8950e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7458e-04 - val_loss: 9.8749e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7320e-04 - val_loss: 9.8548e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7184e-04 - val_loss: 9.8347e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7046e-04 - val_loss: 9.8148e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6910e-04 - val_loss: 9.7950e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6774e-04 - val_loss: 9.7752e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6639e-04 - val_loss: 9.7554e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6503e-04 - val_loss: 9.7355e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6368e-04 - val_loss: 9.7157e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6233e-04 - val_loss: 9.6963e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6100e-04 - val_loss: 9.6768e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.5966e-04 - val_loss: 9.6573e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5833e-04 - val_loss: 9.6379e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5699e-04 - val_loss: 9.6184e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5567e-04 - val_loss: 9.5993e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5434e-04 - val_loss: 9.5797e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5303e-04 - val_loss: 9.5605e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5171e-04 - val_loss: 9.5416e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5040e-04 - val_loss: 9.5222e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4909e-04 - val_loss: 9.5034e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4778e-04 - val_loss: 9.4839e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4648e-04 - val_loss: 9.4651e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4518e-04 - val_loss: 9.4462e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4388e-04 - val_loss: 9.4272e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4260e-04 - val_loss: 9.4085e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4131e-04 - val_loss: 9.3895e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4001e-04 - val_loss: 9.3708e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3873e-04 - val_loss: 9.3522e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.3745e-04 - val_loss: 9.3335e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3617e-04 - val_loss: 9.3151e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3491e-04 - val_loss: 9.2965e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3364e-04 - val_loss: 9.2784e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 6.3237e-04 - val_loss: 9.2598e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3111e-04 - val_loss: 9.2415e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2985e-04 - val_loss: 9.2233e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2859e-04 - val_loss: 9.2050e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2734e-04 - val_loss: 9.1870e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2609e-04 - val_loss: 9.1688e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 6.2484e-04 - val_loss: 9.1508e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2360e-04 - val_loss: 9.1329e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2237e-04 - val_loss: 9.1149e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2112e-04 - val_loss: 9.0970e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1989e-04 - val_loss: 9.0792e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1866e-04 - val_loss: 9.0612e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1742e-04 - val_loss: 9.0432e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1620e-04 - val_loss: 9.0258e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1499e-04 - val_loss: 9.0079e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1377e-04 - val_loss: 8.9903e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1255e-04 - val_loss: 8.9727e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1134e-04 - val_loss: 8.9550e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1013e-04 - val_loss: 8.9374e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0893e-04 - val_loss: 8.9199e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0772e-04 - val_loss: 8.9026e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0652e-04 - val_loss: 8.8851e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0533e-04 - val_loss: 8.8680e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0413e-04 - val_loss: 8.8508e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0294e-04 - val_loss: 8.8337e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0175e-04 - val_loss: 8.8168e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0056e-04 - val_loss: 8.7995e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9939e-04 - val_loss: 8.7825e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9820e-04 - val_loss: 8.7654e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9702e-04 - val_loss: 8.7485e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9585e-04 - val_loss: 8.7316e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9467e-04 - val_loss: 8.7147e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9351e-04 - val_loss: 8.6978e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 5.9234e-04 - val_loss: 8.6807e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9118e-04 - val_loss: 8.6641e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9003e-04 - val_loss: 8.6471e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8886e-04 - val_loss: 8.6303e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8772e-04 - val_loss: 8.6138e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8657e-04 - val_loss: 8.5969e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8541e-04 - val_loss: 8.5804e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8427e-04 - val_loss: 8.5639e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8312e-04 - val_loss: 8.5477e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8200e-04 - val_loss: 8.5311e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.8084e-04 - val_loss: 8.5151e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.7972e-04 - val_loss: 8.4988e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.7859e-04 - val_loss: 8.4827e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 5.7746e-04 - val_loss: 8.4663e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7634e-04 - val_loss: 8.4505e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 5.7521e-04 - val_loss: 8.4340e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 5.7409e-04 - val_loss: 8.4177e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.7297e-04 - val_loss: 8.4018e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 5.7186e-04 - val_loss: 8.3856e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7074e-04 - val_loss: 8.3695e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 5.6964e-04 - val_loss: 8.3536e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 5.6853e-04 - val_loss: 8.3378e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6742e-04 - val_loss: 8.3217e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6633e-04 - val_loss: 8.3057e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6523e-04 - val_loss: 8.2900e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6412e-04 - val_loss: 8.2739e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6303e-04 - val_loss: 8.2583e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 5.6194e-04 - val_loss: 8.2428e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6085e-04 - val_loss: 8.2268e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 5.5976e-04 - val_loss: 8.2114e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 5.5868e-04 - val_loss: 8.1961e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.5760e-04 - val_loss: 8.1804e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5652e-04 - val_loss: 8.1650e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5544e-04 - val_loss: 8.1497e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5437e-04 - val_loss: 8.1344e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 5.5330e-04 - val_loss: 8.1190e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5223e-04 - val_loss: 8.1037e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.5117e-04 - val_loss: 8.0881e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 5.5009e-04 - val_loss: 8.0729e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4904e-04 - val_loss: 8.0573e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4798e-04 - val_loss: 8.0421e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 194us/step - loss: 5.4692e-04 - val_loss: 8.0269e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.4587e-04 - val_loss: 8.0120e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4482e-04 - val_loss: 7.9965e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4377e-04 - val_loss: 7.9817e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4272e-04 - val_loss: 7.9668e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4168e-04 - val_loss: 7.9518e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4064e-04 - val_loss: 7.9370e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3960e-04 - val_loss: 7.9224e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3856e-04 - val_loss: 7.9075e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 5.3752e-04 - val_loss: 7.8927e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3650e-04 - val_loss: 7.8781e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3548e-04 - val_loss: 7.8633e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3444e-04 - val_loss: 7.8484e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3342e-04 - val_loss: 7.8338e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 5.3239e-04 - val_loss: 7.8190e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 5.3137e-04 - val_loss: 7.8045e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3036e-04 - val_loss: 7.7897e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2934e-04 - val_loss: 7.7752e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2833e-04 - val_loss: 7.7604e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2731e-04 - val_loss: 7.7461e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2630e-04 - val_loss: 7.7313e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 5.2530e-04 - val_loss: 7.7171e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2429e-04 - val_loss: 7.7026e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2329e-04 - val_loss: 7.6884e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 5.2230e-04 - val_loss: 7.6740e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.2130e-04 - val_loss: 7.6599e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 5.2031e-04 - val_loss: 7.6457e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1931e-04 - val_loss: 7.6317e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1833e-04 - val_loss: 7.6174e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 5.1732e-04 - val_loss: 7.6035e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1635e-04 - val_loss: 7.5894e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1536e-04 - val_loss: 7.5753e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1438e-04 - val_loss: 7.5613e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1341e-04 - val_loss: 7.5472e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1242e-04 - val_loss: 7.5332e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1145e-04 - val_loss: 7.5195e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 5.1048e-04 - val_loss: 7.5052e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0950e-04 - val_loss: 7.4913e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0854e-04 - val_loss: 7.4774e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0757e-04 - val_loss: 7.4634e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0660e-04 - val_loss: 7.4497e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0565e-04 - val_loss: 7.4357e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.0469e-04 - val_loss: 7.4221e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0373e-04 - val_loss: 7.4088e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0278e-04 - val_loss: 7.3949e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 5.0182e-04 - val_loss: 7.3813e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.0087e-04 - val_loss: 7.3679e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9992e-04 - val_loss: 7.3544e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9898e-04 - val_loss: 7.3409e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9804e-04 - val_loss: 7.3274e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.9709e-04 - val_loss: 7.3142e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9615e-04 - val_loss: 7.3006e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 4.9520e-04 - val_loss: 7.2871e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9427e-04 - val_loss: 7.2736e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9334e-04 - val_loss: 7.2602e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.9241e-04 - val_loss: 7.2470e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9148e-04 - val_loss: 7.2335e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9055e-04 - val_loss: 7.2201e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.8962e-04 - val_loss: 7.2071e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8871e-04 - val_loss: 7.1937e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8778e-04 - val_loss: 7.1808e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8686e-04 - val_loss: 7.1676e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8593e-04 - val_loss: 7.1547e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8503e-04 - val_loss: 7.1416e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 4.8411e-04 - val_loss: 7.1286e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8320e-04 - val_loss: 7.1157e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8229e-04 - val_loss: 7.1027e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8138e-04 - val_loss: 7.0897e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8047e-04 - val_loss: 7.0766e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7957e-04 - val_loss: 7.0639e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7867e-04 - val_loss: 7.0509e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7777e-04 - val_loss: 7.0378e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7687e-04 - val_loss: 7.0251e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.7598e-04 - val_loss: 7.0124e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 4.7508e-04 - val_loss: 6.9995e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7419e-04 - val_loss: 6.9867e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7330e-04 - val_loss: 6.9739e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7241e-04 - val_loss: 6.9612e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7153e-04 - val_loss: 6.9488e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7064e-04 - val_loss: 6.9362e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6976e-04 - val_loss: 6.9237e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6888e-04 - val_loss: 6.9112e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6800e-04 - val_loss: 6.8986e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6713e-04 - val_loss: 6.8865e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6625e-04 - val_loss: 6.8739e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6537e-04 - val_loss: 6.8613e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 4.6450e-04 - val_loss: 6.8489e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.6364e-04 - val_loss: 6.8364e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6277e-04 - val_loss: 6.8238e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6190e-04 - val_loss: 6.8113e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 4.6104e-04 - val_loss: 6.7989e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 4.6018e-04 - val_loss: 6.7870e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5932e-04 - val_loss: 6.7746e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 4.5847e-04 - val_loss: 6.7624e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5761e-04 - val_loss: 6.7502e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5675e-04 - val_loss: 6.7380e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.5589e-04 - val_loss: 6.7259e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 4.5506e-04 - val_loss: 6.7137e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5420e-04 - val_loss: 6.7016e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5335e-04 - val_loss: 6.6898e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5251e-04 - val_loss: 6.6777e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5167e-04 - val_loss: 6.6656e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 4.5083e-04 - val_loss: 6.6535e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4999e-04 - val_loss: 6.6416e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 4.4915e-04 - val_loss: 6.6294e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 4.4831e-04 - val_loss: 6.6175e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4748e-04 - val_loss: 6.6057e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4665e-04 - val_loss: 6.5936e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4582e-04 - val_loss: 6.5816e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.4499e-04 - val_loss: 6.5699e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4416e-04 - val_loss: 6.5581e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4333e-04 - val_loss: 6.5464e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.4251e-04 - val_loss: 6.5346e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 4.4169e-04 - val_loss: 6.5231e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4086e-04 - val_loss: 6.5116e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4005e-04 - val_loss: 6.4998e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3923e-04 - val_loss: 6.4882e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3841e-04 - val_loss: 6.4767e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 4.3760e-04 - val_loss: 6.4652e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 4.3680e-04 - val_loss: 6.4536e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3598e-04 - val_loss: 6.4421e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3518e-04 - val_loss: 6.4304e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3437e-04 - val_loss: 6.4188e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3357e-04 - val_loss: 6.4071e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3275e-04 - val_loss: 6.3957e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3196e-04 - val_loss: 6.3843e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3116e-04 - val_loss: 6.3728e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3036e-04 - val_loss: 6.3613e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2957e-04 - val_loss: 6.3503e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 4.2877e-04 - val_loss: 6.3388e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.2798e-04 - val_loss: 6.3277e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.2720e-04 - val_loss: 6.3164e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2640e-04 - val_loss: 6.3052e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2561e-04 - val_loss: 6.2939e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2482e-04 - val_loss: 6.2830e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2405e-04 - val_loss: 6.2719e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2326e-04 - val_loss: 6.2606e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2248e-04 - val_loss: 6.2493e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2170e-04 - val_loss: 6.2381e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2092e-04 - val_loss: 6.2270e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2015e-04 - val_loss: 6.2158e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.1937e-04 - val_loss: 6.2045e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1860e-04 - val_loss: 6.1935e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 4.1783e-04 - val_loss: 6.1825e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1705e-04 - val_loss: 6.1717e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1629e-04 - val_loss: 6.1609e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 4.1552e-04 - val_loss: 6.1500e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1476e-04 - val_loss: 6.1391e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 4.1400e-04 - val_loss: 6.1283e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.1323e-04 - val_loss: 6.1177e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1247e-04 - val_loss: 6.1069e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1172e-04 - val_loss: 6.0960e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 4.1096e-04 - val_loss: 6.0852e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1020e-04 - val_loss: 6.0742e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 4.0945e-04 - val_loss: 6.0637e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0870e-04 - val_loss: 6.0527e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0794e-04 - val_loss: 6.0417e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0719e-04 - val_loss: 6.0311e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0645e-04 - val_loss: 6.0204e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0569e-04 - val_loss: 6.0096e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0495e-04 - val_loss: 5.9990e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.0422e-04 - val_loss: 5.9883e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0347e-04 - val_loss: 5.9778e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 4.0273e-04 - val_loss: 5.9673e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0199e-04 - val_loss: 5.9570e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 4.0126e-04 - val_loss: 5.9466e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 4.0052e-04 - val_loss: 5.9362e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9979e-04 - val_loss: 5.9257e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9906e-04 - val_loss: 5.9153e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9832e-04 - val_loss: 5.9048e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.9760e-04 - val_loss: 5.8945e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9687e-04 - val_loss: 5.8842e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9614e-04 - val_loss: 5.8736e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9542e-04 - val_loss: 5.8632e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 3.9469e-04 - val_loss: 5.8529e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.9397e-04 - val_loss: 5.8426e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.9325e-04 - val_loss: 5.8321e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9254e-04 - val_loss: 5.8219e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9182e-04 - val_loss: 5.8117e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9110e-04 - val_loss: 5.8016e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9038e-04 - val_loss: 5.7913e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8967e-04 - val_loss: 5.7811e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8896e-04 - val_loss: 5.7712e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8825e-04 - val_loss: 5.7611e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 3.8754e-04 - val_loss: 5.7510e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8683e-04 - val_loss: 5.7408e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.8613e-04 - val_loss: 5.7308e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8543e-04 - val_loss: 5.7208e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8472e-04 - val_loss: 5.7108e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8402e-04 - val_loss: 5.7008e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8332e-04 - val_loss: 5.6907e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 3.8262e-04 - val_loss: 5.6805e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 3.8192e-04 - val_loss: 5.6705e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8123e-04 - val_loss: 5.6605e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8053e-04 - val_loss: 5.6505e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 3.7984e-04 - val_loss: 5.6408e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7915e-04 - val_loss: 5.6309e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7846e-04 - val_loss: 5.6211e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7777e-04 - val_loss: 5.6113e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7708e-04 - val_loss: 5.6017e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7640e-04 - val_loss: 5.5920e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7571e-04 - val_loss: 5.5822e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7504e-04 - val_loss: 5.5724e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.7435e-04 - val_loss: 5.5627e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.7367e-04 - val_loss: 5.5532e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 3.7300e-04 - val_loss: 5.5435e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7232e-04 - val_loss: 5.5336e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7164e-04 - val_loss: 5.5240e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.7097e-04 - val_loss: 5.5143e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7029e-04 - val_loss: 5.5043e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6962e-04 - val_loss: 5.4949e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6895e-04 - val_loss: 5.4852e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6828e-04 - val_loss: 5.4756e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.6761e-04 - val_loss: 5.4660e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 3.6695e-04 - val_loss: 5.4567e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.6628e-04 - val_loss: 5.4471e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6562e-04 - val_loss: 5.4377e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6495e-04 - val_loss: 5.4283e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6429e-04 - val_loss: 5.4188e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6363e-04 - val_loss: 5.4098e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 3.6298e-04 - val_loss: 5.4002e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6232e-04 - val_loss: 5.3909e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.6167e-04 - val_loss: 5.3817e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.6100e-04 - val_loss: 5.3722e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6035e-04 - val_loss: 5.3629e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 3.5970e-04 - val_loss: 5.3536e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5905e-04 - val_loss: 5.3440e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.5840e-04 - val_loss: 5.3346e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5775e-04 - val_loss: 5.3254e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5711e-04 - val_loss: 5.3160e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5646e-04 - val_loss: 5.3066e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5582e-04 - val_loss: 5.2975e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 3.5518e-04 - val_loss: 5.2885e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 3.5454e-04 - val_loss: 5.2795e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5390e-04 - val_loss: 5.2703e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5325e-04 - val_loss: 5.2611e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5262e-04 - val_loss: 5.2522e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 3.5198e-04 - val_loss: 5.2431e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5135e-04 - val_loss: 5.2338e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.5072e-04 - val_loss: 5.2251e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5008e-04 - val_loss: 5.2161e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4945e-04 - val_loss: 5.2071e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4882e-04 - val_loss: 5.1981e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4819e-04 - val_loss: 5.1889e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 3.4757e-04 - val_loss: 5.1798e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.4694e-04 - val_loss: 5.1708e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4631e-04 - val_loss: 5.1619e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 3.4568e-04 - val_loss: 5.1530e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.4507e-04 - val_loss: 5.1440e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.4444e-04 - val_loss: 5.1351e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 3.4382e-04 - val_loss: 5.1262e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.4321e-04 - val_loss: 5.1175e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4259e-04 - val_loss: 5.1087e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 3.4197e-04 - val_loss: 5.1000e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.4136e-04 - val_loss: 5.0912e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4075e-04 - val_loss: 5.0824e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4013e-04 - val_loss: 5.0736e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3952e-04 - val_loss: 5.0649e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.3891e-04 - val_loss: 5.0564e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3831e-04 - val_loss: 5.0476e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3769e-04 - val_loss: 5.0390e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3709e-04 - val_loss: 5.0303e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3648e-04 - val_loss: 5.0214e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.3587e-04 - val_loss: 5.0129e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3528e-04 - val_loss: 5.0043e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.3468e-04 - val_loss: 4.9956e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.3407e-04 - val_loss: 4.9870e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3347e-04 - val_loss: 4.9782e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 3.3288e-04 - val_loss: 4.9695e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 3.3228e-04 - val_loss: 4.9609e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 3.3169e-04 - val_loss: 4.9525e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3109e-04 - val_loss: 4.9440e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3050e-04 - val_loss: 4.9355e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.2990e-04 - val_loss: 4.9273e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.2932e-04 - val_loss: 4.9188e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2872e-04 - val_loss: 4.9103e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2814e-04 - val_loss: 4.9020e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2755e-04 - val_loss: 4.8936e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2696e-04 - val_loss: 4.8852e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 3.2637e-04 - val_loss: 4.8770e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2579e-04 - val_loss: 4.8686e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2521e-04 - val_loss: 4.8602e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.2462e-04 - val_loss: 4.8518e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2404e-04 - val_loss: 4.8436e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2346e-04 - val_loss: 4.8351e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.2289e-04 - val_loss: 4.8267e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2231e-04 - val_loss: 4.8185e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 210us/step - loss: 3.2174e-04 - val_loss: 4.8101e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2116e-04 - val_loss: 4.8019e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2059e-04 - val_loss: 4.7938e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 3.2001e-04 - val_loss: 4.7857e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1944e-04 - val_loss: 4.7775e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.1887e-04 - val_loss: 4.7694e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 195us/step - loss: 3.1830e-04 - val_loss: 4.7612e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1773e-04 - val_loss: 4.7532e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1717e-04 - val_loss: 4.7451e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1660e-04 - val_loss: 4.7368e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.1604e-04 - val_loss: 4.7290e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1547e-04 - val_loss: 4.7208e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1491e-04 - val_loss: 4.7127e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 3.1435e-04 - val_loss: 4.7046e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1379e-04 - val_loss: 4.6965e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 3.1322e-04 - val_loss: 4.6887e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1267e-04 - val_loss: 4.6805e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 3.1212e-04 - val_loss: 4.6724e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1156e-04 - val_loss: 4.6642e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1100e-04 - val_loss: 4.6565e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 3.1045e-04 - val_loss: 4.6485e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.0990e-04 - val_loss: 4.6405e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 3.0934e-04 - val_loss: 4.6329e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0879e-04 - val_loss: 4.6250e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0824e-04 - val_loss: 4.6173e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0770e-04 - val_loss: 4.6094e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.0715e-04 - val_loss: 4.6017e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0660e-04 - val_loss: 4.5936e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0606e-04 - val_loss: 4.5861e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.0552e-04 - val_loss: 4.5779e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.0497e-04 - val_loss: 4.5701e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0443e-04 - val_loss: 4.5624e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0389e-04 - val_loss: 4.5548e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0335e-04 - val_loss: 4.5470e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0281e-04 - val_loss: 4.5392e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 3.0227e-04 - val_loss: 4.5315e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0173e-04 - val_loss: 4.5239e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0120e-04 - val_loss: 4.5160e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0066e-04 - val_loss: 4.5084e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0013e-04 - val_loss: 4.5008e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9960e-04 - val_loss: 4.4932e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9907e-04 - val_loss: 4.4853e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9853e-04 - val_loss: 4.4780e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9801e-04 - val_loss: 4.4703e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9748e-04 - val_loss: 4.4626e-04\n",
      "0.0003826652537100017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.09387104,  0.44794676, -0.9581307 , -0.80688125,  0.45144805,\n",
       "          0.71762943,  0.27972683, -0.2861967 , -0.6753328 ,  0.6117131 ],\n",
       "        [ 1.2731714 , -0.23780279,  0.41497785,  0.39323267,  0.35095212,\n",
       "         -0.7965661 ,  0.29592818,  0.25799155, -0.13029987,  0.10059815],\n",
       "        [ 0.70047224, -0.6196809 , -0.6312383 ,  0.9282479 ,  1.1063507 ,\n",
       "          0.70490867, -0.8073384 ,  0.5214568 , -0.3223029 ,  1.7474324 ]],\n",
       "       dtype=float32),\n",
       " array([-0.4336528 ,  0.6199729 ,  0.6150489 , -0.5336144 ,  0.5968196 ,\n",
       "        -0.6498447 ,  0.28098714,  0.61180943,  0.55085194,  0.28109884],\n",
       "       dtype=float32),\n",
       " array([[ 6.1483198e-01, -3.0546552e-01,  2.8894332e-01,  1.7758511e-01,\n",
       "         -4.8411402e-01],\n",
       "        [ 7.3918238e-02, -2.6886219e-01, -8.6621881e-01,  6.2503922e-01,\n",
       "         -7.8445029e-01],\n",
       "        [-1.0726971e-01,  4.7291529e-01, -5.1571685e-01, -2.6251176e-01,\n",
       "         -3.6824557e-01],\n",
       "        [ 2.3006614e-01, -6.5256077e-01,  7.1913427e-01, -4.2915991e-01,\n",
       "         -1.5642932e-01],\n",
       "        [ 6.2486343e-04,  8.4701329e-01, -9.3589336e-01, -1.0897334e-01,\n",
       "          8.2181260e-02],\n",
       "        [-1.4112544e-01, -6.0210615e-01,  3.9469206e-01, -1.8321482e-02,\n",
       "          5.5039749e-03],\n",
       "        [-5.2030110e-01,  1.6667667e-01, -1.5843813e-01, -3.1585693e-01,\n",
       "         -3.3385530e-01],\n",
       "        [ 5.3063715e-01,  2.6114118e-01, -4.5317802e-01, -5.4090250e-02,\n",
       "          6.5241623e-01],\n",
       "        [ 1.6336271e-03,  6.5490717e-01,  2.9898089e-01,  1.5253906e-01,\n",
       "         -3.7263337e-01],\n",
       "        [-2.3808633e-01, -1.1111718e-01, -7.9435903e-01,  2.7545249e-01,\n",
       "         -4.9505973e-01]], dtype=float32),\n",
       " array([-0.18418059,  0.7717781 , -0.7792871 ,  0.684605  , -0.73476523],\n",
       "       dtype=float32),\n",
       " array([[-0.02228233],\n",
       "        [ 0.977082  ],\n",
       "        [-1.0835118 ],\n",
       "        [ 0.35137805],\n",
       "        [-0.4928515 ]], dtype=float32),\n",
       " array([0.81129193], dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_4(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure4_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.1131 - val_loss: 34.4920\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 33.7954 - val_loss: 31.1982\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.0407 - val_loss: 25.4551\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 112us/step - loss: 24.3040 - val_loss: 17.3561\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 16.6160 - val_loss: 8.1542\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0074 - val_loss: 1.0582\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.2955 - val_loss: 2.3854\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9518 - val_loss: 9.2999\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4058 - val_loss: 7.8942\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0608 - val_loss: 3.6809\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1355 - val_loss: 1.1136\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2073 - val_loss: 0.5901\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.5145 - val_loss: 1.1694\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2862 - val_loss: 1.9162\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2858 - val_loss: 2.3326\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8707 - val_loss: 2.3063\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.9267 - val_loss: 1.9287\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 2.5628 - val_loss: 1.3690\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9520 - val_loss: 0.8055\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2697 - val_loss: 0.3835\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6733 - val_loss: 0.1842\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2941 - val_loss: 0.2061\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.2102 - val_loss: 0.3711\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3950 - val_loss: 0.5606\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6897 - val_loss: 0.6656\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8746 - val_loss: 0.6291\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8215 - val_loss: 0.4705\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5747 - val_loss: 0.2731\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2867 - val_loss: 0.1331\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0985 - val_loss: 0.1031\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0666 - val_loss: 0.1693\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1571 - val_loss: 0.2729\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.2867 - val_loss: 0.3524\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3764 - val_loss: 0.3758\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3867 - val_loss: 0.3465\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.3234 - val_loss: 0.2890\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.2229 - val_loss: 0.2297\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.1284 - val_loss: 0.1841\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0709 - val_loss: 0.1544\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0589 - val_loss: 0.1358\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0805 - val_loss: 0.1234\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1128 - val_loss: 0.1137\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1343 - val_loss: 0.1028\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1344 - val_loss: 0.0875\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1156 - val_loss: 0.0674\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0885 - val_loss: 0.0472\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0634 - val_loss: 0.0335\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0462 - val_loss: 0.0308\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0387 - val_loss: 0.0392\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0398 - val_loss: 0.0542\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0464 - val_loss: 0.0695\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0545 - val_loss: 0.0796\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0593 - val_loss: 0.0814\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0578 - val_loss: 0.0748\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0495 - val_loss: 0.0622\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0374 - val_loss: 0.0470\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0259 - val_loss: 0.0331\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0189 - val_loss: 0.0237\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0182 - val_loss: 0.0200\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0226 - val_loss: 0.0209\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0286 - val_loss: 0.0232\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0325 - val_loss: 0.0241\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0318 - val_loss: 0.0229\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0269 - val_loss: 0.0212\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0202 - val_loss: 0.0218\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0258\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0129 - val_loss: 0.0323\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0141 - val_loss: 0.0384\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0167 - val_loss: 0.0418\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0188 - val_loss: 0.0413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0193 - val_loss: 0.0375\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0179 - val_loss: 0.0319\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.0261\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0130 - val_loss: 0.0213\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0179\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0111 - val_loss: 0.0158\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0117 - val_loss: 0.0145\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0129 - val_loss: 0.0136\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0157\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0176\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0198\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0220\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0236\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0098 - val_loss: 0.0244\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0099 - val_loss: 0.0244\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0238\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0227\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0094 - val_loss: 0.0214\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0200\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0087 - val_loss: 0.0188\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0178\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0085 - val_loss: 0.0171\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0166\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0086 - val_loss: 0.0163\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0085 - val_loss: 0.0162\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0084 - val_loss: 0.0162\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0082 - val_loss: 0.0162\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0164\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0078 - val_loss: 0.0166\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0167\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0168\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0077 - val_loss: 0.0167\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0077 - val_loss: 0.0165\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0076 - val_loss: 0.0161\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0075 - val_loss: 0.0157\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0074 - val_loss: 0.0152\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.0073 - val_loss: 0.0147\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0143\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0072 - val_loss: 0.0140\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0137\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0071 - val_loss: 0.0135\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0134\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0070 - val_loss: 0.0134\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0069 - val_loss: 0.0134\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0134\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0067 - val_loss: 0.0135\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0067 - val_loss: 0.0135\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0066 - val_loss: 0.0135\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0066 - val_loss: 0.0133\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0065 - val_loss: 0.0131\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0064 - val_loss: 0.0129\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0126\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0122\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0119\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0116\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0062 - val_loss: 0.0114\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0062 - val_loss: 0.0112\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0061 - val_loss: 0.0110\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0061 - val_loss: 0.0109\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0109\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0060 - val_loss: 0.0108\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0108\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0059 - val_loss: 0.0108\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0108\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0107\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0106\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0105\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0104\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0056 - val_loss: 0.0101\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0056 - val_loss: 0.0100\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0055 - val_loss: 0.0099\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 190us/step - loss: 0.0054 - val_loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0053 - val_loss: 0.0093\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0053 - val_loss: 0.0093\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0092\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0052 - val_loss: 0.0091\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0052 - val_loss: 0.0091\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0090\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0089\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0051 - val_loss: 0.0087\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0050 - val_loss: 0.0086\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0085\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0084\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0049 - val_loss: 0.0083\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0082\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 0.0081\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0080\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0079\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0078\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0075\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0046 - val_loss: 0.0075\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0045 - val_loss: 0.0071\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0034 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 201us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 196us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 199us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0017 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 198us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9692e-04 - val_loss: 0.0011\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 9.9354e-04 - val_loss: 0.0011\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9017e-04 - val_loss: 0.0011\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.8680e-04 - val_loss: 0.0011\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.8346e-04 - val_loss: 0.0011\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8012e-04 - val_loss: 0.0011\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7681e-04 - val_loss: 0.0011\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7351e-04 - val_loss: 0.0011\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7022e-04 - val_loss: 0.0011\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6696e-04 - val_loss: 0.0010\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 9.6369e-04 - val_loss: 0.0010\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 9.6045e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9.5721e-04 - val_loss: 0.0010\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5399e-04 - val_loss: 0.0010\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5080e-04 - val_loss: 0.0010\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9.4761e-04 - val_loss: 0.0010\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.4443e-04 - val_loss: 0.0010\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 191us/step - loss: 9.4125e-04 - val_loss: 0.0010\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3810e-04 - val_loss: 0.0010\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3496e-04 - val_loss: 0.0010\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3184e-04 - val_loss: 0.0010\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2872e-04 - val_loss: 0.0010\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2562e-04 - val_loss: 0.0010\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2254e-04 - val_loss: 9.9839e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 9.1946e-04 - val_loss: 9.9483e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1641e-04 - val_loss: 9.9129e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1336e-04 - val_loss: 9.8776e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 9.1032e-04 - val_loss: 9.8427e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0729e-04 - val_loss: 9.8082e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0427e-04 - val_loss: 9.7735e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0128e-04 - val_loss: 9.7392e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 8.9830e-04 - val_loss: 9.7048e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 8.9532e-04 - val_loss: 9.6704e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9235e-04 - val_loss: 9.6364e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 8.8940e-04 - val_loss: 9.6023e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 193us/step - loss: 8.8646e-04 - val_loss: 9.5689e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8354e-04 - val_loss: 9.5353e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8063e-04 - val_loss: 9.5018e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 8.7773e-04 - val_loss: 9.4687e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 8.7483e-04 - val_loss: 9.4357e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 8.7195e-04 - val_loss: 9.4030e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6910e-04 - val_loss: 9.3703e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 8.6624e-04 - val_loss: 9.3374e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6340e-04 - val_loss: 9.3051e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6057e-04 - val_loss: 9.2726e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.5773e-04 - val_loss: 9.2404e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5493e-04 - val_loss: 9.2084e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 8.5213e-04 - val_loss: 9.1767e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 8.4935e-04 - val_loss: 9.1450e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4659e-04 - val_loss: 9.1134e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 8.4381e-04 - val_loss: 9.0819e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4106e-04 - val_loss: 9.0507e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.3833e-04 - val_loss: 9.0196e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 8.3559e-04 - val_loss: 8.9884e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 8.3287e-04 - val_loss: 8.9577e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.3015e-04 - val_loss: 8.9273e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2747e-04 - val_loss: 8.8967e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2478e-04 - val_loss: 8.8661e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2210e-04 - val_loss: 8.8358e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1945e-04 - val_loss: 8.8058e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 8.1678e-04 - val_loss: 8.7756e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.1413e-04 - val_loss: 8.7460e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 8.1151e-04 - val_loss: 8.7160e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0889e-04 - val_loss: 8.6865e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0628e-04 - val_loss: 8.6569e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0367e-04 - val_loss: 8.6274e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 8.0108e-04 - val_loss: 8.5982e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.9850e-04 - val_loss: 8.5693e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9593e-04 - val_loss: 8.5403e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 7.9336e-04 - val_loss: 8.5118e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9082e-04 - val_loss: 8.4827e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8828e-04 - val_loss: 8.4546e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8574e-04 - val_loss: 8.4258e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 7.8323e-04 - val_loss: 8.3976e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.8071e-04 - val_loss: 8.3695e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7822e-04 - val_loss: 8.3412e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 7.7572e-04 - val_loss: 8.3135e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 7.7324e-04 - val_loss: 8.2857e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7078e-04 - val_loss: 8.2580e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6831e-04 - val_loss: 8.2304e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 7.6586e-04 - val_loss: 8.2033e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 7.6342e-04 - val_loss: 8.1759e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6098e-04 - val_loss: 8.1486e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5856e-04 - val_loss: 8.1217e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5614e-04 - val_loss: 8.0946e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 7.5374e-04 - val_loss: 8.0679e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.5134e-04 - val_loss: 8.0412e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4896e-04 - val_loss: 8.0144e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4659e-04 - val_loss: 7.9879e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4422e-04 - val_loss: 7.9617e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.4186e-04 - val_loss: 7.9354e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3951e-04 - val_loss: 7.9094e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 7.3717e-04 - val_loss: 7.8834e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3484e-04 - val_loss: 7.8573e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 7.3252e-04 - val_loss: 7.8317e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 7.3021e-04 - val_loss: 7.8059e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.2790e-04 - val_loss: 7.7805e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2560e-04 - val_loss: 7.7549e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2332e-04 - val_loss: 7.7296e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2105e-04 - val_loss: 7.7044e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1878e-04 - val_loss: 7.6791e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1652e-04 - val_loss: 7.6543e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1427e-04 - val_loss: 7.6292e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1202e-04 - val_loss: 7.6046e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 7.0980e-04 - val_loss: 7.5799e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0757e-04 - val_loss: 7.5553e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0535e-04 - val_loss: 7.5309e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.0314e-04 - val_loss: 7.5065e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0094e-04 - val_loss: 7.4824e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9876e-04 - val_loss: 7.4584e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9657e-04 - val_loss: 7.4340e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.9439e-04 - val_loss: 7.4101e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9223e-04 - val_loss: 7.3862e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 6.9007e-04 - val_loss: 7.3625e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 6.8792e-04 - val_loss: 7.3390e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8578e-04 - val_loss: 7.3155e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8365e-04 - val_loss: 7.2919e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8153e-04 - val_loss: 7.2688e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7941e-04 - val_loss: 7.2455e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7729e-04 - val_loss: 7.2223e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7519e-04 - val_loss: 7.1992e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.7309e-04 - val_loss: 7.1762e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7101e-04 - val_loss: 7.1535e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 6.6894e-04 - val_loss: 7.1306e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6686e-04 - val_loss: 7.1080e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6480e-04 - val_loss: 7.0854e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6275e-04 - val_loss: 7.0628e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 6.6071e-04 - val_loss: 7.0405e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.5867e-04 - val_loss: 7.0183e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5663e-04 - val_loss: 6.9961e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.5461e-04 - val_loss: 6.9741e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5259e-04 - val_loss: 6.9523e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5059e-04 - val_loss: 6.9303e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4859e-04 - val_loss: 6.9085e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4658e-04 - val_loss: 6.8869e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4461e-04 - val_loss: 6.8652e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.4263e-04 - val_loss: 6.8436e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4065e-04 - val_loss: 6.8220e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3869e-04 - val_loss: 6.8006e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3674e-04 - val_loss: 6.7794e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 6.3479e-04 - val_loss: 6.7582e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.3285e-04 - val_loss: 6.7373e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3090e-04 - val_loss: 6.7162e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 6.2898e-04 - val_loss: 6.6951e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2705e-04 - val_loss: 6.6744e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2515e-04 - val_loss: 6.6537e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.2324e-04 - val_loss: 6.6330e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2134e-04 - val_loss: 6.6124e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1944e-04 - val_loss: 6.5918e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1756e-04 - val_loss: 6.5716e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1568e-04 - val_loss: 6.5513e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1381e-04 - val_loss: 6.5310e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 6.1195e-04 - val_loss: 6.5109e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1009e-04 - val_loss: 6.4908e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.0823e-04 - val_loss: 6.4709e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0640e-04 - val_loss: 6.4509e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0455e-04 - val_loss: 6.4310e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0272e-04 - val_loss: 6.4113e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0090e-04 - val_loss: 6.3918e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 197us/step - loss: 5.9908e-04 - val_loss: 6.3720e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 5.9727e-04 - val_loss: 6.3526e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9546e-04 - val_loss: 6.3331e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9366e-04 - val_loss: 6.3138e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9187e-04 - val_loss: 6.2945e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.9009e-04 - val_loss: 6.2753e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8831e-04 - val_loss: 6.2562e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8654e-04 - val_loss: 6.2373e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8479e-04 - val_loss: 6.2184e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 5.8301e-04 - val_loss: 6.1994e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8126e-04 - val_loss: 6.1805e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7951e-04 - val_loss: 6.1618e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7777e-04 - val_loss: 6.1432e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 5.7604e-04 - val_loss: 6.1248e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7431e-04 - val_loss: 6.1061e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7259e-04 - val_loss: 6.0877e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7088e-04 - val_loss: 6.0696e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6916e-04 - val_loss: 6.0511e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6746e-04 - val_loss: 6.0329e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6576e-04 - val_loss: 6.0148e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6408e-04 - val_loss: 5.9969e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 5.6239e-04 - val_loss: 5.9788e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.6071e-04 - val_loss: 5.9608e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5904e-04 - val_loss: 5.9429e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5737e-04 - val_loss: 5.9252e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5572e-04 - val_loss: 5.9075e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.5405e-04 - val_loss: 5.8898e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5241e-04 - val_loss: 5.8722e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5077e-04 - val_loss: 5.8549e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 5.4912e-04 - val_loss: 5.8375e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4749e-04 - val_loss: 5.8202e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4588e-04 - val_loss: 5.8026e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4425e-04 - val_loss: 5.7854e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4264e-04 - val_loss: 5.7684e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4103e-04 - val_loss: 5.7513e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3942e-04 - val_loss: 5.7343e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3782e-04 - val_loss: 5.7171e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3624e-04 - val_loss: 5.7004e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3464e-04 - val_loss: 5.6835e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 5.3306e-04 - val_loss: 5.6670e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3149e-04 - val_loss: 5.6503e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 5.2991e-04 - val_loss: 5.6336e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 5.2836e-04 - val_loss: 5.6169e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.2680e-04 - val_loss: 5.6004e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2525e-04 - val_loss: 5.5841e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2371e-04 - val_loss: 5.5677e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2216e-04 - val_loss: 5.5511e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2062e-04 - val_loss: 5.5352e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1909e-04 - val_loss: 5.5190e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1756e-04 - val_loss: 5.5029e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1605e-04 - val_loss: 5.4869e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1453e-04 - val_loss: 5.4709e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1302e-04 - val_loss: 5.4548e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1151e-04 - val_loss: 5.4392e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1001e-04 - val_loss: 5.4232e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0852e-04 - val_loss: 5.4076e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 5.0703e-04 - val_loss: 5.3918e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0555e-04 - val_loss: 5.3762e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0407e-04 - val_loss: 5.3606e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0259e-04 - val_loss: 5.3452e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 5.0113e-04 - val_loss: 5.3298e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9966e-04 - val_loss: 5.3143e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.9820e-04 - val_loss: 5.2991e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.9675e-04 - val_loss: 5.2838e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.9530e-04 - val_loss: 5.2687e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9386e-04 - val_loss: 5.2535e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9242e-04 - val_loss: 5.2385e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 4.9099e-04 - val_loss: 5.2233e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8956e-04 - val_loss: 5.2084e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8813e-04 - val_loss: 5.1936e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8672e-04 - val_loss: 5.1786e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8530e-04 - val_loss: 5.1639e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8390e-04 - val_loss: 5.1491e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.8249e-04 - val_loss: 5.1343e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8109e-04 - val_loss: 5.1196e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7969e-04 - val_loss: 5.1052e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7830e-04 - val_loss: 5.0906e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7692e-04 - val_loss: 5.0761e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 4.7554e-04 - val_loss: 5.0616e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7416e-04 - val_loss: 5.0474e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7280e-04 - val_loss: 5.0331e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.7143e-04 - val_loss: 5.0187e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7006e-04 - val_loss: 5.0045e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6871e-04 - val_loss: 4.9904e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6735e-04 - val_loss: 4.9763e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6601e-04 - val_loss: 4.9624e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6466e-04 - val_loss: 4.9485e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6332e-04 - val_loss: 4.9345e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 4.6199e-04 - val_loss: 4.9206e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 4.6066e-04 - val_loss: 4.9069e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5934e-04 - val_loss: 4.8930e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 191us/step - loss: 4.5801e-04 - val_loss: 4.8793e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 4.5670e-04 - val_loss: 4.8656e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5539e-04 - val_loss: 4.8520e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5408e-04 - val_loss: 4.8383e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5278e-04 - val_loss: 4.8249e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 4.5148e-04 - val_loss: 4.8116e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5018e-04 - val_loss: 4.7980e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 205us/step - loss: 4.4889e-04 - val_loss: 4.7846e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4761e-04 - val_loss: 4.7713e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.4633e-04 - val_loss: 4.7580e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4505e-04 - val_loss: 4.7448e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4378e-04 - val_loss: 4.7317e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4251e-04 - val_loss: 4.7185e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.4125e-04 - val_loss: 4.7054e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3998e-04 - val_loss: 4.6925e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 4.3873e-04 - val_loss: 4.6794e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3748e-04 - val_loss: 4.6666e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3623e-04 - val_loss: 4.6536e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3498e-04 - val_loss: 4.6408e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3374e-04 - val_loss: 4.6278e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3251e-04 - val_loss: 4.6151e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3128e-04 - val_loss: 4.6025e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3005e-04 - val_loss: 4.5898e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2883e-04 - val_loss: 4.5772e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2761e-04 - val_loss: 4.5647e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2639e-04 - val_loss: 4.5522e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.2518e-04 - val_loss: 4.5398e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 4.2398e-04 - val_loss: 4.5273e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2278e-04 - val_loss: 4.5149e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 4.2157e-04 - val_loss: 4.5025e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2037e-04 - val_loss: 4.4903e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1919e-04 - val_loss: 4.4782e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1800e-04 - val_loss: 4.4657e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.1682e-04 - val_loss: 4.4537e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 4.1563e-04 - val_loss: 4.4416e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1446e-04 - val_loss: 4.4295e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1329e-04 - val_loss: 4.4174e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1212e-04 - val_loss: 4.4054e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1096e-04 - val_loss: 4.3933e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0979e-04 - val_loss: 4.3816e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0864e-04 - val_loss: 4.3698e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0749e-04 - val_loss: 4.3579e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.0634e-04 - val_loss: 4.3461e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0519e-04 - val_loss: 4.3344e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0405e-04 - val_loss: 4.3227e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 4.0291e-04 - val_loss: 4.3111e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0178e-04 - val_loss: 4.2995e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 4.0065e-04 - val_loss: 4.2879e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 3.9952e-04 - val_loss: 4.2766e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9840e-04 - val_loss: 4.2650e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9728e-04 - val_loss: 4.2535e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9616e-04 - val_loss: 4.2421e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9505e-04 - val_loss: 4.2308e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9394e-04 - val_loss: 4.2193e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9284e-04 - val_loss: 4.2082e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9174e-04 - val_loss: 4.1969e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9064e-04 - val_loss: 4.1857e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8954e-04 - val_loss: 4.1746e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.8845e-04 - val_loss: 4.1634e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8736e-04 - val_loss: 4.1524e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8629e-04 - val_loss: 4.1413e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8520e-04 - val_loss: 4.1303e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8412e-04 - val_loss: 4.1194e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.8305e-04 - val_loss: 4.1083e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.8198e-04 - val_loss: 4.0975e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8091e-04 - val_loss: 4.0866e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7985e-04 - val_loss: 4.0758e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7879e-04 - val_loss: 4.0651e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 193us/step - loss: 3.7774e-04 - val_loss: 4.0543e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.7668e-04 - val_loss: 4.0437e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 3.7563e-04 - val_loss: 4.0329e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7458e-04 - val_loss: 4.0223e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7354e-04 - val_loss: 4.0119e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7250e-04 - val_loss: 4.0011e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7146e-04 - val_loss: 3.9908e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 3.7043e-04 - val_loss: 3.9802e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6940e-04 - val_loss: 3.9698e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 3.6838e-04 - val_loss: 3.9593e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6735e-04 - val_loss: 3.9489e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6633e-04 - val_loss: 3.9386e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 3.6531e-04 - val_loss: 3.9284e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6430e-04 - val_loss: 3.9181e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6329e-04 - val_loss: 3.9079e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6228e-04 - val_loss: 3.8976e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6128e-04 - val_loss: 3.8875e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.6028e-04 - val_loss: 3.8774e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5928e-04 - val_loss: 3.8675e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5829e-04 - val_loss: 3.8573e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5729e-04 - val_loss: 3.8473e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 3.5630e-04 - val_loss: 3.8373e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5532e-04 - val_loss: 3.8273e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5434e-04 - val_loss: 3.8175e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.5336e-04 - val_loss: 3.8075e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5238e-04 - val_loss: 3.7977e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 3.5141e-04 - val_loss: 3.7878e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5044e-04 - val_loss: 3.7780e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 3.4947e-04 - val_loss: 3.7683e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4850e-04 - val_loss: 3.7586e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4754e-04 - val_loss: 3.7489e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 3.4659e-04 - val_loss: 3.7393e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.4563e-04 - val_loss: 3.7297e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4469e-04 - val_loss: 3.7202e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4374e-04 - val_loss: 3.7107e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4278e-04 - val_loss: 3.7011e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4184e-04 - val_loss: 3.6915e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4090e-04 - val_loss: 3.6822e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3997e-04 - val_loss: 3.6726e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.3903e-04 - val_loss: 3.6632e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3810e-04 - val_loss: 3.6539e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3717e-04 - val_loss: 3.6445e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3624e-04 - val_loss: 3.6352e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3532e-04 - val_loss: 3.6260e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3440e-04 - val_loss: 3.6168e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3348e-04 - val_loss: 3.6076e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3257e-04 - val_loss: 3.5984e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3166e-04 - val_loss: 3.5893e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3075e-04 - val_loss: 3.5802e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 3.2985e-04 - val_loss: 3.5711e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2894e-04 - val_loss: 3.5621e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.2804e-04 - val_loss: 3.5529e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2714e-04 - val_loss: 3.5440e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2624e-04 - val_loss: 3.5350e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2535e-04 - val_loss: 3.5260e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2446e-04 - val_loss: 3.5171e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2358e-04 - val_loss: 3.5084e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2270e-04 - val_loss: 3.4995e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2181e-04 - val_loss: 3.4908e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2094e-04 - val_loss: 3.4818e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2006e-04 - val_loss: 3.4731e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1919e-04 - val_loss: 3.4643e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1831e-04 - val_loss: 3.4557e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1745e-04 - val_loss: 3.4470e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1659e-04 - val_loss: 3.4383e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1572e-04 - val_loss: 3.4298e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 3.1486e-04 - val_loss: 3.4211e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1400e-04 - val_loss: 3.4127e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1315e-04 - val_loss: 3.4040e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1230e-04 - val_loss: 3.3956e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1145e-04 - val_loss: 3.3871e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.1060e-04 - val_loss: 3.3786e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.0975e-04 - val_loss: 3.3702e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0891e-04 - val_loss: 3.3619e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 3.0807e-04 - val_loss: 3.3535e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.0723e-04 - val_loss: 3.3451e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0640e-04 - val_loss: 3.3368e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 3.0557e-04 - val_loss: 3.3286e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0474e-04 - val_loss: 3.3204e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0392e-04 - val_loss: 3.3120e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 3.0309e-04 - val_loss: 3.3038e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 3.0226e-04 - val_loss: 3.2957e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 3.0145e-04 - val_loss: 3.2874e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0063e-04 - val_loss: 3.2792e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9981e-04 - val_loss: 3.2712e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9900e-04 - val_loss: 3.2631e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9820e-04 - val_loss: 3.2551e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9739e-04 - val_loss: 3.2471e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9658e-04 - val_loss: 3.2391e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9577e-04 - val_loss: 3.2312e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9498e-04 - val_loss: 3.2232e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9419e-04 - val_loss: 3.2152e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9338e-04 - val_loss: 3.2075e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9259e-04 - val_loss: 3.1996e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9181e-04 - val_loss: 3.1917e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9101e-04 - val_loss: 3.1839e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.9023e-04 - val_loss: 3.1760e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8945e-04 - val_loss: 3.1683e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 2.8866e-04 - val_loss: 3.1605e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8788e-04 - val_loss: 3.1527e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 2.8711e-04 - val_loss: 3.1451e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.8634e-04 - val_loss: 3.1375e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8557e-04 - val_loss: 3.1298e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.8480e-04 - val_loss: 3.1222e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8403e-04 - val_loss: 3.1147e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8326e-04 - val_loss: 3.1070e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8250e-04 - val_loss: 3.0995e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8174e-04 - val_loss: 3.0921e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.8098e-04 - val_loss: 3.0845e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.8023e-04 - val_loss: 3.0769e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 2.7947e-04 - val_loss: 3.0694e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7872e-04 - val_loss: 3.0621e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 2.7798e-04 - val_loss: 3.0547e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 2.7723e-04 - val_loss: 3.0472e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 2.7648e-04 - val_loss: 3.0399e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7574e-04 - val_loss: 3.0325e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7500e-04 - val_loss: 3.0253e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.7426e-04 - val_loss: 3.0180e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7352e-04 - val_loss: 3.0106e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 2.7279e-04 - val_loss: 3.0034e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.7205e-04 - val_loss: 2.9962e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7133e-04 - val_loss: 2.9889e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7060e-04 - val_loss: 2.9818e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6987e-04 - val_loss: 2.9746e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6915e-04 - val_loss: 2.9675e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6843e-04 - val_loss: 2.9604e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6771e-04 - val_loss: 2.9533e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6699e-04 - val_loss: 2.9463e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6627e-04 - val_loss: 2.9392e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6557e-04 - val_loss: 2.9321e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6485e-04 - val_loss: 2.9252e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6415e-04 - val_loss: 2.9181e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 2.6344e-04 - val_loss: 2.9112e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6273e-04 - val_loss: 2.9042e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6203e-04 - val_loss: 2.8973e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6133e-04 - val_loss: 2.8904e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.6063e-04 - val_loss: 2.8834e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5994e-04 - val_loss: 2.8765e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 2.5924e-04 - val_loss: 2.8698e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 2.5855e-04 - val_loss: 2.8630e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5786e-04 - val_loss: 2.8562e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.5717e-04 - val_loss: 2.8494e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.5648e-04 - val_loss: 2.8426e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5580e-04 - val_loss: 2.8359e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5512e-04 - val_loss: 2.8292e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5444e-04 - val_loss: 2.8224e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.5376e-04 - val_loss: 2.8158e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5308e-04 - val_loss: 2.8090e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 2.5241e-04 - val_loss: 2.8025e-04\n",
      "0.00023763412900734693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.30344215,  0.5981575 ,  1.3714898 , -0.3562178 , -0.31354195,\n",
       "          0.13192108,  0.13221851,  0.9863693 , -0.65575457, -0.07532035],\n",
       "        [-0.86586976,  0.05136219, -0.22377595,  0.59202933, -0.23341396,\n",
       "          0.14532332, -0.7001754 ,  0.12755077,  0.29753608,  0.8739443 ],\n",
       "        [ 0.1435279 , -0.17363562,  0.437401  ,  0.48312804, -0.2889677 ,\n",
       "          0.6466802 ,  0.5057201 ,  0.89197576,  0.6346137 ,  0.27146336]],\n",
       "       dtype=float32),\n",
       " array([-0.28273633,  0.4288475 , -0.28342763,  0.14944038,  0.4033937 ,\n",
       "         0.45628664, -0.44824025,  0.30493417, -0.21832311, -0.11787035],\n",
       "       dtype=float32),\n",
       " array([[-0.15507554,  0.15060177, -0.5361081 ,  0.11823204, -0.00429425,\n",
       "          0.18165737, -0.38480863, -0.17095774,  0.05339982, -0.13141346],\n",
       "        [-0.48483717,  0.56164473, -0.24717133, -0.21279953, -0.4196161 ,\n",
       "         -0.46178466,  0.55522066,  0.15830465,  0.0506952 , -0.4591233 ],\n",
       "        [ 0.17016777, -0.21019843,  0.5921142 , -0.08638865,  0.16511907,\n",
       "          0.5552239 , -0.51959306,  0.25031567,  0.27062893,  0.30009922],\n",
       "        [-0.29351848,  0.09657393,  0.2514668 ,  0.21641512, -0.06715547,\n",
       "         -0.11011752,  0.6368967 , -0.5343339 , -0.7751655 , -0.02998322],\n",
       "        [-0.5765074 ,  0.19861521, -0.3034206 ,  0.5865021 , -0.25422585,\n",
       "         -0.53461385,  0.53898627, -0.33654094, -0.66261923,  0.24763407],\n",
       "        [-0.34492356,  0.03455408,  0.14156526,  0.22609349, -0.6712683 ,\n",
       "         -0.6849869 ,  0.16738573,  0.31484395, -0.50190103, -0.7801512 ],\n",
       "        [ 0.45804647, -0.02020334, -0.25140196, -0.24254985, -0.03075194,\n",
       "         -0.2760525 , -0.49309477,  0.28588232,  0.09214255,  0.38953376],\n",
       "        [-0.10915916,  0.5179752 , -0.44941142,  0.21199776, -0.59435785,\n",
       "          0.11546681,  0.10492066, -0.6469055 ,  0.13248064, -0.63987184],\n",
       "        [ 0.6671101 , -0.8480249 ,  0.01013376, -0.07918991, -0.22366281,\n",
       "          0.536234  , -0.33893567,  0.51068646, -0.00756985,  0.27284306],\n",
       "        [-0.08084991, -0.63686234,  0.17477499, -0.67351645,  0.25871196,\n",
       "         -0.0089409 , -0.09067044,  0.01692854, -0.03743125, -0.33799142]],\n",
       "       dtype=float32),\n",
       " array([-0.6851191 ,  0.7033042 , -0.5582886 ,  0.69892603, -0.5516055 ,\n",
       "        -0.6354014 ,  0.70560944, -0.45351723, -0.6766989 , -0.70301753],\n",
       "       dtype=float32),\n",
       " array([[-0.5037331 ],\n",
       "        [ 0.61335087],\n",
       "        [-0.23849016],\n",
       "        [ 0.53291065],\n",
       "        [-0.2378184 ],\n",
       "        [-0.38595966],\n",
       "        [ 0.5555511 ],\n",
       "        [-0.21381897],\n",
       "        [-0.42998216],\n",
       "        [-0.4951776 ]], dtype=float32),\n",
       " array([0.78252494], dtype=float32)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_5(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure5_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 35.0801 - val_loss: 30.2971\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 31.3201 - val_loss: 23.3272\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.2064 - val_loss: 14.3936\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 16.8484 - val_loss: 5.4380\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7.7804 - val_loss: 0.9248\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9577 - val_loss: 5.2689\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9827 - val_loss: 8.1814\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 8.2586 - val_loss: 5.9398\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 5.7285 - val_loss: 3.7829\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2123 - val_loss: 3.3078\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.8489 - val_loss: 3.6114\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4889 - val_loss: 3.7656\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6603 - val_loss: 3.4937\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3367 - val_loss: 2.8411\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2777 - val_loss: 1.9829\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 2.6531 - val_loss: 1.1330\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7515 - val_loss: 0.4801\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.8714 - val_loss: 0.1555\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2793 - val_loss: 0.2086\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.1474 - val_loss: 0.5656\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4462 - val_loss: 1.0087\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.9004 - val_loss: 1.2719\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 1.1610 - val_loss: 1.2203\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 1.0733 - val_loss: 0.9172\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7389 - val_loss: 0.5414\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.3742 - val_loss: 0.2595\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1502 - val_loss: 0.1432\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1153 - val_loss: 0.1649\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2140 - val_loss: 0.2472\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3509 - val_loss: 0.3157\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.4465 - val_loss: 0.3289\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.4604 - val_loss: 0.2816\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.3926 - val_loss: 0.1958\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.2734 - val_loss: 0.1046\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1487 - val_loss: 0.0381\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0631 - val_loss: 0.0118\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0408 - val_loss: 0.0223\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0757 - val_loss: 0.0506\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1359 - val_loss: 0.0742\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1828 - val_loss: 0.0787\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1919 - val_loss: 0.0635\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1617 - val_loss: 0.0394\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1096 - val_loss: 0.0212\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0600 - val_loss: 0.0183\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0312 - val_loss: 0.0313\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0285 - val_loss: 0.0527\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0442 - val_loss: 0.0729\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0652 - val_loss: 0.0837\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0793 - val_loss: 0.0820\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0803 - val_loss: 0.0688\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0685 - val_loss: 0.0490\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0495 - val_loss: 0.0286\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0310 - val_loss: 0.0129\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0197 - val_loss: 0.0043\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0180 - val_loss: 0.0022\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0239 - val_loss: 0.0038\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0322 - val_loss: 0.0060\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0377 - val_loss: 0.0068\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0375 - val_loss: 0.0056\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0320 - val_loss: 0.0034\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0237 - val_loss: 0.0021\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0032\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0133 - val_loss: 0.0170\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0197\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0183 - val_loss: 0.0194\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0181 - val_loss: 0.0165\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.0123\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0127 - val_loss: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0099 - val_loss: 0.0044\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0084 - val_loss: 0.0022\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0084 - val_loss: 0.0012\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0094 - val_loss: 9.1714e-04\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0106 - val_loss: 9.8924e-04\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.0011\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0109 - val_loss: 0.0011\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0099 - val_loss: 0.0013\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0085 - val_loss: 0.0017\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0074 - val_loss: 0.0024\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0071 - val_loss: 0.0033\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0066 - val_loss: 0.0025\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0060 - val_loss: 0.0016\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0060 - val_loss: 0.0015\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0014\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0015\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 202us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 195us/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 9.9423e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 9.8698e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0037 - val_loss: 9.8071e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0037 - val_loss: 9.7561e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0036 - val_loss: 9.7179e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 9.6881e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 9.6602e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 9.6286e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 9.5873e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0035 - val_loss: 9.5345e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0035 - val_loss: 9.4714e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.0035 - val_loss: 9.4016e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 9.3295e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 9.2585e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 9.1906e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 9.1268e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 9.0662e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0034 - val_loss: 9.0083e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 8.9533e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0034 - val_loss: 8.9005e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 8.8492e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 8.7994e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 8.7493e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 8.6980e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 8.6438e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 8.5864e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 8.5260e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 8.4641e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0032 - val_loss: 8.4027e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 8.3429e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 8.2856e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 8.2304e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 8.1766e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 8.1238e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 8.0710e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 8.0180e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 7.9654e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 7.9139e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0031 - val_loss: 7.8637e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0031 - val_loss: 7.8148e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0030 - val_loss: 7.7665e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0030 - val_loss: 7.7184e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 7.6691e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0030 - val_loss: 7.6189e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 7.5670e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 7.5142e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 7.4609e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0029 - val_loss: 7.4075e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 7.3547e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 7.3023e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 7.2506e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0029 - val_loss: 7.1990e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 7.1481e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 7.0978e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 7.0481e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 6.9987e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 6.9500e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 193us/step - loss: 0.0028 - val_loss: 6.9013e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 6.8525e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 6.8033e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 6.7541e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0028 - val_loss: 6.7046e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 6.6557e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.6071e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 6.5593e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0027 - val_loss: 6.5122e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 200us/step - loss: 0.0027 - val_loss: 6.4657e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0027 - val_loss: 6.4198e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.3743e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 6.3289e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.2840e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.2395e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0026 - val_loss: 6.1951e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0026 - val_loss: 6.1513e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 6.1078e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0026 - val_loss: 6.0650e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.0220e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 5.9792e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0025 - val_loss: 5.9364e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0025 - val_loss: 5.8938e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 5.8516e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 5.8096e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 5.7676e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0025 - val_loss: 5.7260e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0025 - val_loss: 5.6851e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0025 - val_loss: 5.6440e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0024 - val_loss: 5.6033e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 5.5629e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0024 - val_loss: 5.5229e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0024 - val_loss: 5.4831e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 5.4435e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0024 - val_loss: 5.4043e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0024 - val_loss: 5.3656e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0024 - val_loss: 5.3268e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 5.2881e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.2494e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 5.2115e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 210us/step - loss: 0.0023 - val_loss: 5.1736e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0023 - val_loss: 5.1361e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 5.0988e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 5.0621e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 5.0256e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0023 - val_loss: 4.9891e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 4.9530e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.9172e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.8816e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 4.8466e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.8119e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 4.7773e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.7427e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.7084e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.6745e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.6409e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 4.6074e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.5742e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0021 - val_loss: 4.5414e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.5085e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.4762e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.4441e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 4.4123e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 4.3804e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.3490e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0021 - val_loss: 4.3178e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.2870e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.2561e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.2256e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.1954e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.1655e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 4.1358e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 4.1063e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.0770e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0020 - val_loss: 4.0479e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 0.0020 - val_loss: 4.0190e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 3.9902e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 3.9619e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.9338e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 3.9058e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0019 - val_loss: 3.8781e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 3.8506e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 3.8233e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.7963e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 3.7695e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.7427e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 3.7165e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.6903e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.6643e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 195us/step - loss: 0.0018 - val_loss: 3.6385e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.6128e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0018 - val_loss: 3.5875e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 3.5623e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0018 - val_loss: 3.5373e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.5126e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 3.4880e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0018 - val_loss: 3.4636e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0018 - val_loss: 3.4395e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 3.4156e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 3.3917e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0018 - val_loss: 3.3680e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 3.3446e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 3.3214e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 3.2986e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 3.2758e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 3.2530e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0017 - val_loss: 3.2306e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 3.2085e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 203us/step - loss: 0.0017 - val_loss: 3.1861e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 3.1643e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 3.1427e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 3.1211e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 3.0999e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 3.0788e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 3.0575e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0016 - val_loss: 3.0368e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.0161e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 2.9956e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 2.9753e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.9550e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.9353e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 2.9154e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.8955e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.8761e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 2.8568e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 2.8376e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.8187e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.7998e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 2.7812e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 2.7627e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0015 - val_loss: 2.7442e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 2.7259e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 2.7079e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.6900e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 2.6723e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 2.6546e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0015 - val_loss: 2.6371e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 2.6198e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.6025e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0015 - val_loss: 2.5856e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0015 - val_loss: 2.5685e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 2.5519e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0014 - val_loss: 2.5352e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.5187e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0014 - val_loss: 2.5025e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.4863e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4702e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 2.4542e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4384e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.4227e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4073e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.3919e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.3766e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.3615e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.3465e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.3316e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 2.3168e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 2.3023e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.2876e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 2.2732e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.2589e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.2450e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 2.2310e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.2171e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.2034e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.1895e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.1760e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.1627e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.1493e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.1360e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.1229e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.1100e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.0972e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.0844e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.0717e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.0591e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 2.0466e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.0343e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.0221e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.0100e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 1.9980e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.9861e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.9743e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 1.9625e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.9510e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 1.9394e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.9280e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 1.9167e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.9054e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.8943e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.8832e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 1.8723e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.8614e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0011 - val_loss: 1.8506e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 1.8400e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8294e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 1.8190e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0011 - val_loss: 1.8085e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.0011 - val_loss: 1.7983e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.7880e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 1.7779e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 1.7679e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 1.7579e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.7480e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 1.7383e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 1.7286e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.7188e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 1.7093e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 1.6999e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.6905e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.6812e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.6720e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.6629e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 1.6538e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.6447e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.6359e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.6271e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.6183e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.6096e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0010 - val_loss: 1.6010e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.5924e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.5840e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0010 - val_loss: 1.5756e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 1.5672e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9718e-04 - val_loss: 1.5590e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 9.9269e-04 - val_loss: 1.5510e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 9.8822e-04 - val_loss: 1.5428e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8378e-04 - val_loss: 1.5347e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7935e-04 - val_loss: 1.5267e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.7495e-04 - val_loss: 1.5189e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7056e-04 - val_loss: 1.5110e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6621e-04 - val_loss: 1.5032e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6185e-04 - val_loss: 1.4954e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5753e-04 - val_loss: 1.4879e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5324e-04 - val_loss: 1.4803e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4895e-04 - val_loss: 1.4728e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4467e-04 - val_loss: 1.4654e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4044e-04 - val_loss: 1.4580e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3621e-04 - val_loss: 1.4506e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3201e-04 - val_loss: 1.4435e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 197us/step - loss: 9.2781e-04 - val_loss: 1.4362e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9.2366e-04 - val_loss: 1.4291e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1951e-04 - val_loss: 1.4220e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1538e-04 - val_loss: 1.4151e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1127e-04 - val_loss: 1.4081e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0719e-04 - val_loss: 1.4013e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 190us/step - loss: 9.0312e-04 - val_loss: 1.3943e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9907e-04 - val_loss: 1.3875e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9504e-04 - val_loss: 1.3808e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.9102e-04 - val_loss: 1.3742e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8703e-04 - val_loss: 1.3675e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8306e-04 - val_loss: 1.3610e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7910e-04 - val_loss: 1.3545e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.7516e-04 - val_loss: 1.3481e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7124e-04 - val_loss: 1.3417e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6734e-04 - val_loss: 1.3354e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6346e-04 - val_loss: 1.3290e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5959e-04 - val_loss: 1.3229e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5575e-04 - val_loss: 1.3167e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.5192e-04 - val_loss: 1.3106e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4810e-04 - val_loss: 1.3045e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4431e-04 - val_loss: 1.2985e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4053e-04 - val_loss: 1.2925e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3677e-04 - val_loss: 1.2867e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3303e-04 - val_loss: 1.2807e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2930e-04 - val_loss: 1.2749e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2560e-04 - val_loss: 1.2693e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2191e-04 - val_loss: 1.2636e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1824e-04 - val_loss: 1.2579e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1459e-04 - val_loss: 1.2522e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1094e-04 - val_loss: 1.2466e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0732e-04 - val_loss: 1.2412e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0372e-04 - val_loss: 1.2357e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.0013e-04 - val_loss: 1.2302e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9656e-04 - val_loss: 1.2248e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9301e-04 - val_loss: 1.2195e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8947e-04 - val_loss: 1.2142e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 7.8594e-04 - val_loss: 1.2090e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8245e-04 - val_loss: 1.2038e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7897e-04 - val_loss: 1.1987e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7549e-04 - val_loss: 1.1935e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7204e-04 - val_loss: 1.1884e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6859e-04 - val_loss: 1.1834e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6518e-04 - val_loss: 1.1784e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.6177e-04 - val_loss: 1.1735e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5838e-04 - val_loss: 1.1686e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5499e-04 - val_loss: 1.1637e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5163e-04 - val_loss: 1.1590e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4829e-04 - val_loss: 1.1542e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4497e-04 - val_loss: 1.1494e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4165e-04 - val_loss: 1.1447e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 7.3835e-04 - val_loss: 1.1401e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3508e-04 - val_loss: 1.1355e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3181e-04 - val_loss: 1.1308e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2856e-04 - val_loss: 1.1263e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2532e-04 - val_loss: 1.1219e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2210e-04 - val_loss: 1.1174e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 7.1889e-04 - val_loss: 1.1129e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 7.1570e-04 - val_loss: 1.1086e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1253e-04 - val_loss: 1.1042e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0936e-04 - val_loss: 1.0999e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0622e-04 - val_loss: 1.0956e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0309e-04 - val_loss: 1.0914e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9997e-04 - val_loss: 1.0872e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9687e-04 - val_loss: 1.0831e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9378e-04 - val_loss: 1.0790e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.9070e-04 - val_loss: 1.0748e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8765e-04 - val_loss: 1.0708e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8460e-04 - val_loss: 1.0668e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8157e-04 - val_loss: 1.0628e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7855e-04 - val_loss: 1.0588e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7555e-04 - val_loss: 1.0549e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 6.7256e-04 - val_loss: 1.0509e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6959e-04 - val_loss: 1.0470e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6663e-04 - val_loss: 1.0432e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6369e-04 - val_loss: 1.0395e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6075e-04 - val_loss: 1.0358e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5783e-04 - val_loss: 1.0321e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5492e-04 - val_loss: 1.0283e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5203e-04 - val_loss: 1.0246e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4915e-04 - val_loss: 1.0210e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4628e-04 - val_loss: 1.0174e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.4344e-04 - val_loss: 1.0138e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4060e-04 - val_loss: 1.0102e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3778e-04 - val_loss: 1.0069e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 6.3497e-04 - val_loss: 1.0033e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3216e-04 - val_loss: 9.9988e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2938e-04 - val_loss: 9.9646e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 203us/step - loss: 6.2662e-04 - val_loss: 9.9305e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2385e-04 - val_loss: 9.8965e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2111e-04 - val_loss: 9.8633e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1837e-04 - val_loss: 9.8298e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1565e-04 - val_loss: 9.7968e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.1294e-04 - val_loss: 9.7638e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1025e-04 - val_loss: 9.7318e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.0757e-04 - val_loss: 9.7003e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0490e-04 - val_loss: 9.6691e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.0225e-04 - val_loss: 9.6388e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9960e-04 - val_loss: 9.6063e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9696e-04 - val_loss: 9.5754e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.9435e-04 - val_loss: 9.5445e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9174e-04 - val_loss: 9.5141e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.8915e-04 - val_loss: 9.4842e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 5.8656e-04 - val_loss: 9.4542e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8399e-04 - val_loss: 9.4240e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8143e-04 - val_loss: 9.3946e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7889e-04 - val_loss: 9.3659e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.7635e-04 - val_loss: 9.3375e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7382e-04 - val_loss: 9.3086e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7132e-04 - val_loss: 9.2802e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.6882e-04 - val_loss: 9.2518e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6633e-04 - val_loss: 9.2239e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6386e-04 - val_loss: 9.1957e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6140e-04 - val_loss: 9.1682e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.5894e-04 - val_loss: 9.1413e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5650e-04 - val_loss: 9.1143e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5407e-04 - val_loss: 9.0873e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5166e-04 - val_loss: 9.0612e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 5.4925e-04 - val_loss: 9.0353e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4685e-04 - val_loss: 9.0094e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4447e-04 - val_loss: 8.9830e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4210e-04 - val_loss: 8.9576e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3975e-04 - val_loss: 8.9319e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3739e-04 - val_loss: 8.9061e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3506e-04 - val_loss: 8.8810e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3271e-04 - val_loss: 8.8563e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3040e-04 - val_loss: 8.8326e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2809e-04 - val_loss: 8.8090e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2580e-04 - val_loss: 8.7847e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2352e-04 - val_loss: 8.7603e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2124e-04 - val_loss: 8.7366e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.1898e-04 - val_loss: 8.7127e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1673e-04 - val_loss: 8.6897e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1449e-04 - val_loss: 8.6656e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1225e-04 - val_loss: 8.6433e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1003e-04 - val_loss: 8.6199e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0783e-04 - val_loss: 8.5986e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0563e-04 - val_loss: 8.5751e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0344e-04 - val_loss: 8.5532e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0126e-04 - val_loss: 8.5313e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9909e-04 - val_loss: 8.5095e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.9693e-04 - val_loss: 8.4883e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9478e-04 - val_loss: 8.4662e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9265e-04 - val_loss: 8.4455e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9052e-04 - val_loss: 8.4242e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8839e-04 - val_loss: 8.4029e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8629e-04 - val_loss: 8.3820e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8420e-04 - val_loss: 8.3614e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8210e-04 - val_loss: 8.3409e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8003e-04 - val_loss: 8.3205e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7796e-04 - val_loss: 8.3013e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7591e-04 - val_loss: 8.2810e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7385e-04 - val_loss: 8.2616e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7182e-04 - val_loss: 8.2421e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6978e-04 - val_loss: 8.2227e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6776e-04 - val_loss: 8.2040e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6576e-04 - val_loss: 8.1849e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6376e-04 - val_loss: 8.1663e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6177e-04 - val_loss: 8.1468e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5978e-04 - val_loss: 8.1280e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5781e-04 - val_loss: 8.1095e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5585e-04 - val_loss: 8.0919e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5390e-04 - val_loss: 8.0732e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5195e-04 - val_loss: 8.0552e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5002e-04 - val_loss: 8.0376e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.4809e-04 - val_loss: 8.0202e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4617e-04 - val_loss: 8.0029e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4426e-04 - val_loss: 7.9853e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.4236e-04 - val_loss: 7.9677e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.4048e-04 - val_loss: 7.9508e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3860e-04 - val_loss: 7.9334e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3672e-04 - val_loss: 7.9168e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3487e-04 - val_loss: 7.9009e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 4.3301e-04 - val_loss: 7.8843e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3116e-04 - val_loss: 7.8680e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2933e-04 - val_loss: 7.8510e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2750e-04 - val_loss: 7.8363e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2569e-04 - val_loss: 7.8200e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2387e-04 - val_loss: 7.8043e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2207e-04 - val_loss: 7.7881e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2028e-04 - val_loss: 7.7729e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1849e-04 - val_loss: 7.7575e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1671e-04 - val_loss: 7.7422e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1495e-04 - val_loss: 7.7265e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.1318e-04 - val_loss: 7.7118e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1143e-04 - val_loss: 7.6973e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0969e-04 - val_loss: 7.6831e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0795e-04 - val_loss: 7.6678e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0623e-04 - val_loss: 7.6525e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0451e-04 - val_loss: 7.6385e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0281e-04 - val_loss: 7.6245e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0110e-04 - val_loss: 7.6105e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9941e-04 - val_loss: 7.5962e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9773e-04 - val_loss: 7.5822e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9605e-04 - val_loss: 7.5690e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9438e-04 - val_loss: 7.5542e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9272e-04 - val_loss: 7.5408e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9105e-04 - val_loss: 7.5277e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.8941e-04 - val_loss: 7.5148e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.8778e-04 - val_loss: 7.5012e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.8615e-04 - val_loss: 7.4885e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.8453e-04 - val_loss: 7.4749e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8291e-04 - val_loss: 7.4622e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.8130e-04 - val_loss: 7.4496e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7970e-04 - val_loss: 7.4359e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.7811e-04 - val_loss: 7.4244e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.7652e-04 - val_loss: 7.4117e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 3.7495e-04 - val_loss: 7.3999e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.7338e-04 - val_loss: 7.3869e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7182e-04 - val_loss: 7.3748e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.7026e-04 - val_loss: 7.3622e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6872e-04 - val_loss: 7.3502e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6718e-04 - val_loss: 7.3384e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6564e-04 - val_loss: 7.3272e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6412e-04 - val_loss: 7.3161e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6260e-04 - val_loss: 7.3037e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6109e-04 - val_loss: 7.2922e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5959e-04 - val_loss: 7.2805e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5809e-04 - val_loss: 7.2692e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5660e-04 - val_loss: 7.2578e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5512e-04 - val_loss: 7.2467e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5364e-04 - val_loss: 7.2367e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5218e-04 - val_loss: 7.2249e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5071e-04 - val_loss: 7.2131e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4926e-04 - val_loss: 7.2037e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4782e-04 - val_loss: 7.1928e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4637e-04 - val_loss: 7.1826e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4494e-04 - val_loss: 7.1719e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4351e-04 - val_loss: 7.1613e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4209e-04 - val_loss: 7.1505e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4068e-04 - val_loss: 7.1407e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3927e-04 - val_loss: 7.1305e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3788e-04 - val_loss: 7.1207e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3648e-04 - val_loss: 7.1106e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3509e-04 - val_loss: 7.1005e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3371e-04 - val_loss: 7.0908e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3234e-04 - val_loss: 7.0814e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 3.3098e-04 - val_loss: 7.0716e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2962e-04 - val_loss: 7.0614e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2826e-04 - val_loss: 7.0520e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2692e-04 - val_loss: 7.0433e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.2557e-04 - val_loss: 7.0336e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2424e-04 - val_loss: 7.0235e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.2291e-04 - val_loss: 7.0146e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2158e-04 - val_loss: 7.0057e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2027e-04 - val_loss: 6.9966e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1897e-04 - val_loss: 6.9872e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1767e-04 - val_loss: 6.9785e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1637e-04 - val_loss: 6.9700e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1508e-04 - val_loss: 6.9607e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1378e-04 - val_loss: 6.9519e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1251e-04 - val_loss: 6.9434e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1123e-04 - val_loss: 6.9351e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0997e-04 - val_loss: 6.9265e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0871e-04 - val_loss: 6.9174e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0746e-04 - val_loss: 6.9098e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0621e-04 - val_loss: 6.9008e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0497e-04 - val_loss: 6.8924e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0373e-04 - val_loss: 6.8845e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0250e-04 - val_loss: 6.8761e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0128e-04 - val_loss: 6.8688e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0005e-04 - val_loss: 6.8610e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9885e-04 - val_loss: 6.8530e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9764e-04 - val_loss: 6.8447e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9643e-04 - val_loss: 6.8380e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9524e-04 - val_loss: 6.8295e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9405e-04 - val_loss: 6.8214e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9287e-04 - val_loss: 6.8143e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9168e-04 - val_loss: 6.8067e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9051e-04 - val_loss: 6.7984e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8935e-04 - val_loss: 6.7918e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.8819e-04 - val_loss: 6.7843e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8703e-04 - val_loss: 6.7768e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8588e-04 - val_loss: 6.7689e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8473e-04 - val_loss: 6.7613e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.8359e-04 - val_loss: 6.7551e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8246e-04 - val_loss: 6.7473e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8133e-04 - val_loss: 6.7404e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8020e-04 - val_loss: 6.7329e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7908e-04 - val_loss: 6.7263e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7797e-04 - val_loss: 6.7190e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7686e-04 - val_loss: 6.7121e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7576e-04 - val_loss: 6.7055e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7466e-04 - val_loss: 6.6988e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7357e-04 - val_loss: 6.6918e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7249e-04 - val_loss: 6.6844e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7140e-04 - val_loss: 6.6784e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7033e-04 - val_loss: 6.6720e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6925e-04 - val_loss: 6.6652e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6818e-04 - val_loss: 6.6594e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6712e-04 - val_loss: 6.6531e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6607e-04 - val_loss: 6.6458e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6502e-04 - val_loss: 6.6396e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6397e-04 - val_loss: 6.6335e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6293e-04 - val_loss: 6.6272e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6189e-04 - val_loss: 6.6215e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6086e-04 - val_loss: 6.6146e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.5983e-04 - val_loss: 6.6091e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5881e-04 - val_loss: 6.6022e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.5779e-04 - val_loss: 6.5962e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5678e-04 - val_loss: 6.5897e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5578e-04 - val_loss: 6.5844e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5477e-04 - val_loss: 6.5785e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5377e-04 - val_loss: 6.5725e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5278e-04 - val_loss: 6.5670e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5179e-04 - val_loss: 6.5617e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5081e-04 - val_loss: 6.5551e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4983e-04 - val_loss: 6.5496e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4885e-04 - val_loss: 6.5433e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4788e-04 - val_loss: 6.5383e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4692e-04 - val_loss: 6.5318e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4596e-04 - val_loss: 6.5262e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.4500e-04 - val_loss: 6.5205e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4405e-04 - val_loss: 6.5154e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4310e-04 - val_loss: 6.5097e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4216e-04 - val_loss: 6.5050e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4122e-04 - val_loss: 6.4991e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4029e-04 - val_loss: 6.4940e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3936e-04 - val_loss: 6.4881e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3844e-04 - val_loss: 6.4829e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3751e-04 - val_loss: 6.4771e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3660e-04 - val_loss: 6.4722e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3569e-04 - val_loss: 6.4673e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3478e-04 - val_loss: 6.4618e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.3388e-04 - val_loss: 6.4562e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3297e-04 - val_loss: 6.4518e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3208e-04 - val_loss: 6.4466e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3119e-04 - val_loss: 6.4417e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3031e-04 - val_loss: 6.4363e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2942e-04 - val_loss: 6.4316e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2854e-04 - val_loss: 6.4257e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.2767e-04 - val_loss: 6.4210e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2680e-04 - val_loss: 6.4165e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2594e-04 - val_loss: 6.4122e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2508e-04 - val_loss: 6.4063e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2422e-04 - val_loss: 6.4021e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2336e-04 - val_loss: 6.3972e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2251e-04 - val_loss: 6.3923e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2167e-04 - val_loss: 6.3874e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2083e-04 - val_loss: 6.3830e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1999e-04 - val_loss: 6.3780e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1915e-04 - val_loss: 6.3731e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1832e-04 - val_loss: 6.3677e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1750e-04 - val_loss: 6.3631e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1668e-04 - val_loss: 6.3583e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1586e-04 - val_loss: 6.3548e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1504e-04 - val_loss: 6.3501e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1423e-04 - val_loss: 6.3454e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1343e-04 - val_loss: 6.3411e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1263e-04 - val_loss: 6.3356e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1183e-04 - val_loss: 6.3315e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 250us/step - loss: 2.1103e-04 - val_loss: 6.3267e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 248us/step - loss: 2.1025e-04 - val_loss: 6.3229e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.0946e-04 - val_loss: 6.3177e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0867e-04 - val_loss: 6.3144e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0789e-04 - val_loss: 6.3095e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0711e-04 - val_loss: 6.3053e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.0634e-04 - val_loss: 6.3011e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0557e-04 - val_loss: 6.2971e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.0481e-04 - val_loss: 6.2919e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.0404e-04 - val_loss: 6.2874e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0328e-04 - val_loss: 6.2832e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0253e-04 - val_loss: 6.2791e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0178e-04 - val_loss: 6.2746e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.0103e-04 - val_loss: 6.2702e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.0029e-04 - val_loss: 6.2669e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.9954e-04 - val_loss: 6.2627e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.9881e-04 - val_loss: 6.2577e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.9808e-04 - val_loss: 6.2538e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9734e-04 - val_loss: 6.2492e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.9662e-04 - val_loss: 6.2455e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9589e-04 - val_loss: 6.2412e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9518e-04 - val_loss: 6.2371e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9446e-04 - val_loss: 6.2329e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9374e-04 - val_loss: 6.2294e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9304e-04 - val_loss: 6.2251e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9233e-04 - val_loss: 6.2210e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9162e-04 - val_loss: 6.2173e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.9092e-04 - val_loss: 6.2127e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9022e-04 - val_loss: 6.2088e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8953e-04 - val_loss: 6.2050e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.8884e-04 - val_loss: 6.2006e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8816e-04 - val_loss: 6.1969e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 1.8747e-04 - val_loss: 6.1924e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8679e-04 - val_loss: 6.1890e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8611e-04 - val_loss: 6.1851e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8544e-04 - val_loss: 6.1810e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8476e-04 - val_loss: 6.1776e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.8410e-04 - val_loss: 6.1732e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8343e-04 - val_loss: 6.1699e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8277e-04 - val_loss: 6.1662e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8211e-04 - val_loss: 6.1615e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.8146e-04 - val_loss: 6.1575e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.8080e-04 - val_loss: 6.1540e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8015e-04 - val_loss: 6.1506e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7951e-04 - val_loss: 6.1468e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7886e-04 - val_loss: 6.1428e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.7822e-04 - val_loss: 6.1392e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7759e-04 - val_loss: 6.1354e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7695e-04 - val_loss: 6.1315e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.7631e-04 - val_loss: 6.1274e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7569e-04 - val_loss: 6.1239e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.7506e-04 - val_loss: 6.1198e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.7444e-04 - val_loss: 6.1161e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 1.7382e-04 - val_loss: 6.1127e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7320e-04 - val_loss: 6.1091e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.7258e-04 - val_loss: 6.1051e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7197e-04 - val_loss: 6.1012e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7137e-04 - val_loss: 6.0976e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7076e-04 - val_loss: 6.0940e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7016e-04 - val_loss: 6.0899e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6956e-04 - val_loss: 6.0861e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6896e-04 - val_loss: 6.0828e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6836e-04 - val_loss: 6.0791e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6777e-04 - val_loss: 6.0753e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6718e-04 - val_loss: 6.0719e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6659e-04 - val_loss: 6.0687e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6601e-04 - val_loss: 6.0643e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6543e-04 - val_loss: 6.0607e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6485e-04 - val_loss: 6.0566e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 1.6428e-04 - val_loss: 6.0533e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6371e-04 - val_loss: 6.0502e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6313e-04 - val_loss: 6.0464e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6257e-04 - val_loss: 6.0426e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6200e-04 - val_loss: 6.0394e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6144e-04 - val_loss: 6.0354e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6087e-04 - val_loss: 6.0320e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6032e-04 - val_loss: 6.0283e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5976e-04 - val_loss: 6.0242e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5921e-04 - val_loss: 6.0207e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5866e-04 - val_loss: 6.0177e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5812e-04 - val_loss: 6.0139e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5757e-04 - val_loss: 6.0104e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5703e-04 - val_loss: 6.0067e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5649e-04 - val_loss: 6.0031e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5595e-04 - val_loss: 5.9996e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5542e-04 - val_loss: 5.9962e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 1.5488e-04 - val_loss: 5.9926e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.5436e-04 - val_loss: 5.9890e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5383e-04 - val_loss: 5.9854e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5330e-04 - val_loss: 5.9813e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5278e-04 - val_loss: 5.9781e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5226e-04 - val_loss: 5.9740e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.5174e-04 - val_loss: 5.9707e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5122e-04 - val_loss: 5.9665e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5071e-04 - val_loss: 5.9640e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5020e-04 - val_loss: 5.9605e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.4969e-04 - val_loss: 5.9575e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 1.4919e-04 - val_loss: 5.9532e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.4868e-04 - val_loss: 5.9497e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 198us/step - loss: 1.4818e-04 - val_loss: 5.9452e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 1.4768e-04 - val_loss: 5.9419e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4718e-04 - val_loss: 5.9388e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4669e-04 - val_loss: 5.9348e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.4620e-04 - val_loss: 5.9317e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4571e-04 - val_loss: 5.9285e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4522e-04 - val_loss: 5.9252e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4473e-04 - val_loss: 5.9211e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4425e-04 - val_loss: 5.9170e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4377e-04 - val_loss: 5.9139e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4329e-04 - val_loss: 5.9104e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4281e-04 - val_loss: 5.9068e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4234e-04 - val_loss: 5.9033e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4187e-04 - val_loss: 5.8998e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4140e-04 - val_loss: 5.8960e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4093e-04 - val_loss: 5.8927e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4046e-04 - val_loss: 5.8890e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4000e-04 - val_loss: 5.8853e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3954e-04 - val_loss: 5.8818e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3908e-04 - val_loss: 5.8782e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3862e-04 - val_loss: 5.8749e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3816e-04 - val_loss: 5.8716e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 1.3771e-04 - val_loss: 5.8676e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3725e-04 - val_loss: 5.8642e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3680e-04 - val_loss: 5.8612e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.3636e-04 - val_loss: 5.8576e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3591e-04 - val_loss: 5.8536e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3547e-04 - val_loss: 5.8499e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3503e-04 - val_loss: 5.8461e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3459e-04 - val_loss: 5.8427e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3415e-04 - val_loss: 5.8393e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3371e-04 - val_loss: 5.8354e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3328e-04 - val_loss: 5.8321e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3285e-04 - val_loss: 5.8282e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3242e-04 - val_loss: 5.8246e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3199e-04 - val_loss: 5.8212e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3157e-04 - val_loss: 5.8178e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3114e-04 - val_loss: 5.8135e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3072e-04 - val_loss: 5.8103e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3030e-04 - val_loss: 5.8074e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2988e-04 - val_loss: 5.8040e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2947e-04 - val_loss: 5.7996e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2905e-04 - val_loss: 5.7963e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2864e-04 - val_loss: 5.7924e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2823e-04 - val_loss: 5.7884e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2782e-04 - val_loss: 5.7849e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2741e-04 - val_loss: 5.7807e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2700e-04 - val_loss: 5.7778e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2660e-04 - val_loss: 5.7744e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2620e-04 - val_loss: 5.7706e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2580e-04 - val_loss: 5.7672e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.2541e-04 - val_loss: 5.7633e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2501e-04 - val_loss: 5.7600e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2462e-04 - val_loss: 5.7558e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2422e-04 - val_loss: 5.7531e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2383e-04 - val_loss: 5.7489e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2344e-04 - val_loss: 5.7450e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2305e-04 - val_loss: 5.7411e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2267e-04 - val_loss: 5.7377e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.2229e-04 - val_loss: 5.7341e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2190e-04 - val_loss: 5.7303e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 1.2152e-04 - val_loss: 5.7266e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2114e-04 - val_loss: 5.7230e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2077e-04 - val_loss: 5.7196e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2039e-04 - val_loss: 5.7154e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2002e-04 - val_loss: 5.7122e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1965e-04 - val_loss: 5.7083e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1927e-04 - val_loss: 5.7051e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.1891e-04 - val_loss: 5.7008e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1854e-04 - val_loss: 5.6971e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1817e-04 - val_loss: 5.6931e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.1781e-04 - val_loss: 5.6899e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.1745e-04 - val_loss: 5.6861e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1709e-04 - val_loss: 5.6822e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1673e-04 - val_loss: 5.6788e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1637e-04 - val_loss: 5.6750e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1601e-04 - val_loss: 5.6709e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 1.1566e-04 - val_loss: 5.6673e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1531e-04 - val_loss: 5.6636e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1496e-04 - val_loss: 5.6594e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1460e-04 - val_loss: 5.6556e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1425e-04 - val_loss: 5.6523e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1391e-04 - val_loss: 5.6489e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1357e-04 - val_loss: 5.6449e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1322e-04 - val_loss: 5.6408e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 199us/step - loss: 1.1288e-04 - val_loss: 5.6368e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1254e-04 - val_loss: 5.6334e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1220e-04 - val_loss: 5.6296e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.1186e-04 - val_loss: 5.6260e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1153e-04 - val_loss: 5.6215e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1119e-04 - val_loss: 5.6181e-05\n",
      "0.00013674215006176382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.1186784 ,  0.5071984 ,  0.71971214,  0.19782898, -0.39259022,\n",
       "         -0.3644355 ,  0.90937513,  0.3558004 ,  0.22596833,  0.52333874],\n",
       "        [-0.10546404, -0.339198  , -0.45486286,  0.33948243, -0.37335497,\n",
       "          0.2354284 ,  0.03002328,  0.23226644,  0.80701184, -0.6658903 ],\n",
       "        [-1.4980038 , -0.9150436 , -0.33741596, -0.0348817 , -0.8857887 ,\n",
       "          0.04428585,  1.5919839 ,  1.6355377 ,  0.8622473 ,  0.44304168]],\n",
       "       dtype=float32),\n",
       " array([-0.3669674 ,  0.43546796,  0.2732511 ,  0.17991593, -0.28736356,\n",
       "         0.4976804 , -0.15350744,  0.38114703, -0.31616494, -0.4709147 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.3071579 , -0.2548043 ,  0.41262117,  0.3132513 ,  0.3595088 ,\n",
       "         -0.28894395,  0.18239592,  0.38625085,  0.39865914, -0.251236  ,\n",
       "          0.07151511, -0.30121744, -0.06108657,  0.56440085, -0.22462454],\n",
       "        [-0.18699262,  0.15194319,  0.37452093,  0.15611991, -0.5705591 ,\n",
       "          0.20795155,  0.12751439,  0.38170597, -0.41096804,  0.3844417 ,\n",
       "          0.35667667,  0.2832678 ,  0.48918575, -0.17378795, -0.4492268 ],\n",
       "        [-0.38973466, -0.19758289,  0.33692908,  0.32962686, -0.33445132,\n",
       "          0.2308138 ,  0.07898802, -0.36874214, -0.22237879,  0.33046946,\n",
       "         -0.44274965, -0.16039534, -0.11358418, -0.4240196 ,  0.16998078],\n",
       "        [-0.28998607,  0.46678966, -0.33884978,  0.01977551,  0.3616724 ,\n",
       "         -0.05959846,  0.18326542, -0.28262708, -0.4501179 ,  0.10573801,\n",
       "         -0.36343256,  0.13585027,  0.3589207 ,  0.21938866, -0.34171566],\n",
       "        [ 0.08747031, -0.2232233 ,  0.4673766 , -0.2097286 ,  0.50281745,\n",
       "         -0.41189954,  0.32688645, -0.51666915, -0.09222814,  0.31117782,\n",
       "          0.00473689,  0.5284184 , -0.07263186,  0.3434078 ,  0.12345432],\n",
       "        [-0.5246719 ,  0.0727374 , -0.26226202, -0.43336836, -0.2090167 ,\n",
       "          0.29548883, -0.55554074,  0.21464187, -0.0368484 ,  0.32351184,\n",
       "         -0.40731773, -0.09784319,  0.5516326 , -0.13603894,  0.15183228],\n",
       "        [-0.236543  ,  0.24416168,  0.57352465, -0.72913975, -0.15351686,\n",
       "         -0.24182905, -0.10143493,  0.25687644, -0.23448116, -0.46324608,\n",
       "          0.32859057, -0.0573724 ,  0.12332983,  0.542776  ,  0.47668895],\n",
       "        [-0.09157081, -0.04963265, -0.44205174,  0.27087963, -0.55376834,\n",
       "          0.61052066, -0.5768627 , -0.20950074,  0.43288293, -0.09181889,\n",
       "          0.30850017, -0.00426023,  0.51332384,  0.0655862 , -0.2855376 ],\n",
       "        [ 0.34883982,  0.14457864,  0.34659946, -0.20039019,  0.27735648,\n",
       "          0.2377045 ,  0.21897261,  0.06877662, -0.17979027, -0.2813946 ,\n",
       "          0.22772956, -0.24243404, -0.10480426, -0.04436877,  0.04668605],\n",
       "        [ 0.53333455,  0.21675344, -0.11224167,  0.3542075 ,  0.4257275 ,\n",
       "         -0.32857507, -0.05845153, -0.48438016,  0.3644167 ,  0.02412262,\n",
       "          0.04324057, -0.03973351,  0.3685671 ,  0.53243273,  0.37543726]],\n",
       "       dtype=float32),\n",
       " array([-0.62632644, -0.5746948 , -0.5304835 ,  0.5256832 , -0.609638  ,\n",
       "         0.63705707, -0.14551717,  0.58282053,  0.3279011 ,  0.6038114 ,\n",
       "        -0.46547496,  0.2856145 ,  0.6054794 , -0.61763585, -0.61411446],\n",
       "       dtype=float32),\n",
       " array([[-0.6465292 ],\n",
       "        [-0.32582426],\n",
       "        [-0.20878822],\n",
       "        [ 0.21433128],\n",
       "        [-0.5356864 ],\n",
       "        [ 0.6979487 ],\n",
       "        [-0.07651677],\n",
       "        [ 0.38668883],\n",
       "        [ 0.04044453],\n",
       "        [ 0.5188079 ],\n",
       "        [-0.1586719 ],\n",
       "        [ 0.11298482],\n",
       "        [ 0.49161613],\n",
       "        [-0.5560202 ],\n",
       "        [-0.5317599 ]], dtype=float32),\n",
       " array([0.68933207], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_6(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure6_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
