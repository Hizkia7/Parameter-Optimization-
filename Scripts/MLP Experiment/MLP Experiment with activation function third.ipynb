{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_linear(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_relu(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_sigmoid(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_tanh(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 415us/step - loss: 15171.1581 - val_loss: 14297.0350\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11958.5941 - val_loss: 8342.4812\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4046.4079 - val_loss: 602.7095\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 122.7981 - val_loss: 46.1555\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 28.9929 - val_loss: 27.0359\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 23.0049 - val_loss: 26.0121\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2592 - val_loss: 25.6841\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9671 - val_loss: 25.8513\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7576 - val_loss: 25.8608\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6786 - val_loss: 25.8827\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6833 - val_loss: 25.6568\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.6257 - val_loss: 26.4378\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5089 - val_loss: 25.7798\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5197 - val_loss: 26.0331\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4667 - val_loss: 26.6176\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5471 - val_loss: 25.9073\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4147 - val_loss: 25.7830\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5806 - val_loss: 25.6071\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5951 - val_loss: 25.9357\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3214 - val_loss: 25.7026\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4586 - val_loss: 25.7753\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7676 - val_loss: 25.7154\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6057 - val_loss: 26.5234\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5314 - val_loss: 25.6785\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.0086 - val_loss: 27.5847\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2440 - val_loss: 26.7921\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6617 - val_loss: 26.3487\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7217 - val_loss: 25.7795\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5648 - val_loss: 25.6590\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.4171 - val_loss: 25.9971\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5571 - val_loss: 26.0368\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.4861 - val_loss: 26.0325\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0059 - val_loss: 25.4028\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4752 - val_loss: 25.9675\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.7667 - val_loss: 25.5787\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.5126 - val_loss: 25.4441\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6237 - val_loss: 26.4009\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9640 - val_loss: 26.8798\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.3650 - val_loss: 25.5712\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7840 - val_loss: 25.8151\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6317 - val_loss: 26.1378\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.4278 - val_loss: 26.2733\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6379 - val_loss: 26.3468\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6905 - val_loss: 26.0586\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.6602 - val_loss: 25.5492\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.3353 - val_loss: 25.7490\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7070 - val_loss: 25.7320\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7307 - val_loss: 25.6691\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.4108 - val_loss: 25.8616\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6243 - val_loss: 25.5883\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5427 - val_loss: 25.6845\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9055 - val_loss: 26.1104\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8257 - val_loss: 25.6084\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5704 - val_loss: 25.8554\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.4410 - val_loss: 26.4787\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.8293 - val_loss: 26.0693\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6479 - val_loss: 25.6817\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5727 - val_loss: 26.5255\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.4202 - val_loss: 25.6994\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6562 - val_loss: 25.3866\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7899 - val_loss: 25.2710\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4106 - val_loss: 26.6804\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7627 - val_loss: 25.6910\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7134 - val_loss: 26.8132\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7028 - val_loss: 25.9798\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8965 - val_loss: 25.6126\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7988 - val_loss: 25.2726\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1205 - val_loss: 26.0335\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1537 - val_loss: 25.6905\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5384 - val_loss: 25.8591\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1216 - val_loss: 25.4433\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6371 - val_loss: 26.8279\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7656 - val_loss: 27.8368\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7712 - val_loss: 26.3293\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6736 - val_loss: 25.8286\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8447 - val_loss: 26.0813\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6279 - val_loss: 25.7739\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3142 - val_loss: 27.2531\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7599 - val_loss: 26.9711\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2560 - val_loss: 25.6717\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5482 - val_loss: 25.6269\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5635 - val_loss: 26.7506\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9148 - val_loss: 27.6592\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.0115 - val_loss: 26.2563\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.2408 - val_loss: 26.1249\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8487 - val_loss: 25.8759\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.8638 - val_loss: 25.8361\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8709 - val_loss: 25.3305\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4464 - val_loss: 26.2714\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9203 - val_loss: 25.2306\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9850 - val_loss: 26.0905\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.0676 - val_loss: 25.2648\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6587 - val_loss: 25.1990\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.2575 - val_loss: 26.0619\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6967 - val_loss: 26.1676\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.9581 - val_loss: 26.3536\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.6960 - val_loss: 25.9826\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3478 - val_loss: 28.0113\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.6784 - val_loss: 26.1779\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7789 - val_loss: 25.5374\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8021 - val_loss: 26.5078\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5223 - val_loss: 27.0956\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9548 - val_loss: 26.8020\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.5680 - val_loss: 25.4891\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1088 - val_loss: 26.8053\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8942 - val_loss: 26.2040\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1192 - val_loss: 29.3262\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.5967 - val_loss: 25.3631\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.2944 - val_loss: 26.7005\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.6626 - val_loss: 26.9331\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9629 - val_loss: 25.8113\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5598 - val_loss: 26.0673\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0728 - val_loss: 25.9759\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.0979 - val_loss: 26.6967\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.1011 - val_loss: 27.6378\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3117 - val_loss: 26.3569\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.3563 - val_loss: 27.3402\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.6843 - val_loss: 25.0702\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6709 - val_loss: 26.9163\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9727 - val_loss: 26.1296\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.8138 - val_loss: 25.2606\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0880 - val_loss: 25.3735\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9409 - val_loss: 26.0329\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8714 - val_loss: 25.3160\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.4453 - val_loss: 27.8969\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.7505 - val_loss: 25.5506\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9791 - val_loss: 30.6557\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.6830 - val_loss: 28.3509\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.5780 - val_loss: 25.3760\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4426 - val_loss: 26.1840\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.2931 - val_loss: 25.6315\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3564 - val_loss: 28.4471\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0412 - val_loss: 27.4221\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4501 - val_loss: 25.9028\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8882 - val_loss: 25.7721\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5932 - val_loss: 25.5787\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8148 - val_loss: 25.5193\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1196 - val_loss: 27.4982\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7815 - val_loss: 25.7161\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.4289 - val_loss: 26.1980\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1139 - val_loss: 25.8013\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1739 - val_loss: 24.4682\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0249 - val_loss: 25.1431\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5485 - val_loss: 26.3245\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0413 - val_loss: 25.5209\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4831 - val_loss: 25.2396\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6379 - val_loss: 25.4674\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8810 - val_loss: 25.0900\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9233 - val_loss: 28.0425\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3907 - val_loss: 25.4635\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.4205 - val_loss: 24.4772\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.5034 - val_loss: 24.7254\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.4666 - val_loss: 25.7657\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 22.6538 - val_loss: 25.0559\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.3857 - val_loss: 25.3219\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.3034 - val_loss: 25.1867\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.4917 - val_loss: 26.5384\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9902 - val_loss: 25.0072\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 21.0877 - val_loss: 24.3745\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.4623 - val_loss: 26.3358\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.9783 - val_loss: 25.0343\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9727 - val_loss: 26.5285\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.8339 - val_loss: 25.0413\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.0489 - val_loss: 23.5114\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.1405 - val_loss: 23.3789\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.6876 - val_loss: 24.4146\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.0268 - val_loss: 24.8359\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.3853 - val_loss: 28.0359\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.0563 - val_loss: 24.7825\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.9265 - val_loss: 23.3449\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.7763 - val_loss: 23.9834\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3273 - val_loss: 23.6157\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.7799 - val_loss: 25.2520\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1601 - val_loss: 23.1304\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6749 - val_loss: 22.3382\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7082 - val_loss: 22.8057\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9412 - val_loss: 22.2625\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.4972 - val_loss: 22.9539\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1539 - val_loss: 23.7342\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.6467 - val_loss: 23.6115\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6481 - val_loss: 23.1674\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4449 - val_loss: 21.9137\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6522 - val_loss: 22.4933\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2349 - val_loss: 22.1616\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0906 - val_loss: 22.4469\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9433 - val_loss: 23.2076\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9794 - val_loss: 21.2252\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2641 - val_loss: 20.9740\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1635 - val_loss: 21.2752\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7419 - val_loss: 20.8671\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5018 - val_loss: 20.4071\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3049 - val_loss: 22.2836\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3647 - val_loss: 19.8968\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2163 - val_loss: 20.5704\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2834 - val_loss: 21.4118\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0649 - val_loss: 19.3243\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.1564 - val_loss: 20.3497\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.9251 - val_loss: 19.3825\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.0951 - val_loss: 19.1960\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4671 - val_loss: 20.8697\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.3430 - val_loss: 19.7425\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1032 - val_loss: 21.2970\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.5968 - val_loss: 21.8890\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1403 - val_loss: 19.9879\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.5528 - val_loss: 18.5537\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.3929 - val_loss: 19.3372\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.1060 - val_loss: 18.9869\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9941 - val_loss: 18.6631\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.4017 - val_loss: 18.2497\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6706 - val_loss: 19.2699\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8329 - val_loss: 19.3089\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.4236 - val_loss: 18.3484\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2656 - val_loss: 18.3277\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2557 - val_loss: 18.8431\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.1224 - val_loss: 18.4178\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.6449 - val_loss: 18.2166\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.2917 - val_loss: 18.2469\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.1032 - val_loss: 18.7159\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.4412 - val_loss: 18.1310\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2024 - val_loss: 19.0627\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.4895 - val_loss: 17.8591\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.6981 - val_loss: 20.0387\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4380 - val_loss: 19.3242\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.6469 - val_loss: 17.0348\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2669 - val_loss: 17.9545\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3609 - val_loss: 17.3367\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.6168 - val_loss: 20.1672\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6879 - val_loss: 18.0147\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.1492 - val_loss: 18.3903\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9967 - val_loss: 18.9956\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.7656 - val_loss: 17.5349\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6754 - val_loss: 17.7138\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4629 - val_loss: 17.3041\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7789 - val_loss: 16.9976\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.8295 - val_loss: 17.8256\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3781 - val_loss: 17.0852\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2058 - val_loss: 16.8891\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3342 - val_loss: 17.7843\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2529 - val_loss: 18.6809\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0095 - val_loss: 17.3108\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9140 - val_loss: 18.1607\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7728 - val_loss: 18.4043\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9434 - val_loss: 17.5017\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6292 - val_loss: 17.1414\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7494 - val_loss: 16.7311\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8046 - val_loss: 18.2811\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.8377 - val_loss: 20.7537\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5897 - val_loss: 18.0776\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4603 - val_loss: 16.0747\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.4997 - val_loss: 18.7978\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3337 - val_loss: 18.2279\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.2032 - val_loss: 16.0331\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3951 - val_loss: 16.8118\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6173 - val_loss: 16.6312\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.4445 - val_loss: 16.4472\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7816 - val_loss: 16.4065\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3426 - val_loss: 17.1209\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3550 - val_loss: 14.8428\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7479 - val_loss: 15.2253\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8105 - val_loss: 16.6632\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7717 - val_loss: 16.6023\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4237 - val_loss: 15.8809\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1382 - val_loss: 14.9536\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5661 - val_loss: 16.5117\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4488 - val_loss: 16.0405\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0370 - val_loss: 15.4848\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1376 - val_loss: 18.5075\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8156 - val_loss: 15.6694\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2331 - val_loss: 16.0808\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.1472 - val_loss: 14.8632\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8884 - val_loss: 14.3434\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9260 - val_loss: 15.5120\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8696 - val_loss: 15.8073\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5726 - val_loss: 14.3259\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8015 - val_loss: 14.6887\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9741 - val_loss: 18.6712\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3157 - val_loss: 16.2592\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3963 - val_loss: 14.3367\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6487 - val_loss: 17.2621\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0963 - val_loss: 17.0697\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8771 - val_loss: 14.2571\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5917 - val_loss: 14.0515\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9203 - val_loss: 14.0290\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1149 - val_loss: 13.7695\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1053 - val_loss: 14.4625\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8947 - val_loss: 15.6411\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5500 - val_loss: 13.7159\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4312 - val_loss: 15.0630\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7493 - val_loss: 13.9085\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9365 - val_loss: 13.8333\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2199 - val_loss: 13.2054\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6474 - val_loss: 16.5369\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4376 - val_loss: 14.1389\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9698 - val_loss: 14.4211\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0144 - val_loss: 14.5598\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1676 - val_loss: 14.8401\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2359 - val_loss: 14.1846\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2230 - val_loss: 12.6232\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6319 - val_loss: 13.1887\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.8765 - val_loss: 18.7184\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3443 - val_loss: 12.9354\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7549 - val_loss: 12.8103\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6254 - val_loss: 14.0614\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1696 - val_loss: 13.6339\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.9978 - val_loss: 15.5009\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 10.3174 - val_loss: 15.2344\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6681 - val_loss: 14.2703\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8398 - val_loss: 15.2621\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.8041 - val_loss: 12.3819\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.2100 - val_loss: 13.2973\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.4513 - val_loss: 13.8809\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3104 - val_loss: 12.1693\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 122us/step - loss: 10.1946 - val_loss: 12.3634\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 10.0661 - val_loss: 12.6355\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 10.1599 - val_loss: 15.4296\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 10.9302 - val_loss: 12.3385\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.8074 - val_loss: 12.4543\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.1898 - val_loss: 13.1403\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 10.2146 - val_loss: 13.6402\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 11.0018 - val_loss: 12.6348\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 10.4507 - val_loss: 12.1100\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 9.9170 - val_loss: 12.1086\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4831 - val_loss: 12.5515\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8959 - val_loss: 12.2033\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8497 - val_loss: 12.4286\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.3699 - val_loss: 13.7125\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4533 - val_loss: 14.9617\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0179 - val_loss: 12.7228\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7015 - val_loss: 12.4625\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8100 - val_loss: 12.0891\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1034 - val_loss: 15.5659\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2672 - val_loss: 12.9925\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8555 - val_loss: 12.7662\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2790 - val_loss: 12.8387\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8503 - val_loss: 13.8165\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6323 - val_loss: 14.2177\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9342 - val_loss: 12.3157\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.8276 - val_loss: 14.6989\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.3057 - val_loss: 12.2965\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9335 - val_loss: 13.4000\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7982 - val_loss: 12.2090\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0461 - val_loss: 11.9963\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2904 - val_loss: 14.1630\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6080 - val_loss: 12.9657\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5349 - val_loss: 12.3646\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3553 - val_loss: 12.6172\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7777 - val_loss: 11.5784\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.6882 - val_loss: 11.8619\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6910 - val_loss: 12.5739\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0763 - val_loss: 11.9940\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.0038 - val_loss: 11.7085\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7288 - val_loss: 12.0713\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.0005 - val_loss: 12.7306\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1352 - val_loss: 11.9886\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8857 - val_loss: 12.6049\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7973 - val_loss: 11.7533\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3212 - val_loss: 12.2215\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4866 - val_loss: 12.7758\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8140 - val_loss: 13.2066\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4249 - val_loss: 12.4918\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5615 - val_loss: 11.5501\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3952 - val_loss: 12.0371\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7694 - val_loss: 11.7384\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4743 - val_loss: 12.0357\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3333 - val_loss: 11.4805\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2137 - val_loss: 13.4631\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8625 - val_loss: 12.5039\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1701 - val_loss: 12.1374\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5061 - val_loss: 13.5226\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0089 - val_loss: 11.8071\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5208 - val_loss: 12.0410\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4870 - val_loss: 12.1400\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4820 - val_loss: 14.2104\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7523 - val_loss: 12.5000\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 9.0720 - val_loss: 11.6374\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3537 - val_loss: 11.1735\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4062 - val_loss: 11.4459\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3721 - val_loss: 11.7329\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6739 - val_loss: 12.1009\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1306 - val_loss: 13.5935\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.7750 - val_loss: 11.7612\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5498 - val_loss: 12.0661\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8346 - val_loss: 14.1403\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8504 - val_loss: 11.1062\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2178 - val_loss: 11.3554\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3144 - val_loss: 11.2727\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2430 - val_loss: 11.8141\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1811 - val_loss: 12.3278\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3056 - val_loss: 11.1873\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2959 - val_loss: 10.8602\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6982 - val_loss: 11.2722\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6988 - val_loss: 11.1049\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0953 - val_loss: 12.0136\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9692 - val_loss: 12.6944\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3417 - val_loss: 11.5678\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0280 - val_loss: 11.4427\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1440 - val_loss: 12.1888\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2107 - val_loss: 11.6523\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4866 - val_loss: 11.0643\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.0580 - val_loss: 11.8022\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2222 - val_loss: 12.4535\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4679 - val_loss: 11.7042\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0945 - val_loss: 12.1497\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5364 - val_loss: 12.3760\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9541 - val_loss: 11.0979\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7486 - val_loss: 13.1392\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 9.1080 - val_loss: 11.3501\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3562 - val_loss: 11.6131\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5772 - val_loss: 13.5658\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5466 - val_loss: 11.6975\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1905 - val_loss: 11.3165\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5320 - val_loss: 11.6144\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8522 - val_loss: 11.1225\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.1192 - val_loss: 12.2586\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1807 - val_loss: 11.2082\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5089 - val_loss: 11.0896\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1144 - val_loss: 11.3620\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9812 - val_loss: 12.8844\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5213 - val_loss: 10.9350\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6565 - val_loss: 11.7154\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5937 - val_loss: 11.5805\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1476 - val_loss: 11.0669\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2977 - val_loss: 11.1659\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0353 - val_loss: 11.1254\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3498 - val_loss: 11.5163\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6874 - val_loss: 12.2867\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3192 - val_loss: 11.5916\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4783 - val_loss: 11.9926\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2072 - val_loss: 11.1765\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3489 - val_loss: 11.8586\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3903 - val_loss: 11.2262\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3403 - val_loss: 12.6091\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2528 - val_loss: 11.0867\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4777 - val_loss: 12.8064\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.0269 - val_loss: 11.0972\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3030 - val_loss: 12.4955\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9431 - val_loss: 11.7297\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3466 - val_loss: 10.8367\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6048 - val_loss: 10.7601\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1833 - val_loss: 11.2163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9704 - val_loss: 11.0355\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3153 - val_loss: 11.2533\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0355 - val_loss: 10.9792\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5892 - val_loss: 11.6315\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4496 - val_loss: 11.1616\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3195 - val_loss: 10.8768\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6760 - val_loss: 11.7629\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1295 - val_loss: 11.4551\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2229 - val_loss: 10.8007\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2077 - val_loss: 12.7052\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5828 - val_loss: 11.2727\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3970 - val_loss: 11.7283\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5859 - val_loss: 11.1671\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7631 - val_loss: 15.6298\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0122 - val_loss: 11.3032\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2939 - val_loss: 11.0503\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3565 - val_loss: 10.9674\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2871 - val_loss: 11.4903\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7974 - val_loss: 12.7444\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5317 - val_loss: 10.9254\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6289 - val_loss: 11.1689\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0279 - val_loss: 11.1629\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9360 - val_loss: 11.7026\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2849 - val_loss: 11.5303\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1553 - val_loss: 10.7635\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2026 - val_loss: 11.2966\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6279 - val_loss: 12.5814\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5772 - val_loss: 10.8980\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1067 - val_loss: 11.1635\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1828 - val_loss: 11.9220\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9656 - val_loss: 11.0401\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2718 - val_loss: 11.6816\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2598 - val_loss: 11.2508\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.2779 - val_loss: 11.4494\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6705 - val_loss: 11.9546\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2167 - val_loss: 12.4202\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1333 - val_loss: 11.1511\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0261 - val_loss: 11.0278\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1691 - val_loss: 11.3737\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3012 - val_loss: 11.6913\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0971 - val_loss: 11.4205\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9923 - val_loss: 11.1321\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0553 - val_loss: 11.4150\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 9.6912 - val_loss: 11.2185\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.5492 - val_loss: 11.1029\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.8976 - val_loss: 11.5497\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5138 - val_loss: 11.5075\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2805 - val_loss: 11.4616\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4726 - val_loss: 11.4226\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6720 - val_loss: 11.1488\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3413 - val_loss: 11.4232\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0445 - val_loss: 11.0293\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2592 - val_loss: 11.6605\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3345 - val_loss: 10.9215\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2064 - val_loss: 10.8327\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0858 - val_loss: 11.6811\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5235 - val_loss: 11.5165\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1579 - val_loss: 10.9297\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2965 - val_loss: 12.6116\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1925 - val_loss: 11.2004\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0373 - val_loss: 11.9084\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9536 - val_loss: 11.4796\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0417 - val_loss: 11.6477\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7225 - val_loss: 12.2008\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5259 - val_loss: 11.8043\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5533 - val_loss: 11.5582\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4251 - val_loss: 10.9254\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0103 - val_loss: 11.4895\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0705 - val_loss: 12.9775\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7144 - val_loss: 11.6713\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1380 - val_loss: 11.0066\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1793 - val_loss: 11.3662\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9967 - val_loss: 11.8858\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3239 - val_loss: 10.7404\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3929 - val_loss: 11.3838\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.5488 - val_loss: 11.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1663 - val_loss: 12.3133\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1796 - val_loss: 11.9609\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3631 - val_loss: 11.5808\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3789 - val_loss: 12.6103\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4903 - val_loss: 13.9578\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6268 - val_loss: 11.4016\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6808 - val_loss: 11.0232\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0042 - val_loss: 12.6161\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.9064 - val_loss: 11.2376\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1033 - val_loss: 11.3077\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4316 - val_loss: 11.3415\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9299 - val_loss: 10.9308\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1185 - val_loss: 12.4269\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2235 - val_loss: 11.3331\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5222 - val_loss: 12.2477\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3897 - val_loss: 11.0440\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2560 - val_loss: 11.2359\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7623 - val_loss: 11.9134\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1343 - val_loss: 11.2524\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1823 - val_loss: 11.2113\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0284 - val_loss: 10.6915\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2186 - val_loss: 10.9652\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1628 - val_loss: 11.5996\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1052 - val_loss: 11.2444\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0724 - val_loss: 10.7237\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3191 - val_loss: 11.1221\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6689 - val_loss: 11.9536\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4338 - val_loss: 10.8827\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8950 - val_loss: 11.4016\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3390 - val_loss: 11.9629\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8950 - val_loss: 10.9149\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1243 - val_loss: 11.3975\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0903 - val_loss: 11.5646\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1105 - val_loss: 11.4509\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0612 - val_loss: 12.6357\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7487 - val_loss: 11.1033\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9597 - val_loss: 16.2731\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5693 - val_loss: 11.2610\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1164 - val_loss: 11.5287\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9373 - val_loss: 11.9322\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.1310 - val_loss: 11.1648\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1387 - val_loss: 11.1555\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8572 - val_loss: 11.7705\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5080 - val_loss: 12.0929\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0430 - val_loss: 12.4289\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1869 - val_loss: 10.8457\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7817 - val_loss: 12.5539\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8693 - val_loss: 14.6003\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5050 - val_loss: 10.6851\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3140 - val_loss: 11.4386\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3668 - val_loss: 11.1227\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.1868 - 0s 92us/step - loss: 9.4933 - val_loss: 11.4850\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.2332 - val_loss: 13.4650\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6902 - val_loss: 12.6740\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2323 - val_loss: 11.1806\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7141 - val_loss: 10.7533\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0165 - val_loss: 11.3063\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2768 - val_loss: 11.4218\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0386 - val_loss: 11.4288\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4806 - val_loss: 13.0162\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.8779 - val_loss: 12.6007\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5836 - val_loss: 11.5199\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9495 - val_loss: 11.2373\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4921 - val_loss: 10.8518\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2523 - val_loss: 11.7406\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3035 - val_loss: 12.4721\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9717 - val_loss: 10.9781\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2504 - val_loss: 11.7588\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2125 - val_loss: 10.8923\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9056 - val_loss: 11.1209\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7901 - val_loss: 11.0079\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1096 - val_loss: 12.4052\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1849 - val_loss: 11.1251\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0868 - val_loss: 11.5945\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1500 - val_loss: 12.1146\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0636 - val_loss: 12.0776\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8462 - val_loss: 11.0806\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1709 - val_loss: 11.1606\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4211 - val_loss: 11.2053\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3301 - val_loss: 11.2472\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1726 - val_loss: 11.8064\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7651 - val_loss: 11.8054\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0902 - val_loss: 11.9627\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0461 - val_loss: 11.5941\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2045 - val_loss: 11.1233\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2611 - val_loss: 12.0854\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0511 - val_loss: 10.8626\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0745 - val_loss: 11.8408\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0859 - val_loss: 11.4926\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2964 - val_loss: 11.1019\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9856 - val_loss: 10.5450\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1286 - val_loss: 11.8038\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4034 - val_loss: 11.8727\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0315 - val_loss: 11.1108\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7599 - val_loss: 11.9383\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2844 - val_loss: 11.9018\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3007 - val_loss: 11.3213\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9390 - val_loss: 12.2991\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0746 - val_loss: 11.0773\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2342 - val_loss: 11.6371\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.9968 - val_loss: 11.5886\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9322 - val_loss: 10.6110\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1226 - val_loss: 11.1077\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1731 - val_loss: 11.4863\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2667 - val_loss: 11.9040\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2197 - val_loss: 13.1278\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7048 - val_loss: 11.4157\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9630 - val_loss: 11.3965\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5533 - val_loss: 10.7605\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3203 - val_loss: 10.8603\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0030 - val_loss: 12.4135\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.6288 - val_loss: 11.9211\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4817 - val_loss: 11.3397\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0252 - val_loss: 10.7129\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9671 - val_loss: 11.2238\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9628 - val_loss: 11.0058\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3645 - val_loss: 12.2319\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3484 - val_loss: 11.0634\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1280 - val_loss: 12.0814\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2351 - val_loss: 11.3081\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3836 - val_loss: 11.9027\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8366 - val_loss: 11.6618\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2615 - val_loss: 10.7844\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2430 - val_loss: 12.0938\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8774 - val_loss: 10.8935\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2998 - val_loss: 10.7341\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0841 - val_loss: 11.3056\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1386 - val_loss: 11.1386\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.1728 - val_loss: 11.4344\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0540 - val_loss: 11.4599\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1100 - val_loss: 12.5976\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.9291 - val_loss: 11.4305\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 9.6051 - val_loss: 11.0436\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 9.1048 - val_loss: 11.0417\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.1447 - val_loss: 10.7650\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.0553 - val_loss: 11.5100\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.0329 - val_loss: 11.1515\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.2036 - val_loss: 10.7089\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 9.0508 - val_loss: 12.1577\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.2550 - val_loss: 10.9946\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1523 - val_loss: 12.3148\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3702 - val_loss: 10.8843\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8967 - val_loss: 12.1326\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4797 - val_loss: 10.8070\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8590 - val_loss: 10.5725\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1127 - val_loss: 13.5174\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0896 - val_loss: 10.7462\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.0759 - val_loss: 11.7953\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2674 - val_loss: 12.3283\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 9.2758 - val_loss: 10.9680\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7266 - val_loss: 11.8949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0017 - val_loss: 12.4197\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3098 - val_loss: 11.3434\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0040 - val_loss: 12.4429\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1419 - val_loss: 12.2925\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0557 - val_loss: 11.8554\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1479 - val_loss: 10.9016\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9168 - val_loss: 10.8633\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8589 - val_loss: 11.2232\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2015 - val_loss: 11.7535\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1803 - val_loss: 10.9358\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0559 - val_loss: 11.4805\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2465 - val_loss: 11.5480\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.2128 - val_loss: 11.4788\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3490 - val_loss: 10.9488\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9641 - val_loss: 11.1429\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4499 - val_loss: 12.1922\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4553 - val_loss: 10.9445\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1767 - val_loss: 11.0138\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9077 - val_loss: 10.6521\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2790 - val_loss: 11.1458\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6160 - val_loss: 10.7350\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0086 - val_loss: 11.6590\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.2984 - val_loss: 11.0338\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0713 - val_loss: 11.0577\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8781 - val_loss: 10.6405\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0603 - val_loss: 11.9571\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0385 - val_loss: 10.6676\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1105 - val_loss: 10.5997\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8929 - val_loss: 10.7993\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8287 - val_loss: 11.1465\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9421 - val_loss: 11.3910\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4480 - val_loss: 11.6452\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9480 - val_loss: 11.4096\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2804 - val_loss: 10.9052\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.3147 - val_loss: 11.0362\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.8744 - val_loss: 11.5423\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1809 - val_loss: 11.5385\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9896 - val_loss: 10.9540\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6727 - val_loss: 12.4183\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2138 - val_loss: 11.3751\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0894 - val_loss: 10.8137\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.0214 - val_loss: 12.1305\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2026 - val_loss: 10.9031\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8577 - val_loss: 11.0977\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9051 - val_loss: 12.3162\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7286 - val_loss: 11.0479\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0784 - val_loss: 11.7870\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2441 - val_loss: 10.8152\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0263 - val_loss: 11.0908\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7547 - val_loss: 15.5385\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5456 - val_loss: 10.8857\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8593 - val_loss: 10.9070\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1064 - val_loss: 10.7020\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0026 - val_loss: 12.5867\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.2798 - val_loss: 13.9420\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1476 - val_loss: 10.8570\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1012 - val_loss: 11.1453\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2535 - val_loss: 11.2649\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6397 - val_loss: 13.5685\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5104 - val_loss: 11.1497\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9706 - val_loss: 11.4469\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1276 - val_loss: 13.0284\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3050 - val_loss: 11.3693\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1429 - val_loss: 11.3869\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0834 - val_loss: 11.4382\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1584 - val_loss: 10.5934\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4716 - val_loss: 10.6446\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1543 - val_loss: 11.0523\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0338 - val_loss: 10.8755\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1723 - val_loss: 10.9978\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.1019 - val_loss: 11.4000\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9894 - val_loss: 11.0273\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8395 - val_loss: 11.3239\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8269 - val_loss: 11.2847\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8474 - val_loss: 12.1642\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2044 - val_loss: 10.6592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7167 - val_loss: 11.6371\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5725 - val_loss: 11.2332\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8059 - val_loss: 11.6371\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2037 - val_loss: 11.6800\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1275 - val_loss: 10.9508\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7176 - val_loss: 11.4566\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.8206 - val_loss: 11.3183\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1770 - val_loss: 11.8449\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.5714 - val_loss: 10.7954\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0150 - val_loss: 10.9038\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8987 - val_loss: 11.2650\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0599 - val_loss: 11.8594\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8450 - val_loss: 11.5108\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8544 - val_loss: 11.2748\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3527 - val_loss: 10.7425\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9521 - val_loss: 10.7392\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9546 - val_loss: 10.6938\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8697 - val_loss: 10.6551\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7904 - val_loss: 10.9378\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2664 - val_loss: 11.4337\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3728 - val_loss: 11.8310\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6525 - val_loss: 11.7260\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8149 - val_loss: 12.0402\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3720 - val_loss: 11.2286\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4356 - val_loss: 12.1917\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8645 - val_loss: 11.7641\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0568 - val_loss: 10.7083\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2395 - val_loss: 11.1040\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6883 - val_loss: 10.7333\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9665 - val_loss: 13.6273\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3506 - val_loss: 10.9003\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2209 - val_loss: 11.2262\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8368 - val_loss: 10.7022\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8192 - val_loss: 11.3314\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9344 - val_loss: 11.6816\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1897 - val_loss: 10.6864\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0171 - val_loss: 10.7746\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0979 - val_loss: 13.3513\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1998 - val_loss: 10.6379\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0601 - val_loss: 10.8673\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8492 - val_loss: 11.5465\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.3158 - val_loss: 11.1819\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8318 - val_loss: 10.5284\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.9234 - val_loss: 10.8443\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.3527 - val_loss: 10.8359\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.2048 - val_loss: 11.5681\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9038 - val_loss: 12.3671\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8707 - val_loss: 10.6869\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7970 - val_loss: 11.6380\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1931 - val_loss: 11.3771\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7823 - val_loss: 13.1058\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3214 - val_loss: 12.9649\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4655 - val_loss: 11.6121\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6898 - val_loss: 10.5017\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9669 - val_loss: 10.9574\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2096 - val_loss: 10.8419\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1006 - val_loss: 11.5113\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4004 - val_loss: 10.9887\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1485 - val_loss: 11.0570\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.940 - 0s 85us/step - loss: 8.8737 - val_loss: 10.8799\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1744 - val_loss: 11.4333\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0376 - val_loss: 10.7367\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3585 - val_loss: 10.7562\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0043 - val_loss: 10.6337\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.2351 - 0s 99us/step - loss: 9.2156 - val_loss: 10.9231\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.8452 - val_loss: 11.8446\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 9.0156 - val_loss: 11.4967\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.3765 - val_loss: 11.5748\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.9146 - val_loss: 11.1992\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.7337 - val_loss: 10.9269\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8065 - val_loss: 10.6715\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.5145 - val_loss: 11.8001\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5012 - val_loss: 11.3715\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3713 - val_loss: 10.7379\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.1191 - val_loss: 10.5556\n",
      "Epoch 819/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0861 - val_loss: 13.5373\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2942 - val_loss: 10.4178\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9259 - val_loss: 11.7992\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6771 - val_loss: 10.6622\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8895 - val_loss: 12.0428\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3116 - val_loss: 12.8613\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3455 - val_loss: 13.6812\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2305 - val_loss: 11.4426\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9148 - val_loss: 10.4478\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8818 - val_loss: 11.6162\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3097 - val_loss: 10.2682\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3358 - val_loss: 11.2257\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9355 - val_loss: 10.4690\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2100 - val_loss: 12.0247\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3756 - val_loss: 11.0988\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6057 - val_loss: 10.5055\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1077 - val_loss: 10.9213\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8280 - val_loss: 11.5279\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0082 - val_loss: 10.7856\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7846 - val_loss: 10.3110\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1155 - val_loss: 11.6435\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1338 - val_loss: 10.8410\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4305 - val_loss: 11.3194\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7519 - val_loss: 11.3730\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3672 - val_loss: 12.3159\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9124 - val_loss: 13.3637\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3922 - val_loss: 11.6276\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7205 - val_loss: 11.3396\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2815 - val_loss: 10.5618\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9544 - val_loss: 10.7371\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2020 - val_loss: 10.4938\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3176 - val_loss: 10.5454\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6817 - val_loss: 10.8722\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7538 - val_loss: 10.5194\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9005 - val_loss: 10.6855\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9728 - val_loss: 12.2884\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9127 - val_loss: 10.7766\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9956 - val_loss: 11.0011\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7096 - val_loss: 10.8131\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9773 - val_loss: 11.5029\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9204 - val_loss: 10.3486\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6510 - val_loss: 10.4547\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2116 - val_loss: 11.4137\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2157 - val_loss: 10.4956\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3835 - val_loss: 10.6832\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1315 - val_loss: 10.6350\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8769 - val_loss: 11.6319\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2109 - val_loss: 10.6220\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 126us/step - loss: 9.4448 - val_loss: 11.6950\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0352 - val_loss: 10.7657\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2526 - val_loss: 10.5369\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7329 - val_loss: 10.5441\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1358 - val_loss: 12.5590\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4908 - val_loss: 11.1379\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4187 - val_loss: 10.9943\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9867 - val_loss: 11.4772\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0407 - val_loss: 11.0988\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4383 - val_loss: 10.8564\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1162 - val_loss: 11.7676\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7468 - val_loss: 11.1872\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3632 - val_loss: 11.2069\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0964 - val_loss: 10.7050\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7185 - val_loss: 12.2007\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4128 - val_loss: 10.8953\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9858 - val_loss: 10.3579\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2515 - val_loss: 11.1749\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6617 - val_loss: 10.2761\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6976 - val_loss: 10.4791\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9992 - val_loss: 10.7816\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6856 - val_loss: 10.2573\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1162 - val_loss: 10.5113\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0726 - val_loss: 14.4197\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3649 - val_loss: 10.7719\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2255 - val_loss: 10.5125\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0449 - val_loss: 10.6679\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8164 - val_loss: 10.8354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8485 - val_loss: 10.3481\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0351 - val_loss: 10.4031\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6806 - val_loss: 11.7927\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2338 - val_loss: 11.4087\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1360 - val_loss: 10.7722\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7734 - val_loss: 11.7990\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0804 - val_loss: 10.5640\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9323 - val_loss: 10.3132\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6921 - val_loss: 10.7599\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8069 - val_loss: 10.3966\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6074 - val_loss: 11.7749\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4875 - val_loss: 10.3637\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8602 - val_loss: 11.8617\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8572 - val_loss: 10.1286\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5910 - val_loss: 11.2428\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9259 - val_loss: 10.7212\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3726 - val_loss: 10.9619\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4929 - val_loss: 12.3384\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1844 - val_loss: 10.4856\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1013 - val_loss: 10.3879\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0412 - val_loss: 11.2049\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3705 - val_loss: 10.5350\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8363 - val_loss: 10.1223\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1521 - val_loss: 11.0094\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9023 - val_loss: 13.7257\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0382 - val_loss: 10.1577\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9621 - val_loss: 12.7640\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7671 - val_loss: 10.7629\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0806 - val_loss: 10.7404\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0579 - val_loss: 11.7978\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8633 - val_loss: 10.3527\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7772 - val_loss: 10.3386\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8552 - val_loss: 10.5665\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1942 - val_loss: 11.4366\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1965 - val_loss: 10.3579\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6905 - val_loss: 11.6821\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9086 - val_loss: 10.4456\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8940 - val_loss: 10.5567\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3212 - val_loss: 10.4868\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3775 - val_loss: 11.3901\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7949 - val_loss: 10.5397\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6948 - val_loss: 11.3512\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6327 - val_loss: 10.3498\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6196 - val_loss: 10.3136\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1246 - val_loss: 11.3767\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9198 - val_loss: 10.2812\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6637 - val_loss: 10.4475\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1721 - val_loss: 10.0491\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0283 - val_loss: 10.4666\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1191 - val_loss: 10.4680\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9259 - val_loss: 10.8307\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0176 - val_loss: 10.4170\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9140 - val_loss: 13.6006\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3249 - val_loss: 10.6742\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1587 - val_loss: 10.2987\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8674 - val_loss: 10.4054\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8602 - val_loss: 10.7255\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5297 - val_loss: 10.3120\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9014 - val_loss: 9.9823\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7024 - val_loss: 10.3022\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8362 - val_loss: 10.0541\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9443 - val_loss: 11.5383\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0728 - val_loss: 10.6201\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3283 - val_loss: 10.5751\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6633 - val_loss: 10.1860\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7142 - val_loss: 11.4006\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1001 - val_loss: 10.5938\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5813 - val_loss: 10.0156\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2104 - val_loss: 9.9769\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7505 - val_loss: 10.5884\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0624 - val_loss: 12.1412\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8843 - val_loss: 11.3179\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9794 - val_loss: 10.0862\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0747 - val_loss: 10.4799\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2194 - val_loss: 14.4313\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3079 - val_loss: 10.6606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6429 - val_loss: 10.6211\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0473 - val_loss: 10.8128\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9732 - val_loss: 10.0884\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9096 - val_loss: 10.7253\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0274 - val_loss: 10.4229\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8149 - val_loss: 10.2351\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0869 - val_loss: 12.5964\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7135 - val_loss: 10.8873\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1262 - val_loss: 11.9191\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1497 - val_loss: 11.2137\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0184 - val_loss: 10.7159\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9854 - val_loss: 10.3056\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9694 - val_loss: 10.6917\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0095 - val_loss: 10.6037\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8539 - val_loss: 10.7361\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4640 - val_loss: 11.9521\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1744 - val_loss: 10.6994\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1654 - val_loss: 11.0386\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2239 - val_loss: 10.8722\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5016 - val_loss: 11.0191\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9045 - val_loss: 10.2662\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7544 - val_loss: 11.1815\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6790 - val_loss: 13.2385\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9651 - val_loss: 10.6880\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0458 - val_loss: 10.4129\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9437 - val_loss: 10.6701\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7810 - val_loss: 10.1348\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2774 - val_loss: 9.9720\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0673 - val_loss: 10.5557\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5463 - val_loss: 10.2594\n",
      "8.683912379024303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 3.7658505 , -3.653033  ,  1.0955843 ,  0.21308737, -1.6552277 ],\n",
       "        [-0.34051138,  0.1005788 ,  0.12058192,  0.25269836,  0.36695352],\n",
       "        [ 0.52621067,  0.09195517,  0.36926234,  0.38295838,  0.2762035 ],\n",
       "        [-0.1478223 ,  0.06920976, -0.1331796 , -0.09340351,  0.07526465],\n",
       "        [ 0.4583969 , -2.2980115 ,  1.1225587 ,  0.20043613, -0.1881925 ]],\n",
       "       dtype=float32),\n",
       " array([ 4.666794  , -5.128334  ,  3.055091  ,  0.19168009, -1.2460308 ],\n",
       "       dtype=float32),\n",
       " array([[ 2.1718817 ,  2.323834  ,  1.925013  , -1.8858831 ,  1.7713038 ,\n",
       "         -1.8209128 , -1.9198476 ,  2.3160708 , -2.2104387 , -2.3922737 ],\n",
       "        [-1.9812361 , -1.0783396 , -1.5463561 ,  1.9631652 , -1.1482025 ,\n",
       "          2.094423  ,  1.563533  , -1.6637026 ,  2.0733185 ,  1.649086  ],\n",
       "        [ 1.2483221 ,  1.6556984 ,  1.7763183 , -1.1809382 ,  1.9065167 ,\n",
       "         -1.1999451 , -1.1565288 ,  1.4378055 , -1.4539671 , -1.5442106 ],\n",
       "        [-1.5300195 , -0.64329743, -1.3546942 ,  0.9511247 , -0.7688898 ,\n",
       "          1.2475607 ,  1.2115512 , -0.80531895,  0.37403846,  0.5862726 ],\n",
       "        [ 1.2019818 ,  0.5270186 ,  1.1578641 , -0.13716549,  0.4141596 ,\n",
       "         -1.1068089 , -0.58522695,  0.5416996 , -0.16455945, -1.170145  ]],\n",
       "       dtype=float32),\n",
       " array([ 1.7952942,  1.7474363,  1.7272412, -1.8080509,  1.8070174,\n",
       "        -1.7096884, -1.7193391,  1.7330859, -1.7261354, -1.7792149],\n",
       "       dtype=float32),\n",
       " array([[ 1.6934447],\n",
       "        [ 2.0085027],\n",
       "        [ 2.0319443],\n",
       "        [-1.7996043],\n",
       "        [ 1.6756557],\n",
       "        [-2.0723746],\n",
       "        [-2.1060507],\n",
       "        [ 2.1836975],\n",
       "        [-2.1274836],\n",
       "        [-1.8498951]], dtype=float32),\n",
       " array([1.7316607], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_linear(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_linear_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 198us/step - loss: 9680.5448 - val_loss: 1728.6256\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 820.1432 - val_loss: 421.6311\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 303.0622 - val_loss: 216.9672\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 176.5790 - val_loss: 148.7708\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 120.6628 - val_loss: 101.3770\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 85.1741 - val_loss: 76.5643\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 65.4591 - val_loss: 60.6258\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 51.7689 - val_loss: 50.3566\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 43.7707 - val_loss: 44.6390\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 40.2885 - val_loss: 41.1173\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 37.8647 - val_loss: 39.1917\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 35.4779 - val_loss: 37.8461\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 34.1684 - val_loss: 36.6409\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 33.1357 - val_loss: 36.2248\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 32.0691 - val_loss: 35.0507\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 31.7282 - val_loss: 33.4401\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 30.3892 - val_loss: 34.3280\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 29.3963 - val_loss: 32.5399\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 28.9047 - val_loss: 32.2767\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 27.8861 - val_loss: 31.0540\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 26.9631 - val_loss: 30.1291\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 26.6524 - val_loss: 29.9903\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 25.5000 - val_loss: 29.5542\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 24.8301 - val_loss: 29.0286\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 24.7960 - val_loss: 29.6224\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 23.8077 - val_loss: 28.1606\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 23.9775 - val_loss: 28.3540\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.6146 - val_loss: 28.6976\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.4665 - val_loss: 27.4370\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.9589 - val_loss: 27.3420\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.6566 - val_loss: 26.9571\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4709 - val_loss: 27.3640\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1662 - val_loss: 27.1462\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7536 - val_loss: 27.1308\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8790 - val_loss: 27.4400\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6865 - val_loss: 27.5349\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7545 - val_loss: 26.8716\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7201 - val_loss: 27.6610\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4839 - val_loss: 28.4701\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.5131 - val_loss: 27.0552\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6854 - val_loss: 26.5552\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7110 - val_loss: 28.4105\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.2401 - val_loss: 27.6227\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.4402 - val_loss: 27.0663\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6298 - val_loss: 27.0659\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.2855 - val_loss: 26.9834\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3906 - val_loss: 27.4263\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4673 - val_loss: 27.9924\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2807 - val_loss: 27.4638\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.1555 - val_loss: 28.0731\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.6412 - val_loss: 29.3558\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0568 - val_loss: 28.3112\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7499 - val_loss: 27.3573\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0004 - val_loss: 27.7589\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.9580 - val_loss: 28.0749\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.4483 - val_loss: 27.2164\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.2085 - val_loss: 27.5299\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.3463 - val_loss: 27.6154\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.0173 - val_loss: 26.8652\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.9834 - val_loss: 27.2637\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.2939 - val_loss: 27.4912\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7760 - val_loss: 27.4110\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.3479 - val_loss: 27.1293\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.8720 - val_loss: 27.1894\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.4463 - val_loss: 28.6176\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6012 - val_loss: 27.0066\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.3233 - val_loss: 27.3924\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4532 - val_loss: 28.1551\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2847 - val_loss: 27.9488\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0314 - val_loss: 27.6982\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.4642 - val_loss: 28.5785\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.9903 - val_loss: 26.6229\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.1906 - val_loss: 26.7869\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.8544 - val_loss: 26.8088\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.1349 - val_loss: 27.9432\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.1496 - val_loss: 27.4739\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.0732 - val_loss: 27.5297\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.8158 - val_loss: 27.4374\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.0635 - val_loss: 28.1142\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5213 - val_loss: 28.1569\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8042 - val_loss: 27.4106\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.8665 - val_loss: 27.0852\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3378 - val_loss: 27.1111\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8215 - val_loss: 28.4273\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.1409 - val_loss: 28.0646\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.3989 - val_loss: 26.9034\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.1868 - val_loss: 26.6509\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4591 - val_loss: 26.4339\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9210 - val_loss: 27.5503\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6198 - val_loss: 27.3450\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.8863 - val_loss: 26.6235\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.2253 - val_loss: 26.8521\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.9598 - val_loss: 26.4041\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.7552 - val_loss: 27.9417\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.0826 - val_loss: 27.2648\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.9747 - val_loss: 26.9163\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7699 - val_loss: 26.9907\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.0217 - val_loss: 27.6540\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.7385 - val_loss: 29.4901\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2837 - val_loss: 26.9928\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6917 - val_loss: 28.3364\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2233 - val_loss: 27.2755\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.3461 - val_loss: 27.2549\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.0660 - val_loss: 28.0501\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1488 - val_loss: 29.3962\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.3710 - val_loss: 29.7499\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.5389 - val_loss: 27.0085\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.3573 - val_loss: 26.9192\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.9531 - val_loss: 26.7500\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.8150 - val_loss: 27.2255\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.6896 - val_loss: 27.3877\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.0877 - val_loss: 29.2338\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9908 - val_loss: 26.5955\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.0054 - val_loss: 26.6343\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.0050 - val_loss: 27.0712\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4540 - val_loss: 26.4231\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5956 - val_loss: 26.6669\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.7224 - val_loss: 26.7100\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.3785 - val_loss: 27.5101\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.7569 - val_loss: 26.5399\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.1039 - val_loss: 26.6120\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.6977 - val_loss: 26.1019\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.9191 - val_loss: 26.6079\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5009 - val_loss: 26.6241\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.8315 - val_loss: 26.0823\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6676 - val_loss: 31.4592\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5973 - val_loss: 26.8514\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.1818 - val_loss: 29.0281\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.9018 - val_loss: 26.7239\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5827 - val_loss: 27.1533\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.0162 - val_loss: 26.2616\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.0787 - val_loss: 27.2681\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 20.7770 - val_loss: 25.2259\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 20.9169 - val_loss: 26.7325\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 21.8152 - val_loss: 25.2640\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7428 - val_loss: 26.9245\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.2641 - val_loss: 25.3278\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.5213 - val_loss: 28.0579\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.4872 - val_loss: 26.0014\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.7868 - val_loss: 25.5574\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.1169 - val_loss: 24.5094\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.9305 - val_loss: 26.5592\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.3624 - val_loss: 25.8656\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.7616 - val_loss: 24.9617\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.9493 - val_loss: 24.5157\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2598 - val_loss: 24.4363\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.9917 - val_loss: 25.4127\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.3674 - val_loss: 25.0395\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.6122 - val_loss: 24.3634\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7996 - val_loss: 26.5654\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.5790 - val_loss: 25.1047\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.2601 - val_loss: 27.1349\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.7585 - val_loss: 25.8341\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.6010 - val_loss: 25.4985\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.5842 - val_loss: 25.7167\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0984 - val_loss: 23.6055\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.2684 - val_loss: 25.4508\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.5483 - val_loss: 23.6302\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.1513 - val_loss: 25.9039\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.7131 - val_loss: 24.9847\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.7801 - val_loss: 25.8400\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.4843 - val_loss: 23.5161\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.3047 - val_loss: 23.7737\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.4378 - val_loss: 23.1613\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.1171 - val_loss: 24.0342\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.9281 - val_loss: 23.2976\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.8643 - val_loss: 23.5012\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.8608 - val_loss: 24.3630\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.3557 - val_loss: 24.1064\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.6586 - val_loss: 23.9074\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.5397 - val_loss: 24.3681\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6222 - val_loss: 25.3229\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.3808 - val_loss: 24.5012\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 20.6176 - val_loss: 23.8833\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.5904 - val_loss: 24.6504\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.1188 - val_loss: 25.2677\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.5190 - val_loss: 24.5296\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.9168 - val_loss: 23.6101\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.7716 - val_loss: 26.0453\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.9810 - val_loss: 25.0155\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.1678 - val_loss: 23.3395\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.9903 - val_loss: 24.2463\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.5939 - val_loss: 25.8660\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.9199 - val_loss: 23.5268\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.1253 - val_loss: 27.3410\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.4610 - val_loss: 23.3525\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.8883 - val_loss: 25.0354\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.8353 - val_loss: 25.8239\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.0336 - val_loss: 26.2161\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.7214 - val_loss: 23.4695\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.5143 - val_loss: 24.0322\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.3795 - val_loss: 25.2249\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.2101 - val_loss: 23.0643\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.6895 - val_loss: 24.3623\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.4689 - val_loss: 25.8912\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.4279 - val_loss: 25.6793\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.0479 - val_loss: 23.9788\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 20.1790 - val_loss: 26.3132\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.8950 - val_loss: 24.1162\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.8308 - val_loss: 24.1370\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.1811 - val_loss: 25.5457\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.1439 - val_loss: 24.9279\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.6068 - val_loss: 23.3803\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.8233 - val_loss: 25.3006\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.8886 - val_loss: 27.2577\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.8741 - val_loss: 23.8679\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.6638 - val_loss: 23.9834\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.6820 - val_loss: 23.0622\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2315 - val_loss: 24.4380\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.9738 - val_loss: 24.9523\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.9789 - val_loss: 24.3709\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.4038 - val_loss: 23.4428\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.8572 - val_loss: 24.2272\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.9179 - val_loss: 24.0515\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.9599 - val_loss: 24.7317\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.3117 - val_loss: 23.4952\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.3760 - val_loss: 23.6412\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.2428 - val_loss: 25.5657\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.1090 - val_loss: 24.9479\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.2742 - val_loss: 23.6045\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.2167 - val_loss: 25.6844\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.3071 - val_loss: 24.3206\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.6170 - val_loss: 23.9917\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.2484 - val_loss: 24.7423\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.2441 - val_loss: 24.0408\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2243 - val_loss: 23.2491\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.9603 - val_loss: 24.1188\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 19.3053 - val_loss: 22.5846\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9509 - val_loss: 22.7097\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.7728 - val_loss: 24.4975\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.0409 - val_loss: 27.1156\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.5533 - val_loss: 27.8107\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.5124 - val_loss: 24.0680\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.4845 - val_loss: 24.8482\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.6051 - val_loss: 24.1765\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0047 - val_loss: 23.8995\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1502 - val_loss: 23.2452\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.4244 - val_loss: 25.0289\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1281 - val_loss: 23.4410\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.7337 - val_loss: 24.3833\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.9099 - val_loss: 24.4908\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.4796 - val_loss: 24.3701\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.6122 - val_loss: 22.9358\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.6909 - val_loss: 22.2234\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6021 - val_loss: 22.3505\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 19.2544 - val_loss: 24.2873\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.2414 - val_loss: 25.1061\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.2354 - val_loss: 24.1276\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.9119 - val_loss: 23.7082\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2670 - val_loss: 24.5167\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6618 - val_loss: 24.1673\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.4497 - val_loss: 26.7233\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0661 - val_loss: 22.8857\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.0072 - val_loss: 22.9598\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.1860 - val_loss: 22.8989\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 19.4873 - val_loss: 22.6832\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 21.3023 - val_loss: 23.4423\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 18.5713 - val_loss: 22.6519\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.6664 - val_loss: 23.7697\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 19.9025 - val_loss: 25.0586\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 20.2305 - val_loss: 26.0622\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 19.6799 - val_loss: 23.4186\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 18.7887 - val_loss: 23.0132\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 18.7259 - val_loss: 23.0824\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 19.9005 - val_loss: 23.5172\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 19.5343 - val_loss: 22.2299\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 19.3087 - val_loss: 25.1807\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 19.7032 - val_loss: 23.3109\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 19.1155 - val_loss: 22.8322\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 18.9267 - val_loss: 24.2332\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.1839 - val_loss: 24.5501\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 20.6186 - val_loss: 23.6318\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.7192 - val_loss: 23.0012\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.4868 - val_loss: 24.5887\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.1770 - val_loss: 23.6615\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.4828 - val_loss: 22.8323\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 19.4411 - val_loss: 23.3986\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 18.8857 - val_loss: 24.9476\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.1332 - val_loss: 23.1987\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8443 - val_loss: 24.3125\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.6946 - val_loss: 24.9942\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.0213 - val_loss: 25.3428\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.6694 - val_loss: 22.1682\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.7134 - val_loss: 22.8720\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0805 - val_loss: 23.0664\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7328 - val_loss: 22.6352\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0853 - val_loss: 23.9983\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1197 - val_loss: 23.1979\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9947 - val_loss: 23.4169\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2223 - val_loss: 22.0117\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.0228 - val_loss: 22.5135\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.3016 - val_loss: 22.2547\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4007 - val_loss: 24.6968\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.0920 - val_loss: 23.2550\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 19.3829 - val_loss: 24.0341\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 19.9739 - val_loss: 23.1956\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 19.0521 - val_loss: 22.2500\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 19.1792 - val_loss: 23.8279\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.7826 - val_loss: 22.2801\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 18.6464 - val_loss: 22.1205\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.6837 - val_loss: 22.7348\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.2801 - val_loss: 25.2925\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 19.7285 - val_loss: 22.9582\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.4376 - val_loss: 23.3248\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.8299 - val_loss: 22.6941\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.6812 - val_loss: 23.1310\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.0111 - val_loss: 23.9741\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1802 - val_loss: 23.7588\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.8305 - val_loss: 23.3483\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9440 - val_loss: 22.7558\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.6773 - val_loss: 22.2737\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.2800 - val_loss: 22.7165\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3877 - val_loss: 24.4521\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6096 - val_loss: 22.3839\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0075 - val_loss: 22.4586\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7454 - val_loss: 25.1945\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.6789 - val_loss: 23.2525\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.5945 - val_loss: 23.3572\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.6401 - val_loss: 22.7990\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.6299 - val_loss: 24.0048\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1558 - val_loss: 23.7099\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.1076 - val_loss: 23.7314\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7839 - val_loss: 24.4694\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.2882 - val_loss: 23.3330\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4200 - val_loss: 23.7270\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.4800 - val_loss: 24.4250\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.5718 - val_loss: 22.8012\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 18.3720 - val_loss: 23.5991\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 19.2926 - val_loss: 22.7052\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.2976 - val_loss: 22.9627\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7858 - val_loss: 23.1022\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.5070 - val_loss: 23.2870\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.3667 - val_loss: 23.2794\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.9243 - val_loss: 22.9889\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.2004 - val_loss: 26.6571\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5054 - val_loss: 22.3671\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4711 - val_loss: 22.4767\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5753 - val_loss: 22.3352\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.0068 - val_loss: 22.1410\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.6819 - val_loss: 22.5818\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5747 - val_loss: 23.5369\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0381 - val_loss: 23.1948\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8159 - val_loss: 23.6258\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.7591 - val_loss: 23.4965\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2720 - val_loss: 23.1188\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.1445 - val_loss: 23.0830\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1607 - val_loss: 23.6646\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.5104 - val_loss: 22.2511\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6733 - val_loss: 23.1710\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.4575 - val_loss: 23.3353\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.8262 - val_loss: 26.0080\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4498 - val_loss: 23.0694\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7052 - val_loss: 22.2053\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.9479 - val_loss: 21.9618\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.1194 - val_loss: 22.8175\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.2012 - val_loss: 22.7204\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6897 - val_loss: 22.6919\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.6281 - val_loss: 22.8510\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.6103 - val_loss: 22.8071\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7818 - val_loss: 22.4605\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.4822 - val_loss: 23.4907\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.4765 - val_loss: 25.3595\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.3201 - val_loss: 24.1090\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.6820 - val_loss: 22.9549\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4601 - val_loss: 23.8042\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.9231 - val_loss: 23.0824\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8195 - val_loss: 22.8895\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.0306 - val_loss: 21.9034\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.8482 - val_loss: 25.0525\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1314 - val_loss: 23.5910\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6275 - val_loss: 24.5688\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.6490 - val_loss: 23.0834\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7674 - val_loss: 23.0817\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.3450 - val_loss: 25.7993\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.5294 - val_loss: 23.2461\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9976 - val_loss: 21.8092\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4111 - val_loss: 23.4137\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7266 - val_loss: 24.0776\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.5920 - val_loss: 22.5765\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.8378 - val_loss: 24.0016\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5676 - val_loss: 22.1731\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.2940 - val_loss: 24.7858\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.3352 - val_loss: 24.9586\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.7446 - val_loss: 23.2253\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0499 - val_loss: 24.4701\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.1192 - val_loss: 25.2735\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0808 - val_loss: 23.5794\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6892 - val_loss: 23.3148\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5587 - val_loss: 22.9552\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0846 - val_loss: 22.5279\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1747 - val_loss: 22.6020\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7124 - val_loss: 25.3492\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.4240 - val_loss: 23.2188\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8149 - val_loss: 22.3886\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.7285 - val_loss: 22.6422\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4504 - val_loss: 22.7592\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5117 - val_loss: 22.3282\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5042 - val_loss: 22.3481\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2094 - val_loss: 23.2487\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6443 - val_loss: 25.1208\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5931 - val_loss: 23.3349\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3819 - val_loss: 25.7255\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.4342 - val_loss: 23.5979\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.8881 - val_loss: 23.5269\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1967 - val_loss: 23.3945\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6935 - val_loss: 22.6248\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.3395 - val_loss: 23.5563\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.4007 - val_loss: 23.5475\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.1569 - val_loss: 22.4562\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2866 - val_loss: 22.7566\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9093 - val_loss: 24.4803\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.9162 - val_loss: 24.5386\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.6296 - val_loss: 23.4303\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3241 - val_loss: 24.0678\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7583 - val_loss: 23.3141\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.7539 - val_loss: 22.0180\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4491 - val_loss: 23.5916\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.6014 - val_loss: 22.4830\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.5673 - val_loss: 23.5385\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.8419 - val_loss: 22.2653\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.4746 - val_loss: 22.8084\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7724 - val_loss: 22.1939\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.5844 - val_loss: 24.1776\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2990 - val_loss: 22.8964\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5344 - val_loss: 24.2553\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3626 - val_loss: 22.2584\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0065 - val_loss: 29.5287\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3120 - val_loss: 22.3919\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4536 - val_loss: 23.3215\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2650 - val_loss: 24.1564\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8189 - val_loss: 22.8351\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6210 - val_loss: 22.7153\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.3055 - val_loss: 24.4276\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.4915 - val_loss: 24.2014\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.0893 - val_loss: 23.5186\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3394 - val_loss: 22.6732\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2366 - val_loss: 22.7688\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7148 - val_loss: 23.8337\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.3837 - val_loss: 22.4045\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.2358 - val_loss: 23.7063\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7088 - val_loss: 23.5850\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7201 - val_loss: 24.7905\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5436 - val_loss: 23.1424\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1046 - val_loss: 23.4931\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3692 - val_loss: 23.3516\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7777 - val_loss: 23.6258\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.1896 - val_loss: 23.3996\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2420 - val_loss: 22.6911\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.8523 - val_loss: 23.0054\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.1164 - val_loss: 24.9039\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4247 - val_loss: 23.1519\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3015 - val_loss: 25.1713\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7993 - val_loss: 23.5248\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.6448 - val_loss: 23.3151\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.2203 - val_loss: 24.0781\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7353 - val_loss: 22.9196\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7439 - val_loss: 22.4965\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0813 - val_loss: 23.5247\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.6777 - val_loss: 23.2421\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.0657 - val_loss: 22.9561\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 19.4049 - val_loss: 24.3640\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 18.8769 - val_loss: 23.1954\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 18.4340 - val_loss: 23.3709\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 19.0894 - val_loss: 23.9924\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9829 - val_loss: 23.1424\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.2386 - val_loss: 22.8155\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.4922 - val_loss: 22.9835\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.2049 - val_loss: 26.0224\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0965 - val_loss: 22.6684\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.8682 - val_loss: 25.6959\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.2858 - val_loss: 23.5879\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6010 - val_loss: 22.7864\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9043 - val_loss: 22.5524\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6751 - val_loss: 23.6756\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.3370 - val_loss: 25.2058\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6059 - val_loss: 23.0962\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0200 - val_loss: 22.5606\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8955 - val_loss: 22.5356\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2920 - val_loss: 22.7382\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7052 - val_loss: 22.5020\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1395 - val_loss: 23.3578\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6623 - val_loss: 24.0845\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3959 - val_loss: 23.6848\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.7717 - val_loss: 23.0783\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5201 - val_loss: 24.6681\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.2803 - val_loss: 26.8755\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.5233 - val_loss: 23.1502\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7229 - val_loss: 25.2868\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.0090 - val_loss: 22.1997\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6165 - val_loss: 23.9981\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0784 - val_loss: 22.8753\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0102 - val_loss: 23.4528\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4061 - val_loss: 23.7522\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.0015 - val_loss: 22.3098\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.6542 - val_loss: 24.6933\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7361 - val_loss: 22.5967\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.8984 - val_loss: 22.5142\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7630 - val_loss: 25.5645\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.6839 - val_loss: 23.1159\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4691 - val_loss: 24.4682\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1859 - val_loss: 24.5610\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3117 - val_loss: 23.4174\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5129 - val_loss: 23.1603\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3419 - val_loss: 25.0752\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4598 - val_loss: 24.4785\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8253 - val_loss: 24.9635\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.9603 - val_loss: 23.9361\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.8684 - val_loss: 25.2673\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.3724 - val_loss: 22.3381\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6320 - val_loss: 23.5824\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5722 - val_loss: 24.7703\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1861 - val_loss: 22.6967\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2966 - val_loss: 24.5370\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.5642 - val_loss: 22.7230\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2832 - val_loss: 23.2483\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1816 - val_loss: 22.7707\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3359 - val_loss: 25.2132\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3226 - val_loss: 22.3278\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6953 - val_loss: 22.5493\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5807 - val_loss: 22.8152\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3120 - val_loss: 22.4470\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3857 - val_loss: 22.9455\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0354 - val_loss: 24.0096\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.8469 - val_loss: 22.3555\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8835 - val_loss: 22.7868\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3465 - val_loss: 23.0318\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9882 - val_loss: 23.3623\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4049 - val_loss: 23.8161\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7832 - val_loss: 23.7693\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9272 - val_loss: 24.7947\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.2034 - val_loss: 23.2185\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7072 - val_loss: 22.0550\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8620 - val_loss: 22.4930\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9687 - val_loss: 22.3988\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8455 - val_loss: 22.3973\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7717 - val_loss: 23.5359\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4343 - val_loss: 23.1447\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2083 - val_loss: 23.8416\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1633 - val_loss: 22.8212\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4340 - val_loss: 22.0439\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0104 - val_loss: 23.1839\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.3578 - val_loss: 24.1667\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5614 - val_loss: 26.4190\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3224 - val_loss: 23.1333\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.3209 - val_loss: 23.3214\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4357 - val_loss: 23.2779\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3010 - val_loss: 22.6788\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9741 - val_loss: 24.2419\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1946 - val_loss: 23.7168\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2154 - val_loss: 22.5225\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.9098 - val_loss: 22.5847\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2649 - val_loss: 23.5448\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2287 - val_loss: 23.6745\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2822 - val_loss: 23.5851\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2632 - val_loss: 23.1835\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4008 - val_loss: 23.3604\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.8993 - val_loss: 24.6179\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.6532 - val_loss: 24.8558\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7775 - val_loss: 24.3094\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9095 - val_loss: 23.3041\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4195 - val_loss: 23.4001\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9803 - val_loss: 22.4609\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.0507 - val_loss: 23.9449\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2254 - val_loss: 22.9096\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3787 - val_loss: 23.9711\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4970 - val_loss: 25.9712\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.6096 - val_loss: 22.7091\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1942 - val_loss: 24.9633\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.1427 - val_loss: 24.9585\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.8579 - val_loss: 23.1106\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3871 - val_loss: 23.4340\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 19.0113 - val_loss: 23.8039\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3158 - val_loss: 24.7577\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8910 - val_loss: 23.7597\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0769 - val_loss: 22.6962\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1824 - val_loss: 24.7344\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.4162 - val_loss: 23.4471\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.9664 - val_loss: 22.4323\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6846 - val_loss: 23.5168\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3787 - val_loss: 22.6039\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1525 - val_loss: 23.1537\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2966 - val_loss: 23.9136\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3401 - val_loss: 24.4979\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2418 - val_loss: 23.2828\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1070 - val_loss: 24.2589\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3340 - val_loss: 24.0116\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.8539 - val_loss: 23.9447\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.3149 - val_loss: 23.0115\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0369 - val_loss: 22.4487\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5588 - val_loss: 23.8995\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5382 - val_loss: 23.4172\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6631 - val_loss: 23.1758\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7009 - val_loss: 23.5703\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8379 - val_loss: 22.2369\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0412 - val_loss: 23.7533\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1356 - val_loss: 21.9835\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1638 - val_loss: 24.6486\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.3735 - val_loss: 23.1317\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1372 - val_loss: 22.2782\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6056 - val_loss: 24.0476\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0282 - val_loss: 22.9394\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7962 - val_loss: 22.5018\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1984 - val_loss: 23.3830\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2062 - val_loss: 25.4467\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3813 - val_loss: 23.4248\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.6148 - val_loss: 23.8597\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6857 - val_loss: 23.1565\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1110 - val_loss: 22.3822\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0729 - val_loss: 23.1527\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4968 - val_loss: 23.0590\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4304 - val_loss: 24.0266\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1804 - val_loss: 23.3485\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0682 - val_loss: 23.1155\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0244 - val_loss: 22.9775\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2517 - val_loss: 24.1912\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3256 - val_loss: 22.9515\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2718 - val_loss: 23.3072\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4293 - val_loss: 22.6136\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.7877 - val_loss: 22.6965\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2040 - val_loss: 23.4412\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7628 - val_loss: 25.6792\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.2197 - val_loss: 22.6011\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.6974 - val_loss: 24.1833\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 17.8278 - val_loss: 23.2717\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 18.3454 - val_loss: 22.3307\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8128 - val_loss: 22.1117\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9337 - val_loss: 24.6142\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.0192 - val_loss: 22.8367\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.0058 - val_loss: 24.2536\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.7218 - val_loss: 22.4462\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.0454 - val_loss: 24.1052\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1080 - val_loss: 23.7780\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5689 - val_loss: 22.4469\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8868 - val_loss: 22.7406\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2064 - val_loss: 23.5958\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9474 - val_loss: 22.8278\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1832 - val_loss: 23.5008\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2060 - val_loss: 23.8240\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8727 - val_loss: 22.8161\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.2938 - val_loss: 24.1548\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9963 - val_loss: 22.7798\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.1251 - val_loss: 22.9112\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5498 - val_loss: 22.7831\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5962 - val_loss: 22.4357\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7537 - val_loss: 23.3019\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8130 - val_loss: 22.2588\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7143 - val_loss: 23.7009\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4405 - val_loss: 24.1852\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7164 - val_loss: 22.7286\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8804 - val_loss: 23.9375\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4939 - val_loss: 24.9331\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.9786 - val_loss: 22.7435\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0180 - val_loss: 22.6776\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5628 - val_loss: 22.7429\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6488 - val_loss: 22.8345\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6224 - val_loss: 22.6266\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4342 - val_loss: 22.4939\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2104 - val_loss: 22.8172\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7991 - val_loss: 22.2857\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7219 - val_loss: 22.8793\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6933 - val_loss: 22.8423\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7163 - val_loss: 23.1764\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4721 - val_loss: 21.9558\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1312 - val_loss: 25.1093\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6171 - val_loss: 22.3034\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3372 - val_loss: 22.6119\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2720 - val_loss: 21.9340\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 17.7685 - val_loss: 23.0004\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4181 - val_loss: 23.0241\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4231 - val_loss: 22.7988\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3341 - val_loss: 23.0009\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3947 - val_loss: 22.5787\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7987 - val_loss: 22.3913\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3084 - val_loss: 22.7441\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5079 - val_loss: 23.6291\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9527 - val_loss: 22.7982\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8733 - val_loss: 22.7376\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7415 - val_loss: 24.9402\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.5623 - val_loss: 23.6279\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1234 - val_loss: 23.1811\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1986 - val_loss: 25.1512\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5167 - val_loss: 22.9325\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3815 - val_loss: 22.6483\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5713 - val_loss: 22.9889\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6454 - val_loss: 24.9223\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2219 - val_loss: 24.7784\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8668 - val_loss: 22.3872\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9950 - val_loss: 24.7794\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2344 - val_loss: 27.9281\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7437 - val_loss: 23.8333\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0705 - val_loss: 26.2962\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0592 - val_loss: 22.7428\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6497 - val_loss: 24.7276\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0168 - val_loss: 22.7667\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2389 - val_loss: 24.4774\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.7317 - val_loss: 24.3521\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4523 - val_loss: 22.9420\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7023 - val_loss: 23.0222\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4061 - val_loss: 23.5182\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1620 - val_loss: 23.1412\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2123 - val_loss: 23.6338\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3454 - val_loss: 22.2501\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2889 - val_loss: 22.4067\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6472 - val_loss: 21.9473\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7828 - val_loss: 25.8836\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9290 - val_loss: 22.5278\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2725 - val_loss: 22.9508\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6864 - val_loss: 22.9807\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9557 - val_loss: 23.7417\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9184 - val_loss: 23.4881\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3053 - val_loss: 22.6935\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.4765 - val_loss: 23.5830\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8183 - val_loss: 22.9062\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8693 - val_loss: 23.9129\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0534 - val_loss: 22.3880\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4626 - val_loss: 22.8502\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7294 - val_loss: 22.3298\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1992 - val_loss: 23.7893\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8526 - val_loss: 22.7868\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0349 - val_loss: 22.7548\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6703 - val_loss: 23.3029\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7938 - val_loss: 22.3197\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0196 - val_loss: 23.6383\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9271 - val_loss: 23.1242\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7129 - val_loss: 21.9762\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3062 - val_loss: 24.1012\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2014 - val_loss: 23.2400\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5929 - val_loss: 23.3969\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1578 - val_loss: 22.9369\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2795 - val_loss: 22.7991\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4261 - val_loss: 22.5741\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4869 - val_loss: 23.9236\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7676 - val_loss: 23.6535\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6008 - val_loss: 23.2507\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5031 - val_loss: 22.8047\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3425 - val_loss: 22.9178\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7599 - val_loss: 23.7080\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8991 - val_loss: 22.2037\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.5337 - val_loss: 22.5911\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.3853 - val_loss: 23.9697\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4723 - val_loss: 22.3733\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3908 - val_loss: 22.0229\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2586 - val_loss: 22.7190\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7996 - val_loss: 23.7539\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6067 - val_loss: 22.2089\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8756 - val_loss: 23.1378\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4172 - val_loss: 23.0251\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2823 - val_loss: 23.7127\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3236 - val_loss: 23.0406\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3015 - val_loss: 23.1944\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9726 - val_loss: 23.7872\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2410 - val_loss: 22.2669\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.1017 - val_loss: 24.5376\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6084 - val_loss: 23.0219\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5823 - val_loss: 24.7273\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7220 - val_loss: 23.8913\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6840 - val_loss: 23.3449\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7990 - val_loss: 23.8145\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3192 - val_loss: 23.7477\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3170 - val_loss: 23.3010\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9674 - val_loss: 23.0649\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2987 - val_loss: 22.9837\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.4966 - val_loss: 22.7963\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.8148 - val_loss: 23.7877\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5521 - val_loss: 22.2047\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2835 - val_loss: 23.5032\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3596 - val_loss: 22.6776\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4176 - val_loss: 22.3638\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9837 - val_loss: 25.2975\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8584 - val_loss: 22.4343\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2752 - val_loss: 23.0307\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.4775 - val_loss: 21.9406\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5918 - val_loss: 22.8757\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.2864 - val_loss: 22.9999\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8742 - val_loss: 22.0593\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4746 - val_loss: 22.7156\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6649 - val_loss: 22.8127\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7511 - val_loss: 23.3409\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0440 - val_loss: 23.9086\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0574 - val_loss: 23.0652\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0623 - val_loss: 23.1446\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5466 - val_loss: 23.7561\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4009 - val_loss: 22.6668\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5989 - val_loss: 22.7594\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8564 - val_loss: 22.8244\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4663 - val_loss: 23.0998\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5036 - val_loss: 22.2246\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5329 - val_loss: 23.0063\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6623 - val_loss: 23.6084\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 17.2358 - val_loss: 23.1336\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.1428 - val_loss: 24.0004\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2366 - val_loss: 22.8176\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.9214 - val_loss: 23.6445\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 17.7237 - val_loss: 22.4670\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4667 - val_loss: 23.2845\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.7599 - val_loss: 22.4667\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0344 - val_loss: 22.1016\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 17.6290 - val_loss: 22.9794\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6224 - val_loss: 23.8957\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5273 - val_loss: 22.1851\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1535 - val_loss: 23.5112\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3766 - val_loss: 22.6188\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0330 - val_loss: 22.6707\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7197 - val_loss: 22.2758\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1025 - val_loss: 26.0553\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6631 - val_loss: 21.8936\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1281 - val_loss: 22.1811\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9215 - val_loss: 22.6084\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7142 - val_loss: 22.1435\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4179 - val_loss: 22.3134\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.8514 - val_loss: 22.5880\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6808 - val_loss: 25.0130\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6012 - val_loss: 22.3332\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0127 - val_loss: 23.3143\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8811 - val_loss: 24.8480\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7817 - val_loss: 24.6258\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1480 - val_loss: 23.5726\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0048 - val_loss: 24.5123\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1854 - val_loss: 22.5178\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8299 - val_loss: 23.5107\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.8215 - val_loss: 23.4184\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6245 - val_loss: 22.6495\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2398 - val_loss: 22.6719\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2424 - val_loss: 22.7430\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8232 - val_loss: 24.3394\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3253 - val_loss: 22.4964\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0714 - val_loss: 22.2390\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1293 - val_loss: 23.0990\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4716 - val_loss: 23.2169\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4513 - val_loss: 22.9637\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8666 - val_loss: 23.8516\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2903 - val_loss: 22.8744\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4872 - val_loss: 23.0342\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1043 - val_loss: 25.0215\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2830 - val_loss: 22.4542\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6988 - val_loss: 21.9852\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4191 - val_loss: 24.5576\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4125 - val_loss: 22.3256\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4081 - val_loss: 23.6193\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4613 - val_loss: 23.2815\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.9796 - val_loss: 22.5404\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9601 - val_loss: 22.3884\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1824 - val_loss: 22.2844\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.0655 - val_loss: 22.9789\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8244 - val_loss: 22.1522\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6606 - val_loss: 23.5723\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7216 - val_loss: 23.9562\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8953 - val_loss: 24.0160\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9031 - val_loss: 22.2133\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2102 - val_loss: 22.4609\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1486 - val_loss: 22.2538\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.0888 - val_loss: 22.9249\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2804 - val_loss: 22.4529\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5467 - val_loss: 22.4150\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5144 - val_loss: 23.9623\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3590 - val_loss: 23.0182\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0621 - val_loss: 23.1581\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.9793 - val_loss: 22.6913\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2406 - val_loss: 22.1515\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3649 - val_loss: 24.5547\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5079 - val_loss: 22.5205\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.8184 - val_loss: 23.3173\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1142 - val_loss: 22.3885\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7871 - val_loss: 23.2932\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1964 - val_loss: 22.0754\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.9243 - val_loss: 22.7255\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5109 - val_loss: 23.2812\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.5133 - val_loss: 24.1967\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1670 - val_loss: 22.7315\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.7935 - val_loss: 21.9388\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.0366 - val_loss: 23.3909\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7657 - val_loss: 22.9948\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1846 - val_loss: 23.4944\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2824 - val_loss: 22.7096\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 16.9567 - val_loss: 22.5978\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8560 - val_loss: 22.6407\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2644 - val_loss: 23.4440\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3157 - val_loss: 22.8109\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0547 - val_loss: 22.3228\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6830 - val_loss: 23.0567\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6999 - val_loss: 23.4628\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0725 - val_loss: 22.7349\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4475 - val_loss: 22.6786\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6148 - val_loss: 24.3712\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5308 - val_loss: 22.5579\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0050 - val_loss: 22.7114\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.8972 - val_loss: 22.3023\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.3006 - val_loss: 23.0676\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4909 - val_loss: 23.2839\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1421 - val_loss: 23.5228\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3117 - val_loss: 22.3036\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9810 - val_loss: 23.9197\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6888 - val_loss: 22.2884\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2314 - val_loss: 23.3550\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6184 - val_loss: 23.4083\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0777 - val_loss: 22.1379\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8201 - val_loss: 23.0318\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8144 - val_loss: 22.0848\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1716 - val_loss: 22.8371\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9026 - val_loss: 23.3390\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3326 - val_loss: 23.5352\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2001 - val_loss: 22.5868\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4522 - val_loss: 22.4500\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2242 - val_loss: 25.6483\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.4398 - val_loss: 23.5136\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1077 - val_loss: 22.8033\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1722 - val_loss: 22.5238\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9914 - val_loss: 22.5801\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1088 - val_loss: 22.0570\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.2238 - val_loss: 23.4845\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3146 - val_loss: 24.1651\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6126 - val_loss: 22.9095\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5173 - val_loss: 22.7596\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8946 - val_loss: 22.6366\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2893 - val_loss: 22.4591\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7368 - val_loss: 22.1853\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0518 - val_loss: 22.9037\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6819 - val_loss: 23.1136\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2315 - val_loss: 23.5623\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9024 - val_loss: 23.6018\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6645 - val_loss: 22.3358\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2610 - val_loss: 23.5710\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.4789 - val_loss: 23.9008\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5561 - val_loss: 23.1465\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5719 - val_loss: 22.4956\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1998 - val_loss: 24.7906\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4260 - val_loss: 22.7251\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0039 - val_loss: 23.6039\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.8569 - val_loss: 22.2766\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0768 - val_loss: 22.5975\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1887 - val_loss: 22.3619\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7253 - val_loss: 24.0694\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3767 - val_loss: 22.5843\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2412 - val_loss: 22.4346\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5505 - val_loss: 22.9867\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3177 - val_loss: 22.9517\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0063 - val_loss: 22.2260\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6974 - val_loss: 22.3895\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8263 - val_loss: 23.1325\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4398 - val_loss: 21.9954\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3609 - val_loss: 23.0210\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3951 - val_loss: 23.0956\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6070 - val_loss: 25.5148\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4702 - val_loss: 22.0709\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9255 - val_loss: 22.4613\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1653 - val_loss: 22.7528\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.9542 - val_loss: 22.6943\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3424 - val_loss: 23.7701\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1189 - val_loss: 23.1069\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2754 - val_loss: 22.2257\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8123 - val_loss: 22.8856\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.6204 - val_loss: 23.0375\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1335 - val_loss: 22.0083\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0136 - val_loss: 22.9151\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.0891 - val_loss: 23.7461\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.0851 - val_loss: 21.9005\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.1956 - val_loss: 22.1834\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 17.2852 - val_loss: 22.7772\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5043 - val_loss: 22.2886\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.1768 - val_loss: 21.9641\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5619 - val_loss: 23.1674\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.1832 - val_loss: 23.0219\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.0220 - val_loss: 22.3370\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.2631 - val_loss: 21.9167\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.9025 - val_loss: 21.8231\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0580 - val_loss: 22.5883\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9055 - val_loss: 23.2119\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9060 - val_loss: 23.3283\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6466 - val_loss: 22.6567\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6349 - val_loss: 22.2965\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0875 - val_loss: 22.7210\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5703 - val_loss: 23.7153\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0206 - val_loss: 22.8930\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4505 - val_loss: 22.6968\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4011 - val_loss: 24.3332\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1240 - val_loss: 23.7359\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6762 - val_loss: 22.5995\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0207 - val_loss: 22.1148\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7827 - val_loss: 22.4560\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0539 - val_loss: 22.6955\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2020 - val_loss: 22.9152\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.7848 - val_loss: 22.1837\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4981 - val_loss: 23.2030\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7360 - val_loss: 23.0579\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0506 - val_loss: 22.8454\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5026 - val_loss: 22.7877\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.8550 - val_loss: 24.8776\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3433 - val_loss: 21.9061\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7594 - val_loss: 22.6500\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9492 - val_loss: 22.9721\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.3068 - val_loss: 23.2587\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9432 - val_loss: 22.2293\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3181 - val_loss: 22.9730\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.0592 - val_loss: 23.4921\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7371 - val_loss: 22.6538\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2525 - val_loss: 23.1526\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4625 - val_loss: 24.7466\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3100 - val_loss: 22.4915\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1796 - val_loss: 22.3371\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2460 - val_loss: 22.8676\n",
      "16.19954027327816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.837782  , -0.5893652 ,  0.44344148, -0.37679902,  0.29762483],\n",
       "        [-0.02188136,  0.85622156,  0.26500577, -0.8885995 , -0.98142815],\n",
       "        [ 2.4306722 , -0.8199033 ,  0.86364365, -0.74336743, -0.44113207],\n",
       "        [ 0.05766043,  0.58668154, -0.99283904, -1.4635586 ,  1.4678351 ],\n",
       "        [ 0.04846913,  0.06993047, -0.71572864,  0.24526842, -0.06539471]],\n",
       "       dtype=float32),\n",
       " array([1.5074065, 3.8480053, 3.0673833, 2.809164 , 2.859303 ],\n",
       "       dtype=float32),\n",
       " array([[-0.4362043 , -1.0618963 , -1.5817282 , -0.57516956,  0.5314147 ,\n",
       "          1.1288497 , -0.59765995, -0.9144926 ,  1.1658046 , -0.52084994],\n",
       "        [-0.23517165, -0.82399905, -1.0328338 , -0.410401  ,  1.2093011 ,\n",
       "          1.9458966 , -0.77957994, -0.56000936,  2.1545522 ,  1.1526929 ],\n",
       "        [-0.2604112 , -0.47729313,  1.287791  , -1.0578175 ,  0.1511706 ,\n",
       "          1.3583767 , -1.0426543 , -0.8223603 ,  0.8810432 ,  0.04247031],\n",
       "        [-0.56300616, -0.23698232, -0.29415813,  0.06415842,  0.9292746 ,\n",
       "          1.5771033 ,  0.03497441, -0.17720354,  0.93345207, -0.23161331],\n",
       "        [-0.13261604, -0.6731214 ,  0.79183704, -0.26563624,  1.0245142 ,\n",
       "          1.4054421 ,  0.00607101, -0.8400859 ,  0.9976525 , -0.09878318]],\n",
       "       dtype=float32),\n",
       " array([-0.77361387, -0.6469729 ,  4.266154  , -0.5085775 ,  3.9908376 ,\n",
       "         4.42617   , -0.49525073, -0.41131952,  4.407973  ,  3.696272  ],\n",
       "       dtype=float32),\n",
       " array([[ 0.14408605],\n",
       "        [ 0.32284224],\n",
       "        [ 1.4531381 ],\n",
       "        [-0.06908879],\n",
       "        [ 1.2934827 ],\n",
       "        [ 1.8743552 ],\n",
       "        [ 0.2917574 ],\n",
       "        [-0.30376917],\n",
       "        [ 1.7903279 ],\n",
       "        [ 0.662883  ]], dtype=float32),\n",
       " array([4.2154436], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_relu(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_relu_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 215us/step - loss: 13736.6454 - val_loss: 11735.7768\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10075.9823 - val_loss: 8749.5808\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7757.5607 - val_loss: 6941.3698\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6245.9094 - val_loss: 5675.5593\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5145.3696 - val_loss: 4715.7805\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4294.1447 - val_loss: 3959.8240\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 3614.9345 - val_loss: 3347.1749\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 3060.6519 - val_loss: 2842.8777\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 2601.8971 - val_loss: 2422.7881\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 2218.3813 - val_loss: 2069.7375\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 1894.8249 - val_loss: 1772.1938\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 1621.5768 - val_loss: 1517.8054\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 1388.5355 - val_loss: 1301.7718\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 1190.1388 - val_loss: 1116.8133\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 1020.1857 - val_loss: 959.3616\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 875.2484 - val_loss: 823.6100\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 750.9501 - val_loss: 707.2734\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 644.3534 - val_loss: 608.0500\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 553.5168 - val_loss: 522.3101\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 475.4082 - val_loss: 449.4193\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 408.6461 - val_loss: 387.3912\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 352.0629 - val_loss: 333.4831\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 303.3389 - val_loss: 288.2017\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 262.1079 - val_loss: 249.4871\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 227.0953 - val_loss: 216.3464\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 197.2663 - val_loss: 188.5616\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 172.2180 - val_loss: 164.6380\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 150.9345 - val_loss: 144.6062\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 133.1015 - val_loss: 127.6075\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 118.0826 - val_loss: 113.4403\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 105.5994 - val_loss: 101.3828\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 95.0611 - val_loss: 91.5202\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 86.3880 - val_loss: 83.1408\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 79.1638 - val_loss: 76.1601\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 73.1608 - val_loss: 70.4482\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 68.2849 - val_loss: 65.5714\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 64.2161 - val_loss: 61.6317\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 60.8957 - val_loss: 58.4044\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 58.1989 - val_loss: 55.7511\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 56.0254 - val_loss: 53.5132\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 54.2311 - val_loss: 51.7231\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 52.7991 - val_loss: 50.2670\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 51.6516 - val_loss: 49.0548\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 50.7331 - val_loss: 48.0687\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 49.9884 - val_loss: 47.3003\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 49.4196 - val_loss: 46.6342\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 48.9613 - val_loss: 46.0883\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 48.5803 - val_loss: 45.7237\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 48.3115 - val_loss: 45.3609\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 48.0775 - val_loss: 45.1045\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.9055 - val_loss: 44.8884\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.7733 - val_loss: 44.6869\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.6762 - val_loss: 44.5187\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.5871 - val_loss: 44.4266\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.5324 - val_loss: 44.3231\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.4816 - val_loss: 44.2564\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 47.4441 - val_loss: 44.1879\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.4260 - val_loss: 44.1259\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3867 - val_loss: 44.0908\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3647 - val_loss: 44.0277\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3236 - val_loss: 43.9841\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.2603 - val_loss: 43.8706\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.0139 - val_loss: 43.5015\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 44.0083 - val_loss: 43.0222\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 40.0577 - val_loss: 36.7789\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 36.0329 - val_loss: 34.8714\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 29.5630 - val_loss: 28.3904\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.9281 - val_loss: 26.4108\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.8885 - val_loss: 25.2936\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5330 - val_loss: 24.4490\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.4463 - val_loss: 23.3754\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.5179 - val_loss: 22.7201\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0314 - val_loss: 22.2764\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2419 - val_loss: 22.0600\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7785 - val_loss: 21.4801\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2747 - val_loss: 21.1485\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.9267 - val_loss: 20.6936\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.5882 - val_loss: 20.4781\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2414 - val_loss: 20.1109\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9877 - val_loss: 19.7680\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.8496 - val_loss: 19.5355\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6393 - val_loss: 19.3593\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4645 - val_loss: 19.4865\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.4418 - val_loss: 19.0183\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.2850 - val_loss: 18.8271\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3029 - val_loss: 18.7895\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.0644 - val_loss: 18.9616\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 15.0060 - val_loss: 18.8140\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.0177 - val_loss: 18.6688\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.9169 - val_loss: 18.7743\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.8787 - val_loss: 18.4983\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7917 - val_loss: 18.4239\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7432 - val_loss: 18.3766\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7351 - val_loss: 18.2794\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6601 - val_loss: 18.1857\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6119 - val_loss: 18.4234\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5879 - val_loss: 18.4847\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4645 - val_loss: 18.3276\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4037 - val_loss: 18.0590\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3647 - val_loss: 18.2171\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2912 - val_loss: 18.1224\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3060 - val_loss: 18.3742\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3003 - val_loss: 17.9578\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.3325 - val_loss: 18.0693\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2314 - val_loss: 18.4661\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2473 - val_loss: 18.0509\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1189 - val_loss: 18.1887\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2018 - val_loss: 18.0472\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.0244 - val_loss: 17.9389\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1437 - val_loss: 18.4675\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0538 - val_loss: 17.9936\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.9575 - val_loss: 18.1229\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 13.9761 - val_loss: 17.9513\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.9828 - val_loss: 17.9866\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.9603 - val_loss: 18.1009\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 13.9635 - val_loss: 18.5773\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 13.8780 - val_loss: 17.9564\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 13.8323 - val_loss: 18.2670\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 13.9110 - val_loss: 18.0327\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.9235 - val_loss: 18.0167\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8002 - val_loss: 18.0121\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7295 - val_loss: 17.9504\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8707 - val_loss: 18.0369\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8159 - val_loss: 18.1064\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9030 - val_loss: 18.1491\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.7550 - val_loss: 18.0599\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8402 - val_loss: 18.3850\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7350 - val_loss: 18.5462\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8599 - val_loss: 18.3432\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8360 - val_loss: 18.2392\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7243 - val_loss: 18.1666\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6495 - val_loss: 18.1394\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6969 - val_loss: 18.0045\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7301 - val_loss: 18.1022\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.5829 - val_loss: 18.0556\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5167 - val_loss: 18.1023\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.5731 - val_loss: 18.0847\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.3654 - val_loss: 18.0745\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.3887 - val_loss: 18.2031\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.2491 - val_loss: 18.0550\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.2092 - val_loss: 18.3544\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.2524 - val_loss: 18.1419\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1658 - val_loss: 18.0260\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.0860 - val_loss: 18.0323\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.0730 - val_loss: 18.5174\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.1443 - val_loss: 18.1567\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.9380 - val_loss: 18.1548\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.8959 - val_loss: 18.2955\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.9713 - val_loss: 18.1182\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.9843 - val_loss: 18.1182\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.9227 - val_loss: 18.0646\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.8413 - val_loss: 18.2003\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6905 - val_loss: 18.2726\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.7754 - val_loss: 18.2988\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7378 - val_loss: 18.1283\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7874 - val_loss: 18.1229\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8100 - val_loss: 18.0814\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.7855 - val_loss: 18.5217\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7279 - val_loss: 18.0174\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.6373 - val_loss: 18.1679\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.6412 - val_loss: 17.9744\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6549 - val_loss: 18.2012\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.6987 - val_loss: 18.1068\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.5683 - val_loss: 18.0515\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6005 - val_loss: 18.1949\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4705 - val_loss: 18.0547\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4762 - val_loss: 17.9513\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3556 - val_loss: 17.7646\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3763 - val_loss: 17.9484\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.3746 - val_loss: 18.1628\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4138 - val_loss: 17.6297\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1158 - val_loss: 17.5900\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2796 - val_loss: 17.3582\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2221 - val_loss: 17.5928\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1936 - val_loss: 17.5937\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0246 - val_loss: 17.2559\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9348 - val_loss: 17.2908\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9395 - val_loss: 17.1588\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9506 - val_loss: 17.0097\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8725 - val_loss: 17.0226\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7937 - val_loss: 17.5542\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.9104 - val_loss: 17.0843\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8262 - val_loss: 16.9175\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8758 - val_loss: 16.8405\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9993 - val_loss: 16.7619\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8584 - val_loss: 16.7625\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6916 - val_loss: 17.1160\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6712 - val_loss: 16.7892\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6612 - val_loss: 16.7595\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7000 - val_loss: 16.8592\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5707 - val_loss: 16.7946\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0328 - val_loss: 17.0828\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.7794 - val_loss: 16.6433\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6120 - val_loss: 16.5218\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6963 - val_loss: 16.9771\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6378 - val_loss: 16.4027\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4888 - val_loss: 16.4821\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4736 - val_loss: 16.2035\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5147 - val_loss: 16.4034\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.3687 - val_loss: 16.3959\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4758 - val_loss: 16.1025\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2747 - val_loss: 16.0137\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2037 - val_loss: 16.3607\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2362 - val_loss: 16.1875\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3659 - val_loss: 15.9814\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1188 - val_loss: 16.0542\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2269 - val_loss: 15.9513\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1248 - val_loss: 15.6858\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.1165 - val_loss: 15.7349\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9588 - val_loss: 15.4491\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.9512 - val_loss: 16.0463\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8712 - val_loss: 15.2408\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.9102 - val_loss: 15.6635\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9947 - val_loss: 15.0698\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.8696 - val_loss: 15.3645\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7670 - val_loss: 15.0895\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.8491 - val_loss: 15.0762\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.7203 - val_loss: 15.0167\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8392 - val_loss: 14.7567\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.5801 - val_loss: 14.6174\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6671 - val_loss: 14.9045\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6422 - val_loss: 14.7962\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.6634 - val_loss: 15.1205\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.5972 - val_loss: 14.4012\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.5539 - val_loss: 14.3630\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4837 - val_loss: 14.8604\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3968 - val_loss: 14.1775\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.3064 - val_loss: 14.1657\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5779 - val_loss: 14.0810\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.3244 - val_loss: 14.9484\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4221 - val_loss: 14.1858\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2071 - val_loss: 14.2004\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.2623 - val_loss: 14.0196\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1582 - val_loss: 13.6771\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.2361 - val_loss: 13.4921\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.0904 - val_loss: 13.2593\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9512 - val_loss: 12.8513\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8561 - val_loss: 12.8505\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0455 - val_loss: 12.6229\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8361 - val_loss: 12.7277\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8394 - val_loss: 12.4310\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8316 - val_loss: 12.6026\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7481 - val_loss: 12.1089\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7304 - val_loss: 12.1941\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6041 - val_loss: 11.8131\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6769 - val_loss: 12.5963\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5272 - val_loss: 11.7875\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4646 - val_loss: 11.6798\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4266 - val_loss: 11.5379\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6071 - val_loss: 11.7093\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5734 - val_loss: 11.4283\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2081 - val_loss: 12.9969\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.4759 - val_loss: 12.7519\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2880 - val_loss: 11.5389\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1493 - val_loss: 10.8444\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4094 - val_loss: 11.5107\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1488 - val_loss: 11.4305\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9804 - val_loss: 11.3725\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0842 - val_loss: 10.6690\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9834 - val_loss: 10.3420\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9476 - val_loss: 10.7381\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8129 - val_loss: 10.4749\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9652 - val_loss: 10.6939\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8222 - val_loss: 10.4774\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6211 - val_loss: 10.2205\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6307 - val_loss: 10.9094\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8477 - val_loss: 10.5056\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7287 - val_loss: 10.8383\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5920 - val_loss: 10.6405\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6052 - val_loss: 10.0895\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5422 - val_loss: 10.1754\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5384 - val_loss: 10.1973\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4738 - val_loss: 10.5766\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4690 - val_loss: 10.6205\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4599 - val_loss: 10.1288\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4723 - val_loss: 10.2132\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4070 - val_loss: 10.0943\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4429 - val_loss: 9.9913\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.2761 - val_loss: 10.4582\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6062 - val_loss: 10.2144\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.5379 - val_loss: 9.8366\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.4081 - val_loss: 10.2703\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3910 - val_loss: 10.1574\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3221 - val_loss: 10.0182\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4680 - val_loss: 9.9308\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4064 - val_loss: 10.1719\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2566 - val_loss: 9.8864\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3145 - val_loss: 9.9913\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4325 - val_loss: 9.9153\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3685 - val_loss: 9.6341\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2465 - val_loss: 9.9072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2626 - val_loss: 9.8308\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3861 - val_loss: 9.8776\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3020 - val_loss: 10.0324\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2767 - val_loss: 9.6250\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1723 - val_loss: 10.0233\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2162 - val_loss: 10.2133\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3154 - val_loss: 9.9215\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5280 - val_loss: 9.6834\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0899 - val_loss: 10.1982\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1678 - val_loss: 9.6523\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2027 - val_loss: 9.6764\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0731 - val_loss: 9.5011\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9997 - val_loss: 9.7264\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8837 - val_loss: 10.5206\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0917 - val_loss: 9.3909\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8620 - val_loss: 9.5460\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7563 - val_loss: 9.2826\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8082 - val_loss: 9.2791\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8389 - val_loss: 9.3794\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0537 - val_loss: 9.3986\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7438 - val_loss: 9.4925\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8335 - val_loss: 9.3129\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7337 - val_loss: 8.9606\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7686 - val_loss: 9.2030\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7262 - val_loss: 9.0795\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7855 - val_loss: 9.3896\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7729 - val_loss: 9.1363\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7493 - val_loss: 9.2623\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6897 - val_loss: 9.1661\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9265 - val_loss: 9.3887\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6590 - val_loss: 8.9773\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6471 - val_loss: 9.0287\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6693 - val_loss: 8.7954\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8374 - val_loss: 9.0650\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9087 - val_loss: 8.8265\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7268 - val_loss: 9.1323\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9457 - val_loss: 9.0170\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6145 - val_loss: 9.4780\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6159 - val_loss: 8.8860\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7130 - val_loss: 8.8732\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6251 - val_loss: 9.1927\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6189 - val_loss: 8.7566\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5738 - val_loss: 8.9697\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5144 - val_loss: 8.7720\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6600 - val_loss: 9.1331\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8134 - val_loss: 8.9116\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6568 - val_loss: 8.7159\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7320 - val_loss: 8.7617\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4662 - val_loss: 8.5940\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5219 - val_loss: 8.8225\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4743 - val_loss: 8.5169\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6927 - val_loss: 8.6024\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4083 - val_loss: 8.6972\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7140 - val_loss: 8.5230\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3955 - val_loss: 8.3481\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4820 - val_loss: 8.7211\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4698 - val_loss: 8.5516\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3657 - val_loss: 8.5014\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4176 - val_loss: 8.5818\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4859 - val_loss: 8.5306\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4162 - val_loss: 8.4682\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5465 - val_loss: 8.8198\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5953 - val_loss: 8.4972\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3785 - val_loss: 8.6803\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.3599 - val_loss: 8.7846\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3885 - val_loss: 8.5700\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.3046 - val_loss: 8.3449\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4982 - val_loss: 8.5415\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4071 - val_loss: 8.5415\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3590 - val_loss: 8.4948\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5782 - val_loss: 8.3886\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3436 - val_loss: 8.3759\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2864 - val_loss: 8.6552\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1531 - val_loss: 8.3682\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2214 - val_loss: 8.4538\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3988 - val_loss: 8.7111\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2584 - val_loss: 8.3590\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3152 - val_loss: 8.2286\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2001 - val_loss: 8.9110\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2605 - val_loss: 8.6030\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1963 - val_loss: 8.4782\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1641 - val_loss: 8.5324\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2472 - val_loss: 9.0277\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2909 - val_loss: 8.8316\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2121 - val_loss: 8.3559\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1683 - val_loss: 8.4225\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1544 - val_loss: 8.4871\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2920 - val_loss: 8.3974\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3773 - val_loss: 8.4823\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2054 - val_loss: 8.4772\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1606 - val_loss: 8.4233\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2821 - val_loss: 8.4345\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2964 - val_loss: 8.4148\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0779 - val_loss: 8.5940\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2457 - val_loss: 8.4120\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1397 - val_loss: 8.3617\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.0612 - val_loss: 8.4336\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2498 - val_loss: 8.1973\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0861 - val_loss: 8.4080\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0228 - val_loss: 8.5464\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0820 - val_loss: 8.3613\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1444 - val_loss: 8.4930\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0816 - val_loss: 8.4977\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0928 - val_loss: 8.0583\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1791 - val_loss: 8.7623\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3768 - val_loss: 8.4770\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1135 - val_loss: 9.0287\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1536 - val_loss: 8.1544\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1269 - val_loss: 8.7066\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0500 - val_loss: 8.2335\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0173 - val_loss: 8.5671\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0892 - val_loss: 8.3250\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.0627 - val_loss: 8.4207\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1028 - val_loss: 8.3939\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0962 - val_loss: 8.3419\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0788 - val_loss: 8.2739\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.0400 - val_loss: 8.6137\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.9606 - val_loss: 8.2108\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0328 - val_loss: 8.2213\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1294 - val_loss: 8.2160\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0346 - val_loss: 8.9586\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.1852 - val_loss: 8.5656\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0429 - val_loss: 8.3486\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3049 - val_loss: 9.5506\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3101 - val_loss: 8.4896\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.1602 - val_loss: 8.4388\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4682 - val_loss: 8.6759\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1784 - val_loss: 8.4768\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0105 - val_loss: 8.4601\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 7.1049 - val_loss: 8.1611\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.9817 - val_loss: 8.3554\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.0251 - val_loss: 7.8724\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.0446 - val_loss: 8.2439\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9938 - val_loss: 8.2633\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0184 - val_loss: 9.3087\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1133 - val_loss: 8.2061\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1938 - val_loss: 8.4897\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0085 - val_loss: 8.1183\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9875 - val_loss: 8.0310\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0203 - val_loss: 8.0117\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8804 - val_loss: 8.2068\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.9644 - val_loss: 8.2313\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1608 - val_loss: 8.4368\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.0947 - val_loss: 8.1193\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9754 - val_loss: 8.3020\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0411 - val_loss: 8.0927\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0222 - val_loss: 7.9883\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0333 - val_loss: 8.8484\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.9788 - val_loss: 7.9230\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.8865 - val_loss: 7.8638\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.9076 - val_loss: 8.0748\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.8351 - val_loss: 7.9094\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.8572 - val_loss: 7.9686\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.8922 - val_loss: 8.0103\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7516 - val_loss: 8.0567\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.0492 - val_loss: 8.2473\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.9044 - val_loss: 7.8539\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7308 - val_loss: 8.3364\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8785 - val_loss: 8.0113\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9535 - val_loss: 8.0292\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9032 - val_loss: 7.8249\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.8399 - val_loss: 8.0331\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6405 - val_loss: 8.5886\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8733 - val_loss: 7.9818\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.7682 - val_loss: 8.2146\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8099 - val_loss: 8.0419\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7580 - val_loss: 8.0080\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9360 - val_loss: 8.0979\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.6332 - val_loss: 7.6939\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6097 - val_loss: 7.9098\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7699 - val_loss: 7.6125\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8285 - val_loss: 8.3183\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.6900 - val_loss: 7.9363\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8400 - val_loss: 7.5975\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5976 - val_loss: 7.9055\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7062 - val_loss: 7.6968\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6897 - val_loss: 7.8135\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5161 - val_loss: 7.7645\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6802 - val_loss: 7.8435\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5951 - val_loss: 7.6717\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7762 - val_loss: 7.5024\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.8443 - val_loss: 8.0999\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7674 - val_loss: 7.4867\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4992 - val_loss: 7.9707\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5510 - val_loss: 7.7793\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5695 - val_loss: 7.4536\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5613 - val_loss: 7.3675\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6984 - val_loss: 7.3894\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6278 - val_loss: 7.6764\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.442 - 0s 93us/step - loss: 6.4712 - val_loss: 7.7582\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5534 - val_loss: 7.5627\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.4001 - val_loss: 7.3343\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4682 - val_loss: 7.6083\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4628 - val_loss: 7.4494\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4539 - val_loss: 7.5743\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4098 - val_loss: 7.8681\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4585 - val_loss: 7.5867\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.5292 - val_loss: 7.3936\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3572 - val_loss: 7.4850\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4950 - val_loss: 7.5840\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4262 - val_loss: 7.3590\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3801 - val_loss: 7.1429\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3279 - val_loss: 7.4458\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4785 - val_loss: 7.8460\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.2959 - val_loss: 7.2966\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3310 - val_loss: 7.6835\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.6578 - val_loss: 7.2397\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4392 - val_loss: 7.1050\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4073 - val_loss: 7.2689\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4491 - val_loss: 7.1482\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4022 - val_loss: 7.1933\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4713 - val_loss: 7.0201\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1733 - val_loss: 7.0549\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3002 - val_loss: 7.1490\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4659 - val_loss: 7.3580\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2872 - val_loss: 7.3205\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1259 - val_loss: 7.2282\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4041 - val_loss: 7.4534\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3599 - val_loss: 7.6535\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2481 - val_loss: 7.3241\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2195 - val_loss: 7.4904\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3411 - val_loss: 7.0399\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2852 - val_loss: 6.9063\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9828 - val_loss: 7.1076\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0301 - val_loss: 7.1909\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0279 - val_loss: 7.3390\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0258 - val_loss: 6.8454\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0585 - val_loss: 7.4240\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1487 - val_loss: 7.0676\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9896 - val_loss: 7.0393\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1303 - val_loss: 7.3056\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1169 - val_loss: 7.0396\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9918 - val_loss: 7.1800\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1079 - val_loss: 7.2130\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1095 - val_loss: 6.9004\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.9306 - val_loss: 6.9533\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9054 - val_loss: 6.8199\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8746 - val_loss: 6.8314\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0518 - val_loss: 7.1984\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9545 - val_loss: 7.0986\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0721 - val_loss: 6.8822\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9720 - val_loss: 7.2166\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9809 - val_loss: 6.8445\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8823 - val_loss: 6.9350\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8720 - val_loss: 6.7100\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7531 - val_loss: 7.3384\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8196 - val_loss: 6.7658\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9937 - val_loss: 6.8860\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7137 - val_loss: 7.2840\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8597 - val_loss: 7.2290\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8342 - val_loss: 6.8437\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7848 - val_loss: 6.8412\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6513 - val_loss: 6.7623\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7319 - val_loss: 6.5815\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6351 - val_loss: 7.2133\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6569 - val_loss: 6.6190\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7414 - val_loss: 6.8927\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6669 - val_loss: 6.7309\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6725 - val_loss: 6.6512\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6170 - val_loss: 6.6455\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5746 - val_loss: 6.5658\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5439 - val_loss: 6.9475\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6187 - val_loss: 6.5294\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4425 - val_loss: 6.7534\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5549 - val_loss: 6.5523\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5923 - val_loss: 6.8133\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4607 - val_loss: 6.6200\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4030 - val_loss: 6.6470\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4052 - val_loss: 6.7143\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5413 - val_loss: 6.3590\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4693 - val_loss: 6.6790\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5589 - val_loss: 6.5729\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8269 - val_loss: 6.6697\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4075 - val_loss: 6.3826\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3814 - val_loss: 6.3887\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.2511 - val_loss: 6.3780\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8309 - val_loss: 6.7294\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4105 - val_loss: 6.8092\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2981 - val_loss: 6.5714\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3341 - val_loss: 6.5754\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2063 - val_loss: 6.2478\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1913 - val_loss: 6.3969\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3008 - val_loss: 6.1406\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.1511 - val_loss: 6.3544\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1795 - val_loss: 6.2594\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2782 - val_loss: 6.3335\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2782 - val_loss: 6.4766\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2623 - val_loss: 6.4970\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1662 - val_loss: 7.2216\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2700 - val_loss: 6.2309\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.0756 - val_loss: 6.2770\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2197 - val_loss: 6.2561\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2096 - val_loss: 6.1970\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1581 - val_loss: 6.3149\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2121 - val_loss: 6.5501\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1309 - val_loss: 6.4998\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1646 - val_loss: 6.1208\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1738 - val_loss: 6.7170\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3519 - val_loss: 6.1451\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1080 - val_loss: 6.2789\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2063 - val_loss: 6.4129\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3124 - val_loss: 6.5999\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3006 - val_loss: 6.3372\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1543 - val_loss: 6.0618\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.2085 - val_loss: 6.2485\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1818 - val_loss: 6.4668\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.0574 - val_loss: 6.2823\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.8666 - val_loss: 6.0563\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.0771 - val_loss: 6.2845\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0059 - val_loss: 5.8597\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0056 - val_loss: 5.7758\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9667 - val_loss: 5.8351\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.9316 - val_loss: 6.2380\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.9235 - val_loss: 6.1121\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.8850 - val_loss: 6.1143\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.0263 - val_loss: 6.1378\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.0842 - val_loss: 6.1920\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.7832 - val_loss: 5.7575\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.8882 - val_loss: 6.1079\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.8772 - val_loss: 6.2362\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.9030 - val_loss: 5.8979\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8654 - val_loss: 6.0153\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8853 - val_loss: 5.8729\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9026 - val_loss: 6.6864\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8124 - val_loss: 6.0144\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0447 - val_loss: 5.9600\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9568 - val_loss: 5.6659\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7701 - val_loss: 6.2639\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0312 - val_loss: 5.7605\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.8526 - val_loss: 5.9841\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.7859 - val_loss: 5.5621\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9162 - val_loss: 6.0333\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.7126 - val_loss: 6.0923\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1798 - val_loss: 5.8725\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7714 - val_loss: 5.7414\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8702 - val_loss: 6.0226\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.8780 - val_loss: 5.5054\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.7183 - val_loss: 5.9041\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6666 - val_loss: 5.5479\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9252 - val_loss: 5.8616\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8700 - val_loss: 5.6884\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6853 - val_loss: 5.6988\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.7526 - val_loss: 5.8360\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6945 - val_loss: 5.8234\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8488 - val_loss: 5.7269\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.7524 - val_loss: 5.8138\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.6245 - val_loss: 6.0620\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7312 - val_loss: 5.5596\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6759 - val_loss: 5.7463\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.7063 - val_loss: 5.7168\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8037 - val_loss: 5.4710\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7219 - val_loss: 5.7477\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7130 - val_loss: 5.7747\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.9318 - val_loss: 5.6462\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.7181 - val_loss: 5.6475\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.6419 - val_loss: 5.6188\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8063 - val_loss: 5.5889\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.8684 - val_loss: 5.6504\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.6695 - val_loss: 5.7357\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8319 - val_loss: 5.8228\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6647 - val_loss: 5.7722\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6636 - val_loss: 5.6270\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7147 - val_loss: 5.8270\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6607 - val_loss: 5.4628\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8014 - val_loss: 5.6022\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.8009 - val_loss: 5.9642\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7896 - val_loss: 5.7918\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9476 - val_loss: 5.7141\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.7306 - val_loss: 5.7361\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8360 - val_loss: 5.5955\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6107 - val_loss: 5.8387\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.8375 - val_loss: 5.6497\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.7182 - val_loss: 5.3440\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.7219 - val_loss: 5.6075\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6995 - val_loss: 5.8205\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6778 - val_loss: 5.6776\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.7943 - val_loss: 5.7880\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5893 - val_loss: 5.5418\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.6210 - val_loss: 5.5871\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6343 - val_loss: 5.9056\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6767 - val_loss: 5.8455\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6042 - val_loss: 5.4603\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5715 - val_loss: 5.5294\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5680 - val_loss: 5.8444\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6778 - val_loss: 5.7797\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5915 - val_loss: 5.6249\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6670 - val_loss: 5.5922\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.5730 - val_loss: 5.4518\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8486 - val_loss: 5.8884\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6952 - val_loss: 6.0352\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5899 - val_loss: 5.4872\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6365 - val_loss: 5.6329\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6408 - val_loss: 5.5920\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6444 - val_loss: 5.5637\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.6962 - val_loss: 5.4378\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.5848 - val_loss: 5.5436\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5639 - val_loss: 5.5522\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5210 - val_loss: 5.4133\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6046 - val_loss: 5.6335\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5724 - val_loss: 5.5254\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5573 - val_loss: 5.4255\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6035 - val_loss: 5.5802\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6246 - val_loss: 5.6418\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6136 - val_loss: 5.5981\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5808 - val_loss: 5.6126\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.7511 - val_loss: 5.4918\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7469 - val_loss: 5.7077\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5587 - val_loss: 6.0048\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6353 - val_loss: 5.5904\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5596 - val_loss: 5.6517\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.6008 - val_loss: 5.7419\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.7086 - val_loss: 5.9581\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5808 - val_loss: 5.7372\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7775 - val_loss: 5.7166\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7428 - val_loss: 5.9945\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7396 - val_loss: 5.9175\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8193 - val_loss: 5.8699\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8463 - val_loss: 5.7227\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6085 - val_loss: 5.7376\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5818 - val_loss: 5.6604\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5239 - val_loss: 5.6226\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5766 - val_loss: 5.7786\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6150 - val_loss: 6.1674\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9459 - val_loss: 5.6115\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5236 - val_loss: 6.2590\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5852 - val_loss: 5.3973\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6765 - val_loss: 5.4128\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5648 - val_loss: 5.9883\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5136 - val_loss: 5.4503\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4588 - val_loss: 5.5678\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5339 - val_loss: 5.8257\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7226 - val_loss: 5.7793\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.6097 - val_loss: 5.6219\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5340 - val_loss: 5.8194\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7630 - val_loss: 5.7821\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7611 - val_loss: 5.6293\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6342 - val_loss: 5.3784\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.6265 - val_loss: 5.5369\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6028 - val_loss: 5.8161\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4551 - val_loss: 5.7577\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6051 - val_loss: 5.8168\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5905 - val_loss: 5.5950\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6426 - val_loss: 5.9597\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7583 - val_loss: 6.2411\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5570 - val_loss: 5.8747\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6214 - val_loss: 6.3026\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6729 - val_loss: 5.9789\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7096 - val_loss: 5.6512\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5268 - val_loss: 5.9482\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5722 - val_loss: 5.4730\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.6866 - val_loss: 5.6300\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6251 - val_loss: 5.6741\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5852 - val_loss: 5.8378\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5621 - val_loss: 5.3297\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.6746 - val_loss: 6.1782\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5779 - val_loss: 5.7019\n",
      "Epoch 748/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5456 - val_loss: 5.6610\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5288 - val_loss: 5.5613\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5186 - val_loss: 5.5830\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6060 - val_loss: 5.8317\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5705 - val_loss: 6.4261\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.6388 - val_loss: 5.6269\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5520 - val_loss: 5.6447\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5121 - val_loss: 5.6342\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6369 - val_loss: 6.1160\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6187 - val_loss: 5.5614\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6604 - val_loss: 5.7106\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6723 - val_loss: 5.5808\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6361 - val_loss: 5.7219\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4937 - val_loss: 5.8617\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4811 - val_loss: 5.3872\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5596 - val_loss: 5.4185\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.5268 - val_loss: 6.2919\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6781 - val_loss: 5.5731\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4775 - val_loss: 5.8504\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6280 - val_loss: 6.0550\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4815 - val_loss: 5.6409\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.5110 - val_loss: 5.6638\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.6167 - val_loss: 5.6634\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.5387 - val_loss: 5.7740\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 4.6441 - val_loss: 5.7783\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.6298 - val_loss: 6.2221\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.5879 - val_loss: 5.7790\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.5348 - val_loss: 5.4244\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4563 - val_loss: 5.7721\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.6633 - val_loss: 6.2865\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6336 - val_loss: 5.6452\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5857 - val_loss: 5.3889\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.6369 - val_loss: 5.8956\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.4442 - val_loss: 5.6308\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5519 - val_loss: 5.7045\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5016 - val_loss: 5.7384\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5873 - val_loss: 5.4780\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4517 - val_loss: 5.5525\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4496 - val_loss: 5.8291\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5005 - val_loss: 5.5221\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5700 - val_loss: 5.8904\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.5561 - val_loss: 5.5575\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4919 - val_loss: 5.8916\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4524 - val_loss: 5.5753\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.4942 - val_loss: 5.9232\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5700 - val_loss: 5.8335\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6020 - val_loss: 5.5056\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5338 - val_loss: 5.4719\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4998 - val_loss: 5.4074\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5169 - val_loss: 5.6968\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7049 - val_loss: 5.5740\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5611 - val_loss: 5.8854\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4508 - val_loss: 5.3028\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4744 - val_loss: 5.3997\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5705 - val_loss: 5.4739\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4558 - val_loss: 5.9170\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4709 - val_loss: 5.6448\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5912 - val_loss: 5.8778\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6685 - val_loss: 5.5702\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5992 - val_loss: 5.6254\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4238 - val_loss: 5.7581\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4705 - val_loss: 5.7325\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5335 - val_loss: 5.9299\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.7115 - val_loss: 5.4676\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5778 - val_loss: 5.5056\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5267 - val_loss: 5.7019\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.6144 - val_loss: 5.5239\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4926 - val_loss: 5.5189\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4348 - val_loss: 5.5768\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5111 - val_loss: 5.4502\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5126 - val_loss: 5.8621\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.6626 - val_loss: 5.6294\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5705 - val_loss: 5.4941\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5906 - val_loss: 5.4370\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5096 - val_loss: 5.6020\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4824 - val_loss: 5.7269\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5662 - val_loss: 5.4120\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5046 - val_loss: 5.8982\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5170 - val_loss: 5.7385\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6398 - val_loss: 5.5143\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5309 - val_loss: 5.5471\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5659 - val_loss: 5.4652\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5349 - val_loss: 6.0062\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4289 - val_loss: 5.5631\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5286 - val_loss: 5.7457\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5745 - val_loss: 5.6782\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6031 - val_loss: 5.5394\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5112 - val_loss: 5.6489\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5829 - val_loss: 5.6675\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5026 - val_loss: 5.4147\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4245 - val_loss: 5.8898\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5289 - val_loss: 5.6774\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5533 - val_loss: 5.6387\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5892 - val_loss: 5.5128\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5171 - val_loss: 5.9054\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5354 - val_loss: 5.5526\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5172 - val_loss: 5.6717\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6244 - val_loss: 5.3033\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5307 - val_loss: 5.5170\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6098 - val_loss: 5.7290\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5720 - val_loss: 5.3374\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4860 - val_loss: 5.7328\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6069 - val_loss: 6.0567\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5141 - val_loss: 5.5352\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.6255 - val_loss: 5.6727\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4387 - val_loss: 5.6046\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4343 - val_loss: 6.0110\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5173 - val_loss: 5.5182\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5076 - val_loss: 5.7951\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5791 - val_loss: 5.6664\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4569 - val_loss: 5.7694\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5412 - val_loss: 5.5269\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4669 - val_loss: 5.9406\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4232 - val_loss: 5.5653\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4622 - val_loss: 5.3425\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.4944 - val_loss: 5.5644\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5046 - val_loss: 6.4156\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7754 - val_loss: 5.6058\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4899 - val_loss: 5.7195\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4965 - val_loss: 5.6285\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5584 - val_loss: 5.4663\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5455 - val_loss: 5.5975\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5267 - val_loss: 6.1061\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4679 - val_loss: 5.6363\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4863 - val_loss: 5.5174\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4729 - val_loss: 5.6666\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4626 - val_loss: 5.4778\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4918 - val_loss: 5.5867\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4501 - val_loss: 5.5754\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4068 - val_loss: 5.7785\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.4521 - val_loss: 5.5639\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4982 - val_loss: 5.3429\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.3117 - val_loss: 5.5739\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.3756 - val_loss: 5.4653\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.5091 - val_loss: 5.5753\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5997 - val_loss: 5.7777\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.7774 - val_loss: 5.6064\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5463 - val_loss: 5.6183\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5641 - val_loss: 5.3950\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4657 - val_loss: 5.4684\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4262 - val_loss: 5.3606\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4891 - val_loss: 5.5576\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4147 - val_loss: 5.7076\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4560 - val_loss: 5.5243\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4012 - val_loss: 5.6335\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.3856 - val_loss: 5.8394\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4270 - val_loss: 5.5284\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5342 - val_loss: 5.6353\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.4692 - val_loss: 5.6495\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5997 - val_loss: 5.6022\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4765 - val_loss: 5.9160\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.4797 - val_loss: 6.3850\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.5320 - val_loss: 5.7489\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4892 - val_loss: 5.8465\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5982 - val_loss: 5.4372\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.6170 - val_loss: 5.5776\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6762 - val_loss: 5.7259\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5134 - val_loss: 5.9842\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7019 - val_loss: 6.1937\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5305 - val_loss: 5.3993\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6253 - val_loss: 5.6036\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5457 - val_loss: 5.6314\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5602 - val_loss: 5.6306\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4932 - val_loss: 5.5263\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4739 - val_loss: 5.6376\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4978 - val_loss: 5.6942\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6595 - val_loss: 5.6122\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4379 - val_loss: 5.4330\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.3842 - val_loss: 5.6194\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.3939 - val_loss: 5.6935\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.4377 - val_loss: 5.4221\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4335 - val_loss: 5.6843\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5101 - val_loss: 5.6453\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.6831 - val_loss: 6.3623\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8474 - val_loss: 5.7589\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5078 - val_loss: 5.7204\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.3295 - val_loss: 5.5087\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.3340 - val_loss: 5.6891\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.3683 - val_loss: 5.6661\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.4287 - val_loss: 5.7774\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4393 - val_loss: 5.8077\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.6655 - val_loss: 5.5717\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5228 - val_loss: 6.0058\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6283 - val_loss: 5.6237\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.4752 - val_loss: 5.5736\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.3784 - val_loss: 5.9717\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.7158 - val_loss: 6.0178\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.5764 - val_loss: 5.4221\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 4.4168 - val_loss: 5.3992\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.4246 - val_loss: 5.8756\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.4534 - val_loss: 5.7634\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 4.3583 - val_loss: 5.8959\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.5583 - val_loss: 5.6181\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.4353 - val_loss: 5.5630\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4209 - val_loss: 5.5938\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.5467 - val_loss: 5.6723\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.5257 - val_loss: 5.4807\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4331 - val_loss: 6.0917\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7136 - val_loss: 5.4993\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.3875 - val_loss: 5.8687\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.3139 - val_loss: 5.5561\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5220 - val_loss: 5.4352\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4392 - val_loss: 5.6578\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4435 - val_loss: 5.3451\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4185 - val_loss: 5.7298\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5102 - val_loss: 5.5413\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.3113 - val_loss: 5.4290\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.3184 - val_loss: 5.6015\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5373 - val_loss: 6.1133\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4002 - val_loss: 5.5912\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4052 - val_loss: 5.9197\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4713 - val_loss: 5.6415\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5118 - val_loss: 5.5163\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4796 - val_loss: 5.7475\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4954 - val_loss: 5.4379\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.3511 - val_loss: 5.6869\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4868 - val_loss: 5.5257\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4430 - val_loss: 5.4634\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4406 - val_loss: 5.4450\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.4801 - val_loss: 5.7161\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.3981 - val_loss: 5.8603\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.3472 - val_loss: 5.8629\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4993 - val_loss: 6.0423\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5667 - val_loss: 5.3630\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.4081 - val_loss: 5.5600\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4131 - val_loss: 5.8100\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.3907 - val_loss: 5.9154\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4737 - val_loss: 5.5152\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.3617 - val_loss: 5.6300\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4127 - val_loss: 5.6321\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.4269 - val_loss: 5.5227\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.3358 - val_loss: 5.8180\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4641 - val_loss: 5.4700\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.4810 - val_loss: 5.6807\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5506 - val_loss: 5.7896\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.3482 - val_loss: 5.8133\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4730 - val_loss: 5.6005\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5323 - val_loss: 5.7482\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5126 - val_loss: 5.7911\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.3997 - val_loss: 5.8718\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 4.552 - 0s 90us/step - loss: 4.3260 - val_loss: 6.0249\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4966 - val_loss: 5.4915\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.3689 - val_loss: 5.4477\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.4721 - val_loss: 5.4021\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5294 - val_loss: 5.7678\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5573 - val_loss: 5.6443\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.3657 - val_loss: 5.4936\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.3326 - val_loss: 5.6899\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5676 - val_loss: 5.3665\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.3557 - val_loss: 5.7439\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5279 - val_loss: 5.6348\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.4079 - val_loss: 5.5607\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.4015 - val_loss: 5.6913\n",
      "5.062023116424021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-6.002497  , -0.00703184, -5.7662573 , -0.6565843 , -1.1423743 ],\n",
       "        [ 0.34317157,  2.3304763 , -2.1094139 , -2.597349  , -1.2172843 ],\n",
       "        [-0.15042885, -0.6251251 , -0.5988963 , -3.4287236 , -0.79466593],\n",
       "        [ 0.13265225, -0.14904036,  0.32933375,  0.28756794,  0.46526277],\n",
       "        [-0.7206939 , -3.084812  , -0.7857606 ,  2.2460759 , -0.27039552]],\n",
       "       dtype=float32),\n",
       " array([-2.7541926,  0.4257172, -1.3515099, -1.1421643,  2.4124908],\n",
       "       dtype=float32),\n",
       " array([[  3.9182904 ,  -1.5499545 ,   1.0811263 ,   8.676617  ,\n",
       "          -2.0654542 ,   4.599918  ,  -5.2806234 ,  14.724277  ,\n",
       "          -2.0936975 ,   2.4185119 ],\n",
       "        [  8.563808  ,   1.461225  ,   0.6538052 ,  16.72399   ,\n",
       "          -0.4404111 ,   6.5120573 , -16.366434  ,   1.4232162 ,\n",
       "          -3.1343946 ,   0.1874299 ],\n",
       "        [ -0.06170878,   3.6289163 ,  -0.02916546,  -1.9480157 ,\n",
       "          -0.8044095 ,  25.436583  ,  -4.764775  ,  12.029613  ,\n",
       "           1.9831724 ,  -1.5668567 ],\n",
       "        [  0.37563577,   2.6677656 ,   2.4739895 ,  -0.8379894 ,\n",
       "           0.0449712 ,  -2.515337  ,  -1.6323984 ,   1.7844149 ,\n",
       "          -7.415874  ,   1.071834  ],\n",
       "        [  0.27857447,  -1.1716729 ,   0.4699466 ,   2.442303  ,\n",
       "           0.4258065 ,   1.0161425 ,   1.6024898 ,  -0.52032125,\n",
       "           1.3631537 ,   1.0601907 ]], dtype=float32),\n",
       " array([ 1.6940203 , -1.6031902 , -0.10411374,  2.5662296 ,  6.320466  ,\n",
       "         2.0232906 ,  1.8918575 ,  2.780744  ,  1.2996068 , -3.0954993 ],\n",
       "       dtype=float32),\n",
       " array([[15.942057],\n",
       "        [11.491961],\n",
       "        [15.355678],\n",
       "        [15.494647],\n",
       "        [18.385715],\n",
       "        [14.185866],\n",
       "        [ 4.647202],\n",
       "        [15.59201 ],\n",
       "        [ 9.930927],\n",
       "        [14.841482]], dtype=float32),\n",
       " array([14.931022], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_sigmoid(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sigmoid_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 227us/step - loss: 12961.0262 - val_loss: 10393.1888\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8712.7500 - val_loss: 7357.7261\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6361.6974 - val_loss: 5537.5269\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4855.7201 - val_loss: 4294.0144\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 3791.7763 - val_loss: 3383.7046\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 3000.4800 - val_loss: 2693.3290\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 2393.8748 - val_loss: 2158.4713\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 1920.6163 - val_loss: 1738.2503\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 1547.0377 - val_loss: 1403.5556\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 1249.1766 - val_loss: 1136.4367\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 1010.7325 - val_loss: 922.1483\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 819.3488 - val_loss: 748.9716\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 665.2126 - val_loss: 609.1449\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 540.7591 - val_loss: 496.9277\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 440.8505 - val_loss: 405.7762\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 360.2088 - val_loss: 332.6275\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 295.5336 - val_loss: 273.5337\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 243.5527 - val_loss: 226.1656\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 201.9689 - val_loss: 188.2724\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 168.7464 - val_loss: 158.1781\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 142.4933 - val_loss: 133.6179\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 121.4469 - val_loss: 114.4079\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 104.8920 - val_loss: 99.2021\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 91.8830 - val_loss: 87.0592\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 81.6715 - val_loss: 77.4919\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 129us/step - loss: 73.6698 - val_loss: 70.0273\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 67.4260 - val_loss: 64.2743\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 62.6591 - val_loss: 59.6224\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 58.9308 - val_loss: 56.0457\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 56.0642 - val_loss: 53.3257\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 53.9099 - val_loss: 51.1350\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 52.2247 - val_loss: 49.5180\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 50.9870 - val_loss: 48.2285\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 50.0342 - val_loss: 47.2337\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 49.3266 - val_loss: 46.4755\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 48.8062 - val_loss: 45.8699\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 48.4056 - val_loss: 45.4450\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 48.1183 - val_loss: 45.1196\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.9218 - val_loss: 44.8171\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.7587 - val_loss: 44.6215\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.6438 - val_loss: 44.4897\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 47.5682 - val_loss: 44.3645\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.5127 - val_loss: 44.2712\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 47.4696 - val_loss: 44.1909\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.4406 - val_loss: 44.1400\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.4226 - val_loss: 44.0894\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 47.4050 - val_loss: 44.0619\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3995 - val_loss: 44.0199\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3870 - val_loss: 44.0033\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3851 - val_loss: 43.9891\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 47.3819 - val_loss: 43.9847\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 47.3787 - val_loss: 43.9711\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3832 - val_loss: 43.9419\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3752 - val_loss: 43.9535\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3822 - val_loss: 43.9565\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3815 - val_loss: 43.9312\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 47.3760 - val_loss: 43.9375\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3749 - val_loss: 43.9346\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 47.3733 - val_loss: 43.9225\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3751 - val_loss: 43.9252\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3739 - val_loss: 43.9297\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 47.3786 - val_loss: 43.9216\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3821 - val_loss: 43.9289\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3998 - val_loss: 43.9056\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 47.3819 - val_loss: 43.9320\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3749 - val_loss: 43.9156\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3737 - val_loss: 43.9105\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3790 - val_loss: 43.9188\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 47.3836 - val_loss: 43.9171\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3762 - val_loss: 43.9299\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3808 - val_loss: 43.9200\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3866 - val_loss: 43.9393\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3715 - val_loss: 43.9200\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3765 - val_loss: 43.9059\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3772 - val_loss: 43.9076\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3790 - val_loss: 43.9245\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3730 - val_loss: 43.9187\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3830 - val_loss: 43.9100\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 47.3812 - val_loss: 43.9037\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3762 - val_loss: 43.9319\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 47.3776 - val_loss: 43.9400\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3804 - val_loss: 43.9098\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3789 - val_loss: 43.9151\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 47.3779 - val_loss: 43.9318\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3763 - val_loss: 43.9235\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3890 - val_loss: 43.9277\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 47.3771 - val_loss: 43.9111\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 47.3818 - val_loss: 43.8974\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 47.3756 - val_loss: 43.9244\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 47.3803 - val_loss: 43.9157\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 47.3752 - val_loss: 43.9280\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 47.3748 - val_loss: 43.9320\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 47.3778 - val_loss: 43.9183\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 47.3786 - val_loss: 43.9329\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 47.3821 - val_loss: 43.9171\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.3857 - val_loss: 43.9020\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3796 - val_loss: 43.9063\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3938 - val_loss: 43.9491\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3821 - val_loss: 43.9106\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3819 - val_loss: 43.9266\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3747 - val_loss: 43.9226\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3728 - val_loss: 43.9061\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.3950 - val_loss: 43.8849\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.4201 - val_loss: 43.9009\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3722 - val_loss: 43.9382\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3781 - val_loss: 43.9489\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3837 - val_loss: 43.9073\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.3756 - val_loss: 43.9382\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3857 - val_loss: 43.9203\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3836 - val_loss: 43.9053\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3757 - val_loss: 43.9194\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.4198 - val_loss: 43.9547\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3655 - val_loss: 43.9142\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3864 - val_loss: 43.8818\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3811 - val_loss: 43.9427\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3708 - val_loss: 43.9184\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.3551 - val_loss: 43.9183\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 47.3346 - val_loss: 43.9504\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 46.4554 - val_loss: 40.6982\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 42.3484 - val_loss: 36.7878\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 33.3976 - val_loss: 29.6208\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 25.1431 - val_loss: 25.3247\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5306 - val_loss: 23.5428\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1748 - val_loss: 21.4464\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7325 - val_loss: 20.4645\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9957 - val_loss: 20.0118\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.4787 - val_loss: 19.5855\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.1450 - val_loss: 19.6420\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.8865 - val_loss: 19.4304\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.9047 - val_loss: 19.2885\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.5437 - val_loss: 18.9977\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.2787 - val_loss: 18.4136\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1326 - val_loss: 18.3483\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5785 - val_loss: 19.0936\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3208 - val_loss: 17.9117\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0640 - val_loss: 17.7409\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6126 - val_loss: 17.5169\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5232 - val_loss: 17.2058\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1234 - val_loss: 16.7529\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.0777 - val_loss: 16.7814\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.9178 - val_loss: 16.3838\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.6195 - val_loss: 15.5972\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3979 - val_loss: 15.7245\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.2502 - val_loss: 15.4384\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9812 - val_loss: 15.1637\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8767 - val_loss: 14.5179\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6684 - val_loss: 15.2851\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2533 - val_loss: 14.6251\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3374 - val_loss: 14.4192\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0863 - val_loss: 14.1567\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7498 - val_loss: 13.3346\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1924 - val_loss: 12.8324\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1488 - val_loss: 13.0780\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1341 - val_loss: 13.0940\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6820 - val_loss: 15.6253\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3941 - val_loss: 12.2891\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7133 - val_loss: 12.1846\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5141 - val_loss: 12.1605\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6040 - val_loss: 12.7998\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2574 - val_loss: 12.4677\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4934 - val_loss: 12.1607\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2797 - val_loss: 11.5088\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1554 - val_loss: 11.3809\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8898 - val_loss: 11.4209\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9658 - val_loss: 11.1451\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9498 - val_loss: 11.4414\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9461 - val_loss: 11.0456\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7613 - val_loss: 11.1763\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6387 - val_loss: 10.8590\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5179 - val_loss: 11.1243\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7372 - val_loss: 10.9886\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4590 - val_loss: 10.3945\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3589 - val_loss: 10.7765\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6832 - val_loss: 11.1425\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1347 - val_loss: 10.6630\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6492 - val_loss: 10.3726\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9836 - val_loss: 10.5676\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9405 - val_loss: 10.2826\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0749 - val_loss: 10.3478\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1880 - val_loss: 9.9303\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9848 - val_loss: 10.2612\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8415 - val_loss: 10.1121\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8085 - val_loss: 9.8879\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6624 - val_loss: 9.7106\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5235 - val_loss: 9.3769\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6287 - val_loss: 9.3890\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6834 - val_loss: 9.1426\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6956 - val_loss: 9.5539\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7637 - val_loss: 9.4931\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5483 - val_loss: 9.2942\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6770 - val_loss: 9.0319\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5226 - val_loss: 9.0569\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5522 - val_loss: 8.9248\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5249 - val_loss: 8.9849\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3148 - val_loss: 9.0337\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2096 - val_loss: 9.0696\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2069 - val_loss: 8.8401\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3561 - val_loss: 9.1571\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6024 - val_loss: 8.9182\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2962 - val_loss: 9.1425\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2693 - val_loss: 8.8287\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1746 - val_loss: 8.3792\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0285 - val_loss: 8.3640\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1651 - val_loss: 8.4123\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0690 - val_loss: 8.3429\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0715 - val_loss: 8.6515\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3646 - val_loss: 8.4856\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2882 - val_loss: 8.2533\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1805 - val_loss: 8.1026\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0066 - val_loss: 8.5813\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3187 - val_loss: 8.9353\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3144 - val_loss: 8.1528\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9191 - val_loss: 8.3053\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8601 - val_loss: 8.4144\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9531 - val_loss: 8.1044\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9779 - val_loss: 7.8341\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9753 - val_loss: 8.7996\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7868 - val_loss: 7.9373\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7498 - val_loss: 7.8455\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6543 - val_loss: 8.1256\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6938 - val_loss: 7.4608\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4814 - val_loss: 7.6047\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4579 - val_loss: 8.1878\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5471 - val_loss: 7.2433\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3518 - val_loss: 7.2853\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2897 - val_loss: 7.3648\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3157 - val_loss: 7.4969\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1861 - val_loss: 7.3473\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2795 - val_loss: 6.9234\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2821 - val_loss: 7.4481\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.319 - 0s 89us/step - loss: 6.2244 - val_loss: 6.8741\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4496 - val_loss: 7.1990\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2789 - val_loss: 7.0891\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2805 - val_loss: 7.2125\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.3348 - val_loss: 6.8883\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0998 - val_loss: 7.4635\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2818 - val_loss: 7.0190\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1094 - val_loss: 7.0639\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2588 - val_loss: 6.9233\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0335 - val_loss: 7.0384\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2040 - val_loss: 7.2104\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1723 - val_loss: 7.4035\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1233 - val_loss: 6.9623\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2488 - val_loss: 7.0403\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0542 - val_loss: 7.0464\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3646 - val_loss: 7.2397\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5305 - val_loss: 8.2448\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2747 - val_loss: 7.2104\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0796 - val_loss: 7.1976\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2207 - val_loss: 6.8460\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0509 - val_loss: 6.9087\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0843 - val_loss: 7.3864\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9863 - val_loss: 7.3628\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 6.1960 - val_loss: 7.1337\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.1204 - val_loss: 7.0472\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.0433 - val_loss: 6.9471\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0220 - val_loss: 6.7489\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.1320 - val_loss: 6.8812\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0822 - val_loss: 6.7523\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1686 - val_loss: 6.7638\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0527 - val_loss: 7.5774\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9864 - val_loss: 7.0509\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1537 - val_loss: 6.8593\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0295 - val_loss: 7.7974\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1978 - val_loss: 6.9189\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1716 - val_loss: 7.2194\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2755 - val_loss: 6.9978\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0443 - val_loss: 7.4351\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1975 - val_loss: 6.7734\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2201 - val_loss: 7.0465\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9668 - val_loss: 7.2959\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1549 - val_loss: 7.7737\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.2257 - val_loss: 6.7902\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1433 - val_loss: 7.1143\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1513 - val_loss: 7.0199\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1563 - val_loss: 7.3162\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.3836 - val_loss: 7.4255\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1294 - val_loss: 7.2471\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0959 - val_loss: 7.2869\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0442 - val_loss: 7.1187\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0507 - val_loss: 6.9634\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9708 - val_loss: 7.3213\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0958 - val_loss: 7.3948\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1454 - val_loss: 7.1588\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 6.0447 - val_loss: 7.0756\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9690 - val_loss: 7.6082\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0339 - val_loss: 7.1157\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.0068 - val_loss: 7.7144\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.4518 - val_loss: 6.9907\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0570 - val_loss: 7.0998\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0569 - val_loss: 6.7116\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0437 - val_loss: 7.1439\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3071 - val_loss: 7.5731\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.0994 - val_loss: 7.2196\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9811 - val_loss: 6.9761\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1358 - val_loss: 7.1787\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0053 - val_loss: 7.1041\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0246 - val_loss: 7.0382\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9703 - val_loss: 6.9716\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9872 - val_loss: 7.1542\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9583 - val_loss: 6.8149\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1064 - val_loss: 6.8033\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0917 - val_loss: 6.9286\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9568 - val_loss: 7.3546\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1864 - val_loss: 6.9045\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0604 - val_loss: 6.9564\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0974 - val_loss: 6.6714\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2097 - val_loss: 7.5151\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1967 - val_loss: 6.7350\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0678 - val_loss: 6.7389\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0145 - val_loss: 7.1948\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9711 - val_loss: 6.9968\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9475 - val_loss: 7.3680\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2252 - val_loss: 7.6953\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9408 - val_loss: 6.8493\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0226 - val_loss: 7.6882\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3238 - val_loss: 7.3417\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1174 - val_loss: 7.3123\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1404 - val_loss: 7.1032\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2525 - val_loss: 7.0198\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0416 - val_loss: 7.0191\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0800 - val_loss: 7.0302\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1373 - val_loss: 7.5525\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3761 - val_loss: 7.3765\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1048 - val_loss: 7.0633\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0101 - val_loss: 7.0400\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9640 - val_loss: 6.9258\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.2596 - val_loss: 7.6658\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0489 - val_loss: 6.9827\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0213 - val_loss: 7.5064\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1499 - val_loss: 6.9320\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.2520 - val_loss: 7.2396\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9895 - val_loss: 7.0452\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1160 - val_loss: 7.3821\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9420 - val_loss: 7.2543\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0508 - val_loss: 7.2527\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0983 - val_loss: 7.5647\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4281 - val_loss: 7.5232\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0584 - val_loss: 7.2645\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1685 - val_loss: 6.9782\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1399 - val_loss: 7.1705\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9818 - val_loss: 7.0896\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9581 - val_loss: 6.7491\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2477 - val_loss: 6.9825\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1496 - val_loss: 6.7228\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2176 - val_loss: 7.7468\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9693 - val_loss: 7.3340\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9603 - val_loss: 7.0590\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0849 - val_loss: 7.1404\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1156 - val_loss: 7.3232\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1261 - val_loss: 7.1156\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9984 - val_loss: 7.4985\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2112 - val_loss: 7.0703\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9096 - val_loss: 7.3724\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9574 - val_loss: 7.3287\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0683 - val_loss: 7.1718\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9446 - val_loss: 7.0239\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9444 - val_loss: 6.9414\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.947 - 0s 90us/step - loss: 5.9847 - val_loss: 6.8683\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0119 - val_loss: 7.0698\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8882 - val_loss: 7.0153\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9565 - val_loss: 7.4914\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3277 - val_loss: 6.8342\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1163 - val_loss: 7.1635\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0601 - val_loss: 7.1926\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2177 - val_loss: 6.9768\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8469 - val_loss: 6.7812\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1131 - val_loss: 6.8120\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0436 - val_loss: 7.5586\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1585 - val_loss: 7.3085\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0172 - val_loss: 6.7987\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9851 - val_loss: 7.1412\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1401 - val_loss: 7.1068\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2821 - val_loss: 6.8249\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1344 - val_loss: 6.9282\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2940 - val_loss: 7.2452\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0562 - val_loss: 7.0515\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0839 - val_loss: 7.1813\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9755 - val_loss: 6.9590\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9944 - val_loss: 6.7587\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2029 - val_loss: 6.9467\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9803 - val_loss: 6.9918\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9570 - val_loss: 6.8840\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9632 - val_loss: 7.0557\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8881 - val_loss: 6.9761\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9993 - val_loss: 7.3820\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5237 - val_loss: 8.2465\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0197 - val_loss: 7.2703\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9367 - val_loss: 6.8188\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9444 - val_loss: 7.1541\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0554 - val_loss: 7.1982\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0106 - val_loss: 7.3150\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9406 - val_loss: 6.9978\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8998 - val_loss: 7.0661\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0545 - val_loss: 6.8034\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0391 - val_loss: 7.2380\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9579 - val_loss: 6.7134\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9355 - val_loss: 7.2229\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9256 - val_loss: 7.2699\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1563 - val_loss: 7.4239\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0858 - val_loss: 6.8585\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2408 - val_loss: 7.1414\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2692 - val_loss: 6.9893\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9737 - val_loss: 7.4366\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9853 - val_loss: 7.4012\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2053 - val_loss: 7.2880\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9154 - val_loss: 6.8444\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9285 - val_loss: 6.8932\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9190 - val_loss: 7.6574\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1589 - val_loss: 6.9350\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0974 - val_loss: 7.4454\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0721 - val_loss: 7.8623\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9861 - val_loss: 6.9638\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1512 - val_loss: 7.3504\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0923 - val_loss: 7.2631\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1994 - val_loss: 7.1563\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.9611 - val_loss: 7.1757\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1330 - val_loss: 7.2343\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.1851 - val_loss: 6.8358\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2070 - val_loss: 7.2829\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2756 - val_loss: 6.9701\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.9333 - val_loss: 7.2698\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.2349 - val_loss: 7.0536\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.0834 - val_loss: 6.9193\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9998 - val_loss: 7.0562\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9446 - val_loss: 7.1342\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9506 - val_loss: 7.1774\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0027 - val_loss: 7.7252\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1138 - val_loss: 7.0296\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1032 - val_loss: 6.7145\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0278 - val_loss: 6.7118\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8400 - val_loss: 7.1573\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0817 - val_loss: 6.9146\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0863 - val_loss: 6.9503\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0735 - val_loss: 7.2678\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0676 - val_loss: 7.0886\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9619 - val_loss: 6.8063\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1046 - val_loss: 6.7728\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9572 - val_loss: 7.3572\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9704 - val_loss: 6.8744\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8046 - val_loss: 6.8717\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0095 - val_loss: 7.2524\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8934 - val_loss: 6.8252\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9495 - val_loss: 6.8595\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3756 - val_loss: 7.4025\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0637 - val_loss: 6.6734\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0200 - val_loss: 7.2325\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1016 - val_loss: 6.9202\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9722 - val_loss: 6.6420\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9631 - val_loss: 6.8989\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8766 - val_loss: 7.3268\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2878 - val_loss: 6.7406\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9799 - val_loss: 6.7834\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4914 - val_loss: 7.2712\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1857 - val_loss: 7.4575\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0958 - val_loss: 6.9051\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8233 - val_loss: 6.9090\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0525 - val_loss: 6.8832\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9430 - val_loss: 6.7704\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9551 - val_loss: 6.7808\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0253 - val_loss: 7.6517\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0756 - val_loss: 6.8399\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9547 - val_loss: 7.2860\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1324 - val_loss: 7.7862\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1689 - val_loss: 7.7770\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9850 - val_loss: 7.3560\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1636 - val_loss: 6.8263\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9697 - val_loss: 7.2887\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9723 - val_loss: 6.9939\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8763 - val_loss: 7.8430\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9856 - val_loss: 7.2446\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0325 - val_loss: 6.8853\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9600 - val_loss: 7.2360\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1035 - val_loss: 6.8917\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0879 - val_loss: 6.8222\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9644 - val_loss: 7.0981\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9407 - val_loss: 6.6932\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9675 - val_loss: 7.0906\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0990 - val_loss: 7.2756\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9466 - val_loss: 6.8222\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8734 - val_loss: 6.7364\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0348 - val_loss: 7.1661\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9385 - val_loss: 7.0112\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8349 - val_loss: 6.7132\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8968 - val_loss: 7.8038\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0332 - val_loss: 6.8080\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0888 - val_loss: 6.6729\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9609 - val_loss: 6.7188\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9977 - val_loss: 7.1509\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9156 - val_loss: 7.2011\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9116 - val_loss: 7.3247\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1150 - val_loss: 6.5991\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0094 - val_loss: 6.7691\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8896 - val_loss: 7.1957\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8769 - val_loss: 6.7986\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9584 - val_loss: 6.7980\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0000 - val_loss: 6.9448\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0817 - val_loss: 6.9203\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8204 - val_loss: 6.9084\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8920 - val_loss: 7.1205\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1407 - val_loss: 6.9323\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1335 - val_loss: 7.1541\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0764 - val_loss: 6.8520\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0165 - val_loss: 7.4645\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9351 - val_loss: 6.7453\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9059 - val_loss: 6.7368\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0269 - val_loss: 6.8433\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8832 - val_loss: 7.1257\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9417 - val_loss: 6.9009\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8167 - val_loss: 7.2390\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9126 - val_loss: 6.7968\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9604 - val_loss: 6.7213\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9378 - val_loss: 7.7994\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9432 - val_loss: 6.8693\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0153 - val_loss: 7.0871\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9828 - val_loss: 7.0556\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9125 - val_loss: 6.9723\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9475 - val_loss: 7.2297\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9247 - val_loss: 7.1861\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9531 - val_loss: 6.9550\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1635 - val_loss: 6.8165\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8393 - val_loss: 6.8037\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8991 - val_loss: 7.4104\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1644 - val_loss: 7.4659\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0371 - val_loss: 6.8592\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9921 - val_loss: 7.3764\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2465 - val_loss: 7.2180\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9285 - val_loss: 6.9383\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8780 - val_loss: 7.4317\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8247 - val_loss: 6.8436\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7299 - val_loss: 6.8873\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8325 - val_loss: 7.3921\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7626 - val_loss: 6.6427\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7927 - val_loss: 6.8832\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7417 - val_loss: 6.9544\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7605 - val_loss: 7.0619\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7776 - val_loss: 7.5098\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8908 - val_loss: 6.5848\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5903 - val_loss: 6.7582\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8430 - val_loss: 6.6183\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7346 - val_loss: 7.1639\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8249 - val_loss: 6.9315\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7077 - val_loss: 6.4468\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8308 - val_loss: 6.6187\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6712 - val_loss: 6.9406\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4970 - val_loss: 6.4562\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5796 - val_loss: 7.1705\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8089 - val_loss: 6.7418\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7598 - val_loss: 6.6233\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5691 - val_loss: 6.4337\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7812 - val_loss: 7.1796\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7335 - val_loss: 6.6242\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7215 - val_loss: 6.3921\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4999 - val_loss: 7.3779\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9745 - val_loss: 6.7500\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6215 - val_loss: 6.4616\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5241 - val_loss: 6.5576\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8269 - val_loss: 6.9073\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6503 - val_loss: 6.9381\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5958 - val_loss: 6.6655\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6356 - val_loss: 7.0609\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6314 - val_loss: 6.5065\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6703 - val_loss: 6.8917\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6655 - val_loss: 6.6437\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6848 - val_loss: 6.4405\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5022 - val_loss: 6.4450\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7323 - val_loss: 6.6821\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6426 - val_loss: 6.7384\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4958 - val_loss: 6.6514\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5453 - val_loss: 6.5724\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7888 - val_loss: 6.3738\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4847 - val_loss: 6.7546\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8083 - val_loss: 6.5233\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6985 - val_loss: 6.2245\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6401 - val_loss: 7.1253\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6660 - val_loss: 6.3089\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5617 - val_loss: 6.5979\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.6243 - val_loss: 6.9431\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5754 - val_loss: 6.3577\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5423 - val_loss: 7.5714\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8061 - val_loss: 6.9018\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.6978 - val_loss: 6.5682\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.7986 - val_loss: 6.8620\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7075 - val_loss: 6.6109\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.5639 - val_loss: 6.9355\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.5584 - val_loss: 6.5689\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5133 - val_loss: 6.7561\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6607 - val_loss: 6.6783\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6181 - val_loss: 7.1430\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.4810 - val_loss: 6.5450\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7019 - val_loss: 6.6737\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6293 - val_loss: 6.6284\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5632 - val_loss: 6.9788\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5614 - val_loss: 6.8192\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5995 - val_loss: 6.4347\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4676 - val_loss: 6.9132\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6691 - val_loss: 6.7628\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6023 - val_loss: 6.5294\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6897 - val_loss: 6.6768\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6059 - val_loss: 6.9749\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7863 - val_loss: 6.5257\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9580 - val_loss: 6.7621\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5675 - val_loss: 6.4994\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5114 - val_loss: 6.5180\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5881 - val_loss: 6.3951\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5561 - val_loss: 7.0551\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6669 - val_loss: 6.3142\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7426 - val_loss: 6.8304\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6973 - val_loss: 6.4269\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6228 - val_loss: 6.4925\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4882 - val_loss: 6.3231\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5119 - val_loss: 6.4360\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4500 - val_loss: 6.5766\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8359 - val_loss: 6.8477\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5054 - val_loss: 7.1792\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5628 - val_loss: 6.1153\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4623 - val_loss: 6.3600\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5233 - val_loss: 6.7606\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7381 - val_loss: 6.3286\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5469 - val_loss: 6.5752\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5652 - val_loss: 6.4722\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5358 - val_loss: 6.7080\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6967 - val_loss: 7.0287\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4990 - val_loss: 6.4240\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6043 - val_loss: 6.5364\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6401 - val_loss: 6.3854\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6634 - val_loss: 6.4269\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.5590 - val_loss: 6.8228\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7375 - val_loss: 6.4488\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9181 - val_loss: 6.6415\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6457 - val_loss: 6.5790\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5799 - val_loss: 6.4635\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5866 - val_loss: 6.3147\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4079 - val_loss: 6.3580\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4911 - val_loss: 6.3968\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6652 - val_loss: 6.6922\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5522 - val_loss: 6.5104\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5945 - val_loss: 6.7277\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7165 - val_loss: 6.7942\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6720 - val_loss: 6.7341\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5800 - val_loss: 6.3550\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5688 - val_loss: 6.5043\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5295 - val_loss: 6.5569\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.7479 - val_loss: 6.4109\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6119 - val_loss: 6.4362\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4900 - val_loss: 6.2926\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5389 - val_loss: 6.5444\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7626 - val_loss: 6.3075\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.5997 - val_loss: 6.2576\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6086 - val_loss: 6.5381\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4424 - val_loss: 6.2601\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5493 - val_loss: 6.6254\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5753 - val_loss: 6.7219\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6456 - val_loss: 6.4293\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5796 - val_loss: 6.2490\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6351 - val_loss: 6.1839\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6681 - val_loss: 6.7586\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5192 - val_loss: 6.7337\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4093 - val_loss: 6.9976\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4532 - val_loss: 6.3122\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4861 - val_loss: 6.6646\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4889 - val_loss: 6.3654\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.6020 - val_loss: 6.4447\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5442 - val_loss: 6.2568\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6755 - val_loss: 6.9163\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5503 - val_loss: 6.6370\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.5369 - val_loss: 6.2682\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6818 - val_loss: 6.3345\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5046 - val_loss: 6.5262\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5924 - val_loss: 6.8348\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4405 - val_loss: 6.1204\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6879 - val_loss: 6.4037\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6093 - val_loss: 6.1505\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.5792 - val_loss: 6.4371\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.5710 - val_loss: 6.4900\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7422 - val_loss: 6.3826\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4932 - val_loss: 6.2366\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6733 - val_loss: 6.6890\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5644 - val_loss: 6.4156\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6795 - val_loss: 7.2259\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5757 - val_loss: 6.5963\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4930 - val_loss: 7.0599\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6664 - val_loss: 6.9777\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7758 - val_loss: 7.3277\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9058 - val_loss: 6.8980\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5904 - val_loss: 6.6582\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7693 - val_loss: 6.3914\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5001 - val_loss: 6.5171\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.5778 - val_loss: 6.5058\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5085 - val_loss: 6.7836\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6430 - val_loss: 6.3599\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6019 - val_loss: 6.5659\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5682 - val_loss: 6.3420\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4843 - val_loss: 6.9658\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5008 - val_loss: 6.6021\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.5658 - val_loss: 6.2912\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4564 - val_loss: 7.1820\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6689 - val_loss: 6.3503\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3663 - val_loss: 6.1893\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4590 - val_loss: 6.3250\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3848 - val_loss: 6.6693\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4362 - val_loss: 6.4651\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6084 - val_loss: 6.3865\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4426 - val_loss: 6.2759\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5479 - val_loss: 6.6174\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4908 - val_loss: 6.3168\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4315 - val_loss: 6.8927\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5280 - val_loss: 6.7120\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4810 - val_loss: 6.8806\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5594 - val_loss: 6.1574\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4130 - val_loss: 6.5251\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5750 - val_loss: 6.3836\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5110 - val_loss: 6.3681\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4735 - val_loss: 6.2640\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4862 - val_loss: 6.1623\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6791 - val_loss: 6.4316\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4235 - val_loss: 6.6920\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5004 - val_loss: 6.2965\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5001 - val_loss: 6.6048\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4120 - val_loss: 6.3076\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4969 - val_loss: 6.6337\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5698 - val_loss: 6.5435\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5876 - val_loss: 6.3222\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4723 - val_loss: 6.2621\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5425 - val_loss: 6.3807\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4691 - val_loss: 6.2981\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4668 - val_loss: 6.6450\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5534 - val_loss: 7.0086\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4888 - val_loss: 6.9644\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4591 - val_loss: 6.8424\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4910 - val_loss: 6.4082\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4117 - val_loss: 6.8499\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5866 - val_loss: 7.5399\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5039 - val_loss: 6.3577\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4922 - val_loss: 6.7964\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5352 - val_loss: 6.3718\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5767 - val_loss: 6.4071\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6230 - val_loss: 6.4127\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4640 - val_loss: 6.3008\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4754 - val_loss: 6.4804\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6231 - val_loss: 6.5510\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5094 - val_loss: 6.9624\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6830 - val_loss: 6.4456\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4150 - val_loss: 6.6471\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4043 - val_loss: 6.3175\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5241 - val_loss: 6.6007\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4212 - val_loss: 6.3884\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9329 - val_loss: 7.1778\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4186 - val_loss: 6.3215\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4971 - val_loss: 6.8031\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.4490 - val_loss: 6.4458\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5262 - val_loss: 6.0860\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4568 - val_loss: 6.4106\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4489 - val_loss: 6.5568\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6428 - val_loss: 6.1700\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5853 - val_loss: 6.7286\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6464 - val_loss: 6.5254\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5953 - val_loss: 6.7911\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6123 - val_loss: 6.7225\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6557 - val_loss: 6.2386\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6047 - val_loss: 6.9146\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5118 - val_loss: 6.1433\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3956 - val_loss: 6.5934\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4074 - val_loss: 6.5363\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6097 - val_loss: 6.6746\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7018 - val_loss: 6.8540\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7608 - val_loss: 6.7410\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3756 - val_loss: 6.2668\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3997 - val_loss: 6.5125\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5802 - val_loss: 7.0579\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5135 - val_loss: 7.2544\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8249 - val_loss: 6.4799\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5747 - val_loss: 6.9128\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5292 - val_loss: 6.6565\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4788 - val_loss: 6.5936\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5809 - val_loss: 6.4224\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5829 - val_loss: 6.4969\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4337 - val_loss: 6.4577\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4310 - val_loss: 6.5404\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3958 - val_loss: 6.3878\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3969 - val_loss: 6.4226\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4646 - val_loss: 6.5104\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5214 - val_loss: 6.2011\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5336 - val_loss: 6.2115\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.627 - 0s 84us/step - loss: 5.4611 - val_loss: 7.3604\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4286 - val_loss: 6.1310\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4541 - val_loss: 7.1637\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3823 - val_loss: 6.3073\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3469 - val_loss: 6.4542\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5964 - val_loss: 6.7175\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4771 - val_loss: 6.3452\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3782 - val_loss: 6.8624\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9374 - val_loss: 6.7265\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5700 - val_loss: 6.5394\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4228 - val_loss: 6.3934\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5672 - val_loss: 6.4255\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6242 - val_loss: 6.3848\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6152 - val_loss: 6.9653\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5950 - val_loss: 6.5211\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5841 - val_loss: 6.3646\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6240 - val_loss: 6.4471\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4933 - val_loss: 6.2806\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6653 - val_loss: 6.9229\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5150 - val_loss: 6.4383\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5873 - val_loss: 6.5489\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4733 - val_loss: 6.3915\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4362 - val_loss: 6.4145\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3775 - val_loss: 6.5635\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4603 - val_loss: 6.4248\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6406 - val_loss: 6.3204\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5371 - val_loss: 6.2964\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7050 - val_loss: 6.6195\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4728 - val_loss: 7.0748\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8610 - val_loss: 6.2683\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3719 - val_loss: 6.5195\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4338 - val_loss: 6.3950\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6308 - val_loss: 6.7600\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9251 - val_loss: 6.2643\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3202 - val_loss: 6.5653\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3600 - val_loss: 6.3428\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4324 - val_loss: 6.4331\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5064 - val_loss: 6.8762\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5741 - val_loss: 6.4400\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4139 - val_loss: 6.3765\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3735 - val_loss: 6.9138\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4879 - val_loss: 6.5980\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4160 - val_loss: 6.6892\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3562 - val_loss: 6.5224\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5862 - val_loss: 6.9998\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3496 - val_loss: 6.5456\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3625 - val_loss: 6.5976\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4020 - val_loss: 6.5086\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4555 - val_loss: 6.9584\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7910 - val_loss: 6.0897\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4227 - val_loss: 6.9966\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3774 - val_loss: 6.6691\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4486 - val_loss: 6.2285\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3606 - val_loss: 6.2110\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4222 - val_loss: 6.3341\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4076 - val_loss: 6.7700\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6267 - val_loss: 6.3108\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4826 - val_loss: 6.5744\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5902 - val_loss: 6.6090\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5051 - val_loss: 6.4398\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4666 - val_loss: 6.2150\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4951 - val_loss: 6.4731\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3870 - val_loss: 6.2314\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3228 - val_loss: 6.5179\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4109 - val_loss: 6.4321\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5613 - val_loss: 6.5611\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4230 - val_loss: 6.5531\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4026 - val_loss: 6.4066\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5291 - val_loss: 6.4625\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3424 - val_loss: 6.6287\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5917 - val_loss: 6.6312\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6660 - val_loss: 6.8651\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4858 - val_loss: 6.5212\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3991 - val_loss: 6.4205\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3613 - val_loss: 6.3357\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4165 - val_loss: 6.1399\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7753 - val_loss: 7.1171\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6094 - val_loss: 6.2432\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5502 - val_loss: 6.4125\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5584 - val_loss: 6.3592\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5010 - val_loss: 6.5268\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5106 - val_loss: 6.3388\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3636 - val_loss: 6.1841\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4613 - val_loss: 6.3439\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4372 - val_loss: 6.3709\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4940 - val_loss: 6.2456\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4226 - val_loss: 6.4941\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3493 - val_loss: 6.2417\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4189 - val_loss: 6.3046\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4232 - val_loss: 6.9397\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4019 - val_loss: 7.0467\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5563 - val_loss: 6.2560\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3884 - val_loss: 6.2907\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5588 - val_loss: 6.8196\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4062 - val_loss: 6.4605\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6042 - val_loss: 6.7078\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4532 - val_loss: 6.5141\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6434 - val_loss: 6.7706\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5230 - val_loss: 6.2812\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3816 - val_loss: 6.2184\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4980 - val_loss: 6.2842\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3859 - val_loss: 6.4234\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4114 - val_loss: 6.2470\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.4680 - val_loss: 6.1391\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4726 - val_loss: 6.2969\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4042 - val_loss: 6.5007\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5441 - val_loss: 6.2342\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4197 - val_loss: 6.6454\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5403 - val_loss: 6.1121\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5865 - val_loss: 6.3652\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3503 - val_loss: 6.2480\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4394 - val_loss: 6.2058\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4217 - val_loss: 6.3409\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3964 - val_loss: 6.3328\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4672 - val_loss: 6.3429\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4849 - val_loss: 7.0443\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4511 - val_loss: 6.4420\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5755 - val_loss: 6.2757\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3669 - val_loss: 6.5357\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4049 - val_loss: 6.6110\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3673 - val_loss: 6.4628\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4402 - val_loss: 6.9946\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4036 - val_loss: 6.5966\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4616 - val_loss: 7.0414\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4252 - val_loss: 6.3416\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4458 - val_loss: 6.2118\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2920 - val_loss: 6.2296\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5408 - val_loss: 6.6813\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.5455 - val_loss: 6.5177\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.5639 - val_loss: 6.4940\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4698 - val_loss: 6.1395\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.3743 - val_loss: 6.4014\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.4908 - val_loss: 6.2911\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.4956 - val_loss: 6.4719\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3822 - val_loss: 6.3413\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.3321 - val_loss: 6.3750\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3702 - val_loss: 6.4871\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6448 - val_loss: 6.2630\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4806 - val_loss: 6.9403\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5283 - val_loss: 6.8166\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4183 - val_loss: 6.7654\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3660 - val_loss: 6.2552\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5084 - val_loss: 6.5380\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4828 - val_loss: 6.1944\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6356 - val_loss: 6.6671\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3607 - val_loss: 6.6736\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3426 - val_loss: 6.1184\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3920 - val_loss: 6.3501\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4290 - val_loss: 6.1848\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3790 - val_loss: 6.7580\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3134 - val_loss: 6.0179\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6332 - val_loss: 6.4672\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3302 - val_loss: 6.8991\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4569 - val_loss: 6.3214\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5226 - val_loss: 6.4129\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2990 - val_loss: 6.6423\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4147 - val_loss: 6.3332\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3497 - val_loss: 6.1552\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4841 - val_loss: 6.4515\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4657 - val_loss: 6.2197\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3327 - val_loss: 6.1901\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4343 - val_loss: 6.4777\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4393 - val_loss: 6.6554\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6338 - val_loss: 6.6392\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4834 - val_loss: 6.6292\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3944 - val_loss: 6.7034\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3051 - val_loss: 6.5415\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3218 - val_loss: 6.8435\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6685 - val_loss: 6.3548\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4318 - val_loss: 6.5845\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3751 - val_loss: 6.5564\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3989 - val_loss: 6.5297\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4546 - val_loss: 6.2641\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3843 - val_loss: 6.1723\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3751 - val_loss: 7.5317\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5792 - val_loss: 6.4204\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5717 - val_loss: 6.3381\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4313 - val_loss: 6.3626\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3481 - val_loss: 6.1638\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4003 - val_loss: 6.3365\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4444 - val_loss: 6.4425\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4225 - val_loss: 6.7874\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5734 - val_loss: 6.5704\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3112 - val_loss: 6.5741\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3784 - val_loss: 7.0256\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5262 - val_loss: 6.3078\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3195 - val_loss: 6.2847\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4556 - val_loss: 6.7785\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4453 - val_loss: 6.6912\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3064 - val_loss: 6.2103\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3508 - val_loss: 6.1247\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4590 - val_loss: 6.6371\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4919 - val_loss: 6.5405\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4240 - val_loss: 6.3454\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5900 - val_loss: 6.2855\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4388 - val_loss: 6.6897\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5275 - val_loss: 6.6639\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2716 - val_loss: 6.0532\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4034 - val_loss: 6.5081\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3031 - val_loss: 6.3575\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3707 - val_loss: 6.5118\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4996 - val_loss: 6.2468\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3450 - val_loss: 6.5904\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3623 - val_loss: 6.1868\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3248 - val_loss: 6.2179\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3178 - val_loss: 6.2262\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2812 - val_loss: 6.2062\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3355 - val_loss: 6.6265\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3646 - val_loss: 6.3449\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4401 - val_loss: 6.6371\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4091 - val_loss: 6.5532\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5342 - val_loss: 5.9682\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4838 - val_loss: 6.4442\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3973 - val_loss: 6.3020\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2646 - val_loss: 6.4323\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4072 - val_loss: 6.1259\n",
      "4.8714130325654965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-5.0920196 , -0.26277733, -1.1332595 , -1.9088807 , -0.21591893],\n",
       "        [-0.17232013, -0.3951683 , -1.8251202 , -0.07073447,  0.15259446],\n",
       "        [-0.42864627, -3.0473502 , -0.6090515 , -0.97683996,  0.11518971],\n",
       "        [ 0.10663496,  0.06479504,  0.39682177,  0.50392634,  0.19545107],\n",
       "        [-0.6286738 , -0.4108839 , -0.06146777, -0.04667597, -0.12458198]],\n",
       "       dtype=float32),\n",
       " array([-1.7349565 , -1.2558692 ,  1.5949044 ,  0.18641746, -0.6460914 ],\n",
       "       dtype=float32),\n",
       " array([[ -2.0011518 ,  -2.2144256 ,   0.27939513,  17.805655  ,\n",
       "          -1.0098608 ,  -1.201983  ,  -0.9318017 ,  -0.61543185,\n",
       "          17.100153  ,  23.035322  ],\n",
       "        [  0.36211967,   0.4207473 , -36.443237  ,   5.472167  ,\n",
       "          -2.799814  ,  -0.42285696,  -0.5090485 ,  -1.9035214 ,\n",
       "           5.5702467 ,   0.46516478],\n",
       "        [  1.7966375 ,   0.6266629 ,   0.48500353,  17.445292  ,\n",
       "          -0.346704  ,  -0.05677722,  -0.44733915,  -0.41755545,\n",
       "          27.375526  ,   0.4886184 ],\n",
       "        [ -0.85297525,  29.537304  ,  -0.26007593,   0.0857691 ,\n",
       "          -0.05564754,   0.4744487 ,  -0.34514943,  -0.39023364,\n",
       "           0.09142949,   1.3419656 ],\n",
       "        [  0.72549963,   0.24869986,  -0.78019273,   0.439697  ,\n",
       "          -0.8461311 ,   0.794002  ,   0.15582047,  -1.2148097 ,\n",
       "           0.22563848,   1.015023  ]], dtype=float32),\n",
       " array([ 4.855766 ,  3.85739  , -3.1001182,  2.3221674, -2.3799424,\n",
       "         2.9275591,  1.3408992, -2.293346 ,  1.1825256,  0.6698591],\n",
       "       dtype=float32),\n",
       " array([[  8.902234 ],\n",
       "        [ 13.97432  ],\n",
       "        [-13.49907  ],\n",
       "        [ 13.723518 ],\n",
       "        [-13.729514 ],\n",
       "        [  8.285656 ],\n",
       "        [ -7.9462233],\n",
       "        [-13.640014 ],\n",
       "        [ 13.862234 ],\n",
       "        [ 13.737599 ]], dtype=float32),\n",
       " array([13.106861], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_tanh(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_tanh_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 664us/step - loss: 494.9005 - val_loss: 281.9612\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 197.0667 - val_loss: 67.4158\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 47.8938 - val_loss: 30.2069\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 26.9708 - val_loss: 26.0353\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 23.6446 - val_loss: 24.4050\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 21.8933 - val_loss: 21.9026\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.0536 - val_loss: 21.5679\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 17.3548 - val_loss: 20.4127\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.4381 - val_loss: 19.5745\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.4091 - val_loss: 18.1373\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 13.7938 - val_loss: 17.3567\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 13.5249 - val_loss: 16.2802\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.8866 - val_loss: 15.2260\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.3788 - val_loss: 14.3958\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.0778 - val_loss: 13.7620\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.4627 - val_loss: 12.7276\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.0639 - val_loss: 11.8174\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.6277 - val_loss: 11.0868\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.3986 - val_loss: 10.7073\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.9957 - val_loss: 10.6084\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.5587 - val_loss: 10.3962\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.3470 - val_loss: 9.9815\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.9656 - val_loss: 10.0551\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.7572 - val_loss: 10.0411\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7708 - val_loss: 9.9878\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5592 - val_loss: 10.0933\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5110 - val_loss: 9.8479\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3719 - val_loss: 9.7562\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4361 - val_loss: 9.7978\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2964 - val_loss: 9.7970\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2237 - val_loss: 9.7920\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2036 - val_loss: 9.8174\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2259 - val_loss: 10.0494\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0062 - val_loss: 9.7334\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9982 - val_loss: 9.5707\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0067 - val_loss: 9.7157\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9992 - val_loss: 9.5051\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0814 - val_loss: 9.4338\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8911 - val_loss: 9.7020\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9935 - val_loss: 9.3993\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.1669 - val_loss: 9.4781\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8849 - val_loss: 9.3925\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8194 - val_loss: 9.1021\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0753 - val_loss: 9.3838\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.6511 - val_loss: 9.4260\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5396 - val_loss: 9.4615\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5888 - val_loss: 9.2931\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.5188 - val_loss: 9.1511\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5149 - val_loss: 9.1730\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5836 - val_loss: 9.0548\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0421 - val_loss: 9.2268\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8358 - val_loss: 9.0606\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5149 - val_loss: 8.7411\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5510 - val_loss: 8.7512\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5432 - val_loss: 9.2277\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7960 - val_loss: 9.5196\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6931 - val_loss: 9.1899\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5408 - val_loss: 9.0239\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.4329 - val_loss: 9.0925\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4773 - val_loss: 8.9813\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2899 - val_loss: 8.7574\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4834 - val_loss: 8.5555\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.4455 - val_loss: 9.2764\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4059 - val_loss: 9.2848\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2562 - val_loss: 8.9188\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3010 - val_loss: 8.6801\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3746 - val_loss: 8.9193\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3800 - val_loss: 8.7274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5042 - val_loss: 9.0066\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.845 - 0s 98us/step - loss: 7.6119 - val_loss: 9.0384\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1910 - val_loss: 8.8557\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1903 - val_loss: 8.8043\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2424 - val_loss: 8.4116\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2392 - val_loss: 8.6803\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2011 - val_loss: 8.7476\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1438 - val_loss: 8.4847\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8014 - val_loss: 8.6297\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6121 - val_loss: 8.8639\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7611 - val_loss: 8.6173\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1994 - val_loss: 9.1039\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2257 - val_loss: 8.8040\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.4098 - val_loss: 8.5209\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2716 - val_loss: 8.7205\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1665 - val_loss: 8.8739\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2309 - val_loss: 8.4612\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1111 - val_loss: 8.7474\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1826 - val_loss: 8.7862\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4254 - val_loss: 8.7275\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8130 - val_loss: 8.2755\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4503 - val_loss: 8.2036\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4034 - val_loss: 8.3822\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0791 - val_loss: 8.8712\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0751 - val_loss: 8.6623\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3030 - val_loss: 8.9967\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0631 - val_loss: 8.3183\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9527 - val_loss: 8.7864\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1502 - val_loss: 8.6540\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9855 - val_loss: 8.7839\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0256 - val_loss: 8.5095\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9515 - val_loss: 8.3569\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9737 - val_loss: 8.4985\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9506 - val_loss: 8.6209\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1698 - val_loss: 8.3707\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2442 - val_loss: 8.6030\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0998 - val_loss: 8.3004\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1737 - val_loss: 8.3276\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1923 - val_loss: 8.1621\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9933 - val_loss: 8.9288\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1246 - val_loss: 8.6078\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9326 - val_loss: 8.4681\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8810 - val_loss: 8.2234\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0759 - val_loss: 8.1992\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1250 - val_loss: 8.3793\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1012 - val_loss: 8.2487\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8799 - val_loss: 8.3678\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9367 - val_loss: 8.3942\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8305 - val_loss: 8.1631\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8154 - val_loss: 8.4675\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8357 - val_loss: 8.4856\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8289 - val_loss: 8.2400\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8360 - val_loss: 8.3608\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9665 - val_loss: 8.2426\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9887 - val_loss: 8.0170\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8882 - val_loss: 8.1689\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8384 - val_loss: 8.1044\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8266 - val_loss: 8.4362\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9444 - val_loss: 8.5828\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8100 - val_loss: 8.4368\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1187 - val_loss: 8.3689\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 129us/step - loss: 7.3262 - val_loss: 8.1923\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9803 - val_loss: 8.1464\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9346 - val_loss: 8.3248\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9922 - val_loss: 8.2822\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9017 - val_loss: 8.6835\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9660 - val_loss: 8.3009\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7677 - val_loss: 8.3306\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8519 - val_loss: 8.3538\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8870 - val_loss: 8.2271\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7419 - val_loss: 8.4800\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8392 - val_loss: 8.2437\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0267 - val_loss: 8.5821\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6999 - val_loss: 8.3989\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0422 - val_loss: 8.1910\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9126 - val_loss: 8.5119\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0772 - val_loss: 8.4531\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.8025 - val_loss: 8.0851\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8163 - val_loss: 8.3585\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7120 - val_loss: 8.4917\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7521 - val_loss: 8.2397\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8413 - val_loss: 8.3727\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0741 - val_loss: 8.6625\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8450 - val_loss: 8.4007\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0415 - val_loss: 8.5407\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0575 - val_loss: 8.5966\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2657 - val_loss: 8.4328\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9013 - val_loss: 8.1817\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6936 - val_loss: 8.5910\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7884 - val_loss: 8.0523\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7316 - val_loss: 8.1452\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7168 - val_loss: 8.2710\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9031 - val_loss: 8.4718\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7943 - val_loss: 8.3783\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6888 - val_loss: 8.1102\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2971 - val_loss: 8.7593\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1114 - val_loss: 8.5079\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3325 - val_loss: 8.6402\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3651 - val_loss: 8.2647\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9381 - val_loss: 8.1522\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8246 - val_loss: 8.3919\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0095 - val_loss: 8.5499\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6827 - val_loss: 8.3122\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7328 - val_loss: 8.5926\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9366 - val_loss: 8.3460\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7179 - val_loss: 8.2388\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7313 - val_loss: 8.1788\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6574 - val_loss: 8.2421\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7009 - val_loss: 8.2016\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8220 - val_loss: 8.1712\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6233 - val_loss: 8.3076\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7211 - val_loss: 7.9032\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7064 - val_loss: 8.0172\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6884 - val_loss: 8.1426\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6571 - val_loss: 8.2764\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6794 - val_loss: 8.1866\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6411 - val_loss: 8.1884\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8115 - val_loss: 8.3143\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7745 - val_loss: 8.0161\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6811 - val_loss: 8.0074\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7049 - val_loss: 8.1097\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9585 - val_loss: 8.4010\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9293 - val_loss: 8.3218\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0314 - val_loss: 8.4474\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7661 - val_loss: 8.1727\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7545 - val_loss: 8.1469\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8199 - val_loss: 8.0732\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8657 - val_loss: 8.1658\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7214 - val_loss: 8.1786\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5996 - val_loss: 8.3223\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6883 - val_loss: 8.4706\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7889 - val_loss: 8.0629\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6768 - val_loss: 7.8815\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6662 - val_loss: 8.1504\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5878 - val_loss: 8.1064\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.8602 - val_loss: 8.1638\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9189 - val_loss: 8.2050\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7270 - val_loss: 8.1942\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6790 - val_loss: 8.4082\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7452 - val_loss: 8.0148\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7910 - val_loss: 8.0761\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0014 - val_loss: 8.1653\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1968 - val_loss: 8.0105\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7535 - val_loss: 8.2132\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6550 - val_loss: 8.0963\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8021 - val_loss: 8.3054\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7083 - val_loss: 8.1113\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6604 - val_loss: 8.4216\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5640 - val_loss: 8.2243\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7443 - val_loss: 8.3469\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8575 - val_loss: 8.1843\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6314 - val_loss: 8.3260\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6929 - val_loss: 8.1920\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8001 - val_loss: 8.2287\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.5984 - val_loss: 8.0767\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7135 - val_loss: 8.0592\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9545 - val_loss: 8.0884\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8105 - val_loss: 8.2885\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6090 - val_loss: 8.2467\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6311 - val_loss: 8.2186\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6094 - val_loss: 8.1707\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6099 - val_loss: 8.1463\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6228 - val_loss: 8.2584\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5861 - val_loss: 8.1205\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6246 - val_loss: 8.0677\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6427 - val_loss: 8.1349\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8282 - val_loss: 8.1423\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6159 - val_loss: 8.1080\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6486 - val_loss: 7.9221\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6627 - val_loss: 7.8096\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6623 - val_loss: 8.1509\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6088 - val_loss: 8.3082\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5496 - val_loss: 8.0696\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8411 - val_loss: 7.8483\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7229 - val_loss: 8.2633\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9079 - val_loss: 8.2678\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9967 - val_loss: 8.0301\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7374 - val_loss: 8.1830\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6683 - val_loss: 8.2327\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7279 - val_loss: 8.1923\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8617 - val_loss: 7.9785\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5140 - val_loss: 7.9620\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5967 - val_loss: 8.2272\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5284 - val_loss: 8.4478\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.6618 - val_loss: 8.3266\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8266 - val_loss: 8.2562\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7319 - val_loss: 8.0800\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5547 - val_loss: 8.1161\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5535 - val_loss: 8.2121\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6129 - val_loss: 8.2299\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5580 - val_loss: 8.1501\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5625 - val_loss: 8.3249\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6668 - val_loss: 8.0220\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8755 - val_loss: 8.3187\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9020 - val_loss: 8.1830\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5797 - val_loss: 8.0625\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6125 - val_loss: 8.2070\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6710 - val_loss: 8.0641\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6464 - val_loss: 8.1855\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6365 - val_loss: 8.0295\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6697 - val_loss: 8.2694\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5957 - val_loss: 8.1727\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7104 - val_loss: 8.2610\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5877 - val_loss: 8.1884\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5487 - val_loss: 8.1736\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7203 - val_loss: 8.2390\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6428 - val_loss: 8.2852\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7028 - val_loss: 8.3761\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6257 - val_loss: 8.0718\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6432 - val_loss: 7.8910\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6973 - val_loss: 7.9178\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7704 - val_loss: 8.1244\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6636 - val_loss: 8.1466\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6587 - val_loss: 8.2409\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7198 - val_loss: 8.0684\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6739 - val_loss: 8.1256\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6457 - val_loss: 7.8491\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6641 - val_loss: 8.2129\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.049 - 0s 98us/step - loss: 6.5830 - val_loss: 8.2359\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5514 - val_loss: 8.1460\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.187 - 0s 106us/step - loss: 6.8222 - val_loss: 8.1073\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6688 - val_loss: 8.2554\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5354 - val_loss: 8.1148\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6140 - val_loss: 7.9556\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5722 - val_loss: 7.9425\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5878 - val_loss: 8.0104\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9196 - val_loss: 8.3111\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8265 - val_loss: 8.2014\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5996 - val_loss: 8.1097\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6216 - val_loss: 8.2053\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7546 - val_loss: 8.1308\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.6836 - val_loss: 7.9795\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8597 - val_loss: 7.8270\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5403 - val_loss: 7.9392\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5282 - val_loss: 8.0692\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6412 - val_loss: 8.0824\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.6678 - val_loss: 8.2119\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7346 - val_loss: 8.4016\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7696 - val_loss: 7.9409\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7729 - val_loss: 7.9464\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4845 - val_loss: 8.2175\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5359 - val_loss: 8.1868\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5318 - val_loss: 8.0769\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5179 - val_loss: 8.1707\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7731 - val_loss: 8.2027\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7821 - val_loss: 8.0678\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6788 - val_loss: 8.1181\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8021 - val_loss: 8.2225\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5301 - val_loss: 8.2509\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5854 - val_loss: 8.1869\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6002 - val_loss: 8.1002\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6547 - val_loss: 7.9288\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6513 - val_loss: 8.3048\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0146 - val_loss: 7.9366\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6330 - val_loss: 8.0339\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5319 - val_loss: 8.2054\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6833 - val_loss: 8.3057\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6214 - val_loss: 8.1089\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5273 - val_loss: 8.0898\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6528 - val_loss: 7.8990\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6371 - val_loss: 8.1795\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6156 - val_loss: 8.1588\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5529 - val_loss: 8.1535\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7421 - val_loss: 8.2898\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4582 - val_loss: 8.2609\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7727 - val_loss: 8.1032\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5316 - val_loss: 8.1337\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6481 - val_loss: 7.9415\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7842 - val_loss: 8.0555\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5252 - val_loss: 8.4363\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6998 - val_loss: 8.2108\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8535 - val_loss: 8.4425\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6940 - val_loss: 8.2554\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7634 - val_loss: 8.5787\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7511 - val_loss: 8.0570\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5398 - val_loss: 8.1738\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5766 - val_loss: 8.0053\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6694 - val_loss: 8.1452\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6584 - val_loss: 8.1972\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7125 - val_loss: 8.1701\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6832 - val_loss: 8.4148\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8347 - val_loss: 7.8666\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4883 - val_loss: 8.1241\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5665 - val_loss: 7.9677\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6020 - val_loss: 8.0402\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6277 - val_loss: 8.1560\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5228 - val_loss: 8.2505\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6176 - val_loss: 8.1551\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5569 - val_loss: 8.0221\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6491 - val_loss: 8.0854\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5081 - val_loss: 7.9372\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4540 - val_loss: 8.0154\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5023 - val_loss: 8.0565\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5133 - val_loss: 8.2305\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5385 - val_loss: 8.0409\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4853 - val_loss: 8.2715\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5773 - val_loss: 8.2908\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6884 - val_loss: 7.9870\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6317 - val_loss: 7.9852\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5343 - val_loss: 8.1314\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4943 - val_loss: 8.0481\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5193 - val_loss: 8.0001\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7006 - val_loss: 8.0833\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5937 - val_loss: 8.1507\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5375 - val_loss: 8.3450\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4865 - val_loss: 8.0709\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7321 - val_loss: 8.0386\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8207 - val_loss: 7.9316\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.5633 - val_loss: 8.0414\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6787 - val_loss: 8.0568\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6790 - val_loss: 8.0100\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6252 - val_loss: 8.1909\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5777 - val_loss: 8.0101\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5088 - val_loss: 7.9803\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5205 - val_loss: 8.2911\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5029 - val_loss: 7.9053\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6018 - val_loss: 8.0707\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9963 - val_loss: 8.0074\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7390 - val_loss: 8.0743\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5809 - val_loss: 7.8250\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7056 - val_loss: 7.8637\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6267 - val_loss: 7.9698\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6337 - val_loss: 8.0817\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5433 - val_loss: 8.1294\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5126 - val_loss: 8.1705\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5632 - val_loss: 8.0894\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5225 - val_loss: 8.0745\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5225 - val_loss: 8.0417\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6852 - val_loss: 7.9697\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7183 - val_loss: 7.9687\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6277 - val_loss: 8.1265\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4879 - val_loss: 8.0796\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8474 - val_loss: 8.3783\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9990 - val_loss: 8.0223\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9622 - val_loss: 7.9315\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7577 - val_loss: 8.1093\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8845 - val_loss: 8.1392\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8121 - val_loss: 7.9941\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4895 - val_loss: 7.8680\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6097 - val_loss: 7.8779\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5906 - val_loss: 8.4324\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5294 - val_loss: 8.3191\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5986 - val_loss: 7.9719\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6784 - val_loss: 7.9129\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8336 - val_loss: 8.0136\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6164 - val_loss: 7.9964\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5543 - val_loss: 8.3148\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5035 - val_loss: 8.1066\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6549 - val_loss: 7.9829\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4818 - val_loss: 7.9887\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4928 - val_loss: 8.1130\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5872 - val_loss: 8.0651\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5763 - val_loss: 8.4565\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6109 - val_loss: 8.2033\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5317 - val_loss: 8.0358\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5954 - val_loss: 7.9648\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8480 - val_loss: 8.2297\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1453 - val_loss: 8.1407\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5224 - val_loss: 7.8666\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5223 - val_loss: 7.8821\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6075 - val_loss: 7.9657\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6748 - val_loss: 7.8520\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5429 - val_loss: 7.8188\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5139 - val_loss: 8.1778\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5334 - val_loss: 8.2280\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5395 - val_loss: 8.0466\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6708 - val_loss: 7.9842\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4252 - val_loss: 8.1630\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6379 - val_loss: 7.8858\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5528 - val_loss: 7.9672\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6075 - val_loss: 8.1348\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5187 - val_loss: 8.2483\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6986 - val_loss: 7.9266\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5446 - val_loss: 8.0203\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5114 - val_loss: 7.9705\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5343 - val_loss: 8.3826\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5341 - val_loss: 8.0797\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6139 - val_loss: 8.1233\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4674 - val_loss: 7.8687\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7089 - val_loss: 7.9196\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8800 - val_loss: 7.9285\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5943 - val_loss: 8.0222\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6656 - val_loss: 7.8830\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6286 - val_loss: 7.8141\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6198 - val_loss: 7.9661\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4990 - val_loss: 8.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6153 - val_loss: 8.0629\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7197 - val_loss: 7.9578\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6267 - val_loss: 7.9848\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6013 - val_loss: 7.9912\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6559 - val_loss: 8.0692\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6123 - val_loss: 7.9733\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5801 - val_loss: 8.2417\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8300 - val_loss: 8.1612\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6465 - val_loss: 8.2124\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6483 - val_loss: 8.0100\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6617 - val_loss: 7.8598\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5206 - val_loss: 7.9988\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6437 - val_loss: 8.0291\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4619 - val_loss: 8.0432\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4595 - val_loss: 7.9673\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5608 - val_loss: 7.8260\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4708 - val_loss: 8.0460\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5018 - val_loss: 8.0962\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5661 - val_loss: 8.0725\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0205 - val_loss: 8.1596\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3350 - val_loss: 8.4733\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0362 - val_loss: 8.1536\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0327 - val_loss: 8.1384\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5064 - val_loss: 8.1564\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7300 - val_loss: 8.1495\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6079 - val_loss: 7.9041\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7232 - val_loss: 7.9430\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5082 - val_loss: 8.0003\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5370 - val_loss: 7.8479\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4310 - val_loss: 7.8430\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4755 - val_loss: 8.0527\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5740 - val_loss: 8.1328\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4892 - val_loss: 8.0737\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4897 - val_loss: 7.9012\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4837 - val_loss: 7.7554\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6200 - val_loss: 7.9046\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5388 - val_loss: 8.0374\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6355 - val_loss: 8.1391\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6692 - val_loss: 8.1175\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5974 - val_loss: 7.9122\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5742 - val_loss: 7.8860\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5544 - val_loss: 7.9375\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5997 - val_loss: 8.0277\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5133 - val_loss: 8.0367\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6029 - val_loss: 8.0996\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5325 - val_loss: 7.9202\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0368 - val_loss: 8.1188\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2318 - val_loss: 8.4510\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1656 - val_loss: 8.1372\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6222 - val_loss: 8.0739\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6144 - val_loss: 7.9598\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5994 - val_loss: 7.9903\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4867 - val_loss: 8.1297\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4816 - val_loss: 8.0938\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8398 - val_loss: 7.8232\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6625 - val_loss: 8.0756\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8419 - val_loss: 8.1051\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8632 - val_loss: 8.1072\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7396 - val_loss: 7.9332\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6156 - val_loss: 8.1998\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8171 - val_loss: 8.0405\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9797 - val_loss: 8.1610\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4294 - val_loss: 8.0533\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8099 - val_loss: 8.0260\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7499 - val_loss: 7.8784\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5217 - val_loss: 8.1431\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6075 - val_loss: 8.0406\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7511 - val_loss: 8.0782\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5733 - val_loss: 7.9242\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5357 - val_loss: 8.1372\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5310 - val_loss: 7.9693\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4549 - val_loss: 7.8417\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5104 - val_loss: 7.9840\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6493 - val_loss: 8.2063\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5628 - val_loss: 8.1924\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5755 - val_loss: 7.9766\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5620 - val_loss: 8.0576\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.6059 - val_loss: 7.8125\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5135 - val_loss: 7.9647\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5169 - val_loss: 7.8798\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5204 - val_loss: 8.1234\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5667 - val_loss: 8.1316\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6121 - val_loss: 8.1222\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6161 - val_loss: 7.8224\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6973 - val_loss: 8.0016\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5880 - val_loss: 8.0259\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5277 - val_loss: 7.9925\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9119 - val_loss: 7.7957\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6610 - val_loss: 7.8824\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6852 - val_loss: 7.9953\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7136 - val_loss: 8.0031\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5146 - val_loss: 8.0031\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6363 - val_loss: 8.3064\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6361 - val_loss: 8.1355\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5928 - val_loss: 8.0058\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1645 - val_loss: 7.9017\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9483 - val_loss: 8.0239\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6892 - val_loss: 8.1169\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8462 - val_loss: 8.2513\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7243 - val_loss: 8.1919\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4971 - val_loss: 7.8129\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4506 - val_loss: 7.8372\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6674 - val_loss: 8.0037\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4586 - val_loss: 7.9576\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5003 - val_loss: 7.9241\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5029 - val_loss: 7.9663\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5889 - val_loss: 8.0682\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7367 - val_loss: 8.1586\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.125 - 0s 102us/step - loss: 6.4604 - val_loss: 8.1030\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7060 - val_loss: 7.9169\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6386 - val_loss: 8.2352\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4390 - val_loss: 8.0180\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7531 - val_loss: 7.9125\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3452 - val_loss: 8.3098\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9539 - val_loss: 8.2609\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9165 - val_loss: 8.2596\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8036 - val_loss: 7.8275\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8451 - val_loss: 8.0782\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6038 - val_loss: 7.9750\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5673 - val_loss: 8.0536\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5132 - val_loss: 8.0216\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5149 - val_loss: 8.1240\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6725 - val_loss: 8.0728\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8913 - val_loss: 8.1793\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8248 - val_loss: 7.8796\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2498 - val_loss: 8.1679\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8542 - val_loss: 7.8861\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4697 - val_loss: 8.1926\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0009 - val_loss: 8.0391\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7228 - val_loss: 8.0675\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5346 - val_loss: 8.3589\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7400 - val_loss: 8.1893\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7318 - val_loss: 8.0338\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5488 - val_loss: 7.9684\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6005 - val_loss: 8.1187\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6302 - val_loss: 7.9539\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6849 - val_loss: 8.0139\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9085 - val_loss: 7.7972\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4487 - val_loss: 7.8517\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4787 - val_loss: 7.8312\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7842 - val_loss: 8.0735\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6347 - val_loss: 8.1024\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6027 - val_loss: 8.1493\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5158 - val_loss: 7.8757\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5532 - val_loss: 8.1587\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6091 - val_loss: 8.1073\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5943 - val_loss: 7.9238\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5537 - val_loss: 7.8816\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5918 - val_loss: 8.0843\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6041 - val_loss: 7.8498\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5107 - val_loss: 8.0901\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5962 - val_loss: 8.2485\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5673 - val_loss: 8.1760\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4624 - val_loss: 7.8871\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.5623 - val_loss: 8.0307\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6023 - val_loss: 8.1876\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7009 - val_loss: 7.9659\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4531 - val_loss: 7.7933\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6753 - val_loss: 7.9678\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4954 - val_loss: 7.9531\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5959 - val_loss: 7.7861\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5746 - val_loss: 8.1253\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4520 - val_loss: 7.9653\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4499 - val_loss: 8.0926\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6074 - val_loss: 7.7504\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5151 - val_loss: 7.8226\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.04 - 0s 98us/step - loss: 6.7588 - val_loss: 8.1124\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5264 - val_loss: 8.0607\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5492 - val_loss: 7.9849\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4371 - val_loss: 7.9452\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4969 - val_loss: 7.8015\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4663 - val_loss: 8.0116\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5714 - val_loss: 8.1105\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5789 - val_loss: 7.9699\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5533 - val_loss: 7.9317\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8268 - val_loss: 7.9320\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6125 - val_loss: 7.9692\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1928 - val_loss: 7.8655\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3406 - val_loss: 8.1368\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9596 - val_loss: 8.0784\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4745 - val_loss: 8.0037\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5387 - val_loss: 8.0196\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4381 - val_loss: 7.9306\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5794 - val_loss: 8.0329\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4839 - val_loss: 8.0532\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6584 - val_loss: 8.0099\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6138 - val_loss: 8.0040\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5161 - val_loss: 7.9899\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4978 - val_loss: 7.7978\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4531 - val_loss: 7.7502\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4359 - val_loss: 7.8370\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5719 - val_loss: 8.1556\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5970 - val_loss: 7.9934\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5584 - val_loss: 8.1603\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.6567 - val_loss: 8.1015\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4469 - val_loss: 8.1102\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4929 - val_loss: 8.1205\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4487 - val_loss: 8.0701\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4861 - val_loss: 7.9295\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5589 - val_loss: 7.8336\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6241 - val_loss: 8.1083\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7695 - val_loss: 8.2615\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6193 - val_loss: 8.2452\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5498 - val_loss: 7.8541\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4846 - val_loss: 7.9802\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4503 - val_loss: 8.0641\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6430 - val_loss: 7.9975\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6478 - val_loss: 8.0319\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4758 - val_loss: 8.0612\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7056 - val_loss: 7.9287\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6344 - val_loss: 7.8546\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5451 - val_loss: 8.0319\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5610 - val_loss: 8.1790\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6164 - val_loss: 7.8887\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4422 - val_loss: 7.8074\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5831 - val_loss: 8.0050\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6328 - val_loss: 8.0057\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5675 - val_loss: 8.0930\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6782 - val_loss: 7.7591\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4562 - val_loss: 7.7853\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5202 - val_loss: 7.8257\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4543 - val_loss: 8.0211\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5239 - val_loss: 7.9184\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4409 - val_loss: 7.9094\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5732 - val_loss: 7.8156\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.4659 - val_loss: 7.9288\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5237 - val_loss: 7.9806\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5076 - val_loss: 7.9217\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4530 - val_loss: 7.9264\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5353 - val_loss: 7.8464\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.4698 - val_loss: 7.7992\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.4376 - val_loss: 7.8092\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4998 - val_loss: 8.0851\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5151 - val_loss: 7.9747\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5028 - val_loss: 8.0008\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7165 - val_loss: 7.9818\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.0628 - val_loss: 7.8761\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8473 - val_loss: 8.0990\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7981 - val_loss: 8.1896\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6856 - val_loss: 8.2828\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5861 - val_loss: 7.9242\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4424 - val_loss: 8.2149\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5704 - val_loss: 8.1907\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6791 - val_loss: 7.9170\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5611 - val_loss: 7.9130\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5204 - val_loss: 7.8266\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5003 - val_loss: 8.0578\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5095 - val_loss: 8.1448\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4778 - val_loss: 7.9800\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5275 - val_loss: 7.7957\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4754 - val_loss: 7.9032\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5069 - val_loss: 8.0459\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4363 - val_loss: 8.0409\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4841 - val_loss: 7.9342\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6783 - val_loss: 8.2099\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5380 - val_loss: 7.9997\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6432 - val_loss: 8.1065\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5208 - val_loss: 7.8312\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4760 - val_loss: 7.8722\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5210 - val_loss: 7.8755\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5065 - val_loss: 7.8974\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4598 - val_loss: 7.9989\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5446 - val_loss: 7.9281\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5242 - val_loss: 8.0636\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4699 - val_loss: 7.9020\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4655 - val_loss: 7.9405\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5158 - val_loss: 8.1509\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6894 - val_loss: 7.9825\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5088 - val_loss: 8.0461\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5961 - val_loss: 7.8859\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7109 - val_loss: 7.9456\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6771 - val_loss: 8.0471\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7000 - val_loss: 8.0714\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5743 - val_loss: 7.9427\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6249 - val_loss: 8.0881\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7506 - val_loss: 8.0968\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5291 - val_loss: 7.8777\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6416 - val_loss: 8.0093\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4737 - val_loss: 8.1915\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4911 - val_loss: 7.9843\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5223 - val_loss: 7.8621\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4860 - val_loss: 7.9302\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5683 - val_loss: 8.0542\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5246 - val_loss: 8.0405\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4888 - val_loss: 8.0105\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3911 - val_loss: 7.9348\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4354 - val_loss: 8.0251\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5148 - val_loss: 8.1263\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6113 - val_loss: 8.0298\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5394 - val_loss: 8.3566\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5449 - val_loss: 8.0571\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5785 - val_loss: 7.9008\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5779 - val_loss: 7.9760\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6191 - val_loss: 8.1108\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5798 - val_loss: 8.1323\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5255 - val_loss: 8.2184\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6093 - val_loss: 7.9975\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4934 - val_loss: 7.9317\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9452 - val_loss: 8.1390\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6770 - val_loss: 8.0215\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7984 - val_loss: 8.0704\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4390 - val_loss: 7.9704\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5248 - val_loss: 7.9577\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4705 - val_loss: 7.9362\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5122 - val_loss: 8.0377\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5153 - val_loss: 8.3457\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7686 - val_loss: 8.3051\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7656 - val_loss: 8.0122\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.5074 - val_loss: 8.0961\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5497 - val_loss: 8.1656\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8764 - val_loss: 7.8783\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6997 - val_loss: 7.9969\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6166 - val_loss: 8.2006\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4852 - val_loss: 8.1544\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5568 - val_loss: 8.0087\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4253 - val_loss: 8.1846\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5325 - val_loss: 8.1025\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8428 - val_loss: 8.4967\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5804 - val_loss: 8.0084\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4035 - val_loss: 8.0590\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4595 - val_loss: 8.0471\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4191 - val_loss: 8.1739\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6088 - val_loss: 8.3145\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4861 - val_loss: 8.1277\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6086 - val_loss: 8.0749\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5696 - val_loss: 7.8230\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4363 - val_loss: 7.9254\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5339 - val_loss: 8.0513\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5475 - val_loss: 8.0811\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5527 - val_loss: 8.2381\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4615 - val_loss: 8.1529\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4270 - val_loss: 8.1777\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4411 - val_loss: 8.2075\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3998 - val_loss: 8.2282\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4294 - val_loss: 8.1260\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5084 - val_loss: 8.1189\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6764 - val_loss: 8.1602\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4294 - val_loss: 8.2872\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3794 - val_loss: 7.9560\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4890 - val_loss: 7.8255\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4979 - val_loss: 7.9890\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7138 - val_loss: 8.1294\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4511 - val_loss: 7.9275\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6568 - val_loss: 7.9601\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5060 - val_loss: 8.4032\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6635 - val_loss: 8.0971\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5359 - val_loss: 8.1853\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4751 - val_loss: 8.1736\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4265 - val_loss: 8.3807\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4835 - val_loss: 7.9332\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4979 - val_loss: 8.0197\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4944 - val_loss: 8.3134\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4460 - val_loss: 8.1582\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5009 - val_loss: 8.0914\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4145 - val_loss: 8.5512\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6255 - val_loss: 8.0928\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4084 - val_loss: 8.1428\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5505 - val_loss: 8.1110\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.5875 - val_loss: 8.2593\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5206 - val_loss: 8.0565\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8571 - val_loss: 8.1726\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.6192 - val_loss: 7.9159\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4774 - val_loss: 7.9670\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5676 - val_loss: 8.1713\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5350 - val_loss: 8.1430\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4252 - val_loss: 8.0746\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4298 - val_loss: 8.3026\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4776 - val_loss: 7.9902\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4454 - val_loss: 7.9217\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.4199 - val_loss: 7.8042\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.5201 - val_loss: 7.8659\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4613 - val_loss: 8.3261\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4410 - val_loss: 8.1655\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5295 - val_loss: 8.3453\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.3756 - val_loss: 8.2213\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5951 - val_loss: 8.1621\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7611 - val_loss: 8.4707\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5479 - val_loss: 8.2423\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4620 - val_loss: 8.1694\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7904 - val_loss: 8.1236\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6163 - val_loss: 8.3623\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4355 - val_loss: 8.2727\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4834 - val_loss: 8.3688\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6111 - val_loss: 8.2117\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6031 - val_loss: 8.1895\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.3778 - val_loss: 8.2995\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6241 - val_loss: 8.5091\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4607 - val_loss: 8.3010\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7108 - val_loss: 8.2969\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6446 - val_loss: 8.2799\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8570 - val_loss: 8.5198\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6066 - val_loss: 8.3271\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6290 - val_loss: 8.2453\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4943 - val_loss: 8.3247\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7273 - val_loss: 8.3941\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4199 - val_loss: 8.2429\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4573 - val_loss: 8.0408\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4367 - val_loss: 8.3791\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4579 - val_loss: 8.3254\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5218 - val_loss: 8.2769\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4839 - val_loss: 8.0710\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5131 - val_loss: 8.1466\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5687 - val_loss: 7.9552\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6677 - val_loss: 8.4305\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4218 - val_loss: 8.1712\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6632 - val_loss: 8.2330\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5381 - val_loss: 8.0575\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4680 - val_loss: 8.1636\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4931 - val_loss: 8.2957\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4805 - val_loss: 8.1946\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4287 - val_loss: 8.2825\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6419 - val_loss: 8.2474\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5380 - val_loss: 8.0864\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4626 - val_loss: 7.9904\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4123 - val_loss: 8.0966\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5101 - val_loss: 8.4465\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.4604 - val_loss: 8.3630\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5074 - val_loss: 8.1387\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5499 - val_loss: 8.2200\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4244 - val_loss: 8.1456\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4540 - val_loss: 8.0900\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3664 - val_loss: 8.3022\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4498 - val_loss: 8.1504\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3791 - val_loss: 8.2821\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4621 - val_loss: 8.2181\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6534 - val_loss: 8.2839\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5818 - val_loss: 7.9616\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5686 - val_loss: 8.0816\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4329 - val_loss: 8.2881\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4771 - val_loss: 8.3332\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4512 - val_loss: 8.3007\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4679 - val_loss: 8.1553\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4653 - val_loss: 8.4033\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7210 - val_loss: 8.2057\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5891 - val_loss: 8.1643\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7928 - val_loss: 8.2651\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7049 - val_loss: 8.1550\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5441 - val_loss: 8.2397\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5276 - val_loss: 8.0581\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3788 - val_loss: 8.3338\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3609 - val_loss: 8.4108\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4579 - val_loss: 8.2373\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5636 - val_loss: 8.1035\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5594 - val_loss: 8.2445\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9673 - val_loss: 8.7206\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7083 - val_loss: 8.5663\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4206 - val_loss: 8.4549\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4458 - val_loss: 8.0945\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4103 - val_loss: 8.2077\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4041 - val_loss: 8.3331\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3953 - val_loss: 8.3225\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5107 - val_loss: 8.3924\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9070 - val_loss: 8.4432\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7603 - val_loss: 8.1068\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5863 - val_loss: 8.0328\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6022 - val_loss: 7.9591\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4427 - val_loss: 8.3371\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3969 - val_loss: 8.0768\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4039 - val_loss: 8.1278\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5739 - val_loss: 7.9859\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5087 - val_loss: 8.1765\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4284 - val_loss: 8.0607\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.3954 - val_loss: 8.3374\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3927 - val_loss: 8.4145\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3501 - val_loss: 8.3103\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4328 - val_loss: 8.2900\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3731 - val_loss: 8.1240\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4896 - val_loss: 8.2262\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7082 - val_loss: 8.3961\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5002 - val_loss: 8.1301\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4267 - val_loss: 8.1068\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3568 - val_loss: 7.9785\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3573 - val_loss: 7.9579\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3397 - val_loss: 8.0145\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4476 - val_loss: 8.1669\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5525 - val_loss: 8.3662\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5241 - val_loss: 8.3818\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6131 - val_loss: 8.3205\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3507 - val_loss: 8.2317\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4383 - val_loss: 8.1502\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5135 - val_loss: 8.2607\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4398 - val_loss: 8.2120\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5922 - val_loss: 7.9718\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1612 - val_loss: 8.2178\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6034 - val_loss: 8.0365\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6580 - val_loss: 8.1097\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5521 - val_loss: 8.0600\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.5230 - val_loss: 8.0786\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5024 - val_loss: 8.2962\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.3726 - val_loss: 8.3552\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4196 - val_loss: 8.4774\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4556 - val_loss: 8.2933\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4580 - val_loss: 8.2210\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3375 - val_loss: 8.3059\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3677 - val_loss: 8.3460\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3442 - val_loss: 8.5313\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3705 - val_loss: 8.1924\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6307 - val_loss: 8.2498\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3267 - val_loss: 8.2228\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5457 - val_loss: 8.2195\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3657 - val_loss: 8.3759\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5865 - val_loss: 8.4841\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3874 - val_loss: 8.2525\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6285 - val_loss: 7.9390\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4000 - val_loss: 8.0317\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3736 - val_loss: 8.2956\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3031 - val_loss: 8.4577\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4427 - val_loss: 8.4142\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4576 - val_loss: 8.2557\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4350 - val_loss: 7.9625\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3548 - val_loss: 8.0742\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4467 - val_loss: 8.2271\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4282 - val_loss: 8.3130\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4111 - val_loss: 8.3592\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3991 - val_loss: 8.1530\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3342 - val_loss: 8.2194\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7078 - val_loss: 8.0722\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5685 - val_loss: 8.1898\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4564 - val_loss: 8.3083\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5084 - val_loss: 8.2405\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5455 - val_loss: 8.2028\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3391 - val_loss: 8.2286\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3520 - val_loss: 8.3404\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3438 - val_loss: 8.1415\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6861 - val_loss: 8.1896\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5129 - val_loss: 8.1303\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6091 - val_loss: 8.7253\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5125 - val_loss: 8.3411\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4708 - val_loss: 8.0043\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9504 - val_loss: 8.5055\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.2904 - val_loss: 8.2210\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8498 - val_loss: 8.6188\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7009 - val_loss: 8.1954\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2772 - val_loss: 8.1227\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4070 - val_loss: 8.0565\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3641 - val_loss: 8.1864\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5718 - val_loss: 8.3929\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3855 - val_loss: 8.2767\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6574 - val_loss: 8.5721\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.4272 - val_loss: 8.3854\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5074 - val_loss: 8.1805\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3228 - val_loss: 8.1996\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5378 - val_loss: 8.3418\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4074 - val_loss: 8.4241\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4945 - val_loss: 8.3948\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4947 - val_loss: 8.1553\n",
      "7.9775951191530385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.4557352 , -1.4603144 ,  0.00431802,  0.77965033,  2.313337  ],\n",
       "        [-3.5607557 ,  1.6285157 ,  0.39313743, -0.7056128 ,  2.1320572 ],\n",
       "        [-1.1097881 , -1.0705929 ,  0.33621332,  0.47667104, -1.7753912 ],\n",
       "        [ 1.692369  , -1.8316298 ,  0.32906792,  0.74673444,  0.02705619],\n",
       "        [ 0.36476725,  1.1165972 ,  0.17069489, -0.68670243, -0.1489947 ],\n",
       "        [-1.0247089 ,  1.1996968 , -0.12543444, -0.32168117,  2.2006674 ],\n",
       "        [ 0.10253755, -0.09364851, -0.39647064,  0.4227315 , -0.32811204]],\n",
       "       dtype=float32),\n",
       " array([ 2.154013  ,  0.14802763,  0.14071143, -0.28499466,  2.2767975 ],\n",
       "       dtype=float32),\n",
       " array([[-0.51445085, -0.7866926 , -0.04045059, -0.36563706,  0.5629598 ,\n",
       "         -0.56360126,  0.05057036, -0.83417493, -0.7739682 ,  0.3012023 ],\n",
       "        [-0.20488733, -0.36186048, -0.0580551 , -0.561227  ,  0.77993053,\n",
       "         -0.44420603,  0.85518086,  0.2302954 , -0.39225513,  0.07703407],\n",
       "        [-1.0661572 , -0.9134894 , -1.2018791 , -1.4237635 ,  1.10383   ,\n",
       "         -0.7319367 ,  0.859751  , -0.8960106 , -1.4372355 ,  0.9763229 ],\n",
       "        [-1.0921994 ,  0.11643899, -1.17911   , -0.5646415 ,  0.6288937 ,\n",
       "         -1.0226791 ,  0.88071567, -0.45699182, -0.4799963 ,  1.0446336 ],\n",
       "        [ 0.34050804, -0.10553394,  0.5784122 ,  0.25013345, -0.07779051,\n",
       "         -0.11555154, -0.14497761, -0.14744325,  0.42855373, -0.4286359 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.8726432,  1.4018645,  1.8281866,  2.016544 , -1.5334073,\n",
       "         1.9676758, -1.8990862,  1.9843392,  2.0901392, -1.8677739],\n",
       "       dtype=float32),\n",
       " array([[ 1.6718942 ],\n",
       "        [ 0.24625671],\n",
       "        [ 1.3637028 ],\n",
       "        [ 1.2601411 ],\n",
       "        [-0.5557145 ],\n",
       "        [ 1.2217274 ],\n",
       "        [-1.3433254 ],\n",
       "        [ 1.3022397 ],\n",
       "        [ 1.1814667 ],\n",
       "        [-1.0015004 ]], dtype=float32),\n",
       " array([1.7510902], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_linear(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_linear_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 764us/step - loss: 320.2456 - val_loss: 130.3620\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 76.5957 - val_loss: 58.4826\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 38.2308 - val_loss: 26.6400\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.6046 - val_loss: 18.9747\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 16.9394 - val_loss: 16.0469\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 13.8377 - val_loss: 13.1063\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.8258 - val_loss: 11.1781\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 11.5141 - val_loss: 10.9380\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 10.2190 - val_loss: 11.2654\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.6992 - val_loss: 10.6091\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.3822 - val_loss: 10.1728\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.1408 - val_loss: 9.6100\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.8341 - val_loss: 9.9322\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.8743 - val_loss: 10.0536\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.6525 - val_loss: 9.4083\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5898 - val_loss: 9.4717\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 8.4088 - val_loss: 9.4694\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 160us/step - loss: 8.3871 - val_loss: 9.4721\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 8.3926 - val_loss: 9.3121\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 8.5541 - val_loss: 9.4019\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.5107 - val_loss: 9.0651\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 8.2594 - val_loss: 8.9718\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 8.3080 - val_loss: 8.9400\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3379 - val_loss: 9.0584\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1931 - val_loss: 9.0581\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9934 - val_loss: 8.8997\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9537 - val_loss: 8.9729\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.1184 - val_loss: 8.9315\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.9491 - val_loss: 8.8197\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0148 - val_loss: 8.6617\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9581 - val_loss: 8.7649\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8263 - val_loss: 8.5667\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8096 - val_loss: 8.4707\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.8088 - val_loss: 8.3783\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.8790 - val_loss: 8.4369\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8269 - val_loss: 8.6053\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0642 - val_loss: 8.4298\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.3978 - val_loss: 8.3065\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.1664 - val_loss: 8.5252\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0942 - val_loss: 8.5081\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6681 - val_loss: 8.3682\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6200 - val_loss: 8.3966\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6381 - val_loss: 8.3909\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8237 - val_loss: 8.1143\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6252 - val_loss: 8.1539\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7203 - val_loss: 8.2533\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.5572 - val_loss: 8.4218\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6185 - val_loss: 8.0888\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7968 - val_loss: 8.1763\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5563 - val_loss: 7.9403\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5494 - val_loss: 8.1493\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6410 - val_loss: 8.1188\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5265 - val_loss: 8.2463\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5233 - val_loss: 8.0065\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5065 - val_loss: 7.9493\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5077 - val_loss: 7.8735\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.5552 - val_loss: 7.8847\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4095 - val_loss: 8.1042\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.5786 - val_loss: 7.8744\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4997 - val_loss: 8.0739\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6151 - val_loss: 8.2238\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3718 - val_loss: 7.9667\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.5211 - val_loss: 7.7780\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4972 - val_loss: 7.7786\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3561 - val_loss: 8.0477\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5036 - val_loss: 8.1099\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4023 - val_loss: 7.9008\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3337 - val_loss: 7.6393\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 7.4420 - val_loss: 7.7083\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3221 - val_loss: 7.6398\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3279 - val_loss: 7.8964\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3601 - val_loss: 7.9845\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2657 - val_loss: 7.7490\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3529 - val_loss: 7.4920\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3085 - val_loss: 7.6299\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 7.2583 - val_loss: 7.6100\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 7.2099 - val_loss: 8.0254\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.3237 - val_loss: 7.8490\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3113 - val_loss: 7.9291\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2473 - val_loss: 7.6911\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3903 - val_loss: 7.7722\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5148 - val_loss: 7.6584\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2564 - val_loss: 7.5312\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2530 - val_loss: 7.5611\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3135 - val_loss: 7.4334\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 7.3344 - val_loss: 7.7113\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.3760 - val_loss: 7.4588\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1886 - val_loss: 7.5915\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1397 - val_loss: 7.6589\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.2836 - val_loss: 7.6527\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2684 - val_loss: 7.7092\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.5474 - val_loss: 7.4500\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4603 - val_loss: 7.5314\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6008 - val_loss: 7.4855\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 7.2978 - val_loss: 7.4459\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1308 - val_loss: 7.9221\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2845 - val_loss: 7.6175\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3998 - val_loss: 7.5532\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4492 - val_loss: 7.3578\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4353 - val_loss: 7.3832\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2932 - val_loss: 7.6645\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 7.3875 - val_loss: 7.6116\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2406 - val_loss: 7.5712\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2854 - val_loss: 7.4873\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.5192 - val_loss: 7.4293\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.5058 - val_loss: 7.4583\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 7.2086 - val_loss: 7.5613\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 129us/step - loss: 7.0992 - val_loss: 7.4647\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 7.2119 - val_loss: 7.8376\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 186us/step - loss: 7.1448 - val_loss: 7.6134\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 7.2556 - val_loss: 7.3759\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2382 - val_loss: 7.3148\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 7.2364 - val_loss: 7.5849\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 7.2064 - val_loss: 7.6160\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 7.3588 - val_loss: 7.3216\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1767 - val_loss: 7.5994\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4749 - val_loss: 7.2986\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2905 - val_loss: 7.4411\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2059 - val_loss: 7.2066\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0467 - val_loss: 7.1743\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0188 - val_loss: 7.2143\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0072 - val_loss: 7.1869\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1038 - val_loss: 7.2695\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0546 - val_loss: 7.2389\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1027 - val_loss: 7.1753\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1312 - val_loss: 7.1867\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4161 - val_loss: 7.1123\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0340 - val_loss: 6.9752\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.1526 - val_loss: 6.9099\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.0630 - val_loss: 7.1705\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.9512 - val_loss: 7.2830\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 7.0440 - val_loss: 6.9913\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 7.0134 - val_loss: 7.1035\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 7.0055 - val_loss: 7.1028\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9246 - val_loss: 7.3249\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0715 - val_loss: 6.9491\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0362 - val_loss: 6.9765\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1337 - val_loss: 6.9971\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0010 - val_loss: 7.1738\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9349 - val_loss: 7.1509\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9810 - val_loss: 6.8868\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2036 - val_loss: 7.1168\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0211 - val_loss: 7.2648\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9460 - val_loss: 7.0872\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9463 - val_loss: 7.4254\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9425 - val_loss: 6.8551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9877 - val_loss: 7.1129\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1166 - val_loss: 6.9061\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9084 - val_loss: 7.3079\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9328 - val_loss: 7.0758\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9478 - val_loss: 7.0503\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0050 - val_loss: 7.2338\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0779 - val_loss: 6.9788\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0040 - val_loss: 6.9363\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9748 - val_loss: 7.0568\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.9548 - val_loss: 6.8191\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9185 - val_loss: 6.8923\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9567 - val_loss: 7.0432\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9165 - val_loss: 7.0897\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9271 - val_loss: 6.8827\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9523 - val_loss: 7.0625\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9475 - val_loss: 7.0440\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.9057 - val_loss: 7.2965\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0082 - val_loss: 6.9427\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0871 - val_loss: 7.4132\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2008 - val_loss: 6.8521\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0059 - val_loss: 6.9506\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1678 - val_loss: 7.2625\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0780 - val_loss: 7.0872\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.9595 - val_loss: 7.0703\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 262us/step - loss: 7.0825 - val_loss: 7.0830\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 6.9802 - val_loss: 6.9810\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8613 - val_loss: 6.8295\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9450 - val_loss: 7.1235\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9635 - val_loss: 6.9797\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9896 - val_loss: 7.0975\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0761 - val_loss: 7.0612\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1473 - val_loss: 7.1639\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1074 - val_loss: 6.9471\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0304 - val_loss: 7.0227\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0697 - val_loss: 6.8989\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9993 - val_loss: 7.0316\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1258 - val_loss: 6.6137\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2794 - val_loss: 7.1590\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1426 - val_loss: 7.0613\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1035 - val_loss: 7.3278\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7670 - val_loss: 6.9740\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2870 - val_loss: 6.8215\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9608 - val_loss: 6.9939\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0324 - val_loss: 6.9687\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.2996 - val_loss: 6.8980\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9123 - val_loss: 6.8628\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9772 - val_loss: 7.2897\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9722 - val_loss: 6.8580\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2028 - val_loss: 7.2379\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9973 - val_loss: 6.7203\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9798 - val_loss: 6.8379\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2078 - val_loss: 7.2241\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8815 - val_loss: 6.6627\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8594 - val_loss: 6.9578\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.0243 - val_loss: 6.8517\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9574 - val_loss: 6.9675\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8113 - val_loss: 6.8654\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8658 - val_loss: 7.0325\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8865 - val_loss: 6.9132\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9322 - val_loss: 6.9095\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0586 - val_loss: 7.1018\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8703 - val_loss: 6.8809\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8973 - val_loss: 6.8510\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9136 - val_loss: 6.7522\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9184 - val_loss: 6.9609\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0205 - val_loss: 6.6642\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5452 - val_loss: 7.3851\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0390 - val_loss: 7.0283\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8440 - val_loss: 7.1703\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9251 - val_loss: 6.8035\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8521 - val_loss: 7.0826\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9683 - val_loss: 6.8218\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8886 - val_loss: 7.0179\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9352 - val_loss: 6.8809\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9676 - val_loss: 7.1256\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8604 - val_loss: 6.9166\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9012 - val_loss: 7.3785\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.7592 - val_loss: 6.8328\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0220 - val_loss: 7.1724\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9099 - val_loss: 6.9841\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.9732 - val_loss: 7.2916\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7861 - val_loss: 6.8519\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3025 - val_loss: 7.7658\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9002 - val_loss: 6.9565\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8007 - val_loss: 7.1125\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9379 - val_loss: 6.7678\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8136 - val_loss: 6.9591\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8639 - val_loss: 6.8446\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.9246 - val_loss: 7.4278\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9145 - val_loss: 6.9101\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.8224 - val_loss: 7.1178\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0316 - val_loss: 6.9271\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8839 - val_loss: 6.8476\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0271 - val_loss: 6.8986\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0043 - val_loss: 6.7167\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8483 - val_loss: 6.8170\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.8787 - val_loss: 7.1445\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8530 - val_loss: 7.0619\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.95 - 0s 142us/step - loss: 6.9482 - val_loss: 7.1185\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 7.1443 - val_loss: 7.2607\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8968 - val_loss: 6.9360\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7982 - val_loss: 6.8800\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9578 - val_loss: 7.2117\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0152 - val_loss: 6.6871\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8498 - val_loss: 7.6365\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9913 - val_loss: 6.8600\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9493 - val_loss: 7.2731\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9580 - val_loss: 6.8675\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8753 - val_loss: 6.9724\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9178 - val_loss: 6.8802\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8848 - val_loss: 6.9879\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8343 - val_loss: 6.9638\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8655 - val_loss: 6.9584\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7869 - val_loss: 6.9533\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7955 - val_loss: 6.7915\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7574 - val_loss: 6.7834\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9636 - val_loss: 7.4915\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8591 - val_loss: 6.9630\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1274 - val_loss: 7.2035\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0408 - val_loss: 6.9394\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.9225 - val_loss: 7.1348\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8878 - val_loss: 6.8228\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9810 - val_loss: 7.0382\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0445 - val_loss: 6.6912\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9096 - val_loss: 7.2290\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0176 - val_loss: 6.9726\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8545 - val_loss: 7.1425\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.9511 - val_loss: 7.1302\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.9919 - val_loss: 6.7720\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 7.0923 - val_loss: 6.9996\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 7.2541 - val_loss: 7.0728\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.9592 - val_loss: 7.2156\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.8925 - val_loss: 7.1409\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8136 - val_loss: 6.7034\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1546 - val_loss: 7.2476\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9649 - val_loss: 7.0913\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8121 - val_loss: 7.0310\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8991 - val_loss: 7.1318\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8574 - val_loss: 7.1553\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 144us/step - loss: 6.9865 - val_loss: 6.8689\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8291 - val_loss: 7.1472\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8516 - val_loss: 6.9473\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.7720 - val_loss: 7.0413\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.7471 - val_loss: 7.1534\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.8666 - val_loss: 7.0995\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.7600 - val_loss: 7.0828\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8641 - val_loss: 6.9006\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9795 - val_loss: 7.0169\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8213 - val_loss: 6.9030\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8533 - val_loss: 7.0384\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.8509 - val_loss: 7.1237\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7611 - val_loss: 7.0208\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8089 - val_loss: 6.9560\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8420 - val_loss: 6.7733\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 116us/step - loss: 7.1087 - val_loss: 7.3064\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9491 - val_loss: 7.0295\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7563 - val_loss: 7.1663\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8868 - val_loss: 6.9224\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8419 - val_loss: 7.0451\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8663 - val_loss: 7.0575\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.7774 - val_loss: 6.9158\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.8180 - val_loss: 7.1030\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6731 - val_loss: 6.8995\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.7540 - val_loss: 7.3789\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.9215 - val_loss: 7.0335\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.7818 - val_loss: 6.9657\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9549 - val_loss: 7.3125\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8244 - val_loss: 6.8717\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7759 - val_loss: 7.2284\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.8229 - val_loss: 7.2743\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8770 - val_loss: 7.2125\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8574 - val_loss: 6.8275\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 128us/step - loss: 6.8983 - val_loss: 7.1560\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9971 - val_loss: 6.7350\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7968 - val_loss: 7.6263\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8110 - val_loss: 7.0292\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8069 - val_loss: 7.2465\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8181 - val_loss: 6.9777\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8664 - val_loss: 6.7913\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7048 - val_loss: 7.0522\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.0013 - val_loss: 6.8942\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.3029 - val_loss: 7.7398\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.1085 - val_loss: 7.0017\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 6.7200 - val_loss: 8.2111\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.9973 - val_loss: 6.7238\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.7827 - val_loss: 7.3732\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8415 - val_loss: 6.7702\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9707 - val_loss: 8.0049\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.0630 - val_loss: 6.8093\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6420 - val_loss: 6.9412\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8040 - val_loss: 7.0151\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6256 - val_loss: 7.0081\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6428 - val_loss: 6.8637\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5253 - val_loss: 6.8861\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5654 - val_loss: 6.7819\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9197 - val_loss: 6.7361\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6372 - val_loss: 7.1873\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5758 - val_loss: 6.9005\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5330 - val_loss: 7.3043\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5340 - val_loss: 6.6830\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4770 - val_loss: 6.9783\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4818 - val_loss: 6.6766\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5060 - val_loss: 6.7962\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4655 - val_loss: 6.6482\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3710 - val_loss: 6.6606\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3331 - val_loss: 6.5703\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3965 - val_loss: 6.7437\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5055 - val_loss: 7.0957\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3335 - val_loss: 6.6512\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5186 - val_loss: 6.9397\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4485 - val_loss: 6.8441\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7440 - val_loss: 6.3592\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0735 - val_loss: 7.9758\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8578 - val_loss: 6.6271\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6472 - val_loss: 7.4513\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4013 - val_loss: 6.6615\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2892 - val_loss: 6.7742\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2566 - val_loss: 6.7233\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3027 - val_loss: 6.5876\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2516 - val_loss: 6.7589\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1414 - val_loss: 6.4319\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2878 - val_loss: 7.0202\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1558 - val_loss: 6.4711\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1727 - val_loss: 6.8676\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3479 - val_loss: 6.8225\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1529 - val_loss: 6.3454\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1381 - val_loss: 6.4581\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2788 - val_loss: 6.3440\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3175 - val_loss: 6.4668\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5577 - val_loss: 7.1899\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3934 - val_loss: 6.5873\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 110us/step - loss: 6.1790 - val_loss: 6.6842\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.3931 - val_loss: 6.2613\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.2112 - val_loss: 7.1841\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4498 - val_loss: 6.5154\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.5357 - val_loss: 7.3016\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3033 - val_loss: 6.3685\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3065 - val_loss: 6.4846\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5961 - val_loss: 7.3152\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3490 - val_loss: 6.4452\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1253 - val_loss: 6.7892\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0319 - val_loss: 6.5881\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0134 - val_loss: 6.6691\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1271 - val_loss: 6.3096\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0837 - val_loss: 6.5585\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0519 - val_loss: 6.6805\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1436 - val_loss: 6.2413\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2566 - val_loss: 6.4867\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1690 - val_loss: 6.3230\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 226us/step - loss: 5.9982 - val_loss: 6.4807\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 6.0193 - val_loss: 6.6139\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.3238 - val_loss: 6.4398\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.2639 - val_loss: 6.9567\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2621 - val_loss: 6.3132\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 6.1517 - val_loss: 6.4421\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.0671 - val_loss: 6.5774\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1023 - val_loss: 6.2541\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0711 - val_loss: 6.5301\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9568 - val_loss: 6.5112\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9789 - val_loss: 6.2625\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1753 - val_loss: 6.5113\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3677 - val_loss: 7.5960\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 145us/step - loss: 7.0923 - val_loss: 6.7802\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.2651 - val_loss: 7.9481\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.2842 - val_loss: 6.2716\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.5144 - val_loss: 6.3861\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9280 - val_loss: 6.3917\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 5.8958 - val_loss: 6.5506\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0597 - val_loss: 6.8339\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9300 - val_loss: 6.2480\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8760 - val_loss: 6.4328\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 5.8764 - val_loss: 6.5059\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8984 - val_loss: 6.2566\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0275 - val_loss: 7.0218\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.84 - 0s 98us/step - loss: 5.9584 - val_loss: 6.4110\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8308 - val_loss: 6.5567\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8790 - val_loss: 6.3933\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1844 - val_loss: 6.1117\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1016 - val_loss: 6.8213\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8049 - val_loss: 6.2305\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8772 - val_loss: 6.6514\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9324 - val_loss: 6.1947\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8409 - val_loss: 6.3888\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8041 - val_loss: 6.3656\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7664 - val_loss: 6.3681\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9358 - val_loss: 6.8749\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1350 - val_loss: 6.2669\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4076 - val_loss: 6.4162\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0816 - val_loss: 6.6993\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1846 - val_loss: 6.1608\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1351 - val_loss: 6.9836\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8947 - val_loss: 6.2720\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7970 - val_loss: 6.3783\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7307 - val_loss: 6.1910\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8680 - val_loss: 6.1654\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9622 - val_loss: 7.0739\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9399 - val_loss: 6.4366\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0110 - val_loss: 7.6839\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1517 - val_loss: 6.1030\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8118 - val_loss: 6.4624\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9282 - val_loss: 6.3862\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9147 - val_loss: 6.3818\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9781 - val_loss: 6.8463\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8950 - val_loss: 6.2801\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7997 - val_loss: 6.1993\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8706 - val_loss: 6.6947\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7047 - val_loss: 6.2890\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8882 - val_loss: 6.3692\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.8307 - val_loss: 6.4199\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.0039 - val_loss: 6.7687\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0799 - val_loss: 6.2756\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0457 - val_loss: 6.4364\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0291 - val_loss: 6.7631\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0447 - val_loss: 6.6719\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1714 - val_loss: 7.6260\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1993 - val_loss: 6.7173\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0690 - val_loss: 7.3718\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9271 - val_loss: 6.3105\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7486 - val_loss: 6.3540\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8004 - val_loss: 6.5114\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8455 - val_loss: 6.2628\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8659 - val_loss: 6.9830\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.715 - 0s 107us/step - loss: 5.8276 - val_loss: 6.2112\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8449 - val_loss: 6.3228\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8929 - val_loss: 6.1431\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8267 - val_loss: 6.4389\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8623 - val_loss: 7.2621\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7566 - val_loss: 6.2467\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7295 - val_loss: 7.0383\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0281 - val_loss: 6.6960\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2437 - val_loss: 7.5340\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7597 - val_loss: 6.4039\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9941 - val_loss: 6.4504\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0238 - val_loss: 6.8118\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4562 - val_loss: 6.3630\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8432 - val_loss: 6.4685\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6898 - val_loss: 6.1922\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7126 - val_loss: 6.3634\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6386 - val_loss: 6.5126\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8008 - val_loss: 6.8660\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7246 - val_loss: 6.4150\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6894 - val_loss: 6.3425\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7432 - val_loss: 6.6694\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6945 - val_loss: 6.2879\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7096 - val_loss: 6.6584\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6327 - val_loss: 6.4430\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0205 - val_loss: 7.0458\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9769 - val_loss: 6.1447\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8023 - val_loss: 6.2391\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7141 - val_loss: 6.8875\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9595 - val_loss: 6.5544\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2844 - val_loss: 7.5333\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9086 - val_loss: 6.5377\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6414 - val_loss: 7.5466\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7888 - val_loss: 6.5392\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4618 - val_loss: 6.8759\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9697 - val_loss: 6.6087\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8626 - val_loss: 6.6002\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8181 - val_loss: 6.7467\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3164 - val_loss: 6.4371\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8652 - val_loss: 6.8147\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7092 - val_loss: 6.3718\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7904 - val_loss: 6.5593\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7098 - val_loss: 6.7437\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7112 - val_loss: 6.4908\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7652 - val_loss: 7.4228\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7431 - val_loss: 6.4968\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6292 - val_loss: 6.6846\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7314 - val_loss: 6.5654\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6233 - val_loss: 6.8522\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6065 - val_loss: 6.5046\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7260 - val_loss: 6.6616\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6950 - val_loss: 6.9984\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5937 - val_loss: 6.8494\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7016 - val_loss: 7.3867\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6300 - val_loss: 6.6160\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7449 - val_loss: 6.8773\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6009 - val_loss: 6.5142\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5588 - val_loss: 6.7790\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5849 - val_loss: 6.7506\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7042 - val_loss: 7.3974\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7924 - val_loss: 6.5708\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8434 - val_loss: 6.6213\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7356 - val_loss: 7.1483\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6823 - val_loss: 6.6974\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 5.7428 - val_loss: 6.7951\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3122 - val_loss: 7.5042\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7243 - val_loss: 6.7249\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5864 - val_loss: 6.7139\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6100 - val_loss: 6.9575\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6750 - val_loss: 6.6941\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5458 - val_loss: 7.2804\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6671 - val_loss: 6.8930\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7980 - val_loss: 7.1605\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7259 - val_loss: 6.7704\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6477 - val_loss: 6.8246\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7640 - val_loss: 7.6778\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0784 - val_loss: 6.5616\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7387 - val_loss: 6.9699\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6151 - val_loss: 6.8249\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5132 - val_loss: 7.1562\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6592 - val_loss: 6.8509\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7197 - val_loss: 7.0984\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5606 - val_loss: 7.1461\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6145 - val_loss: 6.8703\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5450 - val_loss: 6.9094\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5964 - val_loss: 6.8856\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6043 - val_loss: 6.8742\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4227 - val_loss: 7.2265\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5930 - val_loss: 6.8193\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7623 - val_loss: 7.1547\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4546 - val_loss: 6.8960\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7169 - val_loss: 8.2599\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9541 - val_loss: 6.8918\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4471 - val_loss: 7.4082\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5585 - val_loss: 7.0805\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5891 - val_loss: 6.9788\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6584 - val_loss: 7.2993\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8196 - val_loss: 7.1142\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1483 - val_loss: 7.0368\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5492 - val_loss: 6.9844\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4799 - val_loss: 6.8399\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4854 - val_loss: 6.9477\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4747 - val_loss: 6.8614\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.5593 - val_loss: 7.1738\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4762 - val_loss: 7.3899\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5346 - val_loss: 7.1978\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4527 - val_loss: 7.1233\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4775 - val_loss: 6.9638\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4883 - val_loss: 6.9481\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5536 - val_loss: 7.0448\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4849 - val_loss: 7.0922\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3930 - val_loss: 7.3484\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5939 - val_loss: 7.6474\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5638 - val_loss: 7.0039\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5603 - val_loss: 7.0972\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4788 - val_loss: 6.9472\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7332 - val_loss: 7.4859\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9329 - val_loss: 7.0045\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7877 - val_loss: 6.9909\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4916 - val_loss: 7.5874\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4640 - val_loss: 6.9304\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4753 - val_loss: 7.1153\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4288 - val_loss: 7.1625\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3978 - val_loss: 7.3609\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4616 - val_loss: 7.3394\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4796 - val_loss: 6.9967\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6333 - val_loss: 7.0155\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4934 - val_loss: 7.2838\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4277 - val_loss: 7.4987\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6365 - val_loss: 7.3601\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5513 - val_loss: 6.9988\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6539 - val_loss: 7.5344\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3577 - val_loss: 7.3813\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4100 - val_loss: 7.4175\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3888 - val_loss: 7.2562\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5043 - val_loss: 7.9511\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0429 - val_loss: 7.7289\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7457 - val_loss: 8.1304\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5208 - val_loss: 7.3382\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5647 - val_loss: 7.0520\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5824 - val_loss: 7.3957\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4446 - val_loss: 7.4224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4279 - val_loss: 7.4748\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6769 - val_loss: 7.8412\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6561 - val_loss: 7.2794\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.7261 - val_loss: 7.3804\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 5.6652 - val_loss: 8.4374\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5153 - val_loss: 7.3922\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4713 - val_loss: 7.9286\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6223 - val_loss: 7.6633\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4158 - val_loss: 7.1635\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.4153 - val_loss: 7.4953\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4072 - val_loss: 7.4511\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4500 - val_loss: 8.0072\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4394 - val_loss: 7.4031\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3439 - val_loss: 7.5475\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4220 - val_loss: 7.3882\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3853 - val_loss: 7.7650\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5523 - val_loss: 7.4247\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4675 - val_loss: 7.7222\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5064 - val_loss: 7.4871\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5599 - val_loss: 7.4302\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9708 - val_loss: 8.3981\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 5.6488 - val_loss: 7.4537\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5709 - val_loss: 7.5971\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6648 - val_loss: 7.4059\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5430 - val_loss: 8.4324\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8003 - val_loss: 7.4889\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4304 - val_loss: 8.0694\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5277 - val_loss: 7.9678\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3616 - val_loss: 7.3830\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5096 - val_loss: 7.8263\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9282 - val_loss: 8.2375\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7421 - val_loss: 7.4958\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8117 - val_loss: 7.9725\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8944 - val_loss: 7.8138\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4150 - val_loss: 7.6902\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4240 - val_loss: 8.1224\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5793 - val_loss: 7.7193\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4066 - val_loss: 7.4042\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3944 - val_loss: 7.8925\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4833 - val_loss: 8.0461\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3669 - val_loss: 7.6601\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4003 - val_loss: 7.7063\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6305 - val_loss: 8.7451\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4945 - val_loss: 7.6771\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4424 - val_loss: 7.8420\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2906 - val_loss: 7.6158\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3034 - val_loss: 7.9557\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3177 - val_loss: 7.9930\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4940 - val_loss: 7.8391\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5986 - val_loss: 7.6776\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3776 - val_loss: 7.9339\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2759 - val_loss: 7.6904\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3606 - val_loss: 8.2870\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4794 - val_loss: 7.6985\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3944 - val_loss: 8.2462\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5200 - val_loss: 7.6324\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6379 - val_loss: 7.9951\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5677 - val_loss: 7.9601\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2651 - val_loss: 8.2708\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4237 - val_loss: 7.9033\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5089 - val_loss: 8.0047\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3940 - val_loss: 7.9964\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5156 - val_loss: 8.6240\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3476 - val_loss: 7.8084\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4049 - val_loss: 7.8288\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2879 - val_loss: 8.0985\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4573 - val_loss: 8.7297\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3189 - val_loss: 7.9840\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2820 - val_loss: 7.7811\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4189 - val_loss: 8.1459\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2568 - val_loss: 8.6508\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3835 - val_loss: 8.1473\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2892 - val_loss: 8.1199\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2685 - val_loss: 8.0542\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2977 - val_loss: 8.2376\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6335 - val_loss: 8.3166\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5520 - val_loss: 8.1433\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.5391 - val_loss: 8.2934\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3603 - val_loss: 9.2210\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5370 - val_loss: 9.4484\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2088 - val_loss: 9.4509\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6139 - val_loss: 8.2317\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3063 - val_loss: 8.8631\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3389 - val_loss: 8.1436\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2596 - val_loss: 8.6081\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2557 - val_loss: 8.6471\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2810 - val_loss: 8.3757\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1900 - val_loss: 8.5540\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2292 - val_loss: 8.3903\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3436 - val_loss: 8.7952\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3910 - val_loss: 8.7039\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2275 - val_loss: 8.4255\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2811 - val_loss: 8.3919\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2410 - val_loss: 8.7918\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2603 - val_loss: 8.4912\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6413 - val_loss: 8.4435\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3679 - val_loss: 8.1252\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2165 - val_loss: 8.3624\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2983 - val_loss: 8.7053\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2729 - val_loss: 8.7144\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2271 - val_loss: 8.6537\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3091 - val_loss: 8.5392\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8675 - val_loss: 8.5388\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5966 - val_loss: 9.3362\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3767 - val_loss: 8.3245\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2445 - val_loss: 8.5133\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2737 - val_loss: 8.2600\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1930 - val_loss: 8.6148\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2820 - val_loss: 8.5285\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2885 - val_loss: 8.8666\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5313 - val_loss: 8.4425\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4795 - val_loss: 8.7945\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2903 - val_loss: 8.3615\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3942 - val_loss: 8.6581\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4991 - val_loss: 8.6400\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2483 - val_loss: 9.0147\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4162 - val_loss: 9.6915\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4575 - val_loss: 8.6742\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5110 - val_loss: 8.7967\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3837 - val_loss: 8.7613\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3768 - val_loss: 8.5948\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7016 - val_loss: 8.6195\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6144 - val_loss: 9.2559\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1733 - val_loss: 8.7930\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2193 - val_loss: 8.7248\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4515 - val_loss: 8.8146\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1858 - val_loss: 8.7482\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1876 - val_loss: 8.4936\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2438 - val_loss: 8.9107\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2074 - val_loss: 8.7618\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1637 - val_loss: 8.9082\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1610 - val_loss: 8.9921\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2550 - val_loss: 8.5832\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1245 - val_loss: 8.8840\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2758 - val_loss: 8.9643\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1614 - val_loss: 8.6179\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2649 - val_loss: 9.2302\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2355 - val_loss: 9.0908\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1847 - val_loss: 8.7718\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1604 - val_loss: 8.6907\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2183 - val_loss: 8.7365\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2485 - val_loss: 8.8387\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1048 - val_loss: 8.7877\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3255 - val_loss: 9.1896\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3482 - val_loss: 8.6258\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0884 - val_loss: 8.9988\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2172 - val_loss: 8.9150\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4447 - val_loss: 8.8838\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1435 - val_loss: 8.6630\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1785 - val_loss: 8.8645\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2079 - val_loss: 9.0889\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1849 - val_loss: 8.4809\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5136 - val_loss: 8.9672\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6416 - val_loss: 9.3879\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2713 - val_loss: 8.9806\n",
      "Epoch 765/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.4752 - val_loss: 8.5213\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5126 - val_loss: 9.1839\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1609 - val_loss: 8.9026\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0919 - val_loss: 8.5145\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2727 - val_loss: 8.8279\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4141 - val_loss: 8.6990\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1502 - val_loss: 8.9124\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1004 - val_loss: 9.0552\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1299 - val_loss: 8.9982\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1487 - val_loss: 8.8043\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2679 - val_loss: 9.3744\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3709 - val_loss: 8.5089\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1325 - val_loss: 9.2511\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3078 - val_loss: 8.8261\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2254 - val_loss: 9.3407\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2555 - val_loss: 9.0391\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2641 - val_loss: 9.1077\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2788 - val_loss: 8.7002\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3898 - val_loss: 9.4674\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7624 - val_loss: 9.0370\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3378 - val_loss: 9.1776\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2554 - val_loss: 8.9622\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1968 - val_loss: 8.6496\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2952 - val_loss: 9.2352\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3545 - val_loss: 9.0171\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2541 - val_loss: 9.0373\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1741 - val_loss: 8.9765\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1151 - val_loss: 8.8482\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4040 - val_loss: 9.1400\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5626 - val_loss: 9.3848\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2587 - val_loss: 8.6654\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1949 - val_loss: 8.9854\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.3184 - val_loss: 9.4164\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1677 - val_loss: 8.9221\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2847 - val_loss: 8.8087\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1440 - val_loss: 9.0222\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4350 - val_loss: 8.8635\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2368 - val_loss: 8.8261\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3607 - val_loss: 9.1763\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1563 - val_loss: 9.1201\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1887 - val_loss: 9.2141\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1215 - val_loss: 8.6603\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2592 - val_loss: 8.8327\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1573 - val_loss: 8.9756\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.4240 - val_loss: 8.8806\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1424 - val_loss: 9.1703\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2801 - val_loss: 8.7491\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2758 - val_loss: 8.8798\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3436 - val_loss: 8.8452\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5767 - val_loss: 10.6007\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5618 - val_loss: 8.5975\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5286 - val_loss: 8.8133\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4435 - val_loss: 9.7550\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4407 - val_loss: 9.0127\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 5.2896 - val_loss: 9.4573\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6381 - val_loss: 9.7423\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2497 - val_loss: 8.7897\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2926 - val_loss: 9.0194\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4097 - val_loss: 8.9715\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4629 - val_loss: 8.9248\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0211 - val_loss: 9.2056\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1518 - val_loss: 9.0862\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1849 - val_loss: 8.8277\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5967 - val_loss: 9.7988\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6326 - val_loss: 8.3615\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5117 - val_loss: 9.1642\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3663 - val_loss: 10.0088\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5462 - val_loss: 9.1419\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1035 - val_loss: 9.0039\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2507 - val_loss: 9.0622\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1750 - val_loss: 8.8515\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1798 - val_loss: 9.3904\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2839 - val_loss: 8.8045\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2145 - val_loss: 9.1723\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3168 - val_loss: 9.3037\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3844 - val_loss: 8.9969\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3676 - val_loss: 9.1121\n",
      "Epoch 842/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 5.1004 - val_loss: 8.9309\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1469 - val_loss: 9.1525\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1865 - val_loss: 8.7211\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0758 - val_loss: 9.0680\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1777 - val_loss: 8.8356\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1962 - val_loss: 9.1194\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1296 - val_loss: 9.6413\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2516 - val_loss: 9.0590\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4286 - val_loss: 9.2629\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3015 - val_loss: 9.1290\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.2742 - val_loss: 8.8983\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2295 - val_loss: 8.9135\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2986 - val_loss: 10.0402\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2434 - val_loss: 8.8739\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3337 - val_loss: 9.0811\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3141 - val_loss: 8.6077\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1701 - val_loss: 9.7824\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4165 - val_loss: 9.0189\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0338 - val_loss: 9.2388\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1134 - val_loss: 9.0888\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1660 - val_loss: 9.0273\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 128us/step - loss: 5.1231 - val_loss: 8.9886\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.1811 - val_loss: 8.9885\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.0747 - val_loss: 8.9734\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3744 - val_loss: 9.0484\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1538 - val_loss: 8.8643\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1292 - val_loss: 9.2532\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3358 - val_loss: 9.8149\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4978 - val_loss: 9.0830\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2291 - val_loss: 9.1325\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2610 - val_loss: 10.3583\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4642 - val_loss: 9.3178\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1597 - val_loss: 9.9132\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4782 - val_loss: 8.8148\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2212 - val_loss: 8.7455\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2094 - val_loss: 8.9638\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.1837 - val_loss: 9.5404\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1419 - val_loss: 8.8757\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.0870 - val_loss: 9.0698\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2561 - val_loss: 9.2854\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2235 - val_loss: 8.9260\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2329 - val_loss: 9.1028\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0237 - val_loss: 8.8708\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1002 - val_loss: 9.6985\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0662 - val_loss: 9.0528\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3397 - val_loss: 9.0959\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2130 - val_loss: 8.8893\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4019 - val_loss: 9.6043\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5304 - val_loss: 8.9130\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2345 - val_loss: 9.2135\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1715 - val_loss: 9.4025\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2563 - val_loss: 8.6827\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4307 - val_loss: 9.1691\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5877 - val_loss: 10.6101\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.7614 - val_loss: 8.4939\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2005 - val_loss: 8.9527\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3599 - val_loss: 8.9203\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2154 - val_loss: 9.1799\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3291 - val_loss: 9.5390\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4280 - val_loss: 8.8406\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1232 - val_loss: 8.8472\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2076 - val_loss: 9.0956\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0458 - val_loss: 8.8291\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1268 - val_loss: 8.8550\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2037 - val_loss: 9.1461\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1466 - val_loss: 8.9029\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1159 - val_loss: 8.7627\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1532 - val_loss: 9.3350\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3775 - val_loss: 9.1065\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3246 - val_loss: 8.9545\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1809 - val_loss: 9.1884\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1682 - val_loss: 9.4004\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4169 - val_loss: 9.1431\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3728 - val_loss: 9.2208\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4778 - val_loss: 9.3991\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3085 - val_loss: 8.7070\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2479 - val_loss: 9.0107\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 5.3117 - val_loss: 9.3613\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1860 - val_loss: 9.5225\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2825 - val_loss: 8.8352\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3968 - val_loss: 10.0526\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3154 - val_loss: 8.6550\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1914 - val_loss: 8.8256\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1142 - val_loss: 9.1581\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0979 - val_loss: 9.0991\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1017 - val_loss: 9.0938\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1331 - val_loss: 9.0754\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4397 - val_loss: 10.3274\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3670 - val_loss: 8.9818\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0023 - val_loss: 8.8514\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1708 - val_loss: 9.4167\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1446 - val_loss: 9.1200\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1433 - val_loss: 9.0731\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1428 - val_loss: 8.9603\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3073 - val_loss: 9.6750\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0511 - val_loss: 9.1908\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2842 - val_loss: 9.1643\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0858 - val_loss: 9.1067\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1163 - val_loss: 8.9286\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2262 - val_loss: 9.8672\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2046 - val_loss: 9.2307\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0622 - val_loss: 9.8591\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.1243 - val_loss: 8.9232\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5708 - val_loss: 8.7264\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5381 - val_loss: 9.6395\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4636 - val_loss: 8.3296\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3635 - val_loss: 10.8903\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4387 - val_loss: 8.8098\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4043 - val_loss: 9.0596\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1676 - val_loss: 9.1646\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2050 - val_loss: 9.2150\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0393 - val_loss: 8.7530\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0523 - val_loss: 8.8836\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2545 - val_loss: 9.5944\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3238 - val_loss: 9.0413\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1837 - val_loss: 8.7049\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5519 - val_loss: 10.0401\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5650 - val_loss: 8.3069\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7412 - val_loss: 8.4452\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5906 - val_loss: 10.0022\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4153 - val_loss: 8.7856\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1857 - val_loss: 8.7403\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0474 - val_loss: 9.0871\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1180 - val_loss: 9.0932\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0405 - val_loss: 9.2940\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1436 - val_loss: 9.2590\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1630 - val_loss: 8.9030\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0761 - val_loss: 9.9774\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2348 - val_loss: 8.8552\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0987 - val_loss: 8.8993\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2469 - val_loss: 9.0611\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1738 - val_loss: 9.4995\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2033 - val_loss: 9.2231\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4044 - val_loss: 9.3239\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1756 - val_loss: 9.1473\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0457 - val_loss: 9.6769\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3002 - val_loss: 9.0415\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2737 - val_loss: 9.1517\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9957 - val_loss: 8.7443\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1060 - val_loss: 9.0734\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0996 - val_loss: 9.0570\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0878 - val_loss: 8.8240\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0831 - val_loss: 9.5608\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2253 - val_loss: 8.8417\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3125 - val_loss: 9.0822\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0994 - val_loss: 9.0871\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1800 - val_loss: 9.3196\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2025 - val_loss: 9.3567\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3190 - val_loss: 8.7330\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1518 - val_loss: 8.7337\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1022 - val_loss: 8.8776\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0753 - val_loss: 9.5391\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1156 - val_loss: 8.6741\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2865 - val_loss: 9.1008\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2610 - val_loss: 9.7921\n",
      "Epoch 997/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 96us/step - loss: 5.3428 - val_loss: 8.8496\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3941 - val_loss: 9.3568\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2890 - val_loss: 8.8301\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9969 - val_loss: 9.0360\n",
      "6.628869258751304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.61748075,  0.8647203 , -0.43723792,  0.62333024, -0.6412967 ],\n",
       "        [-0.9120634 , -1.9209827 ,  1.348925  , -0.9756895 ,  0.91940546],\n",
       "        [-0.2349958 ,  0.2790235 , -0.53637767, -0.90401083, -0.4818502 ],\n",
       "        [ 0.03034029,  0.26190096, -2.1994724 , -0.554997  ,  0.1632381 ],\n",
       "        [-1.0890766 ,  1.0015293 , -0.20767866, -0.6880193 ,  0.4337065 ],\n",
       "        [-0.06539302, -0.54370743,  0.28301778, -0.6741587 ,  1.605055  ],\n",
       "        [-3.208143  , -0.8670386 ,  0.3909985 ,  1.3989067 , -0.20494041]],\n",
       "       dtype=float32),\n",
       " array([1.0712596 , 1.1262215 , 0.72805077, 0.93181837, 1.7721711 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.19756511,  0.04862389, -0.06738003, -0.17663118,  0.31466728,\n",
       "         -0.23976696,  1.2300557 ,  1.953325  ,  0.64703614,  1.7743678 ],\n",
       "        [ 0.83058494, -0.3730811 , -0.547277  ,  0.5496046 ,  1.2318879 ,\n",
       "         -0.37461796,  0.3495903 ,  1.5899234 ,  0.909044  ,  0.3727565 ],\n",
       "        [ 0.5971443 , -0.72728467, -0.7020506 , -0.55599535,  0.5392556 ,\n",
       "         -0.57413596,  0.59354913, -2.0578372 ,  0.37013093, -1.7980894 ],\n",
       "        [ 0.07381061, -0.14306809, -0.22383496,  0.7599417 ,  0.83565253,\n",
       "         -0.17383417,  0.6753946 , -2.2032838 , -0.27648565, -2.62058   ],\n",
       "        [-0.06767246, -0.5576124 , -0.58776027,  0.9815286 ,  1.2413349 ,\n",
       "         -0.5883595 ,  1.3153988 , -0.31629005,  0.5869057 , -1.1962298 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.1520132 , -0.36638057, -0.3176562 ,  1.3254951 ,  1.3248146 ,\n",
       "        -0.35209286,  1.3757367 ,  1.0136595 ,  1.133175  ,  1.3912694 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.4082385 ],\n",
       "        [ 0.17755595],\n",
       "        [ 0.28218415],\n",
       "        [ 0.7115675 ],\n",
       "        [ 1.2006454 ],\n",
       "        [ 0.01857446],\n",
       "        [ 1.2031056 ],\n",
       "        [-2.1264958 ],\n",
       "        [ 0.4311982 ],\n",
       "        [ 2.5494635 ]], dtype=float32),\n",
       " array([1.3808343], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_relu(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_relu_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 787us/step - loss: 500.0123 - val_loss: 406.4902\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 296.0583 - val_loss: 220.9914\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 158.1226 - val_loss: 124.5264\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 94.4328 - val_loss: 81.5898\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 69.1444 - val_loss: 66.0948\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 62.5989 - val_loss: 61.1914\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.4085 - val_loss: 59.9923\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.6933 - val_loss: 59.6731\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 215us/step - loss: 61.5406 - val_loss: 59.7316\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 129us/step - loss: 61.4689 - val_loss: 59.8898\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 61.4844 - val_loss: 60.1582\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 61.3969 - val_loss: 60.1780\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3717 - val_loss: 60.2376\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.3799 - val_loss: 60.2412\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3867 - val_loss: 60.4033\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 61.3597 - val_loss: 60.3782\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 61.3544 - val_loss: 60.3772\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3505 - val_loss: 60.4068\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.3455 - val_loss: 60.4801\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 61.3726 - val_loss: 60.4382\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3338 - val_loss: 60.5257\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3465 - val_loss: 60.5126\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3394 - val_loss: 60.7058\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.3392 - val_loss: 60.6573\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3320 - val_loss: 60.6424\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.3778 - val_loss: 60.4458\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.3304 - val_loss: 60.4070\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3133 - val_loss: 60.4906\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.3036 - val_loss: 60.5153\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 61.3076 - val_loss: 60.7176\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 61.3279 - val_loss: 60.9113\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2910 - val_loss: 60.9270\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2852 - val_loss: 60.9560\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2906 - val_loss: 60.7758\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2419 - val_loss: 60.7508\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2098 - val_loss: 60.8530\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2016 - val_loss: 60.8135\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.1633 - val_loss: 60.9390\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 61.1325 - val_loss: 61.0734\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.0792 - val_loss: 61.1057\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0256 - val_loss: 61.0087\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 60.9917 - val_loss: 61.0322\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 60.9733 - val_loss: 60.9863\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 60.8774 - val_loss: 60.9848\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 60.7983 - val_loss: 60.9676\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 60.6919 - val_loss: 60.7657\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 60.2919 - val_loss: 59.9851\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 55.2130 - val_loss: 50.9504\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 45.2481 - val_loss: 43.4312\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 39.4096 - val_loss: 39.4803\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 36.9436 - val_loss: 36.6198\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 35.3016 - val_loss: 34.5997\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 33.7812 - val_loss: 32.9513\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 29.1137 - val_loss: 28.0051\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 25.6643 - val_loss: 25.6658\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 23.4184 - val_loss: 24.8096\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 22.3722 - val_loss: 24.0418\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 21.3882 - val_loss: 23.7121\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 20.8229 - val_loss: 23.7118\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 20.4933 - val_loss: 23.8983\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 20.2146 - val_loss: 24.0767\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 20.0734 - val_loss: 24.0083\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 19.8560 - val_loss: 24.0730\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.3999 - val_loss: 23.9408\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 18.7924 - val_loss: 24.1434\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 17.8464 - val_loss: 22.6047\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 17.0267 - val_loss: 20.8414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 15.7409 - val_loss: 19.7821\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.6425 - val_loss: 18.4947\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 13.7031 - val_loss: 17.2793\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.6641 - val_loss: 16.6329\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.1221 - val_loss: 16.5681\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 11.5458 - val_loss: 15.8215\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.1484 - val_loss: 15.3532\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.6880 - val_loss: 15.1859\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 10.4265 - val_loss: 14.9478\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.0905 - val_loss: 13.9689\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.8598 - val_loss: 13.8284\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.5615 - val_loss: 13.9359\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 9.3094 - val_loss: 13.6302\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.2136 - val_loss: 13.0805\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 9.0009 - val_loss: 12.8303\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.8078 - val_loss: 12.5649\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.7060 - val_loss: 12.2496\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 8.5756 - val_loss: 12.1195\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.4526 - val_loss: 11.8288\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3587 - val_loss: 11.8772\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1363 - val_loss: 11.6207\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.1688 - val_loss: 11.3935\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.1692 - val_loss: 11.4846\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.0739 - val_loss: 11.1679\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8248 - val_loss: 11.3313\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7487 - val_loss: 11.1634\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6331 - val_loss: 11.2096\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 7.5215 - val_loss: 11.1802\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4864 - val_loss: 11.0003\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3927 - val_loss: 11.0175\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3447 - val_loss: 10.9078\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3315 - val_loss: 10.7221\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2478 - val_loss: 10.7118\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1526 - val_loss: 10.6348\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1255 - val_loss: 10.7271\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0977 - val_loss: 10.8698\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0465 - val_loss: 10.7500\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0307 - val_loss: 10.7968\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0387 - val_loss: 10.6868\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9215 - val_loss: 10.6060\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9266 - val_loss: 10.5958\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9320 - val_loss: 10.5449\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8965 - val_loss: 10.4708\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8517 - val_loss: 10.5018\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8678 - val_loss: 10.3473\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9060 - val_loss: 10.3509\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8571 - val_loss: 10.4230\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8252 - val_loss: 10.3482\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8027 - val_loss: 10.2523\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7798 - val_loss: 10.5320\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.7173 - val_loss: 10.4733\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7640 - val_loss: 10.3659\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7547 - val_loss: 10.4884\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7232 - val_loss: 10.4986\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6684 - val_loss: 10.3377\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6939 - val_loss: 10.2230\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6735 - val_loss: 10.4133\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.7240 - val_loss: 10.3575\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6697 - val_loss: 10.3050\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6556 - val_loss: 10.4569\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7259 - val_loss: 10.3897\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6647 - val_loss: 10.1146\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6761 - val_loss: 10.3928\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6167 - val_loss: 10.3922\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6617 - val_loss: 10.3004\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5608 - val_loss: 10.2430\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5704 - val_loss: 10.3677\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5920 - val_loss: 10.3491\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5641 - val_loss: 10.3190\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6080 - val_loss: 10.1653\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5391 - val_loss: 10.1629\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5092 - val_loss: 10.2506\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5972 - val_loss: 10.3040\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5095 - val_loss: 9.9534\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5257 - val_loss: 10.2435\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.5070 - val_loss: 10.0727\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5148 - val_loss: 10.1220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4756 - val_loss: 10.2606\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4600 - val_loss: 10.1262\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4946 - val_loss: 10.1308\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5409 - val_loss: 9.9476\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5093 - val_loss: 10.2372\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4220 - val_loss: 9.9985\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5219 - val_loss: 10.0026\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5347 - val_loss: 10.3416\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4422 - val_loss: 9.9850\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4291 - val_loss: 10.0810\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4778 - val_loss: 10.1295\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4163 - val_loss: 9.9279\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4251 - val_loss: 10.1898\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4098 - val_loss: 10.1249\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4016 - val_loss: 10.1741\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3879 - val_loss: 10.0698\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3968 - val_loss: 10.0412\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3810 - val_loss: 10.0476\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3729 - val_loss: 10.0507\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3446 - val_loss: 9.9253\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3653 - val_loss: 10.0777\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3587 - val_loss: 10.1153\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3261 - val_loss: 9.9904\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3658 - val_loss: 10.0675\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3292 - val_loss: 10.0608\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3203 - val_loss: 10.0110\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3875 - val_loss: 10.1325\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2785 - val_loss: 9.8805\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3048 - val_loss: 9.7272\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3020 - val_loss: 10.0220\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2910 - val_loss: 9.9189\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2986 - val_loss: 9.9507\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2858 - val_loss: 9.9545\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3427 - val_loss: 10.0124\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3491 - val_loss: 10.2374\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2920 - val_loss: 10.0421\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2826 - val_loss: 9.9782\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.2357 - val_loss: 10.0863\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.2586 - val_loss: 10.0483\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2528 - val_loss: 10.1223\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2530 - val_loss: 9.9116\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2245 - val_loss: 10.0907\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2090 - val_loss: 10.0980\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2510 - val_loss: 9.9587\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2517 - val_loss: 9.9767\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2050 - val_loss: 10.1435\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2239 - val_loss: 10.0433\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4222 - val_loss: 9.8772\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3821 - val_loss: 10.3134\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1903 - val_loss: 9.9574\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2047 - val_loss: 9.9036\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1626 - val_loss: 10.0418\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1783 - val_loss: 9.8707\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1440 - val_loss: 9.9053\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1548 - val_loss: 10.1268\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1456 - val_loss: 10.1397\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1616 - val_loss: 10.0342\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2023 - val_loss: 9.8358\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1973 - val_loss: 10.1498\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1541 - val_loss: 9.7409\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1758 - val_loss: 9.5683\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1153 - val_loss: 9.8492\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1276 - val_loss: 9.8718\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1053 - val_loss: 9.9013\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1339 - val_loss: 9.9099\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2072 - val_loss: 9.9216\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1522 - val_loss: 10.2069\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1849 - val_loss: 9.9453\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0861 - val_loss: 10.1588\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1684 - val_loss: 9.9813\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1504 - val_loss: 9.9518\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1305 - val_loss: 9.8268\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1231 - val_loss: 10.0401\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0776 - val_loss: 9.8354\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0681 - val_loss: 9.7951\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0857 - val_loss: 9.9186\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0684 - val_loss: 9.9447\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.0387 - val_loss: 9.7625\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.0578 - val_loss: 9.8207\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0612 - val_loss: 9.7845\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0600 - val_loss: 9.7213\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0708 - val_loss: 9.9655\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0634 - val_loss: 9.8464\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1173 - val_loss: 9.8546\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0766 - val_loss: 10.0598\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0620 - val_loss: 9.7594\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0326 - val_loss: 9.7939\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0247 - val_loss: 9.6716\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0887 - val_loss: 9.6260\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0311 - val_loss: 9.7838\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0366 - val_loss: 9.7328\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0277 - val_loss: 9.8779\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0347 - val_loss: 9.8452\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0249 - val_loss: 9.9272\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0083 - val_loss: 9.8237\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0044 - val_loss: 9.6669\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0471 - val_loss: 9.9790\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0191 - val_loss: 9.6388\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0067 - val_loss: 9.8336\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9872 - val_loss: 9.7491\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9708 - val_loss: 9.7608\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9843 - val_loss: 9.9827\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0095 - val_loss: 9.7076\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9968 - val_loss: 9.6658\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9630 - val_loss: 9.7085\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9772 - val_loss: 9.5810\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0268 - val_loss: 9.6574\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9181 - val_loss: 9.8974\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0290 - val_loss: 9.6349\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8947 - val_loss: 9.4857\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.403 - 0s 98us/step - loss: 5.9303 - val_loss: 9.5355\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9148 - val_loss: 9.6575\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9181 - val_loss: 9.7046\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8848 - val_loss: 9.7067\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8949 - val_loss: 9.8410\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9470 - val_loss: 9.6200\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9163 - val_loss: 9.5855\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8812 - val_loss: 9.6572\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8636 - val_loss: 9.7726\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8965 - val_loss: 9.6374\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8992 - val_loss: 9.6376\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8867 - val_loss: 9.4405\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8603 - val_loss: 9.6250\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8490 - val_loss: 9.7660\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8651 - val_loss: 9.7713\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8646 - val_loss: 9.6103\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8627 - val_loss: 9.6673\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8753 - val_loss: 9.8440\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8664 - val_loss: 9.5544\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8940 - val_loss: 9.5913\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8445 - val_loss: 9.5307\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8090 - val_loss: 9.7911\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8308 - val_loss: 9.7590\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8689 - val_loss: 9.4666\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.326 - 0s 109us/step - loss: 5.8331 - val_loss: 9.6399\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8169 - val_loss: 9.5402\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8279 - val_loss: 9.6849\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8030 - val_loss: 9.5614\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8041 - val_loss: 9.6560\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8383 - val_loss: 9.5654\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8002 - val_loss: 9.6303\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8175 - val_loss: 9.5718\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7892 - val_loss: 9.4377\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7726 - val_loss: 9.4668\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8044 - val_loss: 9.4158\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7795 - val_loss: 9.5308\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7863 - val_loss: 9.5575\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8537 - val_loss: 9.5239\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7753 - val_loss: 9.8292\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8084 - val_loss: 9.4689\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7737 - val_loss: 9.5760\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8473 - val_loss: 9.5015\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7718 - val_loss: 9.6312\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7705 - val_loss: 9.5453\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.8035 - val_loss: 9.5351\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7738 - val_loss: 9.7105\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7827 - val_loss: 9.3602\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7565 - val_loss: 9.4823\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7536 - val_loss: 9.5132\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7567 - val_loss: 9.5543\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7213 - val_loss: 9.4824\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7444 - val_loss: 9.4584\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7433 - val_loss: 9.5391\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7349 - val_loss: 9.5326\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7428 - val_loss: 9.6959\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7752 - val_loss: 9.5349\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8061 - val_loss: 9.6903\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7525 - val_loss: 9.3608\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7341 - val_loss: 9.5618\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8598 - val_loss: 9.6671\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8023 - val_loss: 9.4215\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7797 - val_loss: 9.5402\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7567 - val_loss: 9.3859\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7219 - val_loss: 9.3749\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7283 - val_loss: 9.5229\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7106 - val_loss: 9.4673\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7449 - val_loss: 9.3627\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7213 - val_loss: 9.3608\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7502 - val_loss: 9.2688\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7905 - val_loss: 9.5846\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7506 - val_loss: 9.1927\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7195 - val_loss: 9.5649\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7488 - val_loss: 9.3327\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7021 - val_loss: 9.2579\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7134 - val_loss: 9.3248\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7079 - val_loss: 9.3566\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6903 - val_loss: 9.2522\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6907 - val_loss: 9.2551\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6923 - val_loss: 9.2159\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6945 - val_loss: 9.2424\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6988 - val_loss: 9.2159\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6803 - val_loss: 9.0704\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6899 - val_loss: 9.3135\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6680 - val_loss: 9.2102\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6662 - val_loss: 9.2203\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6753 - val_loss: 9.3142\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7087 - val_loss: 9.2493\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6747 - val_loss: 8.9913\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6915 - val_loss: 9.1886\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7340 - val_loss: 9.1235\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6730 - val_loss: 9.4693\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7467 - val_loss: 9.1321\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6941 - val_loss: 9.2078\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6384 - val_loss: 9.2223\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6677 - val_loss: 9.2876\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6443 - val_loss: 9.2129\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6519 - val_loss: 9.1198\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6993 - val_loss: 9.1117\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6982 - val_loss: 8.9622\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6753 - val_loss: 9.2073\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6542 - val_loss: 9.0519\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6964 - val_loss: 8.9920\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6986 - val_loss: 9.1531\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6482 - val_loss: 9.0349\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6610 - val_loss: 9.0872\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6975 - val_loss: 8.8402\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6143 - val_loss: 9.0547\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6556 - val_loss: 9.0750\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6332 - val_loss: 8.8614\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6112 - val_loss: 9.0037\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6913 - val_loss: 9.1622\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5947 - val_loss: 9.0435\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6176 - val_loss: 9.0056\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6162 - val_loss: 9.0322\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6126 - val_loss: 8.9924\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5983 - val_loss: 9.0227\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6138 - val_loss: 9.1090\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6178 - val_loss: 8.8896\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5868 - val_loss: 8.9985\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5864 - val_loss: 9.0254\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6359 - val_loss: 9.0364\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 5.5842 - val_loss: 8.9048\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6109 - val_loss: 8.8421\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5813 - val_loss: 9.1354\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5740 - val_loss: 8.9325\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5964 - val_loss: 9.0173\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6497 - val_loss: 9.0416\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5923 - val_loss: 8.9721\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.022 - 0s 120us/step - loss: 5.5797 - val_loss: 8.9416\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 5.5546 - val_loss: 8.9490\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5592 - val_loss: 8.9634\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6237 - val_loss: 9.0540\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5268 - val_loss: 8.8164\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6334 - val_loss: 8.9944\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5780 - val_loss: 8.9377\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5672 - val_loss: 8.9248\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6354 - val_loss: 8.9740\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5273 - val_loss: 8.7703\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5740 - val_loss: 8.9234\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.133 - 0s 113us/step - loss: 5.6183 - val_loss: 9.0461\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5524 - val_loss: 8.8030\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5599 - val_loss: 8.7956\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5491 - val_loss: 8.8621\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 5.5765 - val_loss: 9.0120\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5834 - val_loss: 8.6627\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5275 - val_loss: 8.9446\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5512 - val_loss: 8.9079\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5198 - val_loss: 8.9031\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5439 - val_loss: 8.8576\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5488 - val_loss: 9.0617\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5662 - val_loss: 8.6825\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5412 - val_loss: 8.8617\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5237 - val_loss: 8.7699\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4971 - val_loss: 8.9040\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5653 - val_loss: 8.7965\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5230 - val_loss: 8.8427\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5067 - val_loss: 8.7220\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5277 - val_loss: 8.8066\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5059 - val_loss: 8.7643\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4933 - val_loss: 8.8979\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4923 - val_loss: 8.9325\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5186 - val_loss: 8.7188\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4934 - val_loss: 8.8682\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4802 - val_loss: 8.8330\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5178 - val_loss: 8.7765\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5686 - val_loss: 8.7846\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5088 - val_loss: 8.9873\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.257 - 0s 95us/step - loss: 5.4978 - val_loss: 8.8093\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5079 - val_loss: 8.8926\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4692 - val_loss: 8.8476\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4908 - val_loss: 8.8392\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5487 - val_loss: 8.7405\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4626 - val_loss: 8.9272\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4960 - val_loss: 8.8754\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4734 - val_loss: 8.7951\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4610 - val_loss: 8.7095\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.921 - 0s 113us/step - loss: 5.5127 - val_loss: 8.9213\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5669 - val_loss: 8.8903\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4925 - val_loss: 8.8700\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.4845 - val_loss: 8.9486\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4564 - val_loss: 8.8022\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4729 - val_loss: 8.7237\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4688 - val_loss: 8.9402\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4892 - val_loss: 8.8355\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4575 - val_loss: 8.7636\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4599 - val_loss: 8.8685\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4534 - val_loss: 8.8921\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4624 - val_loss: 8.7685\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5319 - val_loss: 9.0314\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4783 - val_loss: 8.8958\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4559 - val_loss: 8.7688\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4423 - val_loss: 8.7962\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4492 - val_loss: 8.8726\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4354 - val_loss: 8.7025\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5022 - val_loss: 8.7253\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4238 - val_loss: 8.7856\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4445 - val_loss: 8.8285\n",
      "Epoch 452/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.4365 - val_loss: 8.9542\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4836 - val_loss: 8.7727\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4971 - val_loss: 8.8511\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4735 - val_loss: 9.0213\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4360 - val_loss: 8.6653\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4713 - val_loss: 8.6358\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4194 - val_loss: 8.6703\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4357 - val_loss: 8.9172\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4357 - val_loss: 8.6474\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4210 - val_loss: 8.8098\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4105 - val_loss: 8.7473\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4046 - val_loss: 8.6145\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3982 - val_loss: 8.8257\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4132 - val_loss: 8.7448\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4309 - val_loss: 8.9253\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4459 - val_loss: 8.7307\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3973 - val_loss: 8.7991\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4245 - val_loss: 8.9329\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4207 - val_loss: 8.6879\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4843 - val_loss: 8.8488\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4136 - val_loss: 9.1182\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3983 - val_loss: 8.8704\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3809 - val_loss: 8.7836\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3992 - val_loss: 8.8457\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4372 - val_loss: 8.7392\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3737 - val_loss: 9.0107\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3994 - val_loss: 8.8188\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3979 - val_loss: 8.8036\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4299 - val_loss: 8.8074\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3860 - val_loss: 8.9852\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4076 - val_loss: 8.8797\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3962 - val_loss: 9.0073\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3509 - val_loss: 8.8380\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4151 - val_loss: 8.7164\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3465 - val_loss: 8.9848\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3788 - val_loss: 8.8782\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3563 - val_loss: 8.9091\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3653 - val_loss: 8.9688\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4037 - val_loss: 8.7361\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3738 - val_loss: 8.9786\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3698 - val_loss: 8.9283\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3623 - val_loss: 8.7331\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3525 - val_loss: 9.0293\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4453 - val_loss: 9.0195\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4252 - val_loss: 8.8860\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4031 - val_loss: 8.8796\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3511 - val_loss: 8.7286\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3669 - val_loss: 8.9719\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3133 - val_loss: 8.7933\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3386 - val_loss: 8.8396\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3281 - val_loss: 9.0118\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3699 - val_loss: 8.7536\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4176 - val_loss: 9.0639\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3902 - val_loss: 8.9139\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3556 - val_loss: 8.9989\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3475 - val_loss: 8.7716\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3285 - val_loss: 8.9950\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3526 - val_loss: 8.8713\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3513 - val_loss: 8.8838\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3229 - val_loss: 8.9387\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3750 - val_loss: 8.8724\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3578 - val_loss: 8.9942\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3865 - val_loss: 8.8607\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3210 - val_loss: 8.6852\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3133 - val_loss: 8.9064\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3403 - val_loss: 8.9042\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3024 - val_loss: 8.9849\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3519 - val_loss: 8.9247\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3290 - val_loss: 9.0651\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3361 - val_loss: 8.9054\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3249 - val_loss: 8.9221\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3343 - val_loss: 8.8569\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3214 - val_loss: 8.9034\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3635 - val_loss: 9.0865\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3018 - val_loss: 8.8635\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3148 - val_loss: 8.9120\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3126 - val_loss: 9.0428\n",
      "Epoch 529/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.3674 - val_loss: 8.9741\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3401 - val_loss: 8.7882\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4179 - val_loss: 9.1158\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3679 - val_loss: 8.8606\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3073 - val_loss: 8.9827\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3289 - val_loss: 9.1333\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3211 - val_loss: 8.9627\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3814 - val_loss: 9.0892\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4332 - val_loss: 8.9103\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3267 - val_loss: 8.9093\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3476 - val_loss: 8.9368\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3282 - val_loss: 9.0066\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3224 - val_loss: 8.9923\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3183 - val_loss: 8.9132\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3086 - val_loss: 9.0258\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3493 - val_loss: 8.9940\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3126 - val_loss: 8.9568\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3007 - val_loss: 8.9926\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3559 - val_loss: 8.8795\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2825 - val_loss: 9.0863\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3472 - val_loss: 9.2379\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3796 - val_loss: 8.8607\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2966 - val_loss: 9.0281\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2739 - val_loss: 9.0411\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3093 - val_loss: 9.0798\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2763 - val_loss: 9.1406\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3130 - val_loss: 9.0571\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2782 - val_loss: 9.0307\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2779 - val_loss: 8.9539\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2749 - val_loss: 8.7678\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3037 - val_loss: 9.0882\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2899 - val_loss: 8.7948\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3503 - val_loss: 9.0672\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3084 - val_loss: 8.8919\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2669 - val_loss: 9.0030\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2810 - val_loss: 8.9199\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2997 - val_loss: 9.0183\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2920 - val_loss: 9.0398\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2777 - val_loss: 9.0687\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2684 - val_loss: 8.8370\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3294 - val_loss: 8.7452\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3052 - val_loss: 9.0662\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3173 - val_loss: 9.0199\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2656 - val_loss: 8.9042\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2812 - val_loss: 9.0444\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2969 - val_loss: 8.8329\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2758 - val_loss: 9.0045\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2679 - val_loss: 8.9693\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2986 - val_loss: 9.0464\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2577 - val_loss: 8.8305\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2784 - val_loss: 8.8931\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3355 - val_loss: 9.0730\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2722 - val_loss: 8.7570\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2777 - val_loss: 9.0030\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2857 - val_loss: 8.9173\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2916 - val_loss: 8.9844\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3167 - val_loss: 8.8018\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2626 - val_loss: 9.1834\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2873 - val_loss: 8.8796\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3058 - val_loss: 8.8114\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2849 - val_loss: 9.1812\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2521 - val_loss: 8.8140\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2811 - val_loss: 8.8451\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2794 - val_loss: 8.9959\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2505 - val_loss: 8.8709\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2641 - val_loss: 8.8456\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2609 - val_loss: 8.8756\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2967 - val_loss: 9.0843\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2383 - val_loss: 8.7806\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2618 - val_loss: 8.7853\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2287 - val_loss: 8.9333\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3015 - val_loss: 8.8140\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2253 - val_loss: 8.7134\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2607 - val_loss: 8.8487\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2372 - val_loss: 8.8977\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2871 - val_loss: 8.9816\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2205 - val_loss: 8.8459\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 5.2595 - val_loss: 8.9098\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2529 - val_loss: 8.7501\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2494 - val_loss: 8.9228\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2389 - val_loss: 8.7811\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3373 - val_loss: 8.7549\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2131 - val_loss: 8.8567\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2678 - val_loss: 8.7360\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2507 - val_loss: 8.6319\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2291 - val_loss: 8.9664\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2797 - val_loss: 8.9817\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2504 - val_loss: 8.7795\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2379 - val_loss: 8.9399\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2905 - val_loss: 8.7157\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2127 - val_loss: 8.8680\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2104 - val_loss: 8.7708\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2294 - val_loss: 8.7815\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2330 - val_loss: 8.6284\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2185 - val_loss: 8.7569\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2166 - val_loss: 8.8088\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.2203 - val_loss: 8.6065\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2255 - val_loss: 8.8244\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2258 - val_loss: 8.7515\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2972 - val_loss: 8.5515\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2037 - val_loss: 8.9428\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2243 - val_loss: 8.6167\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.2617 - val_loss: 8.6629\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1954 - val_loss: 8.8365\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1828 - val_loss: 8.8011\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1823 - val_loss: 8.6894\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2056 - val_loss: 8.7461\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2330 - val_loss: 8.6237\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2242 - val_loss: 8.7999\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2152 - val_loss: 8.5441\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1817 - val_loss: 8.7007\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2008 - val_loss: 8.7051\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1834 - val_loss: 8.5295\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1944 - val_loss: 8.5311\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1926 - val_loss: 8.6674\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2256 - val_loss: 8.6187\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2117 - val_loss: 8.6450\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1867 - val_loss: 8.4782\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1844 - val_loss: 8.5708\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2365 - val_loss: 8.6806\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2198 - val_loss: 8.4906\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1808 - val_loss: 8.7404\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1492 - val_loss: 8.7110\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1403 - val_loss: 8.6767\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1093 - val_loss: 8.5962\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1514 - val_loss: 8.7631\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0746 - val_loss: 8.6268\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0955 - val_loss: 8.5873\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0910 - val_loss: 8.7128\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0988 - val_loss: 8.5935\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1991 - val_loss: 8.7607\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0758 - val_loss: 8.5270\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0787 - val_loss: 8.5977\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0720 - val_loss: 8.8833\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1169 - val_loss: 8.5930\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0656 - val_loss: 8.7112\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0911 - val_loss: 8.5858\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1213 - val_loss: 8.4793\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0743 - val_loss: 8.7736\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0341 - val_loss: 8.5500\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0620 - val_loss: 8.6382\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0765 - val_loss: 8.7212\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0387 - val_loss: 8.6147\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0591 - val_loss: 8.6899\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0617 - val_loss: 8.7083\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0441 - val_loss: 8.6118\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0260 - val_loss: 8.6962\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0751 - val_loss: 8.6349\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0541 - val_loss: 8.7098\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0587 - val_loss: 8.6826\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0322 - val_loss: 8.6883\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0306 - val_loss: 8.6315\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0456 - val_loss: 8.6386\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0220 - val_loss: 8.6422\n",
      "Epoch 683/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.0375 - val_loss: 8.5807\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0210 - val_loss: 8.6183\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0148 - val_loss: 8.7470\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0195 - val_loss: 8.6537\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0564 - val_loss: 8.5202\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0189 - val_loss: 8.7209\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0112 - val_loss: 8.3883\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9987 - val_loss: 8.6185\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0342 - val_loss: 8.7555\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9866 - val_loss: 8.6568\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0152 - val_loss: 8.5407\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0078 - val_loss: 8.6978\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9915 - val_loss: 8.7149\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0467 - val_loss: 8.7460\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0109 - val_loss: 8.6133\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9608 - val_loss: 8.6456\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0239 - val_loss: 8.6354\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0346 - val_loss: 8.4232\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9830 - val_loss: 8.7578\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9906 - val_loss: 8.7871\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0291 - val_loss: 8.6129\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9588 - val_loss: 8.7440\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9741 - val_loss: 8.6577\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9741 - val_loss: 8.4282\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9738 - val_loss: 8.8517\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9570 - val_loss: 8.6391\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9933 - val_loss: 8.5618\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0901 - val_loss: 8.8274\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9853 - val_loss: 8.6234\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9661 - val_loss: 8.7255\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9551 - val_loss: 8.6585\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9771 - val_loss: 8.6601\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9956 - val_loss: 8.5740\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0342 - val_loss: 8.7847\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0098 - val_loss: 8.4396\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9356 - val_loss: 8.8004\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0255 - val_loss: 8.8313\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9407 - val_loss: 8.7085\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9800 - val_loss: 8.7044\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9167 - val_loss: 8.6913\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9377 - val_loss: 8.7589\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9814 - val_loss: 8.4405\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9830 - val_loss: 8.8978\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9909 - val_loss: 8.6956\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9179 - val_loss: 8.8832\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9259 - val_loss: 8.8586\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9264 - val_loss: 8.7775\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8938 - val_loss: 8.6727\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9272 - val_loss: 8.7387\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.9040 - val_loss: 8.7925\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9641 - val_loss: 8.6147\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9554 - val_loss: 8.9376\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8977 - val_loss: 8.5364\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9716 - val_loss: 8.7403\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9375 - val_loss: 8.8012\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9111 - val_loss: 8.6848\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9189 - val_loss: 8.8696\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.8861 - val_loss: 8.8816\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8742 - val_loss: 8.6655\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8890 - val_loss: 8.7079\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9152 - val_loss: 8.7804\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8942 - val_loss: 8.7603\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8532 - val_loss: 8.7891\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8969 - val_loss: 8.8187\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8694 - val_loss: 8.7861\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.8673 - val_loss: 8.6565\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8730 - val_loss: 8.7783\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8745 - val_loss: 8.8393\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8638 - val_loss: 8.6040\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8785 - val_loss: 8.8543\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8307 - val_loss: 8.9122\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8551 - val_loss: 8.8042\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9682 - val_loss: 8.6781\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9124 - val_loss: 8.5598\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8518 - val_loss: 8.9800\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9155 - val_loss: 8.9587\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8574 - val_loss: 8.7546\n",
      "Epoch 760/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.8358 - val_loss: 8.9424\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.8824 - val_loss: 8.7735\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8435 - val_loss: 8.7691\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8408 - val_loss: 8.9044\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8156 - val_loss: 8.7285\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8727 - val_loss: 8.7674\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8053 - val_loss: 8.9964\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8813 - val_loss: 8.8173\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8647 - val_loss: 8.8138\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8536 - val_loss: 8.9504\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8340 - val_loss: 8.8874\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8026 - val_loss: 8.9908\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8338 - val_loss: 8.7778\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8277 - val_loss: 8.8623\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8153 - val_loss: 8.8341\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8198 - val_loss: 8.8837\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9002 - val_loss: 9.0935\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8366 - val_loss: 8.7198\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8117 - val_loss: 8.9316\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8590 - val_loss: 8.9573\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8327 - val_loss: 8.7702\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8637 - val_loss: 8.8941\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8552 - val_loss: 9.0237\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8028 - val_loss: 8.8589\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8302 - val_loss: 9.0240\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8605 - val_loss: 8.8613\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8381 - val_loss: 8.7253\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8374 - val_loss: 9.1531\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8291 - val_loss: 8.8311\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7864 - val_loss: 9.0551\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7988 - val_loss: 8.7676\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7980 - val_loss: 8.8181\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7782 - val_loss: 8.9438\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7848 - val_loss: 8.9504\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8054 - val_loss: 8.8023\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7711 - val_loss: 8.8667\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8027 - val_loss: 8.8894\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7644 - val_loss: 9.0837\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8054 - val_loss: 8.9149\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7933 - val_loss: 8.9223\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7786 - val_loss: 9.0741\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7594 - val_loss: 8.9365\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7994 - val_loss: 8.9191\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7596 - val_loss: 9.0467\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7993 - val_loss: 9.1348\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7833 - val_loss: 8.7879\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7645 - val_loss: 8.9776\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7755 - val_loss: 8.9156\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7689 - val_loss: 8.9334\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7457 - val_loss: 9.0837\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7680 - val_loss: 9.0278\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.7682 - val_loss: 8.9478\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7572 - val_loss: 8.8843\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7504 - val_loss: 9.0529\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7352 - val_loss: 8.9059\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7624 - val_loss: 8.9535\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7351 - val_loss: 9.0307\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7337 - val_loss: 9.0132\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7403 - val_loss: 9.0620\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7272 - val_loss: 8.8479\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7391 - val_loss: 9.1306\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7926 - val_loss: 9.2078\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9115 - val_loss: 8.8594\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8419 - val_loss: 9.4352\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7619 - val_loss: 8.7295\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7290 - val_loss: 8.9617\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7365 - val_loss: 9.0149\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7812 - val_loss: 8.8878\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7746 - val_loss: 9.0740\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7241 - val_loss: 9.0202\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7457 - val_loss: 9.1192\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7428 - val_loss: 9.1133\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7040 - val_loss: 9.1069\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6986 - val_loss: 8.9455\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6992 - val_loss: 9.1131\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7061 - val_loss: 9.1439\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7146 - val_loss: 9.1888\n",
      "Epoch 837/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.7285 - val_loss: 9.0921\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7124 - val_loss: 9.1558\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7109 - val_loss: 9.2083\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.7404 - val_loss: 9.1573\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7990 - val_loss: 9.1674\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6889 - val_loss: 9.3021\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7616 - val_loss: 8.9596\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7186 - val_loss: 9.1363\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7302 - val_loss: 9.4410\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7519 - val_loss: 9.2051\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6701 - val_loss: 9.3143\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6727 - val_loss: 9.3516\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6923 - val_loss: 9.2429\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6793 - val_loss: 9.2114\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6603 - val_loss: 9.3053\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6769 - val_loss: 9.1378\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6817 - val_loss: 9.1661\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6742 - val_loss: 9.1863\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6666 - val_loss: 9.2708\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6640 - val_loss: 9.2779\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6889 - val_loss: 9.1876\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6656 - val_loss: 9.3400\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7355 - val_loss: 9.4274\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7803 - val_loss: 9.1779\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6570 - val_loss: 9.3123\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6771 - val_loss: 9.2262\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6624 - val_loss: 9.1448\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6632 - val_loss: 9.3596\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6399 - val_loss: 9.2552\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6736 - val_loss: 9.3658\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6654 - val_loss: 9.1303\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6682 - val_loss: 9.3312\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6887 - val_loss: 9.2618\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6414 - val_loss: 9.2589\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6842 - val_loss: 9.4552\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7439 - val_loss: 8.9230\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7096 - val_loss: 9.2862\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6747 - val_loss: 9.3998\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7128 - val_loss: 9.2084\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6312 - val_loss: 9.4161\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6566 - val_loss: 9.2298\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6280 - val_loss: 9.2779\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6481 - val_loss: 9.3220\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6494 - val_loss: 9.4524\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6506 - val_loss: 9.1850\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6596 - val_loss: 9.2274\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6341 - val_loss: 9.3807\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6206 - val_loss: 9.3364\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6581 - val_loss: 9.3517\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6449 - val_loss: 9.3052\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6382 - val_loss: 9.3045\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6256 - val_loss: 9.2887\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6878 - val_loss: 9.1048\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6560 - val_loss: 9.6234\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6037 - val_loss: 9.1799\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6437 - val_loss: 9.3406\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6219 - val_loss: 9.4406\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6104 - val_loss: 9.2014\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5913 - val_loss: 9.2983\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6114 - val_loss: 9.2598\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5871 - val_loss: 9.3827\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6610 - val_loss: 9.2655\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5883 - val_loss: 9.1702\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6484 - val_loss: 9.3789\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6927 - val_loss: 9.3800\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6048 - val_loss: 9.2939\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6237 - val_loss: 9.3296\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6165 - val_loss: 9.3043\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6038 - val_loss: 9.3953\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6302 - val_loss: 9.2803\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6513 - val_loss: 9.1824\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6231 - val_loss: 9.3420\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5930 - val_loss: 9.3279\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5793 - val_loss: 9.4049\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5760 - val_loss: 9.6395\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6248 - val_loss: 9.5055\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5992 - val_loss: 9.5472\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.6125 - val_loss: 9.3836\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6282 - val_loss: 9.4326\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5955 - val_loss: 9.3202\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5782 - val_loss: 9.4691\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6901 - val_loss: 9.3871\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6057 - val_loss: 9.6202\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6088 - val_loss: 9.4425\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6805 - val_loss: 9.5094\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5166 - val_loss: 9.2443\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6412 - val_loss: 9.6355\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6059 - val_loss: 9.4532\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6036 - val_loss: 9.4654\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6531 - val_loss: 9.4284\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7159 - val_loss: 9.2093\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6915 - val_loss: 9.6117\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6583 - val_loss: 9.3846\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5930 - val_loss: 9.5052\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6395 - val_loss: 9.3528\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.6132 - val_loss: 9.5310\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5516 - val_loss: 9.3809\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.5576 - val_loss: 9.3822\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.5756 - val_loss: 9.4454\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6198 - val_loss: 9.5197\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5929 - val_loss: 9.3653\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5815 - val_loss: 9.6897\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6793 - val_loss: 9.5247\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6047 - val_loss: 9.4330\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5655 - val_loss: 9.4731\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5872 - val_loss: 9.4225\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5850 - val_loss: 9.5941\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5521 - val_loss: 9.4845\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5972 - val_loss: 9.5252\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5346 - val_loss: 9.3532\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6110 - val_loss: 9.6695\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.5539 - val_loss: 9.3508\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.6371 - val_loss: 9.3873\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5463 - val_loss: 9.4551\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5279 - val_loss: 9.4536\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5102 - val_loss: 9.4721\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5532 - val_loss: 9.5318\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5564 - val_loss: 9.4741\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5246 - val_loss: 9.3828\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5507 - val_loss: 9.5475\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5235 - val_loss: 9.5473\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5330 - val_loss: 9.6010\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5219 - val_loss: 9.5927\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4942 - val_loss: 9.4593\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.5601 - val_loss: 9.3243\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5263 - val_loss: 9.5924\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5366 - val_loss: 9.5750\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5022 - val_loss: 9.5161\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5271 - val_loss: 9.5180\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5482 - val_loss: 9.5295\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4973 - val_loss: 9.6127\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5320 - val_loss: 9.4528\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5087 - val_loss: 9.5687\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5169 - val_loss: 9.5236\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5323 - val_loss: 9.5115\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5291 - val_loss: 9.5222\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5237 - val_loss: 9.6020\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5524 - val_loss: 9.4812\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5356 - val_loss: 9.4323\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5182 - val_loss: 9.5730\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5223 - val_loss: 9.5053\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5264 - val_loss: 9.5932\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6155 - val_loss: 9.7893\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5375 - val_loss: 9.3432\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5866 - val_loss: 9.4032\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6268 - val_loss: 9.8119\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4907 - val_loss: 9.4219\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5112 - val_loss: 9.5446\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5250 - val_loss: 9.6120\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4930 - val_loss: 9.5368\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5275 - val_loss: 9.6605\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5132 - val_loss: 9.5370\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5253 - val_loss: 9.4408\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5243 - val_loss: 9.6026\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.4760 - val_loss: 9.6569\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5329 - val_loss: 9.4956\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5648 - val_loss: 9.3482\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5117 - val_loss: 9.7939\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5574 - val_loss: 9.6715\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5010 - val_loss: 9.5132\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4867 - val_loss: 9.6195\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5692 - val_loss: 9.6701\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5507 - val_loss: 9.3355\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5316 - val_loss: 9.8843\n",
      "6.1374150615627485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0330298 , -0.36562768,  0.68187046,  2.1354477 , -1.0244323 ],\n",
       "        [-2.025833  ,  0.34108075, -1.1590474 ,  2.5963187 ,  2.9006069 ],\n",
       "        [-0.37135696, -0.3219384 ,  1.7971343 ,  2.5317461 ,  0.23362406],\n",
       "        [-3.5259588 ,  0.36422715,  2.7488182 ,  1.8292645 , -2.7725656 ],\n",
       "        [ 0.78541327, -0.06564779,  1.6035751 ,  3.2468057 ,  1.183425  ],\n",
       "        [ 0.82975286,  0.27237663,  0.4746627 , -1.6341947 ,  3.24872   ],\n",
       "        [-0.23688275,  0.07456251, -4.6085687 , -0.5904711 , -0.32417855]],\n",
       "       dtype=float32),\n",
       " array([-0.01052125, -0.88623625,  0.6775574 ,  0.15670274, -1.4806497 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.11456871, -0.11503306, -1.3995342 , -2.9320226 , 10.674542  ,\n",
       "          7.4178996 ,  0.31648788,  0.9708746 , -0.6354385 ,  0.12557863],\n",
       "        [-0.5933209 ,  0.5133555 ,  0.49433628, -0.11487687,  1.3741077 ,\n",
       "          1.0474004 ,  0.3452741 , -0.4014675 ,  0.41527912, -0.19326656],\n",
       "        [-1.8676417 ,  0.7778452 ,  2.1297069 , -4.8299484 ,  1.0310075 ,\n",
       "         -3.8126667 , -0.9260455 , -6.939569  ,  4.2055693 , -0.28346172],\n",
       "        [ 1.0958003 , -0.7242406 , -1.030874  ,  2.5783503 , -0.905949  ,\n",
       "         13.649243  , -3.0221934 , -0.8804258 ,  3.6488907 , -0.6243775 ],\n",
       "        [ 1.9939718 ,  4.030766  ,  5.162701  ,  1.9726855 ,  3.1081629 ,\n",
       "          1.2511846 ,  1.8055528 , -0.30659774,  3.4829965 , -1.7100852 ]],\n",
       "       dtype=float32),\n",
       " array([-0.9387218 ,  2.8107028 , -1.0543447 ,  1.1979365 , -1.00903   ,\n",
       "        -0.92955273,  1.061584  , -4.146087  , -1.5993323 ,  2.9467723 ],\n",
       "       dtype=float32),\n",
       " array([[5.527915 ],\n",
       "        [4.774538 ],\n",
       "        [3.151379 ],\n",
       "        [1.4917138],\n",
       "        [4.982396 ],\n",
       "        [3.5486896],\n",
       "        [4.450439 ],\n",
       "        [8.207107 ],\n",
       "        [2.5990376],\n",
       "        [3.0469365]], dtype=float32),\n",
       " array([0.9788652], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_sigmoid(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sigmoid_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 819us/step - loss: 490.6468 - val_loss: 340.8101\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 232.6457 - val_loss: 163.2011\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 110.1855 - val_loss: 83.8796\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 68.9385 - val_loss: 61.7339\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.6658 - val_loss: 59.3594\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 62.6143 - val_loss: 59.4110\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 62.5408 - val_loss: 59.3691\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.8277 - val_loss: 59.5756\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.5595 - val_loss: 59.9924\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4598 - val_loss: 60.2991\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4097 - val_loss: 60.2723\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4323 - val_loss: 60.1678\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4244 - val_loss: 60.1778\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4231 - val_loss: 60.2872\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4277 - val_loss: 60.2268\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.4119 - val_loss: 60.1936\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4147 - val_loss: 60.2102\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4453 - val_loss: 60.1662\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4119 - val_loss: 60.3510\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4400 - val_loss: 60.2356\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4186 - val_loss: 60.2591\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.4103 - val_loss: 60.1854\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4151 - val_loss: 60.2000\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.4270 - val_loss: 60.1227\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.4157 - val_loss: 60.0872\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4322 - val_loss: 60.2609\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4285 - val_loss: 60.3308\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4606 - val_loss: 60.1197\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4022 - val_loss: 60.1027\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 61.4305 - val_loss: 60.2150\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4014 - val_loss: 60.1989\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4132 - val_loss: 60.1251\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4547 - val_loss: 60.0333\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4351 - val_loss: 60.2942\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4629 - val_loss: 60.1357\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4465 - val_loss: 60.3813\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.4216 - val_loss: 60.4374\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4137 - val_loss: 60.3461\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4733 - val_loss: 60.1287\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4238 - val_loss: 60.1521\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4213 - val_loss: 60.2306\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4549 - val_loss: 60.1215\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4332 - val_loss: 60.0239\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4125 - val_loss: 60.1749\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.5189 - val_loss: 60.3702\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4480 - val_loss: 60.1800\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4162 - val_loss: 60.1858\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.3946 - val_loss: 60.1427\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4241 - val_loss: 60.1916\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3718 - val_loss: 60.0965\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4035 - val_loss: 60.0229\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4043 - val_loss: 59.9976\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3796 - val_loss: 60.0643\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3425 - val_loss: 60.2695\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3236 - val_loss: 60.1959\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2227 - val_loss: 60.2385\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.1090 - val_loss: 60.1997\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 60.2023 - val_loss: 58.8717\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 49.2546 - val_loss: 44.6363\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 38.1764 - val_loss: 38.0685\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 32.5413 - val_loss: 30.2940\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 27.4104 - val_loss: 25.8537\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 24.5085 - val_loss: 23.5427\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 22.7737 - val_loss: 22.5099\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 22.1226 - val_loss: 22.2125\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 21.9438 - val_loss: 21.8664\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 21.7757 - val_loss: 22.0470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 21.4056 - val_loss: 21.8160\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 21.1816 - val_loss: 21.4652\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 20.6375 - val_loss: 20.5711\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 19.7129 - val_loss: 19.3166\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 17.6425 - val_loss: 16.7103\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.7995 - val_loss: 15.5014\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.0512 - val_loss: 14.8327\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.9182 - val_loss: 14.6684\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.3001 - val_loss: 14.0204\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.5675 - val_loss: 13.1458\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.0896 - val_loss: 12.5806\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.5757 - val_loss: 12.4805\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.1741 - val_loss: 11.9435\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.7937 - val_loss: 11.7814\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.6005 - val_loss: 11.4482\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.3716 - val_loss: 11.2575\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.0168 - val_loss: 11.1919\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.8216 - val_loss: 10.9779\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.6860 - val_loss: 11.2354\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.3348 - val_loss: 10.6631\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.1901 - val_loss: 10.4992\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9921 - val_loss: 10.6281\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.8667 - val_loss: 10.5352\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7169 - val_loss: 10.6763\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5834 - val_loss: 10.9010\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5055 - val_loss: 10.5779\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3068 - val_loss: 11.0067\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2436 - val_loss: 10.8631\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2687 - val_loss: 11.0233\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1330 - val_loss: 11.3134\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0242 - val_loss: 11.0757\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9209 - val_loss: 11.6880\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7942 - val_loss: 11.6065\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.7569 - val_loss: 11.8623\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7297 - val_loss: 12.1294\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7238 - val_loss: 12.3357\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6898 - val_loss: 12.5450\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5587 - val_loss: 12.5338\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5122 - val_loss: 12.8449\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4733 - val_loss: 12.8104\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4718 - val_loss: 12.9692\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3798 - val_loss: 12.8125\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4826 - val_loss: 12.9509\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3660 - val_loss: 13.2016\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3268 - val_loss: 13.1020\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3660 - val_loss: 12.3321\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1887 - val_loss: 12.4938\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1071 - val_loss: 12.2300\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0225 - val_loss: 11.9366\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0449 - val_loss: 11.9190\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0524 - val_loss: 12.3536\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0256 - val_loss: 12.1394\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9878 - val_loss: 12.1347\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0291 - val_loss: 12.3785\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1226 - val_loss: 12.0233\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9449 - val_loss: 12.2049\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0242 - val_loss: 12.4628\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7680 - val_loss: 12.1714\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8072 - val_loss: 12.0020\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8314 - val_loss: 12.1158\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7496 - val_loss: 12.0878\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9809 - val_loss: 12.0838\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6420 - val_loss: 11.6935\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6056 - val_loss: 11.3856\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6492 - val_loss: 11.7270\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6618 - val_loss: 11.5122\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5338 - val_loss: 10.9880\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4438 - val_loss: 11.0489\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3103 - val_loss: 11.0054\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2976 - val_loss: 10.8261\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2379 - val_loss: 10.6318\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0951 - val_loss: 10.5808\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2333 - val_loss: 10.6078\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1269 - val_loss: 10.3719\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0851 - val_loss: 10.4725\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1582 - val_loss: 10.4179\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0602 - val_loss: 10.4712\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.0749 - val_loss: 10.2261\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9457 - val_loss: 10.1049\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0864 - val_loss: 10.0012\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1263 - val_loss: 10.2163\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9462 - val_loss: 10.1151\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9479 - val_loss: 9.9360\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0305 - val_loss: 9.9647\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9374 - val_loss: 10.0025\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9352 - val_loss: 9.7950\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0303 - val_loss: 10.1608\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9187 - val_loss: 9.7106\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9774 - val_loss: 9.5866\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8918 - val_loss: 10.1636\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9508 - val_loss: 9.8396\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8933 - val_loss: 9.7616\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9447 - val_loss: 9.9279\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9750 - val_loss: 9.8586\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7977 - val_loss: 9.8358\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8665 - val_loss: 9.7737\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7713 - val_loss: 9.9096\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8194 - val_loss: 9.7131\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7136 - val_loss: 9.7196\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8141 - val_loss: 9.6482\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8839 - val_loss: 9.6367\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9363 - val_loss: 9.6062\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7525 - val_loss: 9.5718\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.7123 - val_loss: 9.6306\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7098 - val_loss: 9.5372\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7251 - val_loss: 9.4150\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6594 - val_loss: 9.5383\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6900 - val_loss: 9.5703\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6292 - val_loss: 9.3152\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6368 - val_loss: 9.2765\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6309 - val_loss: 9.3815\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6104 - val_loss: 9.2411\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7233 - val_loss: 9.2876\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7285 - val_loss: 9.4797\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6845 - val_loss: 9.2778\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6303 - val_loss: 9.3978\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6509 - val_loss: 9.5655\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5985 - val_loss: 9.4441\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6315 - val_loss: 9.1471\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5576 - val_loss: 9.2889\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5716 - val_loss: 9.3748\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5621 - val_loss: 9.2853\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5436 - val_loss: 9.2899\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6124 - val_loss: 9.0958\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5133 - val_loss: 9.1852\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5954 - val_loss: 9.3524\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5216 - val_loss: 9.0548\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5199 - val_loss: 9.1476\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4549 - val_loss: 9.1113\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5491 - val_loss: 8.8934\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4943 - val_loss: 9.2292\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.4637 - val_loss: 9.1656\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.4928 - val_loss: 8.8035\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4196 - val_loss: 9.0682\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5264 - val_loss: 9.2262\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4207 - val_loss: 8.7311\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4998 - val_loss: 8.8992\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5261 - val_loss: 8.9469\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.5979 - val_loss: 9.1069\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4676 - val_loss: 9.2052\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4286 - val_loss: 9.1230\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4228 - val_loss: 8.8231\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4898 - val_loss: 8.9043\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5014 - val_loss: 9.0881\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4042 - val_loss: 8.9378\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3749 - val_loss: 8.8126\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5466 - val_loss: 8.8204\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5763 - val_loss: 9.2323\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3296 - val_loss: 8.8307\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4011 - val_loss: 8.8386\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3210 - val_loss: 8.7397\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3934 - val_loss: 8.8002\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4101 - val_loss: 8.8886\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3284 - val_loss: 8.8111\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.3029 - val_loss: 9.0225\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3491 - val_loss: 9.0642\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2903 - val_loss: 8.9158\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3910 - val_loss: 8.7810\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2140 - val_loss: 8.8551\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3376 - val_loss: 9.0299\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2966 - val_loss: 8.9465\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2484 - val_loss: 8.9813\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3199 - val_loss: 8.9463\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2943 - val_loss: 8.7478\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3083 - val_loss: 8.9562\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2461 - val_loss: 8.9987\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2615 - val_loss: 8.8775\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2375 - val_loss: 8.8828\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2731 - val_loss: 8.8068\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3040 - val_loss: 8.8688\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2204 - val_loss: 8.7624\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2737 - val_loss: 8.8794\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2145 - val_loss: 8.9228\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2180 - val_loss: 8.8166\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2696 - val_loss: 8.6349\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2729 - val_loss: 8.9275\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2558 - val_loss: 8.9566\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2583 - val_loss: 8.6999\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2532 - val_loss: 8.8985\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2992 - val_loss: 8.7849\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1982 - val_loss: 8.8790\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4140 - val_loss: 8.9687\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6743 - val_loss: 8.7516\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3136 - val_loss: 9.2835\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3020 - val_loss: 9.1501\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3755 - val_loss: 8.8679\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2018 - val_loss: 8.7531\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2615 - val_loss: 8.8966\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1980 - val_loss: 9.0999\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2100 - val_loss: 8.9275\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.2240 - val_loss: 8.7648\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2343 - val_loss: 8.7141\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2069 - val_loss: 8.9227\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1725 - val_loss: 8.7958\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2010 - val_loss: 8.9757\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3083 - val_loss: 9.0801\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2733 - val_loss: 8.9993\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2200 - val_loss: 8.6622\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3042 - val_loss: 8.7398\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2303 - val_loss: 8.9044\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3303 - val_loss: 9.1035\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1658 - val_loss: 8.8633\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1376 - val_loss: 8.6930\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1763 - val_loss: 8.7716\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1556 - val_loss: 9.0141\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1853 - val_loss: 8.8378\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3638 - val_loss: 8.6962\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3191 - val_loss: 8.7938\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2929 - val_loss: 8.9592\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1426 - val_loss: 8.9154\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2757 - val_loss: 8.7453\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1498 - val_loss: 8.8002\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2501 - val_loss: 8.9071\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1280 - val_loss: 8.8026\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2022 - val_loss: 8.9504\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1531 - val_loss: 8.9125\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2282 - val_loss: 8.5531\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1533 - val_loss: 8.8659\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2058 - val_loss: 8.8354\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1242 - val_loss: 8.6627\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2012 - val_loss: 8.5841\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1559 - val_loss: 8.7519\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3248 - val_loss: 9.2871\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2587 - val_loss: 8.9988\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1557 - val_loss: 8.4984\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1754 - val_loss: 8.6791\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1161 - val_loss: 8.8785\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1103 - val_loss: 8.9131\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1085 - val_loss: 8.5803\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1016 - val_loss: 8.6715\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1399 - val_loss: 8.8721\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.1885 - val_loss: 8.7130\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1166 - val_loss: 8.6037\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1225 - val_loss: 8.6622\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1008 - val_loss: 8.6901\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1800 - val_loss: 8.8606\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1126 - val_loss: 8.8623\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2230 - val_loss: 8.7140\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2205 - val_loss: 8.5533\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0768 - val_loss: 8.5477\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1356 - val_loss: 8.9138\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1293 - val_loss: 8.7087\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1596 - val_loss: 8.5629\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0416 - val_loss: 8.7399\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0919 - val_loss: 8.6272\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0448 - val_loss: 8.5585\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0798 - val_loss: 8.7249\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0932 - val_loss: 8.7575\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1487 - val_loss: 8.5135\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1060 - val_loss: 8.6112\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1180 - val_loss: 8.8357\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0965 - val_loss: 8.6710\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0779 - val_loss: 8.6244\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0875 - val_loss: 8.7364\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0628 - val_loss: 8.4913\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0484 - val_loss: 8.5535\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1648 - val_loss: 8.8539\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0605 - val_loss: 8.6094\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0504 - val_loss: 8.7821\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0768 - val_loss: 8.7443\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1503 - val_loss: 8.7743\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0869 - val_loss: 8.9196\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0216 - val_loss: 8.6475\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0330 - val_loss: 8.6995\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1044 - val_loss: 8.9221\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0916 - val_loss: 8.7685\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0276 - val_loss: 8.7104\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0414 - val_loss: 8.8409\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1579 - val_loss: 8.8606\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1170 - val_loss: 8.6454\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1109 - val_loss: 9.1603\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0474 - val_loss: 9.0018\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1139 - val_loss: 8.6600\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0537 - val_loss: 9.0580\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0168 - val_loss: 9.0806\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0596 - val_loss: 8.7880\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0956 - val_loss: 8.6537\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1120 - val_loss: 9.1480\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2012 - val_loss: 8.9102\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0132 - val_loss: 9.1217\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0134 - val_loss: 9.1913\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0378 - val_loss: 8.7181\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2059 - val_loss: 9.0062\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2000 - val_loss: 9.0647\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1114 - val_loss: 8.9543\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1163 - val_loss: 8.9340\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0002 - val_loss: 8.9247\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0959 - val_loss: 9.1635\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0360 - val_loss: 8.9800\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9999 - val_loss: 9.1378\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9852 - val_loss: 8.8936\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9793 - val_loss: 9.0505\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9651 - val_loss: 9.0565\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9793 - val_loss: 8.6480\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0138 - val_loss: 8.8440\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0450 - val_loss: 9.2277\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0286 - val_loss: 8.7821\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9562 - val_loss: 8.9969\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.9812 - val_loss: 8.9872\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9406 - val_loss: 8.9699\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9973 - val_loss: 8.9640\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0209 - val_loss: 8.9165\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9914 - val_loss: 8.8869\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9926 - val_loss: 9.3434\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0377 - val_loss: 9.1118\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9984 - val_loss: 8.5918\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1175 - val_loss: 8.9326\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9801 - val_loss: 9.1831\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.0820 - val_loss: 9.1749\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0749 - val_loss: 9.1380\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0422 - val_loss: 8.7650\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9303 - val_loss: 9.0898\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9472 - val_loss: 9.3746\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9979 - val_loss: 9.0579\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9519 - val_loss: 8.9510\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9884 - val_loss: 8.7711\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9531 - val_loss: 9.1042\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9390 - val_loss: 9.2489\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9658 - val_loss: 9.0633\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0786 - val_loss: 9.2727\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9457 - val_loss: 9.0715\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9667 - val_loss: 8.8455\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9955 - val_loss: 8.9645\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9131 - val_loss: 9.1472\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9875 - val_loss: 9.0470\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8961 - val_loss: 9.1966\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9675 - val_loss: 9.1578\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9955 - val_loss: 8.8419\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9414 - val_loss: 9.0931\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9022 - val_loss: 9.0586\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9703 - val_loss: 9.0487\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9307 - val_loss: 9.1806\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0003 - val_loss: 9.0591\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9218 - val_loss: 8.9751\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0071 - val_loss: 8.8761\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9714 - val_loss: 9.0363\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9128 - val_loss: 9.1784\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9169 - val_loss: 9.1525\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0116 - val_loss: 9.0198\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9150 - val_loss: 9.1165\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8595 - val_loss: 8.9167\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9261 - val_loss: 8.8819\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9507 - val_loss: 9.2234\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0652 - val_loss: 9.0493\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9301 - val_loss: 9.1126\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9205 - val_loss: 8.9764\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8967 - val_loss: 9.0858\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8716 - val_loss: 9.1779\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9671 - val_loss: 8.8025\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8491 - val_loss: 9.1086\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8724 - val_loss: 9.2102\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8681 - val_loss: 9.1111\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9385 - val_loss: 9.0344\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8683 - val_loss: 8.8750\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8882 - val_loss: 8.9460\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9985 - val_loss: 9.1924\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1070 - val_loss: 9.6543\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0068 - val_loss: 9.4146\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0551 - val_loss: 9.0573\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9411 - val_loss: 9.1510\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8908 - val_loss: 9.1542\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.8934 - val_loss: 9.1468\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8396 - val_loss: 9.1252\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9427 - val_loss: 9.0587\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0965 - val_loss: 8.9095\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2209 - val_loss: 9.4765\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9978 - val_loss: 9.3004\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8760 - val_loss: 9.1322\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9056 - val_loss: 9.2318\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9190 - val_loss: 9.0442\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8689 - val_loss: 9.2103\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8703 - val_loss: 9.1319\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8059 - val_loss: 9.2827\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8368 - val_loss: 9.3385\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8481 - val_loss: 9.1551\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9383 - val_loss: 8.7795\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8421 - val_loss: 9.3346\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8967 - val_loss: 9.6171\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9458 - val_loss: 9.1384\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9068 - val_loss: 9.2232\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8459 - val_loss: 9.1375\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8544 - val_loss: 9.1088\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8434 - val_loss: 9.3764\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9344 - val_loss: 9.2905\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8181 - val_loss: 9.0933\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.8327 - val_loss: 9.6009\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8786 - val_loss: 9.4498\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7865 - val_loss: 9.6783\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8246 - val_loss: 10.0805\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7640 - val_loss: 10.0260\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7653 - val_loss: 9.7563\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7718 - val_loss: 10.0003\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7320 - val_loss: 10.2323\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8096 - val_loss: 10.3368\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7690 - val_loss: 10.5013\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8440 - val_loss: 10.5445\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8050 - val_loss: 10.2906\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8324 - val_loss: 10.3204\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7700 - val_loss: 10.6032\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8009 - val_loss: 10.4833\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7077 - val_loss: 10.3839\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7343 - val_loss: 10.5493\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6790 - val_loss: 10.5034\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7842 - val_loss: 10.7358\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6740 - val_loss: 10.3758\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7193 - val_loss: 10.5191\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7202 - val_loss: 10.8833\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7306 - val_loss: 10.7190\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7286 - val_loss: 10.7606\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7614 - val_loss: 10.5704\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7822 - val_loss: 10.6743\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6373 - val_loss: 10.7540\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.6369 - val_loss: 10.9594\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.6786 - val_loss: 10.8525\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.6488 - val_loss: 10.6714\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6857 - val_loss: 10.8237\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6403 - val_loss: 10.8036\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6979 - val_loss: 10.8609\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6759 - val_loss: 11.0888\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7073 - val_loss: 10.7523\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6688 - val_loss: 10.6408\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6517 - val_loss: 10.9639\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6317 - val_loss: 10.8506\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6250 - val_loss: 10.6663\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6159 - val_loss: 10.8027\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6214 - val_loss: 10.7314\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6468 - val_loss: 10.8131\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6442 - val_loss: 11.0077\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6040 - val_loss: 10.8727\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5980 - val_loss: 11.1056\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6578 - val_loss: 10.7676\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6953 - val_loss: 11.0039\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6662 - val_loss: 11.2375\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6288 - val_loss: 10.9967\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6222 - val_loss: 11.0034\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6712 - val_loss: 10.9692\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5720 - val_loss: 10.8860\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6366 - val_loss: 10.8783\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6336 - val_loss: 10.8875\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6173 - val_loss: 11.0621\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7448 - val_loss: 11.1901\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6348 - val_loss: 11.0969\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6556 - val_loss: 11.0818\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6499 - val_loss: 11.1628\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6187 - val_loss: 10.9513\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5942 - val_loss: 11.0022\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6084 - val_loss: 11.1188\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6152 - val_loss: 11.2386\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5959 - val_loss: 11.4716\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6431 - val_loss: 11.0839\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5585 - val_loss: 11.2041\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6189 - val_loss: 11.4866\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5974 - val_loss: 11.3291\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6148 - val_loss: 11.1832\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6664 - val_loss: 11.2342\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6712 - val_loss: 11.7679\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5377 - val_loss: 11.3152\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6236 - val_loss: 11.3612\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5994 - val_loss: 11.6188\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6238 - val_loss: 11.6497\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5307 - val_loss: 11.5900\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5550 - val_loss: 11.6302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6598 - val_loss: 11.5001\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5801 - val_loss: 11.7425\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6729 - val_loss: 11.6021\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5870 - val_loss: 11.8654\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5622 - val_loss: 11.6796\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5529 - val_loss: 11.5584\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6255 - val_loss: 11.4909\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6534 - val_loss: 11.4874\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6332 - val_loss: 11.8377\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7516 - val_loss: 11.7761\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5656 - val_loss: 11.8512\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5623 - val_loss: 11.6600\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5068 - val_loss: 11.7868\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5567 - val_loss: 11.7449\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5305 - val_loss: 11.7130\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5401 - val_loss: 11.6448\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4964 - val_loss: 11.7797\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5251 - val_loss: 11.8537\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4898 - val_loss: 11.7497\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5181 - val_loss: 11.6559\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5018 - val_loss: 11.6710\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5263 - val_loss: 11.7903\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5008 - val_loss: 11.8591\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5123 - val_loss: 11.7944\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4854 - val_loss: 11.9455\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5398 - val_loss: 11.9495\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4967 - val_loss: 11.8965\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5596 - val_loss: 11.6525\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6205 - val_loss: 11.9759\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6716 - val_loss: 12.0767\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.8063 - val_loss: 11.5342\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6482 - val_loss: 12.1925\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5420 - val_loss: 11.9734\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5085 - val_loss: 11.6180\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5372 - val_loss: 11.9577\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4567 - val_loss: 11.9779\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4993 - val_loss: 11.8453\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5266 - val_loss: 11.7693\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4746 - val_loss: 11.9241\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5738 - val_loss: 12.1519\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4478 - val_loss: 11.9407\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4856 - val_loss: 11.6002\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4657 - val_loss: 11.9622\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4581 - val_loss: 11.9389\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4994 - val_loss: 11.8056\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4737 - val_loss: 11.7265\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4757 - val_loss: 11.8485\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5437 - val_loss: 11.6715\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4545 - val_loss: 11.8804\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4618 - val_loss: 12.0171\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4628 - val_loss: 11.8774\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5598 - val_loss: 11.9137\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4422 - val_loss: 11.9846\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4749 - val_loss: 11.9850\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4597 - val_loss: 11.9453\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4550 - val_loss: 11.9556\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4327 - val_loss: 11.7964\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5306 - val_loss: 12.0522\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6251 - val_loss: 11.9817\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5759 - val_loss: 11.8401\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5530 - val_loss: 11.9084\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4552 - val_loss: 12.1016\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4431 - val_loss: 11.9612\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4637 - val_loss: 11.9895\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6013 - val_loss: 11.9178\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5015 - val_loss: 12.0202\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5476 - val_loss: 12.3216\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4664 - val_loss: 11.9057\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4369 - val_loss: 11.7885\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4351 - val_loss: 12.0909\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4715 - val_loss: 12.0360\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4380 - val_loss: 11.9452\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4518 - val_loss: 12.0660\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4509 - val_loss: 11.9581\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4317 - val_loss: 11.9680\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.632 - 0s 106us/step - loss: 4.4665 - val_loss: 12.1331\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.4047 - val_loss: 12.1975\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4472 - val_loss: 11.9571\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4477 - val_loss: 12.1331\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4477 - val_loss: 11.9777\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4409 - val_loss: 11.8913\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4854 - val_loss: 12.1258\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5691 - val_loss: 12.1839\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.5092 - val_loss: 12.1190\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5648 - val_loss: 12.0540\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4791 - val_loss: 12.1299\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4298 - val_loss: 12.1204\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4203 - val_loss: 11.9922\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4282 - val_loss: 12.1306\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5044 - val_loss: 12.1848\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4334 - val_loss: 11.9484\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5451 - val_loss: 12.2943\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6772 - val_loss: 12.2993\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4392 - val_loss: 12.0733\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4406 - val_loss: 12.0700\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5481 - val_loss: 11.9711\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4407 - val_loss: 12.1624\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4509 - val_loss: 12.1894\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4054 - val_loss: 12.2393\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4026 - val_loss: 12.1941\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4390 - val_loss: 12.1470\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4204 - val_loss: 11.9792\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4579 - val_loss: 12.1010\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4111 - val_loss: 12.0077\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4847 - val_loss: 12.0393\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4534 - val_loss: 12.1778\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4318 - val_loss: 12.1300\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3859 - val_loss: 12.2317\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4434 - val_loss: 12.1240\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4227 - val_loss: 12.3370\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4025 - val_loss: 12.0732\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4233 - val_loss: 11.9967\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4266 - val_loss: 12.3559\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4148 - val_loss: 11.9950\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4835 - val_loss: 11.9919\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 178us/step - loss: 4.4951 - val_loss: 12.1630\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.4540 - val_loss: 12.3394\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4768 - val_loss: 11.9819\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3802 - val_loss: 12.0280\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4131 - val_loss: 12.1197\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4163 - val_loss: 12.0911\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4209 - val_loss: 11.9909\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4120 - val_loss: 12.2247\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4239 - val_loss: 12.1335\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3794 - val_loss: 12.1649\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3919 - val_loss: 12.0534\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3622 - val_loss: 12.0054\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4078 - val_loss: 12.1820\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4459 - val_loss: 12.2078\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4299 - val_loss: 11.9332\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4263 - val_loss: 12.1610\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3756 - val_loss: 12.2292\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3764 - val_loss: 12.2795\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4051 - val_loss: 12.2195\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3986 - val_loss: 12.2652\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3444 - val_loss: 12.1894\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4193 - val_loss: 12.1623\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3863 - val_loss: 12.3677\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4395 - val_loss: 12.1380\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4072 - val_loss: 11.9698\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3577 - val_loss: 12.4063\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.5641 - val_loss: 12.5533\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6971 - val_loss: 12.0351\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4536 - val_loss: 12.1433\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3983 - val_loss: 12.2698\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3813 - val_loss: 12.2333\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3427 - val_loss: 12.0651\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3698 - val_loss: 12.2270\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4138 - val_loss: 12.0863\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3859 - val_loss: 12.4081\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3891 - val_loss: 12.3333\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4692 - val_loss: 12.3559\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3533 - val_loss: 12.2806\n",
      "Epoch 683/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.4224 - val_loss: 12.3445\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3938 - val_loss: 12.2122\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3971 - val_loss: 12.1758\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3930 - val_loss: 12.3644\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3517 - val_loss: 12.3466\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3899 - val_loss: 12.3988\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3895 - val_loss: 12.4580\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4952 - val_loss: 12.2967\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4024 - val_loss: 12.3540\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4418 - val_loss: 12.2361\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4577 - val_loss: 12.3615\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4408 - val_loss: 12.1797\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3949 - val_loss: 12.2452\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3893 - val_loss: 12.3817\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3714 - val_loss: 12.4385\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3252 - val_loss: 12.2908\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3742 - val_loss: 12.3666\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3957 - val_loss: 12.5711\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3779 - val_loss: 12.3171\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4224 - val_loss: 12.3140\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4995 - val_loss: 12.2541\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4530 - val_loss: 12.4909\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3498 - val_loss: 12.2442\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3702 - val_loss: 12.2472\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3369 - val_loss: 12.3275\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4078 - val_loss: 12.2696\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3878 - val_loss: 12.1876\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3873 - val_loss: 12.4649\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3725 - val_loss: 12.4185\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4221 - val_loss: 12.2200\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.3231 - val_loss: 12.2681\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3753 - val_loss: 12.4326\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3463 - val_loss: 12.3083\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4438 - val_loss: 12.2308\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3647 - val_loss: 12.3298\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3666 - val_loss: 12.2825\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4281 - val_loss: 12.2332\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4313 - val_loss: 12.3577\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4048 - val_loss: 12.3032\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4078 - val_loss: 12.1375\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4143 - val_loss: 12.2177\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4407 - val_loss: 12.4280\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5035 - val_loss: 12.4236\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4130 - val_loss: 12.4639\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3943 - val_loss: 12.4623\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3376 - val_loss: 12.3806\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3804 - val_loss: 12.5984\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2964 - val_loss: 12.4199\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3349 - val_loss: 12.4377\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3264 - val_loss: 12.4901\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3069 - val_loss: 12.4364\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3183 - val_loss: 12.2296\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3827 - val_loss: 12.5368\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4314 - val_loss: 12.1605\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4244 - val_loss: 12.6297\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3955 - val_loss: 12.4222\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3883 - val_loss: 12.3585\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3380 - val_loss: 12.5435\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3824 - val_loss: 12.5000\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3834 - val_loss: 12.4848\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3834 - val_loss: 12.4235\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3474 - val_loss: 12.5445\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2953 - val_loss: 12.4097\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3660 - val_loss: 12.4895\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4061 - val_loss: 12.4977\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3292 - val_loss: 12.4969\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3210 - val_loss: 12.4332\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3606 - val_loss: 12.4565\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4599 - val_loss: 12.7423\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3708 - val_loss: 12.6122\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4014 - val_loss: 12.3712\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4298 - val_loss: 12.5566\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3775 - val_loss: 12.5809\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3388 - val_loss: 12.5097\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3413 - val_loss: 12.6333\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3344 - val_loss: 12.5748\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3767 - val_loss: 12.1757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3744 - val_loss: 12.3755\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.3156 - val_loss: 12.5066\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4768 - val_loss: 12.4071\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5254 - val_loss: 12.5677\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4263 - val_loss: 12.6711\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3283 - val_loss: 12.4369\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3535 - val_loss: 12.6360\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3573 - val_loss: 12.7197\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4015 - val_loss: 12.6584\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3748 - val_loss: 12.4863\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3501 - val_loss: 12.6006\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3089 - val_loss: 12.5466\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3364 - val_loss: 12.5588\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3292 - val_loss: 12.4731\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3633 - val_loss: 12.7181\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3893 - val_loss: 12.4739\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3231 - val_loss: 12.6063\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3627 - val_loss: 12.5567\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4444 - val_loss: 12.4373\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4429 - val_loss: 12.9086\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4410 - val_loss: 12.4828\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5798 - val_loss: 12.6280\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3439 - val_loss: 12.7573\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3693 - val_loss: 12.4610\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3627 - val_loss: 12.8166\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4164 - val_loss: 12.4191\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3687 - val_loss: 12.8079\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3375 - val_loss: 12.4945\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3793 - val_loss: 12.6805\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4301 - val_loss: 12.8636\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3156 - val_loss: 12.4861\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3793 - val_loss: 12.6157\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3098 - val_loss: 12.6352\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3334 - val_loss: 12.5607\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3435 - val_loss: 12.5377\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3154 - val_loss: 12.8373\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2954 - val_loss: 12.8757\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2870 - val_loss: 12.3146\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2942 - val_loss: 12.5623\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2869 - val_loss: 12.7272\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2937 - val_loss: 12.7632\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2648 - val_loss: 12.4879\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2679 - val_loss: 12.6700\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3226 - val_loss: 12.7390\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2893 - val_loss: 12.6670\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4229 - val_loss: 12.4698\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5313 - val_loss: 12.5156\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.5395 - val_loss: 12.9545\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3355 - val_loss: 12.4895\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2884 - val_loss: 12.5182\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2981 - val_loss: 12.8612\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2797 - val_loss: 12.6299\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3001 - val_loss: 12.3971\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2955 - val_loss: 12.7267\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3054 - val_loss: 12.6455\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3009 - val_loss: 12.6199\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3030 - val_loss: 12.7402\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2971 - val_loss: 12.6239\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2476 - val_loss: 12.7879\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3316 - val_loss: 12.6644\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3056 - val_loss: 12.7697\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2774 - val_loss: 12.7145\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2846 - val_loss: 12.7284\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2678 - val_loss: 12.6144\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2682 - val_loss: 12.6016\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2722 - val_loss: 12.6155\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3031 - val_loss: 12.8134\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3096 - val_loss: 12.6053\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2856 - val_loss: 12.5121\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3064 - val_loss: 12.7567\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5265 - val_loss: 12.6928\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4744 - val_loss: 12.9884\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3399 - val_loss: 12.6360\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3365 - val_loss: 12.6349\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2636 - val_loss: 12.7980\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3349 - val_loss: 12.7801\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2830 - val_loss: 12.4989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3472 - val_loss: 12.7692\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2640 - val_loss: 12.6498\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2251 - val_loss: 12.7579\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2668 - val_loss: 12.6033\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3219 - val_loss: 12.8300\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3222 - val_loss: 12.5275\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2955 - val_loss: 12.5155\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3178 - val_loss: 12.6207\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2900 - val_loss: 12.6298\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2438 - val_loss: 12.6284\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2846 - val_loss: 12.7302\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2986 - val_loss: 12.6247\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2419 - val_loss: 12.7149\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2259 - val_loss: 12.6696\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2972 - val_loss: 12.6561\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2720 - val_loss: 12.6376\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2711 - val_loss: 12.8658\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2348 - val_loss: 12.5899\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2285 - val_loss: 12.6965\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2805 - val_loss: 12.6296\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2402 - val_loss: 12.6143\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3575 - val_loss: 12.7365\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4319 - val_loss: 12.6619\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3838 - val_loss: 12.5884\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4513 - val_loss: 12.5614\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3398 - val_loss: 12.7318\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3072 - val_loss: 12.7219\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3891 - val_loss: 12.7846\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3500 - val_loss: 12.7633\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3233 - val_loss: 12.9380\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3618 - val_loss: 12.6056\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2658 - val_loss: 12.5947\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3114 - val_loss: 12.5227\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2762 - val_loss: 12.8581\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3274 - val_loss: 12.6568\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3221 - val_loss: 12.7427\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2703 - val_loss: 12.7175\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2628 - val_loss: 12.8102\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2631 - val_loss: 12.7396\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3158 - val_loss: 12.8395\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2576 - val_loss: 12.5886\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2631 - val_loss: 12.7049\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2475 - val_loss: 12.9355\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2759 - val_loss: 12.8033\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2601 - val_loss: 12.6276\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2911 - val_loss: 12.8740\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2722 - val_loss: 12.5778\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2336 - val_loss: 12.8029\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2956 - val_loss: 13.0173\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2619 - val_loss: 12.5574\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2672 - val_loss: 12.7915\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2885 - val_loss: 12.7893\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3351 - val_loss: 12.8391\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2701 - val_loss: 12.8935\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2493 - val_loss: 12.8669\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3436 - val_loss: 12.8131\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3471 - val_loss: 12.8856\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5302 - val_loss: 12.6488\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3994 - val_loss: 12.9896\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2609 - val_loss: 12.6450\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3205 - val_loss: 12.9109\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2548 - val_loss: 12.8429\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2428 - val_loss: 12.7008\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2211 - val_loss: 12.7767\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2282 - val_loss: 12.5857\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2346 - val_loss: 12.7967\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2624 - val_loss: 13.0556\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1811 - val_loss: 12.7492\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2402 - val_loss: 12.6534\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3477 - val_loss: 13.0371\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.236 - 0s 98us/step - loss: 4.2179 - val_loss: 12.8256\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2400 - val_loss: 12.5895\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2916 - val_loss: 13.1776\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2478 - val_loss: 12.7928\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2214 - val_loss: 12.7841\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2716 - val_loss: 12.9116\n",
      "Epoch 913/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.3444 - val_loss: 13.1688\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2652 - val_loss: 12.7605\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2240 - val_loss: 12.9239\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2721 - val_loss: 13.2375\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2804 - val_loss: 12.7837\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3007 - val_loss: 13.0457\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4907 - val_loss: 12.8718\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2398 - val_loss: 12.9879\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2762 - val_loss: 13.1738\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2149 - val_loss: 12.9770\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2364 - val_loss: 12.9506\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3204 - val_loss: 12.9678\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2480 - val_loss: 13.0562\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3521 - val_loss: 12.9338\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4110 - val_loss: 12.9157\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4270 - val_loss: 13.2488\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3812 - val_loss: 12.9574\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3088 - val_loss: 13.3481\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3582 - val_loss: 13.5835\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3208 - val_loss: 13.3702\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2731 - val_loss: 13.0291\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2911 - val_loss: 13.2638\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2848 - val_loss: 13.2622\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2557 - val_loss: 13.4548\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3056 - val_loss: 13.3733\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2160 - val_loss: 13.1465\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2529 - val_loss: 13.4643\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2433 - val_loss: 13.3318\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3008 - val_loss: 13.5374\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2692 - val_loss: 13.7587\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2325 - val_loss: 13.5641\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2580 - val_loss: 13.5223\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2488 - val_loss: 13.7268\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2666 - val_loss: 13.6654\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2565 - val_loss: 13.7377\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2036 - val_loss: 13.7134\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2689 - val_loss: 13.7206\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2633 - val_loss: 13.9492\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1859 - val_loss: 13.8598\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2637 - val_loss: 13.8656\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1752 - val_loss: 14.3009\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2036 - val_loss: 14.1924\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2359 - val_loss: 14.0022\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2571 - val_loss: 14.3416\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2187 - val_loss: 14.5937\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2112 - val_loss: 14.4145\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2226 - val_loss: 14.3542\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2026 - val_loss: 14.5044\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2285 - val_loss: 14.4755\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1952 - val_loss: 14.5905\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1914 - val_loss: 14.8862\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1815 - val_loss: 14.5631\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2059 - val_loss: 14.3864\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2135 - val_loss: 14.6057\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2323 - val_loss: 14.8100\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2509 - val_loss: 14.8400\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3064 - val_loss: 15.0345\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1757 - val_loss: 14.7757\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2575 - val_loss: 14.8134\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2589 - val_loss: 14.8582\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2846 - val_loss: 14.8544\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2898 - val_loss: 14.9710\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2617 - val_loss: 14.8337\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3314 - val_loss: 14.8388\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.3037 - val_loss: 14.7162\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2187 - val_loss: 14.8737\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2208 - val_loss: 14.8689\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2392 - val_loss: 14.9989\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1984 - val_loss: 14.7009\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1711 - val_loss: 14.9665\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2178 - val_loss: 14.7560\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.2996 - val_loss: 14.6230\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3194 - val_loss: 14.6710\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3805 - val_loss: 14.9636\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4543 - val_loss: 14.9832\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5806 - val_loss: 14.6101\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4516 - val_loss: 14.7147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3721 - val_loss: 14.8345\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2508 - val_loss: 14.7737\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3582 - val_loss: 14.5232\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3558 - val_loss: 14.3200\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2923 - val_loss: 14.4334\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2408 - val_loss: 14.7218\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3351 - val_loss: 14.6640\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4372 - val_loss: 14.5366\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2554 - val_loss: 15.6062\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4086 - val_loss: 15.0743\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1747 - val_loss: 15.2285\n",
      "9.362760471085371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.61688435, -0.22609827, -0.6342331 ,  0.366641  , -0.9687269 ],\n",
       "        [-1.5270045 , -1.6959621 ,  0.7699968 ,  2.0398297 ,  0.8230238 ],\n",
       "        [-2.937295  , -0.8213965 ,  0.57011265, -2.209137  , -1.0982063 ],\n",
       "        [ 0.9483623 , -0.3457916 ,  0.5764095 , -0.00502201, -3.093615  ],\n",
       "        [-0.21967639, -0.1502939 ,  1.3470758 ,  0.3034525 ,  0.974901  ],\n",
       "        [ 0.9363165 ,  1.0671358 , -0.7812648 ,  2.4391727 ,  0.18126158],\n",
       "        [ 1.444995  , -2.4483917 , -2.198712  ,  1.8460821 ,  1.0266968 ]],\n",
       "       dtype=float32),\n",
       " array([-0.42747882,  0.8547657 ,  0.797431  , -2.1884248 ,  0.02251981],\n",
       "       dtype=float32),\n",
       " array([[ 2.7888947 , -3.6909642 , -1.9547813 , -8.241312  ,  1.260696  ,\n",
       "         -0.97170186,  0.04239525,  0.3131812 , -1.2136418 ,  1.7288454 ],\n",
       "        [ 0.8242471 , -0.35555294, -0.5565403 , -0.2569004 ,  8.258198  ,\n",
       "         -4.1294665 ,  0.5604974 , -8.3181    ,  1.4962405 ,  0.47532576],\n",
       "        [ 1.1886945 , -0.01838726, -0.67866504,  0.37782773, -0.12874104,\n",
       "         -0.76191735, -1.0753627 , -0.8428433 , -1.9838241 , -0.14157154],\n",
       "        [ 0.7590137 , -1.798345  , -0.9714856 , -1.9995385 ,  2.7656615 ,\n",
       "         -1.2267896 ,  2.3380878 , -0.59773725,  0.597303  ,  0.2996074 ],\n",
       "        [ 1.6354383 , -6.331228  , -1.4115725 ,  0.64093226,  1.4628259 ,\n",
       "         -1.6229995 ,  0.55999327, -1.6013066 ,  1.3058892 , -3.937548  ]],\n",
       "       dtype=float32),\n",
       " array([ 0.12578744, -0.0130739 , -0.9728075 , -1.6125305 ,  0.88396865,\n",
       "        -0.34626275, -4.9600887 ,  0.62092775, -2.4323835 , -2.2638025 ],\n",
       "       dtype=float32),\n",
       " array([[ 3.3434691],\n",
       "        [-3.2121902],\n",
       "        [-2.6887455],\n",
       "        [-4.2389297],\n",
       "        [ 3.5687964],\n",
       "        [-3.5664623],\n",
       "        [ 4.5957274],\n",
       "        [-3.1703417],\n",
       "        [ 2.6072857],\n",
       "        [-3.25791  ]], dtype=float32),\n",
       " array([2.5106652], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_tanh(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_tanh_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.6164 - val_loss: 0.0592\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.1046 - val_loss: 0.0632\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0617 - val_loss: 0.0544\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0457 - val_loss: 0.0312\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0326 - val_loss: 0.0124\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0176\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0249 - val_loss: 0.0253\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0243 - val_loss: 0.0192\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0241 - val_loss: 0.0172\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0205 - val_loss: 0.0111\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0204 - val_loss: 0.0097\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0182 - val_loss: 0.0100\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0178 - val_loss: 0.0097\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0172 - val_loss: 0.0092\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0180 - val_loss: 0.0100\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0165 - val_loss: 0.0100\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0160 - val_loss: 0.0097\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0157 - val_loss: 0.0101\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0155 - val_loss: 0.0085\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0145 - val_loss: 0.0075\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0141 - val_loss: 0.0071\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0137 - val_loss: 0.0072\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0132 - val_loss: 0.0069\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0131 - val_loss: 0.0074\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0125 - val_loss: 0.0074\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0128 - val_loss: 0.0057\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0118 - val_loss: 0.0061\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0114 - val_loss: 0.0054\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0108 - val_loss: 0.0053\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0104 - val_loss: 0.0051\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0108 - val_loss: 0.0065\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0141 - val_loss: 0.0055\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0118 - val_loss: 0.0054\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0100 - val_loss: 0.0045\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0099 - val_loss: 0.0074\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0085 - val_loss: 0.0047\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0047\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 117us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0084\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0074\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0074\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0089\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0092\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0073\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0083\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0074\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0067\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0072\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0070\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0065\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0045 - val_loss: 0.0071\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0068\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 118us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0066\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 159us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 141us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0065\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "0.0035022867377847433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.08962713, -0.07162376,  0.86272144, -0.8574913 , -0.3859361 ],\n",
       "        [-0.2578802 , -0.42354757,  0.64654094, -0.81552815, -0.61337024],\n",
       "        [-0.48494235, -0.42052877,  0.32795647, -0.29053494, -0.5026653 ],\n",
       "        [-0.04074199,  0.012768  ,  0.4591793 , -0.6373241 , -0.22697626],\n",
       "        [-0.06616182,  0.58017784,  0.30467945, -0.88342166,  0.09881908],\n",
       "        [-0.03175436, -0.23892978,  0.12526019, -0.41287512, -0.3238747 ],\n",
       "        [-0.41729733, -0.05783236,  0.78667265, -0.58108217, -0.6180167 ],\n",
       "        [ 0.09729291, -0.47072613,  0.0353127 , -0.12659504, -0.47025362],\n",
       "        [ 0.03944265,  0.21105126,  0.46735513, -0.7920194 , -0.27914068],\n",
       "        [ 0.37471417, -0.1255387 ,  0.21492209, -0.09676607, -0.7528574 ],\n",
       "        [-0.19723772, -0.43072805,  0.18906215, -0.17858723,  0.08307343],\n",
       "        [ 0.36781055,  0.45051748,  0.04334582,  1.4489563 , -0.0701236 ],\n",
       "        [ 0.53410214, -0.2146546 ,  0.629229  ,  1.2746509 , -0.44058597],\n",
       "        [ 2.1623554 , -0.09937825,  0.6292028 ,  0.58518606, -0.2860886 ],\n",
       "        [ 0.32817414,  0.18377963,  0.14481299,  0.19461617, -0.13298301],\n",
       "        [ 0.0932234 , -0.61714596,  0.01784875, -0.07752982, -0.19113141],\n",
       "        [-0.43855408, -0.41612288,  0.26894626, -0.2417964 , -0.12617724],\n",
       "        [ 0.32520577, -0.697434  ,  0.34614295,  0.63270456,  0.16312043],\n",
       "        [-0.64297634,  0.08465257,  0.13294469,  0.12057772, -0.80741537],\n",
       "        [ 0.43443608, -0.06784274,  0.2961771 ,  0.35995018, -0.44478682],\n",
       "        [-2.0028284 , -0.7084305 ,  0.23343867, -1.3581502 , -0.27634895],\n",
       "        [-0.44804528,  0.09958745,  0.8781167 , -1.431964  , -0.3429934 ]],\n",
       "       dtype=float32),\n",
       " array([-0.46795177, -0.21836859,  0.45445493, -0.31909874, -0.34265816],\n",
       "       dtype=float32),\n",
       " array([[ 6.4736956e-01, -2.2680837e-01,  8.8529223e-01,  3.3232957e-01,\n",
       "          8.3458312e-02,  1.5864141e-01, -2.5217846e-01, -3.3459540e-02,\n",
       "          3.6780089e-01, -3.1192219e-01],\n",
       "        [ 7.3611528e-02,  4.9543467e-01,  1.9613314e-01, -6.0945594e-01,\n",
       "          2.8147736e-01, -9.1677962e-04,  6.7879456e-01, -2.8871432e-01,\n",
       "          2.0792553e-02,  7.7163875e-01],\n",
       "        [ 3.5733232e-01,  1.8959506e-01,  5.0233561e-01,  6.4037782e-01,\n",
       "          4.0352246e-01,  1.1098130e-01, -1.2021505e-01,  4.4646353e-01,\n",
       "          1.0314219e+00,  1.8448448e-01],\n",
       "        [-8.4557153e-02,  6.4136185e-02, -6.1371034e-01, -8.4468043e-01,\n",
       "         -8.5779138e-02, -5.7562198e-02,  2.0068564e-01,  6.8142787e-02,\n",
       "          2.9025067e-02,  4.3136275e-01],\n",
       "        [-5.0153935e-01, -2.8236922e-02, -2.3025203e-01, -1.7910587e-02,\n",
       "         -1.3447188e-01,  3.7589726e-01, -3.6470258e-01,  2.1385640e-01,\n",
       "          3.5350719e-01, -2.6660413e-01]], dtype=float32),\n",
       " array([-0.4510328 ,  0.4189455 , -0.47805268, -0.5366777 , -0.4172393 ,\n",
       "         0.4402691 ,  0.44769418, -0.46493462, -0.39337334,  0.48205742],\n",
       "       dtype=float32),\n",
       " array([[ 0.02094739],\n",
       "        [-0.12720841],\n",
       "        [ 0.42276853],\n",
       "        [ 0.53977   ],\n",
       "        [ 0.05858704],\n",
       "        [-0.12885842],\n",
       "        [-0.0527382 ],\n",
       "        [-0.00195591],\n",
       "        [ 0.00277057],\n",
       "        [-0.00264832]], dtype=float32),\n",
       " array([-0.45644218], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_linear(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_linear_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0179\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0191 - val_loss: 0.0175\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0167 - val_loss: 0.0123\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0269 - val_loss: 0.0090\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0118 - val_loss: 0.0043\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 112us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0070\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0070\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 119us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "0.01369984820485115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.11434013, -0.23101291,  0.23533805,  0.3012941 , -0.01860092],\n",
       "        [-0.15715042, -0.20493115,  0.07143531,  0.00684328, -0.5178506 ],\n",
       "        [-0.27560306, -0.5702419 ,  0.32215753, -0.24127077, -0.26484188],\n",
       "        [-0.26943636,  0.4254921 ,  0.1678433 ,  0.13394669,  0.08261892],\n",
       "        [-0.14516959, -0.16543148, -0.40655312, -0.18611835, -0.33007383],\n",
       "        [ 0.01265472, -0.43502322, -0.09677108,  0.8036989 , -0.40769297],\n",
       "        [-0.14288017, -0.67743695, -0.45989022, -0.52851385, -0.21921177],\n",
       "        [-0.42936468, -0.6516936 , -1.3956009 ,  0.06700577, -0.58938974],\n",
       "        [-0.28068936, -0.46360838,  0.8266075 , -0.01271482, -0.6302666 ],\n",
       "        [-0.31082898, -0.08831491, -0.4858296 ,  0.693719  , -0.6014654 ],\n",
       "        [-0.04785466, -0.27757713, -1.3705622 ,  0.00760688, -0.49784967],\n",
       "        [ 0.34956238,  0.26266977, -1.0774711 , -0.02182257, -0.32097387],\n",
       "        [ 0.24229142,  0.09338704,  0.33844906, -0.26542825, -0.6417921 ],\n",
       "        [-0.4693879 , -0.4010294 , -0.9830911 ,  1.7690042 , -0.0870204 ],\n",
       "        [-0.3012151 ,  0.3229553 ,  0.25551647,  0.7886993 , -0.11824168],\n",
       "        [-0.09982768, -0.3300971 , -0.27652004, -0.32073212, -0.11847521],\n",
       "        [ 0.21840146,  0.02864479, -0.20567992,  0.03780593, -0.6747224 ],\n",
       "        [-0.23929171, -0.3895526 , -0.45709834,  0.83454674, -0.14329457],\n",
       "        [ 0.14984551,  0.24892852, -0.48299053, -0.9520963 , -0.6406811 ],\n",
       "        [-0.10058945, -0.1196323 ,  0.39984506,  0.83648807, -0.30506974],\n",
       "        [ 0.40013608,  0.22065113,  1.6580954 , -3.0404527 , -0.02632593],\n",
       "        [-0.25270814,  0.25022796,  1.2736839 ,  0.61820906, -0.5162407 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.        , -0.1911858 ,  0.4030817 , -0.45112222, -0.31718555],\n",
       "       dtype=float32),\n",
       " array([[ 0.44731194, -0.44924822,  0.20940799,  0.39757138, -0.5335021 ,\n",
       "          0.0660218 ,  0.31196856, -0.07022536, -0.42686146,  0.22272009],\n",
       "        [-0.12250304,  0.36303192,  0.23833007, -0.19836529, -0.36184072,\n",
       "          0.30245697, -0.6509747 , -0.39017946, -0.09103173,  0.11358345],\n",
       "        [-0.31149825, -0.25056946, -0.8942095 , -0.4273752 , -0.5117065 ,\n",
       "         -1.2262262 , -0.44815466, -0.3276238 , -0.29497576, -0.58437747],\n",
       "        [-0.3167311 , -0.10066973, -0.18462661,  0.50193214, -0.21918786,\n",
       "         -0.14690107,  0.5812924 , -0.32177877, -0.24606729, -0.40879148],\n",
       "        [-0.33569375, -0.39689484,  0.23176041, -0.78507423,  0.38616306,\n",
       "         -0.16340795, -0.14112304, -0.5015024 ,  0.08776474, -0.00131339]],\n",
       "       dtype=float32),\n",
       " array([ 0.        , -0.40748632, -0.16415188,  0.14378788,  0.        ,\n",
       "         0.1534461 , -0.5899819 ,  0.        , -0.31714797,  0.        ],\n",
       "       dtype=float32),\n",
       " array([[ 0.27746683],\n",
       "        [ 0.04940171],\n",
       "        [ 0.38196823],\n",
       "        [ 0.40773952],\n",
       "        [-0.23316556],\n",
       "        [ 0.06988882],\n",
       "        [ 1.3957452 ],\n",
       "        [-0.3116123 ],\n",
       "        [ 0.4129096 ],\n",
       "        [ 0.7171157 ]], dtype=float32),\n",
       " array([0.04824737], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_relu(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_relu_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1988 - val_loss: 0.1606\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0739 - val_loss: 0.0379\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0565 - val_loss: 0.0332\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0462 - val_loss: 0.0364\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0440 - val_loss: 0.0265\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0422 - val_loss: 0.0376\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0394 - val_loss: 0.0252\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0386 - val_loss: 0.0272\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0375 - val_loss: 0.0288\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0257\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0376 - val_loss: 0.0277\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0252\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0291\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0272\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0375 - val_loss: 0.0251\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0381 - val_loss: 0.0307\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0253\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0378 - val_loss: 0.0259\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0376 - val_loss: 0.0273\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0251\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0382 - val_loss: 0.0305\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0255\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0285\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0373 - val_loss: 0.0281\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0269\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0313\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0260\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0296\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0386 - val_loss: 0.0260\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0293\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0268\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0280\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0252\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0284\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0277\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0382 - val_loss: 0.0281\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0254\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0295\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0390 - val_loss: 0.0297\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0366 - val_loss: 0.0249\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0276\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0288\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0290\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0283\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0373 - val_loss: 0.0255\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0281\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0257\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0267\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0376 - val_loss: 0.0296\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0253\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0283\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0251\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0278\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0292\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0265\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0382 - val_loss: 0.0253\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0382 - val_loss: 0.0304\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0254\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0382 - val_loss: 0.0269\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0312\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0254\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0376 - val_loss: 0.0252\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0281\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0283\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0253\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0380 - val_loss: 0.0279\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0251\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0282\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0289\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0251\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0285\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0258\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0374 - val_loss: 0.0284\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0267\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0377 - val_loss: 0.0279\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0256\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0364 - val_loss: 0.0307\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0378 - val_loss: 0.0285\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0257\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0278\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0254\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0293\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0381 - val_loss: 0.0257\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0363 - val_loss: 0.0315\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0385 - val_loss: 0.0265\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0266\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0374 - val_loss: 0.0262\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0255\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0286\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0302\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0251\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0272\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0291\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0385 - val_loss: 0.0261\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0366 - val_loss: 0.0307\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0267\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0380 - val_loss: 0.0260\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0302\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0255\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0265\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0366 - val_loss: 0.0300\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0374 - val_loss: 0.0268\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0259\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0384 - val_loss: 0.0272\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0367 - val_loss: 0.0251\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0262\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0384 - val_loss: 0.0298\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0378 - val_loss: 0.0249\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0383 - val_loss: 0.0298\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0372 - val_loss: 0.0286\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0366 - val_loss: 0.0254\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0262\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0367 - val_loss: 0.0281\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0380 - val_loss: 0.0255\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0367 - val_loss: 0.0292\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0374 - val_loss: 0.0285\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0255\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0287\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0256\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0300\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0284\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0274\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0382 - val_loss: 0.0259\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0291\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0285\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0287\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0285\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0386 - val_loss: 0.0256\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0367 - val_loss: 0.0299\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0290\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0361 - val_loss: 0.0248\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0383 - val_loss: 0.0260\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0377 - val_loss: 0.0314\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0256\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0263\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0317\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0269\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0252\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0293\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0274\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0251\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0301\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0260\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0301\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0270\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0366 - val_loss: 0.0249\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0380 - val_loss: 0.0267\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0281\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0258\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0281\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0255\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0274\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0292\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0285\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0363 - val_loss: 0.0251\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0262\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0310\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0251\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0298\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0256\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0386 - val_loss: 0.0252\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0389 - val_loss: 0.0320\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0253\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0383 - val_loss: 0.0255\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0319\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0378 - val_loss: 0.0269\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0302\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0264\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0390 - val_loss: 0.0317\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0365 - val_loss: 0.0250\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0255\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0377 - val_loss: 0.0285\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0289\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0260\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0265\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0294\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0380 - val_loss: 0.0252\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0291\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0377 - val_loss: 0.0273\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0248\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0273\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0304\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0265\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0285\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0382 - val_loss: 0.0271\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0252\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0277\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0280\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0300\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0273\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0364 - val_loss: 0.0249\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0387 - val_loss: 0.0274\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0283\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.026 - 0s 112us/step - loss: 0.0371 - val_loss: 0.0283\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0252\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0284\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 807us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0280\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.037 - 0s 122us/step - loss: 0.0379 - val_loss: 0.0250\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0297\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0376 - val_loss: 0.0257\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0280\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0256\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0299\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0270\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0366 - val_loss: 0.0303\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0388 - val_loss: 0.0300\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0254\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0265\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0290\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0276\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0258\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0296\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0280\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0255\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0262\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0374 - val_loss: 0.0278\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0293\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0390 - val_loss: 0.0254\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0379 - val_loss: 0.0290\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0267\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0277\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0256\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0277\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0282\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0380 - val_loss: 0.0249\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0316\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0391 - val_loss: 0.0282\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0250\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0293\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0289\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0250\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0270\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0277\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0262\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0299\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0264\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0286\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0267\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0253\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0267\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0257\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0305\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0259\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0289\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0378 - val_loss: 0.0297\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0366 - val_loss: 0.0250\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0265\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0364 - val_loss: 0.0335\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0380 - val_loss: 0.0266\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0389 - val_loss: 0.0248\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0305\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0387 - val_loss: 0.0295\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0251\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0273\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0298\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0257\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0380 - val_loss: 0.0296\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0304\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0388 - val_loss: 0.0252\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0325\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0267\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0264\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0301\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0253\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0375 - val_loss: 0.0256\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0375 - val_loss: 0.0272\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0373 - val_loss: 0.0266\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0386 - val_loss: 0.0291\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0252\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0265\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0291\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0257\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0289\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0376 - val_loss: 0.0303\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0253\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0380 - val_loss: 0.0262\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0300\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0376 - val_loss: 0.0277\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0255\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0286\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0257\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0267\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0306\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0257\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0367 - val_loss: 0.0259\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0383 - val_loss: 0.0255\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0307\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0256\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0291\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0375 - val_loss: 0.0264\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0295\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0252\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0267\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0262\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0296\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0283\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0250\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0376 - val_loss: 0.0278\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0386 - val_loss: 0.0292\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0257\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0373 - val_loss: 0.0272\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0371 - val_loss: 0.0256\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0280\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0255\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0383 - val_loss: 0.0262\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0285\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0281\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0389 - val_loss: 0.0249\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0294\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0273\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0285\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0258\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0366 - val_loss: 0.0292\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0375 - val_loss: 0.0280\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0259\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0264\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0319\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0257\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0267\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0393 - val_loss: 0.0254\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0386 - val_loss: 0.0313\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0255\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0258\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0380 - val_loss: 0.0271\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0372 - val_loss: 0.0267\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0286\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0265\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0372 - val_loss: 0.0292\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0259\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0293\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0269\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0369 - val_loss: 0.0251\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0288\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0383 - val_loss: 0.0309\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0253\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0390 - val_loss: 0.0302\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0250\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0379 - val_loss: 0.0284\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0272\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0286\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0257\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0286\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0262\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0305\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0268\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0258\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0288\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0278\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0379 - val_loss: 0.0252\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0283\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0280\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0252\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0284\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0260\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0258\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0365 - val_loss: 0.0302\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0282\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0383 - val_loss: 0.0248\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0286\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0398 - val_loss: 0.0331\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0248\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0386 - val_loss: 0.0263\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0391 - val_loss: 0.0331\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0258\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0302\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0263\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0292\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0258\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0295\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0289\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0372 - val_loss: 0.0262\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0280\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0365 - val_loss: 0.0253\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0374 - val_loss: 0.0264\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0373 - val_loss: 0.0272\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0264\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0313\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0387 - val_loss: 0.0253\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0377 - val_loss: 0.0255\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0366 - val_loss: 0.0301\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0380 - val_loss: 0.0289\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0250\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0381 - val_loss: 0.0282\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0375 - val_loss: 0.0271\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0281\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0370 - val_loss: 0.0256\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0381 - val_loss: 0.0283\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0391 - val_loss: 0.0248\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0298\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0383 - val_loss: 0.0297\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0373 - val_loss: 0.0250\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0378 - val_loss: 0.0265\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0311\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0375 - val_loss: 0.0264\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0256\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0373 - val_loss: 0.0266\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0374 - val_loss: 0.0320\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0260\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0383 - val_loss: 0.0248\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0298\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0380 - val_loss: 0.0287\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0374 - val_loss: 0.0282\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0257\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0269\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0264\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0382 - val_loss: 0.0290\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0248\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0387 - val_loss: 0.0267\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0347\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0383 - val_loss: 0.0255\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0256\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0374 - val_loss: 0.0271\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0290\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0268\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0255\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0275\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0296\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0260\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0263\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0376 - val_loss: 0.0252\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0380 - val_loss: 0.0307\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0372 - val_loss: 0.0249\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0386 - val_loss: 0.0257\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0370 - val_loss: 0.0312\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0269\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0255\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0275\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0407 - val_loss: 0.0318\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0364 - val_loss: 0.0248\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0392 - val_loss: 0.0264\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0372 - val_loss: 0.0314\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0265\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0253\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0310\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0268\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0256\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0257\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0274\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0377 - val_loss: 0.0251\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0284\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0289\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0260\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0291\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0268\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0294\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0276\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0367 - val_loss: 0.0253\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0376 - val_loss: 0.0259\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0293\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0258\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0267\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0383 - val_loss: 0.0295\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0255\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0267\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0291\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0377 - val_loss: 0.0257\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0366 - val_loss: 0.0298\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0288\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0256\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0262\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0307\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0385 - val_loss: 0.0253\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0319\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0382 - val_loss: 0.0277\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0253\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0269\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0292\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0265\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0297\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0256\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0277\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0375 - val_loss: 0.0277\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0387 - val_loss: 0.0254\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0298\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0265\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0254\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0257\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0293\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0255\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0258\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0264\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0284\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0262\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0259\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0290\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0255\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0283\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0280\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0285\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0259\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0283\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0277\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0264\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0262\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0379 - val_loss: 0.0300\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0251\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0381 - val_loss: 0.0267\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0291\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0257\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0295\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0367 - val_loss: 0.0251\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0380 - val_loss: 0.0255\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0373 - val_loss: 0.0255\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0373 - val_loss: 0.0285\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0255\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0323\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0380 - val_loss: 0.0280\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0249\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0284\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0258\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 121us/step - loss: 0.0375 - val_loss: 0.0282\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0256\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0376 - val_loss: 0.0274\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0250\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0374 - val_loss: 0.0286\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0284\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0265\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0259\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0314\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0272\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0284\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0285\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0388 - val_loss: 0.0250\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0290\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0378 - val_loss: 0.0284\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0249\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0279\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0291\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0256\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0267\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0369 - val_loss: 0.0287\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0379 - val_loss: 0.0279\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0386 - val_loss: 0.0249\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0307\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0386 - val_loss: 0.0281\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0407 - val_loss: 0.0248\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0383 - val_loss: 0.0320\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0390 - val_loss: 0.0283\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0250\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0380 - val_loss: 0.0309\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0266\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0374 - val_loss: 0.0276\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0255\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0288\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0262\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0379 - val_loss: 0.0286\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0251\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0277\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0287\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0260\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0272\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0257\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0287\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0275\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0255\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0300\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0276\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0378 - val_loss: 0.0268\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0296\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0373 - val_loss: 0.0258\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0264\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0366 - val_loss: 0.0301\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0384 - val_loss: 0.0291\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0377 - val_loss: 0.0251\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0270\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0377 - val_loss: 0.0291\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0377 - val_loss: 0.0250\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0383 - val_loss: 0.0302\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0364 - val_loss: 0.0254\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0393 - val_loss: 0.0248\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0313\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0383 - val_loss: 0.0287\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0256\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0265\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0290\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0260\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0363 - val_loss: 0.0321\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0386 - val_loss: 0.0288\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0255\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0287\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0384 - val_loss: 0.0283\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0252\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0303\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0269\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0295\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0257\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0254\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.020 - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0285\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0366 - val_loss: 0.0257\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0384 - val_loss: 0.0254\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0303\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0265\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0262\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0364 - val_loss: 0.0316\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0388 - val_loss: 0.0294\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0249\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0375 - val_loss: 0.0272\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0294\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0383 - val_loss: 0.0250\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0303\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0270\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0255\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0286\n",
      "0.05475309491157532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.49957633, -0.249079  , -0.38113308, -0.2440201 , -0.5736101 ],\n",
       "        [ 0.18682317, -0.18590075, -0.3746217 , -0.44289958, -0.5318268 ],\n",
       "        [-0.13577619, -0.05098948, -0.00992793, -0.72858405, -0.37497455],\n",
       "        [-0.8757082 ,  0.2818046 , -0.14405487,  0.04650554, -0.05325489],\n",
       "        [ 0.30687892, -0.3677082 ,  0.3341878 , -0.208308  , -0.28156185],\n",
       "        [-0.17275247,  0.23256966, -0.11469543, -0.71310455, -0.69733375],\n",
       "        [ 0.01449761, -0.3541085 , -0.3717688 , -0.33210963, -0.4207859 ],\n",
       "        [ 0.0297125 , -0.06756297, -0.06007409, -0.05890652, -0.28310886],\n",
       "        [-0.4354146 , -0.29878822, -0.36236635, -0.23251624,  0.05335467],\n",
       "        [ 0.13461386, -0.3714432 , -0.35374853, -0.11843456,  0.0636933 ],\n",
       "        [-0.55530876,  0.45570073, -0.44587117, -0.20625833, -0.7265014 ],\n",
       "        [-0.58676815, -0.37724912, -0.62073404, -0.6551449 ,  0.02402728],\n",
       "        [-0.4270095 , -0.28017372, -0.62264234, -0.55438703, -0.23027131],\n",
       "        [-0.26775998,  0.19602332,  0.29031846, -0.7979021 ,  0.08535893],\n",
       "        [-0.5135032 , -0.45843005,  0.34175983, -0.12830654, -0.24780123],\n",
       "        [-0.05943297, -0.28026643,  0.10781375, -0.1030947 , -0.6679176 ],\n",
       "        [-0.26102623,  0.42638406, -0.29558524,  0.05496795, -0.05824274],\n",
       "        [-0.3844948 , -0.09119847, -0.38103864, -0.57649475, -0.50566953],\n",
       "        [-0.3462227 , -0.29642823, -0.33229494, -0.15790857, -0.29411325],\n",
       "        [-0.13009305, -0.45351404, -0.37284353, -0.7399185 , -0.7018779 ],\n",
       "        [ 0.05797872,  0.46326658, -0.6659352 , -0.78883314, -0.2012485 ],\n",
       "        [-0.16920097,  0.37178758, -0.5677645 , -0.34402192, -0.13321139]],\n",
       "       dtype=float32),\n",
       " array([-0.23200299,  0.        , -0.27700946, -0.4161186 , -0.31761715],\n",
       "       dtype=float32),\n",
       " array([[-0.08362027,  0.8341615 , -0.08018045, -0.14422555,  0.9539099 ,\n",
       "         -0.1174389 , -0.3530412 ,  0.10355458, -1.0747885 , -0.662383  ],\n",
       "        [-0.08282393, -0.49309784,  0.3671295 , -0.23375031, -0.17706928,\n",
       "         -0.2809799 , -0.31122217, -0.2761331 ,  0.223517  , -0.38284296],\n",
       "        [-0.2720491 , -0.11679261, -0.5689285 , -0.22592118,  0.5654107 ,\n",
       "          0.7569203 , -1.2698793 ,  0.5972189 , -0.49368748, -0.741855  ],\n",
       "        [ 0.22661649, -0.80339825,  0.20180133, -0.04797596, -0.8036841 ,\n",
       "         -0.6553895 ,  0.2515074 , -0.3914152 ,  0.08692112,  0.3332456 ],\n",
       "        [ 0.2777166 ,  0.17446509, -0.16038127,  0.44769868, -0.44568622,\n",
       "          0.2590662 , -0.23045579, -0.88588864, -0.10714038,  0.75127757]],\n",
       "       dtype=float32),\n",
       " array([-0.49035352, -0.3722067 , -0.41870904, -0.09303448, -0.38207668,\n",
       "        -0.86406904, -1.7187458 , -0.83690345, -0.52006966, -0.16039811],\n",
       "       dtype=float32),\n",
       " array([[-0.31974   ],\n",
       "        [-0.43335488],\n",
       "        [ 0.20427318],\n",
       "        [ 0.5725422 ],\n",
       "        [-0.44591108],\n",
       "        [-0.10756502],\n",
       "        [ 0.03868684],\n",
       "        [-0.1100297 ],\n",
       "        [ 0.20315363],\n",
       "        [ 0.5390545 ]], dtype=float32),\n",
       " array([0.08247924], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_sigmoid(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sigmoid_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.0499\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0415 - val_loss: 0.0268\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0418 - val_loss: 0.0394\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0380 - val_loss: 0.0251\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0395 - val_loss: 0.0369\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0404 - val_loss: 0.0254\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0306\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0263\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0261\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0378 - val_loss: 0.0276\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0253\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0380 - val_loss: 0.0280\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0256\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0374 - val_loss: 0.0275\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0294\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0257\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0291\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0254\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0296\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0388 - val_loss: 0.0267\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0399 - val_loss: 0.0353\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0248\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0399 - val_loss: 0.0257\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0362 - val_loss: 0.0325\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0391 - val_loss: 0.0291\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0253\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0376 - val_loss: 0.0309\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0373 - val_loss: 0.0265\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0274\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0288\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0256\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0258\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0366 - val_loss: 0.0292\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0384 - val_loss: 0.0291\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0253\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0257\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0282\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0286\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0289\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0283\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0294\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0372 - val_loss: 0.0290\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0259\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.013 - 0s 120us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0288\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0283\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0286\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0260\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0276\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0292\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0257\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0283\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0258\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0288\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0366 - val_loss: 0.0261\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0255\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0286\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0265\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0257\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.050 - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0289\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0269\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0257\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0275\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0274\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0262\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0257\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0258\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0287\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0267\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0268\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0274\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0285\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "0.054677072912454605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.18902512, -0.6961768 , -0.03246891,  0.08734912,  0.01499031],\n",
       "        [ 0.03572389, -0.47823066,  0.30169538, -0.569627  , -0.71148   ],\n",
       "        [-0.79726505, -0.06101352,  0.3907086 , -0.58199483, -0.54690045],\n",
       "        [-0.29450467, -0.31228286, -0.45967826, -0.46479443, -0.05151529],\n",
       "        [ 0.13206804, -0.45352066, -0.00948709,  0.5802333 , -0.2353901 ],\n",
       "        [-0.65830445, -0.26036334, -0.22236384, -0.15239865, -0.2998223 ],\n",
       "        [-0.35576203, -0.70990014, -0.1361886 , -0.06226719, -0.6989994 ],\n",
       "        [-0.30096236, -0.49809712, -0.3195572 , -0.50653124, -0.6875614 ],\n",
       "        [ 0.06818407, -0.40636608, -0.22167894, -0.28610733, -0.5927921 ],\n",
       "        [-0.13852786, -0.2395119 , -0.41353455, -0.12625119, -0.83585775],\n",
       "        [-0.16287214, -0.12481068, -0.07923281, -0.2977652 , -0.3351205 ],\n",
       "        [-0.05818196, -0.02373775, -0.27866   ,  0.05934656,  0.09832562],\n",
       "        [-0.04890495, -0.65499747, -0.25794208, -0.45954183, -0.0926355 ],\n",
       "        [ 0.07852758, -0.39596343,  0.140982  , -0.30379257, -0.3853562 ],\n",
       "        [-0.00164682, -0.36724773, -0.32711765, -0.52596986, -0.38400522],\n",
       "        [-0.7037678 , -0.4593846 , -0.31819093,  0.14124818, -0.08367826],\n",
       "        [-0.4704303 , -0.41368574, -0.17428476, -0.4299492 , -0.66324234],\n",
       "        [-0.71837175, -0.09252025, -0.2676508 , -0.2425549 , -0.55034477],\n",
       "        [-0.1707719 , -0.5190779 , -0.3379895 , -0.6945864 , -0.09856232],\n",
       "        [ 0.06929126, -0.01768606,  0.3695219 , -0.1276692 ,  0.02330694],\n",
       "        [-0.6768681 , -0.55879456, -0.1730881 ,  0.04721491, -0.60573196],\n",
       "        [-0.5686794 ,  0.0355817 , -0.17233026,  0.34560454, -0.11397877]],\n",
       "       dtype=float32),\n",
       " array([-0.34586936, -0.31691128,  0.        , -0.30818298, -0.37091947],\n",
       "       dtype=float32),\n",
       " array([[-0.48379436,  0.07572015, -0.46561706, -0.9209318 ,  0.2811989 ,\n",
       "         -0.07814975, -0.08366992, -0.26174587, -0.06311224, -0.3013509 ],\n",
       "        [ 0.6177392 , -0.4423648 , -0.09225914,  0.29860926, -0.3022191 ,\n",
       "          0.6348311 ,  0.622173  ,  0.3031665 , -0.5078545 ,  0.15113945],\n",
       "        [ 0.41784602,  0.3097598 , -0.30824122, -0.18212599, -0.47136146,\n",
       "          0.56875914, -0.5921817 ,  0.5243704 , -0.12228894, -0.5040207 ],\n",
       "        [ 0.22112642, -0.0374173 , -0.93739015, -0.7350585 , -0.46225458,\n",
       "         -0.29659268, -0.09170114,  0.8233361 ,  0.37854335, -0.3247765 ],\n",
       "        [-0.21051861, -0.32221738,  0.2920893 ,  0.01460848,  0.24007866,\n",
       "          0.67479473, -0.79484576, -0.9259163 ,  0.18931352,  0.3470743 ]],\n",
       "       dtype=float32),\n",
       " array([-1.9348093e-23,  1.3554590e-24,  1.0567294e-29, -1.0244315e-31,\n",
       "        -8.7485849e-28, -6.9662331e-29,  5.7139875e-32, -2.8556976e-29,\n",
       "        -9.2230221e-29, -1.0635806e-28], dtype=float32),\n",
       " array([[-2.9821000e-23],\n",
       "        [ 3.8318382e-24],\n",
       "        [-1.8124054e-29],\n",
       "        [ 1.4377596e-31],\n",
       "        [-7.2564678e-28],\n",
       "        [ 6.2237576e-29],\n",
       "        [-6.3319866e-32],\n",
       "        [ 1.9765316e-29],\n",
       "        [-9.6885615e-29],\n",
       "        [-1.6426373e-28]], dtype=float32),\n",
       " array([0.20881657], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_tanh(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_tanh_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 35.5652 - val_loss: 31.9906\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.7480 - val_loss: 27.3916\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.0819 - val_loss: 21.6395\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 24.5664 - val_loss: 15.1918\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 19.3875 - val_loss: 9.1601\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 13.9883 - val_loss: 4.9801\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8434 - val_loss: 3.9320\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0352 - val_loss: 6.0431\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9240 - val_loss: 7.8342\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5328 - val_loss: 7.2318\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7143 - val_loss: 5.0443\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8141 - val_loss: 2.6099\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3493 - val_loss: 0.9028\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0706 - val_loss: 0.2924\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4203 - val_loss: 0.5891\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4116 - val_loss: 1.3206\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.7829 - val_loss: 2.0382\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2261 - val_loss: 2.4745\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.5282 - val_loss: 2.5463\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6003 - val_loss: 2.2945\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4507 - val_loss: 1.8247\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1473 - val_loss: 1.2661\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7882 - val_loss: 0.7441\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.4759 - val_loss: 0.3556\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2902 - val_loss: 0.1458\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2620 - val_loss: 0.0958\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3590 - val_loss: 0.1352\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4981 - val_loss: 0.1819\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.5877 - val_loss: 0.1866\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5753 - val_loss: 0.1509\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4680 - val_loss: 0.1105\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3158 - val_loss: 0.1040\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1782 - val_loss: 0.1505\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0948 - val_loss: 0.2428\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0755 - val_loss: 0.3550\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1044 - val_loss: 0.4553\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1532 - val_loss: 0.5174\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1942 - val_loss: 0.5276\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2090 - val_loss: 0.4866\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1926 - val_loss: 0.4073\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1519 - val_loss: 0.3098\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1016 - val_loss: 0.2155\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0582 - val_loss: 0.1408\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0337 - val_loss: 0.0934\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0316 - val_loss: 0.0715\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0466 - val_loss: 0.0664\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0673 - val_loss: 0.0674\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0822 - val_loss: 0.0670\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0843 - val_loss: 0.0627\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0737 - val_loss: 0.0568\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0555 - val_loss: 0.0534\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0370 - val_loss: 0.0557\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0243 - val_loss: 0.0644\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0196 - val_loss: 0.0772\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.0904\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0283 - val_loss: 0.0998\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0342 - val_loss: 0.1023\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0970\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0350 - val_loss: 0.0853\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0294 - val_loss: 0.0698\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0222 - val_loss: 0.0538\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0158 - val_loss: 0.0401\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0119 - val_loss: 0.0300\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0109 - val_loss: 0.0238\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0206\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0143 - val_loss: 0.0193\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0158 - val_loss: 0.0188\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0159 - val_loss: 0.0186\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0145 - val_loss: 0.0188\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0098 - val_loss: 0.0207\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0226\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0248\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0268\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0279\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0086 - val_loss: 0.0280\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0089 - val_loss: 0.0268\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0247\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0079 - val_loss: 0.0220\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0191\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0063 - val_loss: 0.0165\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0143\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0126\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0115\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 0.0108\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0104\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0104\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0107\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0112\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0119\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0127\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0134\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0139\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 0.0141\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0140\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0136\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0129\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0121\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0113\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0105\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0098\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0093\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0090\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0088\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0088\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0089\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0091\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0093\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0095\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0096\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0098\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0098\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0098\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0097\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0095\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0092\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0089\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0086\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0083\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0081\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0079\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0077\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0076\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0034 - val_loss: 0.0075\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0076\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0076\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0076\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0076\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0075\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0073\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0072\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0069\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0067\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0066\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9784e-04 - val_loss: 0.0019\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9128e-04 - val_loss: 0.0019\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8475e-04 - val_loss: 0.0019\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7829e-04 - val_loss: 0.0019\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7186e-04 - val_loss: 0.0019\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6548e-04 - val_loss: 0.0019\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5915e-04 - val_loss: 0.0018\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5286e-04 - val_loss: 0.0018\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4662e-04 - val_loss: 0.0018\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4044e-04 - val_loss: 0.0018\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3428e-04 - val_loss: 0.0018\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2818e-04 - val_loss: 0.0018\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2212e-04 - val_loss: 0.0018\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1611e-04 - val_loss: 0.0017\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1013e-04 - val_loss: 0.0017\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0420e-04 - val_loss: 0.0017\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9831e-04 - val_loss: 0.0017\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9247e-04 - val_loss: 0.0017\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8667e-04 - val_loss: 0.0017\n",
      "Epoch 308/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 125us/step - loss: 8.8091e-04 - val_loss: 0.0017\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7519e-04 - val_loss: 0.0017\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6952e-04 - val_loss: 0.0017\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6388e-04 - val_loss: 0.0016\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5830e-04 - val_loss: 0.0016\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5273e-04 - val_loss: 0.0016\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4721e-04 - val_loss: 0.0016\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4174e-04 - val_loss: 0.0016\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3630e-04 - val_loss: 0.0016\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3090e-04 - val_loss: 0.0016\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2555e-04 - val_loss: 0.0016\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2022e-04 - val_loss: 0.0015\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1494e-04 - val_loss: 0.0015\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.0970e-04 - val_loss: 0.0015\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0448e-04 - val_loss: 0.0015\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9931e-04 - val_loss: 0.0015\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9418e-04 - val_loss: 0.0015\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8907e-04 - val_loss: 0.0015\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8401e-04 - val_loss: 0.0015\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7899e-04 - val_loss: 0.0015\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7399e-04 - val_loss: 0.0015\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6904e-04 - val_loss: 0.0014\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6412e-04 - val_loss: 0.0014\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5923e-04 - val_loss: 0.0014\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5438e-04 - val_loss: 0.0014\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4957e-04 - val_loss: 0.0014\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4477e-04 - val_loss: 0.0014\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4003e-04 - val_loss: 0.0014\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3531e-04 - val_loss: 0.0014\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3063e-04 - val_loss: 0.0014\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 7.2598e-04 - val_loss: 0.0014\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2135e-04 - val_loss: 0.0013\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1677e-04 - val_loss: 0.0013\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1221e-04 - val_loss: 0.0013\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0769e-04 - val_loss: 0.0013\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0321e-04 - val_loss: 0.0013\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9874e-04 - val_loss: 0.0013\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9431e-04 - val_loss: 0.0013\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8991e-04 - val_loss: 0.0013\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8554e-04 - val_loss: 0.0013\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8121e-04 - val_loss: 0.0013\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7690e-04 - val_loss: 0.0013\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7263e-04 - val_loss: 0.0012\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6838e-04 - val_loss: 0.0012\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6416e-04 - val_loss: 0.0012\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5997e-04 - val_loss: 0.0012\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5581e-04 - val_loss: 0.0012\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5168e-04 - val_loss: 0.0012\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.4758e-04 - val_loss: 0.0012\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4349e-04 - val_loss: 0.0012\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3946e-04 - val_loss: 0.0012\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3543e-04 - val_loss: 0.0012\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3145e-04 - val_loss: 0.0012\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2748e-04 - val_loss: 0.0012\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2355e-04 - val_loss: 0.0011\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1964e-04 - val_loss: 0.0011\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1576e-04 - val_loss: 0.0011\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1191e-04 - val_loss: 0.0011\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0807e-04 - val_loss: 0.0011\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0427e-04 - val_loss: 0.0011\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0049e-04 - val_loss: 0.0011\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9674e-04 - val_loss: 0.0011\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9301e-04 - val_loss: 0.0011\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8931e-04 - val_loss: 0.0011\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8565e-04 - val_loss: 0.0011\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8200e-04 - val_loss: 0.0011\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7837e-04 - val_loss: 0.0011\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.7478e-04 - val_loss: 0.0010\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7120e-04 - val_loss: 0.0010\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6764e-04 - val_loss: 0.0010\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6412e-04 - val_loss: 0.0010\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6061e-04 - val_loss: 0.0010\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5714e-04 - val_loss: 0.0010\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5368e-04 - val_loss: 0.0010\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5025e-04 - val_loss: 9.9640e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4684e-04 - val_loss: 9.8964e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4346e-04 - val_loss: 9.8290e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4009e-04 - val_loss: 9.7623e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3676e-04 - val_loss: 9.6958e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3345e-04 - val_loss: 9.6301e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3015e-04 - val_loss: 9.5647e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2687e-04 - val_loss: 9.4998e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.2363e-04 - val_loss: 9.4353e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2040e-04 - val_loss: 9.3714e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1718e-04 - val_loss: 9.3081e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1402e-04 - val_loss: 9.2450e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1084e-04 - val_loss: 9.1825e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0771e-04 - val_loss: 9.1207e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0458e-04 - val_loss: 9.0589e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0148e-04 - val_loss: 8.9979e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9840e-04 - val_loss: 8.9371e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9535e-04 - val_loss: 8.8769e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9231e-04 - val_loss: 8.8172e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8930e-04 - val_loss: 8.7576e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8629e-04 - val_loss: 8.6988e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8332e-04 - val_loss: 8.6402e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8037e-04 - val_loss: 8.5821e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7743e-04 - val_loss: 8.5247e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7451e-04 - val_loss: 8.4674e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7161e-04 - val_loss: 8.4107e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6874e-04 - val_loss: 8.3543e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6588e-04 - val_loss: 8.2985e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6304e-04 - val_loss: 8.2427e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 4.6021e-04 - val_loss: 8.1877e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5742e-04 - val_loss: 8.1331e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5464e-04 - val_loss: 8.0786e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5187e-04 - val_loss: 8.0247e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4913e-04 - val_loss: 7.9713e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4640e-04 - val_loss: 7.9181e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4369e-04 - val_loss: 7.8653e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4099e-04 - val_loss: 7.8130e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3833e-04 - val_loss: 7.7609e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3568e-04 - val_loss: 7.7094e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3304e-04 - val_loss: 7.6580e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3042e-04 - val_loss: 7.6072e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2782e-04 - val_loss: 7.5565e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2523e-04 - val_loss: 7.5066e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2267e-04 - val_loss: 7.4569e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2011e-04 - val_loss: 7.4073e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1757e-04 - val_loss: 7.3582e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1506e-04 - val_loss: 7.3097e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1256e-04 - val_loss: 7.2613e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1008e-04 - val_loss: 7.2134e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0761e-04 - val_loss: 7.1657e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0516e-04 - val_loss: 7.1185e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0273e-04 - val_loss: 7.0713e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0031e-04 - val_loss: 7.0248e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9790e-04 - val_loss: 6.9785e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9552e-04 - val_loss: 6.9325e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9315e-04 - val_loss: 6.8870e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9080e-04 - val_loss: 6.8416e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8846e-04 - val_loss: 6.7967e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8613e-04 - val_loss: 6.7522e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8383e-04 - val_loss: 6.7079e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8154e-04 - val_loss: 6.6638e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7925e-04 - val_loss: 6.6202e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7700e-04 - val_loss: 6.5767e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7475e-04 - val_loss: 6.5336e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7251e-04 - val_loss: 6.4909e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7030e-04 - val_loss: 6.4485e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6809e-04 - val_loss: 6.4065e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6591e-04 - val_loss: 6.3647e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6374e-04 - val_loss: 6.3232e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6158e-04 - val_loss: 6.2818e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5943e-04 - val_loss: 6.2411e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5730e-04 - val_loss: 6.2004e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5518e-04 - val_loss: 6.1600e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5307e-04 - val_loss: 6.1200e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5099e-04 - val_loss: 6.0802e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4891e-04 - val_loss: 6.0407e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4685e-04 - val_loss: 6.0015e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4480e-04 - val_loss: 5.9625e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4277e-04 - val_loss: 5.9240e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4075e-04 - val_loss: 5.8856e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3874e-04 - val_loss: 5.8475e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3675e-04 - val_loss: 5.8097e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3477e-04 - val_loss: 5.7721e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3280e-04 - val_loss: 5.7349e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3085e-04 - val_loss: 5.6978e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2890e-04 - val_loss: 5.6610e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2697e-04 - val_loss: 5.6246e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2506e-04 - val_loss: 5.5886e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2315e-04 - val_loss: 5.5524e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2126e-04 - val_loss: 5.5168e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1938e-04 - val_loss: 5.4814e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1752e-04 - val_loss: 5.4461e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1566e-04 - val_loss: 5.4111e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1382e-04 - val_loss: 5.3765e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1198e-04 - val_loss: 5.3421e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1017e-04 - val_loss: 5.3078e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0836e-04 - val_loss: 5.2739e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0657e-04 - val_loss: 5.2401e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0479e-04 - val_loss: 5.2067e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0302e-04 - val_loss: 5.1734e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0126e-04 - val_loss: 5.1404e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9951e-04 - val_loss: 5.1076e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9777e-04 - val_loss: 5.0751e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9605e-04 - val_loss: 5.0427e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9433e-04 - val_loss: 5.0107e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 2.9264e-04 - val_loss: 4.9788e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9094e-04 - val_loss: 4.9472e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8926e-04 - val_loss: 4.9157e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8759e-04 - val_loss: 4.8848e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.8594e-04 - val_loss: 4.8537e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8429e-04 - val_loss: 4.8230e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8265e-04 - val_loss: 4.7925e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8103e-04 - val_loss: 4.7622e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7941e-04 - val_loss: 4.7320e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7781e-04 - val_loss: 4.7022e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7621e-04 - val_loss: 4.6725e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7463e-04 - val_loss: 4.6431e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7306e-04 - val_loss: 4.6138e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7150e-04 - val_loss: 4.5847e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6994e-04 - val_loss: 4.5559e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6841e-04 - val_loss: 4.5271e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6687e-04 - val_loss: 4.4987e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6535e-04 - val_loss: 4.4705e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6383e-04 - val_loss: 4.4426e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6234e-04 - val_loss: 4.4147e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6084e-04 - val_loss: 4.3872e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5936e-04 - val_loss: 4.3597e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5789e-04 - val_loss: 4.3324e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5642e-04 - val_loss: 4.3055e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5498e-04 - val_loss: 4.2784e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5353e-04 - val_loss: 4.2517e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5210e-04 - val_loss: 4.2253e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5067e-04 - val_loss: 4.1991e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4926e-04 - val_loss: 4.1729e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4785e-04 - val_loss: 4.1471e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4645e-04 - val_loss: 4.1213e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4506e-04 - val_loss: 4.0958e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4369e-04 - val_loss: 4.0703e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4231e-04 - val_loss: 4.0451e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4096e-04 - val_loss: 4.0200e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3960e-04 - val_loss: 3.9951e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3826e-04 - val_loss: 3.9705e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3692e-04 - val_loss: 3.9459e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3560e-04 - val_loss: 3.9217e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3428e-04 - val_loss: 3.8975e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3297e-04 - val_loss: 3.8735e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3167e-04 - val_loss: 3.8497e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3038e-04 - val_loss: 3.8260e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 2.2910e-04 - val_loss: 3.8026e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2783e-04 - val_loss: 3.7792e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2656e-04 - val_loss: 3.7561e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2530e-04 - val_loss: 3.7331e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2405e-04 - val_loss: 3.7103e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2281e-04 - val_loss: 3.6875e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.2157e-04 - val_loss: 3.6650e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2035e-04 - val_loss: 3.6427e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1913e-04 - val_loss: 3.6205e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1793e-04 - val_loss: 3.5985e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1672e-04 - val_loss: 3.5766e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1553e-04 - val_loss: 3.5549e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1435e-04 - val_loss: 3.5333e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1317e-04 - val_loss: 3.5117e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1200e-04 - val_loss: 3.4904e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1084e-04 - val_loss: 3.4692e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0968e-04 - val_loss: 3.4484e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0853e-04 - val_loss: 3.4275e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 2.0739e-04 - val_loss: 3.4067e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0626e-04 - val_loss: 3.3863e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 2.0514e-04 - val_loss: 3.3658e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0402e-04 - val_loss: 3.3455e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0291e-04 - val_loss: 3.3256e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0181e-04 - val_loss: 3.3055e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0071e-04 - val_loss: 3.2856e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9963e-04 - val_loss: 3.2660e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9854e-04 - val_loss: 3.2463e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9746e-04 - val_loss: 3.2269e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9640e-04 - val_loss: 3.2076e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9534e-04 - val_loss: 3.1884e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9428e-04 - val_loss: 3.1693e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9324e-04 - val_loss: 3.1505e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.9220e-04 - val_loss: 3.1316e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9116e-04 - val_loss: 3.1132e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9014e-04 - val_loss: 3.0947e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8912e-04 - val_loss: 3.0764e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8811e-04 - val_loss: 3.0580e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8710e-04 - val_loss: 3.0399e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8610e-04 - val_loss: 3.0219e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 1.8511e-04 - val_loss: 3.0040e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8412e-04 - val_loss: 2.9863e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8314e-04 - val_loss: 2.9687e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8217e-04 - val_loss: 2.9513e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8120e-04 - val_loss: 2.9338e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8024e-04 - val_loss: 2.9165e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7929e-04 - val_loss: 2.8994e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7834e-04 - val_loss: 2.8823e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7739e-04 - val_loss: 2.8654e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7646e-04 - val_loss: 2.8487e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7553e-04 - val_loss: 2.8320e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7461e-04 - val_loss: 2.8155e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7368e-04 - val_loss: 2.7991e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7278e-04 - val_loss: 2.7828e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.7187e-04 - val_loss: 2.7665e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7097e-04 - val_loss: 2.7505e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7007e-04 - val_loss: 2.7344e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6919e-04 - val_loss: 2.7185e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 1.6830e-04 - val_loss: 2.7027e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6743e-04 - val_loss: 2.6871e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6656e-04 - val_loss: 2.6716e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6569e-04 - val_loss: 2.6562e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6483e-04 - val_loss: 2.6408e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6398e-04 - val_loss: 2.6257e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6313e-04 - val_loss: 2.6106e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6229e-04 - val_loss: 2.5955e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6144e-04 - val_loss: 2.5806e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6062e-04 - val_loss: 2.5658e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5979e-04 - val_loss: 2.5511e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5897e-04 - val_loss: 2.5365e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5815e-04 - val_loss: 2.5221e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5734e-04 - val_loss: 2.5077e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5654e-04 - val_loss: 2.4933e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5574e-04 - val_loss: 2.4792e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5495e-04 - val_loss: 2.4651e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5416e-04 - val_loss: 2.4511e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5337e-04 - val_loss: 2.4370e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5259e-04 - val_loss: 2.4234e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5182e-04 - val_loss: 2.4096e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5105e-04 - val_loss: 2.3960e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5029e-04 - val_loss: 2.3824e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4953e-04 - val_loss: 2.3689e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4877e-04 - val_loss: 2.3557e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4802e-04 - val_loss: 2.3425e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.4728e-04 - val_loss: 2.3293e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4654e-04 - val_loss: 2.3162e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4581e-04 - val_loss: 2.3033e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4508e-04 - val_loss: 2.2904e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4435e-04 - val_loss: 2.2776e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4363e-04 - val_loss: 2.2649e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4292e-04 - val_loss: 2.2523e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4221e-04 - val_loss: 2.2397e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4150e-04 - val_loss: 2.2272e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4080e-04 - val_loss: 2.2148e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4010e-04 - val_loss: 2.2026e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3941e-04 - val_loss: 2.1904e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3872e-04 - val_loss: 2.1782e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3804e-04 - val_loss: 2.1662e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3736e-04 - val_loss: 2.1542e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3669e-04 - val_loss: 2.1424e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3601e-04 - val_loss: 2.1306e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3535e-04 - val_loss: 2.1189e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3469e-04 - val_loss: 2.1073e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3403e-04 - val_loss: 2.0959e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3338e-04 - val_loss: 2.0844e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3274e-04 - val_loss: 2.0730e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3209e-04 - val_loss: 2.0617e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3145e-04 - val_loss: 2.0505e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3081e-04 - val_loss: 2.0393e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3018e-04 - val_loss: 2.0283e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2956e-04 - val_loss: 2.0173e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2893e-04 - val_loss: 2.0063e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2831e-04 - val_loss: 1.9954e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2770e-04 - val_loss: 1.9847e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2709e-04 - val_loss: 1.9740e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2648e-04 - val_loss: 1.9634e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2588e-04 - val_loss: 1.9528e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2528e-04 - val_loss: 1.9423e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2468e-04 - val_loss: 1.9320e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2409e-04 - val_loss: 1.9216e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2350e-04 - val_loss: 1.9114e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2292e-04 - val_loss: 1.9012e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2234e-04 - val_loss: 1.8910e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2176e-04 - val_loss: 1.8810e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2119e-04 - val_loss: 1.8710e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2062e-04 - val_loss: 1.8611e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2006e-04 - val_loss: 1.8512e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1950e-04 - val_loss: 1.8414e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1894e-04 - val_loss: 1.8316e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1838e-04 - val_loss: 1.8220e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1783e-04 - val_loss: 1.8124e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1729e-04 - val_loss: 1.8029e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1675e-04 - val_loss: 1.7934e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.1621e-04 - val_loss: 1.7841e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1567e-04 - val_loss: 1.7747e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1514e-04 - val_loss: 1.7655e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1461e-04 - val_loss: 1.7563e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1408e-04 - val_loss: 1.7472e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1356e-04 - val_loss: 1.7381e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1304e-04 - val_loss: 1.7291e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1253e-04 - val_loss: 1.7201e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1201e-04 - val_loss: 1.7112e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1151e-04 - val_loss: 1.7024e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1100e-04 - val_loss: 1.6936e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1050e-04 - val_loss: 1.6849e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1000e-04 - val_loss: 1.6762e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0951e-04 - val_loss: 1.6676e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0901e-04 - val_loss: 1.6591e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0852e-04 - val_loss: 1.6506e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0804e-04 - val_loss: 1.6421e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 1.0756e-04 - val_loss: 1.6338e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0708e-04 - val_loss: 1.6255e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0660e-04 - val_loss: 1.6173e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0613e-04 - val_loss: 1.6091e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0566e-04 - val_loss: 1.6009e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0519e-04 - val_loss: 1.5928e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0473e-04 - val_loss: 1.5848e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0426e-04 - val_loss: 1.5768e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0381e-04 - val_loss: 1.5689e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0335e-04 - val_loss: 1.5610e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0290e-04 - val_loss: 1.5532e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0245e-04 - val_loss: 1.5454e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0200e-04 - val_loss: 1.5377e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0156e-04 - val_loss: 1.5300e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0112e-04 - val_loss: 1.5225e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0069e-04 - val_loss: 1.5150e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0025e-04 - val_loss: 1.5074e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9817e-05 - val_loss: 1.5000e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9389e-05 - val_loss: 1.4926e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8966e-05 - val_loss: 1.4852e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8536e-05 - val_loss: 1.4779e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8118e-05 - val_loss: 1.4706e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7699e-05 - val_loss: 1.4634e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7287e-05 - val_loss: 1.4563e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6875e-05 - val_loss: 1.4492e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6467e-05 - val_loss: 1.4421e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6056e-05 - val_loss: 1.4351e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5652e-05 - val_loss: 1.4281e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5249e-05 - val_loss: 1.4212e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4850e-05 - val_loss: 1.4143e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4456e-05 - val_loss: 1.4075e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4057e-05 - val_loss: 1.4007e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3669e-05 - val_loss: 1.3939e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3281e-05 - val_loss: 1.3872e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2893e-05 - val_loss: 1.3806e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2511e-05 - val_loss: 1.3740e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2127e-05 - val_loss: 1.3674e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1749e-05 - val_loss: 1.3610e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1374e-05 - val_loss: 1.3545e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1001e-05 - val_loss: 1.3481e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0629e-05 - val_loss: 1.3416e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0259e-05 - val_loss: 1.3353e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9894e-05 - val_loss: 1.3290e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9530e-05 - val_loss: 1.3227e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9165e-05 - val_loss: 1.3165e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8805e-05 - val_loss: 1.3103e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8448e-05 - val_loss: 1.3041e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8092e-05 - val_loss: 1.2980e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7741e-05 - val_loss: 1.2920e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7390e-05 - val_loss: 1.2860e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7040e-05 - val_loss: 1.2801e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6699e-05 - val_loss: 1.2741e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6352e-05 - val_loss: 1.2683e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6010e-05 - val_loss: 1.2624e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5674e-05 - val_loss: 1.2566e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.5338e-05 - val_loss: 1.2508e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5000e-05 - val_loss: 1.2451e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4672e-05 - val_loss: 1.2393e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.4336e-05 - val_loss: 1.2336e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.4009e-05 - val_loss: 1.2280e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3684e-05 - val_loss: 1.2224e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3360e-05 - val_loss: 1.2168e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3038e-05 - val_loss: 1.2113e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2718e-05 - val_loss: 1.2058e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2400e-05 - val_loss: 1.2004e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2082e-05 - val_loss: 1.1950e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1772e-05 - val_loss: 1.1896e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1459e-05 - val_loss: 1.1842e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1148e-05 - val_loss: 1.1789e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0838e-05 - val_loss: 1.1737e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0535e-05 - val_loss: 1.1685e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0232e-05 - val_loss: 1.1634e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9930e-05 - val_loss: 1.1581e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9631e-05 - val_loss: 1.1530e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9332e-05 - val_loss: 1.1478e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9035e-05 - val_loss: 1.1428e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8745e-05 - val_loss: 1.1377e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8450e-05 - val_loss: 1.1327e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8158e-05 - val_loss: 1.1278e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7872e-05 - val_loss: 1.1229e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7584e-05 - val_loss: 1.1179e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7299e-05 - val_loss: 1.1131e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7017e-05 - val_loss: 1.1083e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.6738e-05 - val_loss: 1.1034e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6457e-05 - val_loss: 1.0987e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.6181e-05 - val_loss: 1.0940e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5903e-05 - val_loss: 1.0893e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5630e-05 - val_loss: 1.0845e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5358e-05 - val_loss: 1.0799e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5086e-05 - val_loss: 1.0752e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4820e-05 - val_loss: 1.0707e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4553e-05 - val_loss: 1.0661e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4289e-05 - val_loss: 1.0616e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4022e-05 - val_loss: 1.0570e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3759e-05 - val_loss: 1.0526e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3500e-05 - val_loss: 1.0482e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3243e-05 - val_loss: 1.0437e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2985e-05 - val_loss: 1.0394e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2730e-05 - val_loss: 1.0351e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2480e-05 - val_loss: 1.0307e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.2225e-05 - val_loss: 1.0263e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1972e-05 - val_loss: 1.0221e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1726e-05 - val_loss: 1.0178e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1480e-05 - val_loss: 1.0136e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1234e-05 - val_loss: 1.0094e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0989e-05 - val_loss: 1.0053e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0747e-05 - val_loss: 1.0011e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0508e-05 - val_loss: 9.9698e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0267e-05 - val_loss: 9.9290e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0030e-05 - val_loss: 9.8882e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9795e-05 - val_loss: 9.8482e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9559e-05 - val_loss: 9.8079e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9329e-05 - val_loss: 9.7686e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9096e-05 - val_loss: 9.7287e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8862e-05 - val_loss: 9.6892e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8634e-05 - val_loss: 9.6495e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8406e-05 - val_loss: 9.6115e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8182e-05 - val_loss: 9.5724e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.7956e-05 - val_loss: 9.5345e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7733e-05 - val_loss: 9.4963e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7511e-05 - val_loss: 9.4589e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.7293e-05 - val_loss: 9.4206e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7072e-05 - val_loss: 9.3832e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6855e-05 - val_loss: 9.3461e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6639e-05 - val_loss: 9.3096e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6426e-05 - val_loss: 9.2726e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6211e-05 - val_loss: 9.2367e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6000e-05 - val_loss: 9.2002e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5789e-05 - val_loss: 9.1645e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5578e-05 - val_loss: 9.1286e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5370e-05 - val_loss: 9.0934e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5166e-05 - val_loss: 9.0581e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4959e-05 - val_loss: 9.0227e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4752e-05 - val_loss: 8.9884e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4553e-05 - val_loss: 8.9533e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4351e-05 - val_loss: 8.9184e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4150e-05 - val_loss: 8.8846e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3951e-05 - val_loss: 8.8504e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.3754e-05 - val_loss: 8.8170e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3558e-05 - val_loss: 8.7841e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3362e-05 - val_loss: 8.7503e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3168e-05 - val_loss: 8.7166e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2974e-05 - val_loss: 8.6839e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2782e-05 - val_loss: 8.6505e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2590e-05 - val_loss: 8.6185e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2403e-05 - val_loss: 8.5864e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2217e-05 - val_loss: 8.5543e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2031e-05 - val_loss: 8.5220e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1843e-05 - val_loss: 8.4907e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1660e-05 - val_loss: 8.4591e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1474e-05 - val_loss: 8.4283e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1292e-05 - val_loss: 8.3967e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1110e-05 - val_loss: 8.3664e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0930e-05 - val_loss: 8.3353e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0753e-05 - val_loss: 8.3049e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0572e-05 - val_loss: 8.2745e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0398e-05 - val_loss: 8.2440e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0223e-05 - val_loss: 8.2145e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.0046e-05 - val_loss: 8.1842e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9873e-05 - val_loss: 8.1544e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9701e-05 - val_loss: 8.1251e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9532e-05 - val_loss: 8.0958e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9361e-05 - val_loss: 8.0666e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9191e-05 - val_loss: 8.0385e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9026e-05 - val_loss: 8.0097e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8857e-05 - val_loss: 7.9815e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8690e-05 - val_loss: 7.9526e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8525e-05 - val_loss: 7.9249e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8363e-05 - val_loss: 7.8967e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8200e-05 - val_loss: 7.8689e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8038e-05 - val_loss: 7.8408e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7873e-05 - val_loss: 7.8133e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7715e-05 - val_loss: 7.7855e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7554e-05 - val_loss: 7.7586e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7399e-05 - val_loss: 7.7318e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.7242e-05 - val_loss: 7.7048e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7086e-05 - val_loss: 7.6782e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6929e-05 - val_loss: 7.6514e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6778e-05 - val_loss: 7.6254e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6624e-05 - val_loss: 7.5995e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6472e-05 - val_loss: 7.5735e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6321e-05 - val_loss: 7.5479e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6169e-05 - val_loss: 7.5223e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6018e-05 - val_loss: 7.4966e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5871e-05 - val_loss: 7.4707e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5723e-05 - val_loss: 7.4456e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5575e-05 - val_loss: 7.4201e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5431e-05 - val_loss: 7.3953e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5285e-05 - val_loss: 7.3707e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5141e-05 - val_loss: 7.3459e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4998e-05 - val_loss: 7.3211e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4855e-05 - val_loss: 7.2974e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4716e-05 - val_loss: 7.2731e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 5.4573e-05 - val_loss: 7.2491e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4435e-05 - val_loss: 7.2248e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4294e-05 - val_loss: 7.2013e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4155e-05 - val_loss: 7.1781e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4020e-05 - val_loss: 7.1542e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3882e-05 - val_loss: 7.1308e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3747e-05 - val_loss: 7.1078e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3613e-05 - val_loss: 7.0842e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3477e-05 - val_loss: 7.0614e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3345e-05 - val_loss: 7.0380e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3210e-05 - val_loss: 7.0160e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3081e-05 - val_loss: 6.9937e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2949e-05 - val_loss: 6.9709e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2817e-05 - val_loss: 6.9492e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2690e-05 - val_loss: 6.9264e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2560e-05 - val_loss: 6.9048e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2435e-05 - val_loss: 6.8829e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2308e-05 - val_loss: 6.8610e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2182e-05 - val_loss: 6.8391e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2055e-05 - val_loss: 6.8182e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1929e-05 - val_loss: 6.7971e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1808e-05 - val_loss: 6.7756e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1681e-05 - val_loss: 6.7544e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1562e-05 - val_loss: 6.7332e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1438e-05 - val_loss: 6.7123e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1317e-05 - val_loss: 6.6919e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1197e-05 - val_loss: 6.6711e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1077e-05 - val_loss: 6.6504e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0958e-05 - val_loss: 6.6295e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0840e-05 - val_loss: 6.6093e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0721e-05 - val_loss: 6.5892e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0605e-05 - val_loss: 6.5692e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0490e-05 - val_loss: 6.5493e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0372e-05 - val_loss: 6.5302e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0259e-05 - val_loss: 6.5097e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0144e-05 - val_loss: 6.4905e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0032e-05 - val_loss: 6.4713e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9918e-05 - val_loss: 6.4521e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9807e-05 - val_loss: 6.4327e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9694e-05 - val_loss: 6.4138e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 4.9584e-05 - val_loss: 6.3948e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9475e-05 - val_loss: 6.3756e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9364e-05 - val_loss: 6.3566e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9255e-05 - val_loss: 6.3382e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9147e-05 - val_loss: 6.3193e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9037e-05 - val_loss: 6.3009e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8933e-05 - val_loss: 6.2822e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8825e-05 - val_loss: 6.2644e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8720e-05 - val_loss: 6.2468e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8616e-05 - val_loss: 6.2277e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8508e-05 - val_loss: 6.2105e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8408e-05 - val_loss: 6.1922e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8302e-05 - val_loss: 6.1745e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8198e-05 - val_loss: 6.1567e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8096e-05 - val_loss: 6.1393e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.7994e-05 - val_loss: 6.1218e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7894e-05 - val_loss: 6.1047e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7793e-05 - val_loss: 6.0874e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7691e-05 - val_loss: 6.0700e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7592e-05 - val_loss: 6.0529e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7494e-05 - val_loss: 6.0358e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7394e-05 - val_loss: 6.0193e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7298e-05 - val_loss: 6.0020e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7203e-05 - val_loss: 5.9852e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7103e-05 - val_loss: 5.9682e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7008e-05 - val_loss: 5.9522e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6913e-05 - val_loss: 5.9358e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6817e-05 - val_loss: 5.9195e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6724e-05 - val_loss: 5.9035e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6628e-05 - val_loss: 5.8877e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6535e-05 - val_loss: 5.8714e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6443e-05 - val_loss: 5.8558e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6351e-05 - val_loss: 5.8391e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6258e-05 - val_loss: 5.8235e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6166e-05 - val_loss: 5.8081e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6075e-05 - val_loss: 5.7926e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5984e-05 - val_loss: 5.7763e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5895e-05 - val_loss: 5.7609e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5805e-05 - val_loss: 5.7461e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5719e-05 - val_loss: 5.7308e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5631e-05 - val_loss: 5.7156e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5541e-05 - val_loss: 5.7005e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5454e-05 - val_loss: 5.6855e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5366e-05 - val_loss: 5.6701e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5279e-05 - val_loss: 5.6554e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5194e-05 - val_loss: 5.6402e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5106e-05 - val_loss: 5.6262e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5023e-05 - val_loss: 5.6115e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4938e-05 - val_loss: 5.5966e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4853e-05 - val_loss: 5.5827e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4771e-05 - val_loss: 5.5679e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4686e-05 - val_loss: 5.5541e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4606e-05 - val_loss: 5.5396e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4522e-05 - val_loss: 5.5253e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4441e-05 - val_loss: 5.5108e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4358e-05 - val_loss: 5.4968e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4276e-05 - val_loss: 5.4829e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4197e-05 - val_loss: 5.4693e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4117e-05 - val_loss: 5.4554e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4036e-05 - val_loss: 5.4419e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3957e-05 - val_loss: 5.4282e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3878e-05 - val_loss: 5.4149e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3800e-05 - val_loss: 5.4015e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3720e-05 - val_loss: 5.3881e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3644e-05 - val_loss: 5.3746e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3566e-05 - val_loss: 5.3612e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3488e-05 - val_loss: 5.3477e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3413e-05 - val_loss: 5.3347e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3339e-05 - val_loss: 5.3215e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3262e-05 - val_loss: 5.3087e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3187e-05 - val_loss: 5.2959e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3111e-05 - val_loss: 5.2827e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3037e-05 - val_loss: 5.2696e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2962e-05 - val_loss: 5.2573e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2890e-05 - val_loss: 5.2448e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2814e-05 - val_loss: 5.2319e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2741e-05 - val_loss: 5.2199e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2669e-05 - val_loss: 5.2073e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2598e-05 - val_loss: 5.1946e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2525e-05 - val_loss: 5.1828e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2455e-05 - val_loss: 5.1695e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2382e-05 - val_loss: 5.1574e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2311e-05 - val_loss: 5.1455e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2243e-05 - val_loss: 5.1334e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2171e-05 - val_loss: 5.1215e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2101e-05 - val_loss: 5.1093e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2032e-05 - val_loss: 5.0976e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1964e-05 - val_loss: 5.0861e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1895e-05 - val_loss: 5.0738e-05\n",
      "7.20828611520119e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.10643508,  0.54745764, -0.05210108,  0.4669482 ,  0.4391452 ],\n",
       "        [-1.84319   , -0.30426893, -0.62738734, -0.4054012 , -1.3709867 ],\n",
       "        [ 0.5649113 , -0.28606787,  1.9581379 , -0.26380616,  1.0169952 ]],\n",
       "       dtype=float32),\n",
       " array([-0.7721934 ,  0.75424886,  0.7743762 ,  0.54508924, -0.8148524 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.14334433,  0.15444417,  0.22191133,  0.42854095,  0.13896328,\n",
       "          0.22103484, -0.14986765, -0.35678798,  0.40056825,  0.458663  ],\n",
       "        [-0.06148617, -0.46502087, -0.07358157,  0.04440384, -0.07494152,\n",
       "         -0.7138819 ,  0.47739705,  0.44126603,  0.6834026 ,  0.28745282],\n",
       "        [-0.43262243,  0.546841  ,  0.23919335, -0.25790882,  0.43518898,\n",
       "          0.17378587, -0.04364296, -0.40937567, -0.44869474,  0.34150118],\n",
       "        [-0.30034098, -0.13103005,  0.3807028 ,  0.40733862,  0.06492361,\n",
       "         -0.9796437 ,  0.74423414,  0.16784516, -0.5434292 , -0.25296772],\n",
       "        [ 0.03275327, -0.01874728, -0.09551244,  0.4966205 ,  0.19220665,\n",
       "          0.61241466, -0.02117561,  0.50591284, -0.31886086,  0.09166283]],\n",
       "       dtype=float32),\n",
       " array([-0.85518587, -0.8564796 ,  0.83939755, -0.8718305 ,  0.8157863 ,\n",
       "         0.55375284, -0.7504487 ,  0.8262567 ,  0.8752511 ,  0.82118917],\n",
       "       dtype=float32),\n",
       " array([[-0.68384   ],\n",
       "        [-0.7140214 ],\n",
       "        [ 0.6426074 ],\n",
       "        [-0.81958264],\n",
       "        [ 0.45961922],\n",
       "        [ 0.22398023],\n",
       "        [-0.32832307],\n",
       "        [ 0.5905592 ],\n",
       "        [ 0.88012224],\n",
       "        [ 0.52935916]], dtype=float32),\n",
       " array([0.8782768], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_linear(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_linear_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 38.1877 - val_loss: 37.1808\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5334 - val_loss: 34.6492\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.9370 - val_loss: 31.9030\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9501 - val_loss: 28.5876\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 26.5073 - val_loss: 24.8000\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 22.5236 - val_loss: 20.5132\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 18.0193 - val_loss: 15.7726\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 13.1726 - val_loss: 11.0058\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6133 - val_loss: 7.1503\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8631 - val_loss: 5.7953\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5874 - val_loss: 6.6725\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.1229 - val_loss: 6.9484\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5858 - val_loss: 5.9184\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7615 - val_loss: 4.5019\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3074 - val_loss: 3.4984\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4095 - val_loss: 3.1353\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3838 - val_loss: 3.0258\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9821 - val_loss: 3.0804\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8855 - val_loss: 3.1219\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8974 - val_loss: 3.0908\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9149 - val_loss: 2.9396\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8952 - val_loss: 2.6720\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8254 - val_loss: 2.3498\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7182 - val_loss: 2.0100\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5800 - val_loss: 1.6792\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4177 - val_loss: 1.3741\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2293 - val_loss: 1.0990\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0202 - val_loss: 0.8595\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8046 - val_loss: 0.6660\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6044 - val_loss: 0.5193\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4392 - val_loss: 0.4176\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3229 - val_loss: 0.3538\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2594 - val_loss: 0.3233\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2438 - val_loss: 0.3171\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2633 - val_loss: 0.3252\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3014 - val_loss: 0.3380\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3406 - val_loss: 0.3475\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3669 - val_loss: 0.3484\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3719 - val_loss: 0.3380\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3557 - val_loss: 0.3143\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3200 - val_loss: 0.2816\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2719 - val_loss: 0.2447\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2222 - val_loss: 0.2077\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1777 - val_loss: 0.1743\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1423 - val_loss: 0.1469\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1182 - val_loss: 0.1269\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1047 - val_loss: 0.1144\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0992 - val_loss: 0.1088\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0982 - val_loss: 0.1085\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0985 - val_loss: 0.1119\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0980 - val_loss: 0.1171\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0960 - val_loss: 0.1224\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0922 - val_loss: 0.1263\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0890 - val_loss: 0.1277\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0864 - val_loss: 0.1261\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0819 - val_loss: 0.1214\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0760 - val_loss: 0.1142\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0693 - val_loss: 0.1050\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0622 - val_loss: 0.0946\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0555 - val_loss: 0.0841\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0498 - val_loss: 0.0742\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0453 - val_loss: 0.0655\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0423 - val_loss: 0.0584\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0407 - val_loss: 0.0528\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0402 - val_loss: 0.0487\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0404 - val_loss: 0.0457\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0407 - val_loss: 0.0436\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0409 - val_loss: 0.0420\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0407 - val_loss: 0.0408\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0398 - val_loss: 0.0398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0384 - val_loss: 0.0390\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0366 - val_loss: 0.0384\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0345 - val_loss: 0.0380\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0325 - val_loss: 0.0378\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0306 - val_loss: 0.0377\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0290 - val_loss: 0.0376\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0277 - val_loss: 0.0375\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0267 - val_loss: 0.0373\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0259 - val_loss: 0.0368\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0254 - val_loss: 0.0361\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0249 - val_loss: 0.0351\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0245 - val_loss: 0.0339\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0241 - val_loss: 0.0326\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0237 - val_loss: 0.0312\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0232 - val_loss: 0.0298\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0226 - val_loss: 0.0284\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0272\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0212 - val_loss: 0.0261\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0205 - val_loss: 0.0251\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0243\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0191 - val_loss: 0.0237\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0186 - val_loss: 0.0231\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0181 - val_loss: 0.0226\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0176 - val_loss: 0.0221\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0173 - val_loss: 0.0216\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0169 - val_loss: 0.0211\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0199\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0160 - val_loss: 0.0193\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0157 - val_loss: 0.0186\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0179\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0173\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0146 - val_loss: 0.0167\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0133 - val_loss: 0.0149\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0122 - val_loss: 0.0140\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0135\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0088\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0061 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.8937e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0015 - val_loss: 9.7402e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.5893e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.4411e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.2954e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.1521e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.0111e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 8.8726e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.7362e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.6021e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.4702e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.3405e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.2125e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0013 - val_loss: 8.0869e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 7.9633e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 7.8417e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 7.7219e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 7.6042e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 7.4882e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.0012 - val_loss: 7.3742e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.2620e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 7.1517e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.0432e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.9364e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.8313e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.7279e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.6261e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 6.5259e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.4274e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.3303e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9174e-04 - val_loss: 6.2347e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7794e-04 - val_loss: 6.1405e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6433e-04 - val_loss: 6.0479e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5090e-04 - val_loss: 5.9568e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3766e-04 - val_loss: 5.8671e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2460e-04 - val_loss: 5.7787e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.1171e-04 - val_loss: 5.6918e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9899e-04 - val_loss: 5.6061e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8644e-04 - val_loss: 5.5219e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7407e-04 - val_loss: 5.4390e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6186e-04 - val_loss: 5.3574e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4982e-04 - val_loss: 5.2768e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3793e-04 - val_loss: 5.1977e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2622e-04 - val_loss: 5.1197e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1465e-04 - val_loss: 5.0429e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0324e-04 - val_loss: 4.9674e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9199e-04 - val_loss: 4.8930e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8089e-04 - val_loss: 4.8196e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6993e-04 - val_loss: 4.7474e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5913e-04 - val_loss: 4.6764e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4848e-04 - val_loss: 4.6064e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3797e-04 - val_loss: 4.5374e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2759e-04 - val_loss: 4.4696e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1737e-04 - val_loss: 4.4028e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0727e-04 - val_loss: 4.3369e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9732e-04 - val_loss: 4.2722e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8750e-04 - val_loss: 4.2084e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7781e-04 - val_loss: 4.1454e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6825e-04 - val_loss: 4.0837e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 6.5883e-04 - val_loss: 4.0226e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4953e-04 - val_loss: 3.9624e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4035e-04 - val_loss: 3.9033e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3131e-04 - val_loss: 3.8450e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2238e-04 - val_loss: 3.7875e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1357e-04 - val_loss: 3.7310e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0489e-04 - val_loss: 3.6753e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9632e-04 - val_loss: 3.6205e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8788e-04 - val_loss: 3.5664e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7954e-04 - val_loss: 3.5132e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7132e-04 - val_loss: 3.4609e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6321e-04 - val_loss: 3.4092e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5521e-04 - val_loss: 3.3584e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4732e-04 - val_loss: 3.3083e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3954e-04 - val_loss: 3.2590e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3187e-04 - val_loss: 3.2103e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2429e-04 - val_loss: 3.1625e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1683e-04 - val_loss: 3.1153e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0946e-04 - val_loss: 3.0687e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0218e-04 - val_loss: 3.0230e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9503e-04 - val_loss: 2.9778e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8796e-04 - val_loss: 2.9334e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8099e-04 - val_loss: 2.8896e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7411e-04 - val_loss: 2.8465e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6733e-04 - val_loss: 2.8039e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6065e-04 - val_loss: 2.7620e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5405e-04 - val_loss: 2.7209e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4754e-04 - val_loss: 2.6803e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4112e-04 - val_loss: 2.6403e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3479e-04 - val_loss: 2.6009e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2855e-04 - val_loss: 2.5619e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2240e-04 - val_loss: 2.5237e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1633e-04 - val_loss: 2.4860e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1034e-04 - val_loss: 2.4488e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0443e-04 - val_loss: 2.4123e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.9861e-04 - val_loss: 2.3762e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.9287e-04 - val_loss: 2.3407e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8720e-04 - val_loss: 2.3057e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8162e-04 - val_loss: 2.2712e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7611e-04 - val_loss: 2.2372e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7068e-04 - val_loss: 2.2037e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6532e-04 - val_loss: 2.1708e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6004e-04 - val_loss: 2.1383e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.5483e-04 - val_loss: 2.1063e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4969e-04 - val_loss: 2.0748e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4463e-04 - val_loss: 2.0436e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3962e-04 - val_loss: 2.0131e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3470e-04 - val_loss: 1.9830e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2984e-04 - val_loss: 1.9532e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2505e-04 - val_loss: 1.9239e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2033e-04 - val_loss: 1.8951e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1567e-04 - val_loss: 1.8666e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1108e-04 - val_loss: 1.8386e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0654e-04 - val_loss: 1.8109e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0208e-04 - val_loss: 1.7838e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9768e-04 - val_loss: 1.7570e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9333e-04 - val_loss: 1.7306e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8905e-04 - val_loss: 1.7046e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8483e-04 - val_loss: 1.6790e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8066e-04 - val_loss: 1.6538e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7656e-04 - val_loss: 1.6290e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7251e-04 - val_loss: 1.6044e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6852e-04 - val_loss: 1.5802e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6459e-04 - val_loss: 1.5565e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6071e-04 - val_loss: 1.5330e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5688e-04 - val_loss: 1.5099e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.5311e-04 - val_loss: 1.4871e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4939e-04 - val_loss: 1.4647e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4573e-04 - val_loss: 1.4426e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4211e-04 - val_loss: 1.4208e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3855e-04 - val_loss: 1.3994e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3504e-04 - val_loss: 1.3783e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3157e-04 - val_loss: 1.3575e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2816e-04 - val_loss: 1.3370e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2479e-04 - val_loss: 1.3168e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2147e-04 - val_loss: 1.2969e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1820e-04 - val_loss: 1.2773e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1497e-04 - val_loss: 1.2580e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1179e-04 - val_loss: 1.2389e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.0866e-04 - val_loss: 1.2201e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0557e-04 - val_loss: 1.2016e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0252e-04 - val_loss: 1.1834e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9952e-04 - val_loss: 1.1655e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9656e-04 - val_loss: 1.1478e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9364e-04 - val_loss: 1.1304e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9076e-04 - val_loss: 1.1132e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8793e-04 - val_loss: 1.0963e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8513e-04 - val_loss: 1.0796e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8237e-04 - val_loss: 1.0633e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7966e-04 - val_loss: 1.0471e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7698e-04 - val_loss: 1.0312e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7433e-04 - val_loss: 1.0155e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7173e-04 - val_loss: 1.0000e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6917e-04 - val_loss: 9.8477e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6664e-04 - val_loss: 9.6981e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6415e-04 - val_loss: 9.5505e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6169e-04 - val_loss: 9.4048e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5927e-04 - val_loss: 9.2607e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5688e-04 - val_loss: 9.1195e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5453e-04 - val_loss: 8.9806e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5221e-04 - val_loss: 8.8430e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4993e-04 - val_loss: 8.7075e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4768e-04 - val_loss: 8.5747e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 1.4546e-04 - val_loss: 8.4436e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4327e-04 - val_loss: 8.3138e-05\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4111e-04 - val_loss: 8.1864e-05\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3899e-04 - val_loss: 8.0614e-05\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3689e-04 - val_loss: 7.9379e-05\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3483e-04 - val_loss: 7.8158e-05\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3279e-04 - val_loss: 7.6962e-05\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3079e-04 - val_loss: 7.5780e-05\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2881e-04 - val_loss: 7.4621e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2686e-04 - val_loss: 7.3476e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2495e-04 - val_loss: 7.2346e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2305e-04 - val_loss: 7.1235e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2119e-04 - val_loss: 7.0136e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1935e-04 - val_loss: 6.9056e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1754e-04 - val_loss: 6.7992e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1576e-04 - val_loss: 6.6944e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1400e-04 - val_loss: 6.5913e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1227e-04 - val_loss: 6.4890e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1056e-04 - val_loss: 6.3891e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0888e-04 - val_loss: 6.2905e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0722e-04 - val_loss: 6.1935e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0559e-04 - val_loss: 6.0977e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0398e-04 - val_loss: 6.0037e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0239e-04 - val_loss: 5.9109e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0083e-04 - val_loss: 5.8195e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9290e-05 - val_loss: 5.7298e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7773e-05 - val_loss: 5.6403e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6277e-05 - val_loss: 5.5532e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4806e-05 - val_loss: 5.4672e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.3355e-05 - val_loss: 5.3826e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1922e-05 - val_loss: 5.2990e-05\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0513e-05 - val_loss: 5.2161e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9124e-05 - val_loss: 5.1354e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7757e-05 - val_loss: 5.0556e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6409e-05 - val_loss: 4.9765e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.5081e-05 - val_loss: 4.8992e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3772e-05 - val_loss: 4.8230e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2482e-05 - val_loss: 4.7481e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1215e-05 - val_loss: 4.6742e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9960e-05 - val_loss: 4.6013e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8730e-05 - val_loss: 4.5294e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7514e-05 - val_loss: 4.4588e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6317e-05 - val_loss: 4.3892e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5139e-05 - val_loss: 4.3206e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3977e-05 - val_loss: 4.2531e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2833e-05 - val_loss: 4.1867e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1706e-05 - val_loss: 4.1212e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0597e-05 - val_loss: 4.0564e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9502e-05 - val_loss: 3.9929e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8423e-05 - val_loss: 3.9304e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7362e-05 - val_loss: 3.8684e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6318e-05 - val_loss: 3.8079e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5287e-05 - val_loss: 3.7482e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4270e-05 - val_loss: 3.6893e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3273e-05 - val_loss: 3.6313e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.2288e-05 - val_loss: 3.5743e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1317e-05 - val_loss: 3.5179e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0362e-05 - val_loss: 3.4624e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9421e-05 - val_loss: 3.4078e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8493e-05 - val_loss: 3.3544e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7581e-05 - val_loss: 3.3015e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6680e-05 - val_loss: 3.2493e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5795e-05 - val_loss: 3.1984e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4922e-05 - val_loss: 3.1479e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4062e-05 - val_loss: 3.0981e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3217e-05 - val_loss: 3.0489e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2381e-05 - val_loss: 3.0008e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1562e-05 - val_loss: 2.9532e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0752e-05 - val_loss: 2.9061e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9955e-05 - val_loss: 2.8601e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9171e-05 - val_loss: 2.8148e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8397e-05 - val_loss: 2.7703e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7635e-05 - val_loss: 2.7266e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6888e-05 - val_loss: 2.6832e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6148e-05 - val_loss: 2.6405e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5419e-05 - val_loss: 2.5985e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4704e-05 - val_loss: 2.5574e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3999e-05 - val_loss: 2.5167e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3304e-05 - val_loss: 2.4766e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2619e-05 - val_loss: 2.4369e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1946e-05 - val_loss: 2.3983e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1284e-05 - val_loss: 2.3598e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0629e-05 - val_loss: 2.3223e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9986e-05 - val_loss: 2.2852e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9354e-05 - val_loss: 2.2488e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8729e-05 - val_loss: 2.2128e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8114e-05 - val_loss: 2.1774e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7510e-05 - val_loss: 2.1427e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6914e-05 - val_loss: 2.1082e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6327e-05 - val_loss: 2.0746e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5749e-05 - val_loss: 2.0413e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5180e-05 - val_loss: 2.0087e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4619e-05 - val_loss: 1.9763e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4068e-05 - val_loss: 1.9447e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3526e-05 - val_loss: 1.9134e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2990e-05 - val_loss: 1.8828e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2465e-05 - val_loss: 1.8523e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1944e-05 - val_loss: 1.8227e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1435e-05 - val_loss: 1.7933e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0932e-05 - val_loss: 1.7643e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0436e-05 - val_loss: 1.7360e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9950e-05 - val_loss: 1.7079e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9471e-05 - val_loss: 1.6803e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8997e-05 - val_loss: 1.6534e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8533e-05 - val_loss: 1.6267e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8074e-05 - val_loss: 1.6006e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7622e-05 - val_loss: 1.5748e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7179e-05 - val_loss: 1.5494e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6742e-05 - val_loss: 1.5240e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6312e-05 - val_loss: 1.4993e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5889e-05 - val_loss: 1.4750e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5471e-05 - val_loss: 1.4510e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5061e-05 - val_loss: 1.4272e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4657e-05 - val_loss: 1.4038e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4259e-05 - val_loss: 1.3813e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3867e-05 - val_loss: 1.3591e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3481e-05 - val_loss: 1.3371e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3101e-05 - val_loss: 1.3153e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2727e-05 - val_loss: 1.2941e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2359e-05 - val_loss: 1.2731e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1998e-05 - val_loss: 1.2523e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1640e-05 - val_loss: 1.2319e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1289e-05 - val_loss: 1.2115e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0944e-05 - val_loss: 1.1918e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0605e-05 - val_loss: 1.1723e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0270e-05 - val_loss: 1.1531e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9940e-05 - val_loss: 1.1342e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9616e-05 - val_loss: 1.1157e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9296e-05 - val_loss: 1.0974e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8982e-05 - val_loss: 1.0795e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8674e-05 - val_loss: 1.0619e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.8370e-05 - val_loss: 1.0444e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8070e-05 - val_loss: 1.0274e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7774e-05 - val_loss: 1.0107e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7483e-05 - val_loss: 9.9405e-06\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7198e-05 - val_loss: 9.7774e-06\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6916e-05 - val_loss: 9.6159e-06\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6640e-05 - val_loss: 9.4580e-06\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6368e-05 - val_loss: 9.3009e-06\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6099e-05 - val_loss: 9.1473e-06\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5835e-05 - val_loss: 8.9968e-06\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5576e-05 - val_loss: 8.8485e-06\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5320e-05 - val_loss: 8.7024e-06\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5069e-05 - val_loss: 8.5602e-06\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4821e-05 - val_loss: 8.4197e-06\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4578e-05 - val_loss: 8.2793e-06\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4338e-05 - val_loss: 8.1426e-06\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4101e-05 - val_loss: 8.0083e-06\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.3870e-05 - val_loss: 7.8751e-06\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3641e-05 - val_loss: 7.7453e-06\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3416e-05 - val_loss: 7.6178e-06\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3194e-05 - val_loss: 7.4914e-06\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2977e-05 - val_loss: 7.3667e-06\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2762e-05 - val_loss: 7.2449e-06\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2552e-05 - val_loss: 7.1255e-06\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2344e-05 - val_loss: 7.0052e-06\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2140e-05 - val_loss: 6.8879e-06\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1939e-05 - val_loss: 6.7732e-06\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1741e-05 - val_loss: 6.6618e-06\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1546e-05 - val_loss: 6.5499e-06\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1354e-05 - val_loss: 6.4419e-06\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1167e-05 - val_loss: 6.3354e-06\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0981e-05 - val_loss: 6.2298e-06\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0798e-05 - val_loss: 6.1258e-06\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0619e-05 - val_loss: 6.0228e-06\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0442e-05 - val_loss: 5.9237e-06\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0267e-05 - val_loss: 5.8248e-06\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0098e-05 - val_loss: 5.7261e-06\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 9.9284e-06 - val_loss: 5.6302e-06\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7634e-06 - val_loss: 5.5366e-06\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6011e-06 - val_loss: 5.4430e-06\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4398e-06 - val_loss: 5.3520e-06\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2828e-06 - val_loss: 5.2623e-06\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1282e-06 - val_loss: 5.1744e-06\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9753e-06 - val_loss: 5.0869e-06\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8247e-06 - val_loss: 5.0014e-06\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6770e-06 - val_loss: 4.9163e-06\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5311e-06 - val_loss: 4.8349e-06\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3886e-06 - val_loss: 4.7531e-06\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2474e-06 - val_loss: 4.6746e-06\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1096e-06 - val_loss: 4.5954e-06\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9729e-06 - val_loss: 4.5186e-06\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8397e-06 - val_loss: 4.4419e-06\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7070e-06 - val_loss: 4.3677e-06\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5780e-06 - val_loss: 4.2936e-06\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4503e-06 - val_loss: 4.2205e-06\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3245e-06 - val_loss: 4.1490e-06\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2010e-06 - val_loss: 4.0786e-06\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0789e-06 - val_loss: 4.0090e-06\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9594e-06 - val_loss: 3.9413e-06\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8430e-06 - val_loss: 3.8747e-06\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7273e-06 - val_loss: 3.8094e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6140e-06 - val_loss: 3.7438e-06\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5016e-06 - val_loss: 3.6810e-06\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3919e-06 - val_loss: 3.6182e-06\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2834e-06 - val_loss: 3.5575e-06\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1769e-06 - val_loss: 3.4972e-06\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0722e-06 - val_loss: 3.4374e-06\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9693e-06 - val_loss: 3.3782e-06\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 5.8678e-06 - val_loss: 3.3218e-06\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7681e-06 - val_loss: 3.2657e-06\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6703e-06 - val_loss: 3.2100e-06\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5742e-06 - val_loss: 3.1552e-06\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4794e-06 - val_loss: 3.1014e-06\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 5.3864e-06 - val_loss: 3.0487e-06\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2944e-06 - val_loss: 2.9957e-06\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2041e-06 - val_loss: 2.9440e-06\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1151e-06 - val_loss: 2.8946e-06\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0280e-06 - val_loss: 2.8441e-06\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9424e-06 - val_loss: 2.7965e-06\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.8579e-06 - val_loss: 2.7473e-06\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7746e-06 - val_loss: 2.7007e-06\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6938e-06 - val_loss: 2.6547e-06\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6129e-06 - val_loss: 2.6090e-06\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5341e-06 - val_loss: 2.5635e-06\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4563e-06 - val_loss: 2.5199e-06\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3797e-06 - val_loss: 2.4769e-06\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3050e-06 - val_loss: 2.4341e-06\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2303e-06 - val_loss: 2.3928e-06\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1585e-06 - val_loss: 2.3518e-06\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0868e-06 - val_loss: 2.3113e-06\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0165e-06 - val_loss: 2.2708e-06\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.9476e-06 - val_loss: 2.2310e-06\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8790e-06 - val_loss: 2.1930e-06\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8126e-06 - val_loss: 2.1557e-06\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7471e-06 - val_loss: 2.1192e-06\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6826e-06 - val_loss: 2.0825e-06\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6189e-06 - val_loss: 2.0458e-06\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5564e-06 - val_loss: 2.0102e-06\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4953e-06 - val_loss: 1.9752e-06\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4345e-06 - val_loss: 1.9413e-06\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3752e-06 - val_loss: 1.9076e-06\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3170e-06 - val_loss: 1.8745e-06\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.2595e-06 - val_loss: 1.8415e-06\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2032e-06 - val_loss: 1.8093e-06\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1475e-06 - val_loss: 1.7783e-06\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0931e-06 - val_loss: 1.7479e-06\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0394e-06 - val_loss: 1.7171e-06\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9871e-06 - val_loss: 1.6879e-06\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9349e-06 - val_loss: 1.6579e-06\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8838e-06 - val_loss: 1.6293e-06\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8338e-06 - val_loss: 1.6014e-06\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7844e-06 - val_loss: 1.5727e-06\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7357e-06 - val_loss: 1.5453e-06\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6883e-06 - val_loss: 1.5183e-06\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6416e-06 - val_loss: 1.4920e-06\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5955e-06 - val_loss: 1.4658e-06\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5502e-06 - val_loss: 1.4403e-06\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5058e-06 - val_loss: 1.4146e-06\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4617e-06 - val_loss: 1.3901e-06\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4189e-06 - val_loss: 1.3652e-06\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3764e-06 - val_loss: 1.3422e-06\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3351e-06 - val_loss: 1.3185e-06\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2940e-06 - val_loss: 1.2959e-06\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2540e-06 - val_loss: 1.2729e-06\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2142e-06 - val_loss: 1.2512e-06\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1756e-06 - val_loss: 1.2283e-06\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1373e-06 - val_loss: 1.2070e-06\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0999e-06 - val_loss: 1.1856e-06\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0630e-06 - val_loss: 1.1650e-06\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0267e-06 - val_loss: 1.1447e-06\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9912e-06 - val_loss: 1.1246e-06\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9561e-06 - val_loss: 1.1043e-06\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9216e-06 - val_loss: 1.0845e-06\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8877e-06 - val_loss: 1.0653e-06\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8544e-06 - val_loss: 1.0466e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8217e-06 - val_loss: 1.0276e-06\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7895e-06 - val_loss: 1.0097e-06\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7579e-06 - val_loss: 9.9190e-07\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7271e-06 - val_loss: 9.7470e-07\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6963e-06 - val_loss: 9.5804e-07\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6667e-06 - val_loss: 9.4118e-07\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6375e-06 - val_loss: 9.2403e-07\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6079e-06 - val_loss: 9.0809e-07\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5796e-06 - val_loss: 8.9175e-07\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5516e-06 - val_loss: 8.7583e-07\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5242e-06 - val_loss: 8.6027e-07\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4968e-06 - val_loss: 8.4515e-07\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.4706e-06 - val_loss: 8.2960e-07\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4444e-06 - val_loss: 8.1446e-07\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4187e-06 - val_loss: 8.0039e-07\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3935e-06 - val_loss: 7.8598e-07\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3687e-06 - val_loss: 7.7169e-07\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3440e-06 - val_loss: 7.5759e-07\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3206e-06 - val_loss: 7.4395e-07\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2968e-06 - val_loss: 7.3121e-07\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2735e-06 - val_loss: 7.1826e-07\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 1.2511e-06 - val_loss: 7.0528e-07\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2285e-06 - val_loss: 6.9315e-07\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2067e-06 - val_loss: 6.8127e-07\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1851e-06 - val_loss: 6.6883e-07\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1638e-06 - val_loss: 6.5653e-07\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1429e-06 - val_loss: 6.4454e-07\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1226e-06 - val_loss: 6.3314e-07\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1025e-06 - val_loss: 6.2134e-07\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0827e-06 - val_loss: 6.1003e-07\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0634e-06 - val_loss: 5.9883e-07\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0443e-06 - val_loss: 5.8870e-07\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0253e-06 - val_loss: 5.7816e-07\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0070e-06 - val_loss: 5.6768e-07\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.8898e-07 - val_loss: 5.5786e-07\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7096e-07 - val_loss: 5.4795e-07\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.5363e-07 - val_loss: 5.3795e-07\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3641e-07 - val_loss: 5.2819e-07\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1952e-07 - val_loss: 5.1878e-07\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0301e-07 - val_loss: 5.0898e-07\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8664e-07 - val_loss: 4.9978e-07\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7069e-07 - val_loss: 4.9054e-07\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5490e-07 - val_loss: 4.8201e-07\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3956e-07 - val_loss: 4.7321e-07\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2414e-07 - val_loss: 4.6462e-07\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0930e-07 - val_loss: 4.5643e-07\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9490e-07 - val_loss: 4.4822e-07\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8038e-07 - val_loss: 4.4009e-07\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6598e-07 - val_loss: 4.3218e-07\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5215e-07 - val_loss: 4.2425e-07\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3865e-07 - val_loss: 4.1640e-07\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2535e-07 - val_loss: 4.0879e-07\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1229e-07 - val_loss: 4.0136e-07\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9930e-07 - val_loss: 3.9386e-07\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8645e-07 - val_loss: 3.8660e-07\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7391e-07 - val_loss: 3.8003e-07\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6195e-07 - val_loss: 3.7278e-07\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4961e-07 - val_loss: 3.6634e-07\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3778e-07 - val_loss: 3.5975e-07\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2601e-07 - val_loss: 3.5292e-07\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1488e-07 - val_loss: 3.4652e-07\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0382e-07 - val_loss: 3.4014e-07\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9264e-07 - val_loss: 3.3395e-07\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8168e-07 - val_loss: 3.2736e-07\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7097e-07 - val_loss: 3.2143e-07\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6067e-07 - val_loss: 3.1572e-07\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5048e-07 - val_loss: 3.1015e-07\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4039e-07 - val_loss: 3.0417e-07\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3029e-07 - val_loss: 2.9857e-07\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2057e-07 - val_loss: 2.9335e-07\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1113e-07 - val_loss: 2.8799e-07\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0159e-07 - val_loss: 2.8271e-07\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9255e-07 - val_loss: 2.7745e-07\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8343e-07 - val_loss: 2.7255e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7454e-07 - val_loss: 2.6742e-07\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.6575e-07 - val_loss: 2.6233e-07\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5715e-07 - val_loss: 2.5734e-07\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4876e-07 - val_loss: 2.5265e-07\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4055e-07 - val_loss: 2.4793e-07\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3234e-07 - val_loss: 2.4333e-07\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2441e-07 - val_loss: 2.3883e-07\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1655e-07 - val_loss: 2.3451e-07\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0894e-07 - val_loss: 2.3027e-07\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0139e-07 - val_loss: 2.2605e-07\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9391e-07 - val_loss: 2.2209e-07\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8660e-07 - val_loss: 2.1795e-07\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7949e-07 - val_loss: 2.1383e-07\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7252e-07 - val_loss: 2.0975e-07\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6549e-07 - val_loss: 2.0579e-07\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5867e-07 - val_loss: 2.0176e-07\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5208e-07 - val_loss: 1.9835e-07\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4564e-07 - val_loss: 1.9465e-07\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3917e-07 - val_loss: 1.9109e-07\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3293e-07 - val_loss: 1.8760e-07\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2664e-07 - val_loss: 1.8409e-07\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2062e-07 - val_loss: 1.8043e-07\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1470e-07 - val_loss: 1.7712e-07\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.0881e-07 - val_loss: 1.7372e-07\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0305e-07 - val_loss: 1.7068e-07\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9734e-07 - val_loss: 1.6746e-07\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.9184e-07 - val_loss: 1.6426e-07\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8647e-07 - val_loss: 1.6111e-07\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8096e-07 - val_loss: 1.5807e-07\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7578e-07 - val_loss: 1.5507e-07\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7061e-07 - val_loss: 1.5233e-07\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6550e-07 - val_loss: 1.4958e-07\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.6061e-07 - val_loss: 1.4670e-07\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5573e-07 - val_loss: 1.4418e-07\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5094e-07 - val_loss: 1.4158e-07\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.4617e-07 - val_loss: 1.3906e-07\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4165e-07 - val_loss: 1.3624e-07\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3707e-07 - val_loss: 1.3359e-07\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3260e-07 - val_loss: 1.3113e-07\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2828e-07 - val_loss: 1.2846e-07\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2402e-07 - val_loss: 1.2587e-07\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1973e-07 - val_loss: 1.2350e-07\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1570e-07 - val_loss: 1.2140e-07\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1156e-07 - val_loss: 1.1903e-07\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0749e-07 - val_loss: 1.1677e-07\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0365e-07 - val_loss: 1.1465e-07\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9976e-07 - val_loss: 1.1243e-07\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9600e-07 - val_loss: 1.1025e-07\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9230e-07 - val_loss: 1.0811e-07\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8866e-07 - val_loss: 1.0616e-07\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.8511e-07 - val_loss: 1.0426e-07\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8159e-07 - val_loss: 1.0234e-07\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7817e-07 - val_loss: 1.0032e-07\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7490e-07 - val_loss: 9.8438e-08\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7142e-07 - val_loss: 9.6684e-08\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6825e-07 - val_loss: 9.4655e-08\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6508e-07 - val_loss: 9.2844e-08\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6196e-07 - val_loss: 9.1073e-08\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5890e-07 - val_loss: 8.9378e-08\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5586e-07 - val_loss: 8.7609e-08\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5289e-07 - val_loss: 8.5846e-08\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4996e-07 - val_loss: 8.4354e-08\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4711e-07 - val_loss: 8.2667e-08\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.4430e-07 - val_loss: 8.1098e-08\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4163e-07 - val_loss: 7.9513e-08\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3883e-07 - val_loss: 7.7898e-08\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3623e-07 - val_loss: 7.6605e-08\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3358e-07 - val_loss: 7.5162e-08\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3113e-07 - val_loss: 7.3604e-08\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2849e-07 - val_loss: 7.2350e-08\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2606e-07 - val_loss: 7.1013e-08\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2371e-07 - val_loss: 6.9639e-08\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2128e-07 - val_loss: 6.8179e-08\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1894e-07 - val_loss: 6.7060e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1677e-07 - val_loss: 6.5557e-08\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1448e-07 - val_loss: 6.4378e-08\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1228e-07 - val_loss: 6.2978e-08\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1010e-07 - val_loss: 6.1880e-08\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0795e-07 - val_loss: 6.0590e-08\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0581e-07 - val_loss: 5.9599e-08\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0386e-07 - val_loss: 5.8451e-08\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0181e-07 - val_loss: 5.7377e-08\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9916e-08 - val_loss: 5.6215e-08\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7988e-08 - val_loss: 5.5245e-08\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6124e-08 - val_loss: 5.4135e-08\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4253e-08 - val_loss: 5.3040e-08\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2396e-08 - val_loss: 5.1940e-08\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0661e-08 - val_loss: 5.0965e-08\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8849e-08 - val_loss: 4.9838e-08\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7119e-08 - val_loss: 4.8892e-08\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5478e-08 - val_loss: 4.7970e-08\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3883e-08 - val_loss: 4.7089e-08\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2241e-08 - val_loss: 4.6233e-08\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0650e-08 - val_loss: 4.5432e-08\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9121e-08 - val_loss: 4.4462e-08\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7555e-08 - val_loss: 4.3675e-08\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6014e-08 - val_loss: 4.2698e-08\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4553e-08 - val_loss: 4.1903e-08\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3132e-08 - val_loss: 4.1022e-08\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1652e-08 - val_loss: 4.0259e-08\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0291e-08 - val_loss: 3.9420e-08\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8941e-08 - val_loss: 3.8704e-08\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7542e-08 - val_loss: 3.7898e-08\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6247e-08 - val_loss: 3.7194e-08\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4932e-08 - val_loss: 3.6437e-08\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3628e-08 - val_loss: 3.5813e-08\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2511e-08 - val_loss: 3.5001e-08\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1225e-08 - val_loss: 3.4346e-08\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0033e-08 - val_loss: 3.3703e-08\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8882e-08 - val_loss: 3.3045e-08\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7736e-08 - val_loss: 3.2329e-08\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6549e-08 - val_loss: 3.1680e-08\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5461e-08 - val_loss: 3.1025e-08\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4350e-08 - val_loss: 3.0491e-08\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3298e-08 - val_loss: 2.9951e-08\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2239e-08 - val_loss: 2.9459e-08\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1274e-08 - val_loss: 2.8799e-08\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0220e-08 - val_loss: 2.8285e-08\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9238e-08 - val_loss: 2.7703e-08\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8289e-08 - val_loss: 2.7191e-08\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7388e-08 - val_loss: 2.6585e-08\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6409e-08 - val_loss: 2.6074e-08\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5524e-08 - val_loss: 2.5456e-08\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4580e-08 - val_loss: 2.4998e-08\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3764e-08 - val_loss: 2.4531e-08\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2904e-08 - val_loss: 2.4009e-08\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 4.2020e-08 - val_loss: 2.3604e-08\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1206e-08 - val_loss: 2.3149e-08\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0368e-08 - val_loss: 2.2644e-08\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9583e-08 - val_loss: 2.2264e-08\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8788e-08 - val_loss: 2.1862e-08\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7994e-08 - val_loss: 2.1365e-08\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7308e-08 - val_loss: 2.0914e-08\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6500e-08 - val_loss: 2.0541e-08\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5818e-08 - val_loss: 2.0193e-08\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.5095e-08 - val_loss: 1.9752e-08\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4406e-08 - val_loss: 1.9306e-08\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.3705e-08 - val_loss: 1.8908e-08\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3034e-08 - val_loss: 1.8632e-08\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2377e-08 - val_loss: 1.8171e-08\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1734e-08 - val_loss: 1.7843e-08\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1131e-08 - val_loss: 1.7495e-08\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0497e-08 - val_loss: 1.7121e-08\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9868e-08 - val_loss: 1.6849e-08\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9327e-08 - val_loss: 1.6487e-08\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8733e-08 - val_loss: 1.6150e-08\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8102e-08 - val_loss: 1.5888e-08\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7609e-08 - val_loss: 1.5590e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7006e-08 - val_loss: 1.5244e-08\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6468e-08 - val_loss: 1.4922e-08\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5973e-08 - val_loss: 1.4598e-08\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5430e-08 - val_loss: 1.4258e-08\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4931e-08 - val_loss: 1.3977e-08\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4435e-08 - val_loss: 1.3695e-08\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3954e-08 - val_loss: 1.3448e-08\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3481e-08 - val_loss: 1.3154e-08\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3023e-08 - val_loss: 1.2894e-08\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2548e-08 - val_loss: 1.2669e-08\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2075e-08 - val_loss: 1.2472e-08\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1633e-08 - val_loss: 1.2275e-08\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1197e-08 - val_loss: 1.1957e-08\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0772e-08 - val_loss: 1.1740e-08\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0357e-08 - val_loss: 1.1501e-08\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9930e-08 - val_loss: 1.1247e-08\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9547e-08 - val_loss: 1.0986e-08\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9179e-08 - val_loss: 1.0749e-08\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8774e-08 - val_loss: 1.0548e-08\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8392e-08 - val_loss: 1.0344e-08\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8053e-08 - val_loss: 1.0078e-08\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7641e-08 - val_loss: 9.9163e-09\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7316e-08 - val_loss: 9.7078e-09\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6934e-08 - val_loss: 9.5540e-09\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6592e-08 - val_loss: 9.3227e-09\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6270e-08 - val_loss: 9.1528e-09\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5935e-08 - val_loss: 8.9972e-09\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5638e-08 - val_loss: 8.8091e-09\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5287e-08 - val_loss: 8.6580e-09\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4992e-08 - val_loss: 8.4670e-09\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4679e-08 - val_loss: 8.3038e-09\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4402e-08 - val_loss: 8.0807e-09\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4137e-08 - val_loss: 7.9009e-09\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3790e-08 - val_loss: 7.7433e-09\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3537e-08 - val_loss: 7.5568e-09\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3254e-08 - val_loss: 7.4447e-09\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2949e-08 - val_loss: 7.2628e-09\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2712e-08 - val_loss: 7.1547e-09\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2471e-08 - val_loss: 7.0293e-09\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2211e-08 - val_loss: 6.8714e-09\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1943e-08 - val_loss: 6.7267e-09\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1692e-08 - val_loss: 6.6181e-09\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1465e-08 - val_loss: 6.4949e-09\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1222e-08 - val_loss: 6.3653e-09\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1043e-08 - val_loss: 6.1983e-09\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0794e-08 - val_loss: 6.0812e-09\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0564e-08 - val_loss: 5.9636e-09\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0351e-08 - val_loss: 5.8401e-09\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0168e-08 - val_loss: 5.6741e-09\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9214e-09 - val_loss: 5.5957e-09\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7059e-09 - val_loss: 5.5021e-09\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5141e-09 - val_loss: 5.3743e-09\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3308e-09 - val_loss: 5.2394e-09\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1461e-09 - val_loss: 5.1454e-09\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9426e-09 - val_loss: 5.0489e-09\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7573e-09 - val_loss: 4.9253e-09\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5718e-09 - val_loss: 4.8420e-09\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3955e-09 - val_loss: 4.7568e-09\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2376e-09 - val_loss: 4.6683e-09\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0557e-09 - val_loss: 4.5653e-09\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8818e-09 - val_loss: 4.4507e-09\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7459e-09 - val_loss: 4.3607e-09\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5754e-09 - val_loss: 4.2636e-09\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4106e-09 - val_loss: 4.1437e-09\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2491e-09 - val_loss: 4.0794e-09\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1124e-09 - val_loss: 3.9848e-09\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.9548e-09 - val_loss: 3.9149e-09\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8280e-09 - val_loss: 3.8429e-09\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6902e-09 - val_loss: 3.7315e-09\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5234e-09 - val_loss: 3.6875e-09\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4019e-09 - val_loss: 3.6380e-09\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2861e-09 - val_loss: 3.5375e-09\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1438e-09 - val_loss: 3.4674e-09\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.0040e-09 - val_loss: 3.4144e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8940e-09 - val_loss: 3.3389e-09\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7644e-09 - val_loss: 3.2617e-09\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6293e-09 - val_loss: 3.1573e-09\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.5259e-09 - val_loss: 3.1149e-09\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4223e-09 - val_loss: 3.0189e-09\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2951e-09 - val_loss: 2.9701e-09\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1890e-09 - val_loss: 2.8942e-09\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0742e-09 - val_loss: 2.8622e-09\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9701e-09 - val_loss: 2.8360e-09\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8897e-09 - val_loss: 2.7463e-09\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7841e-09 - val_loss: 2.6900e-09\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6633e-09 - val_loss: 2.6250e-09\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5758e-09 - val_loss: 2.5848e-09\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4779e-09 - val_loss: 2.5302e-09\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3740e-09 - val_loss: 2.4674e-09\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2878e-09 - val_loss: 2.4135e-09\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2018e-09 - val_loss: 2.3621e-09\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1074e-09 - val_loss: 2.2969e-09\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0316e-09 - val_loss: 2.2617e-09\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9295e-09 - val_loss: 2.2248e-09\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8521e-09 - val_loss: 2.1788e-09\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7614e-09 - val_loss: 2.1565e-09\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6945e-09 - val_loss: 2.0962e-09\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6213e-09 - val_loss: 2.0511e-09\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5378e-09 - val_loss: 2.0011e-09\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4749e-09 - val_loss: 1.9523e-09\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3944e-09 - val_loss: 1.9085e-09\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3132e-09 - val_loss: 1.8748e-09\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2515e-09 - val_loss: 1.8232e-09\n",
      "4.145996601589985e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-5.0512969e-01, -4.6921757e-04, -2.0486562e-02, -7.8703612e-01,\n",
       "          1.0930594e+00],\n",
       "        [-7.3067862e-01, -1.8316913e-01,  8.1406611e-01,  6.4535424e-02,\n",
       "         -1.4243491e-01],\n",
       "        [-4.0648007e-01, -3.5018343e-01,  8.9940965e-01, -2.0395689e-01,\n",
       "          1.8476747e-01]], dtype=float32),\n",
       " array([ 0.03973232, -0.87257665, -0.11280363,  0.3913937 ,  0.47099224],\n",
       "       dtype=float32),\n",
       " array([[-0.01115614, -0.2148926 , -0.17948215, -0.9198766 , -0.7324524 ,\n",
       "         -0.4067296 ,  0.48221585, -0.1654384 , -0.64242756, -0.5671849 ],\n",
       "        [ 0.7274891 ,  0.05872794, -0.1598261 , -0.3036224 , -0.6564543 ,\n",
       "         -0.06771255, -0.00233848,  0.17615391, -0.25959533, -0.6724642 ],\n",
       "        [ 0.25946453, -0.2461972 , -0.14643149, -0.56728023, -0.5555576 ,\n",
       "         -0.30541337,  0.1951243 , -0.6604656 , -0.22110936, -0.80494845],\n",
       "        [ 0.3896581 , -0.62934005, -0.6545125 , -0.17608666, -0.10321164,\n",
       "         -0.6887154 ,  0.5622161 , -0.5420234 , -0.7465959 ,  0.01487166],\n",
       "        [ 0.14640924, -0.6427299 , -0.5690766 , -0.22681493, -0.21257752,\n",
       "          0.01670711, -0.11077294, -0.06485333, -0.4131475 , -0.01937599]],\n",
       "       dtype=float32),\n",
       " array([ 1.3753346 , -0.5039171 , -0.44825843, -0.31743687, -0.5900387 ,\n",
       "         1.4883394 ,  1.3248744 , -0.35179844, -0.45700932, -0.49182424],\n",
       "       dtype=float32),\n",
       " array([[ 0.7628819 ],\n",
       "        [ 0.03477386],\n",
       "        [ 0.01048971],\n",
       "        [ 0.23305385],\n",
       "        [ 0.11453235],\n",
       "        [ 1.4297968 ],\n",
       "        [ 1.2232478 ],\n",
       "        [ 0.39900026],\n",
       "        [-0.12529399],\n",
       "        [-0.10860009]], dtype=float32),\n",
       " array([1.2019645], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_relu(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_relu_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 38.7623 - val_loss: 35.6385\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6147 - val_loss: 31.8868\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6944 - val_loss: 27.9067\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.5518 - val_loss: 23.9251\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 23.4250 - val_loss: 20.0518\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 19.4310 - val_loss: 16.3598\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 15.6566 - val_loss: 12.9144\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 12.1735 - val_loss: 9.7896\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0536 - val_loss: 7.0672\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3721 - val_loss: 4.8147\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1846 - val_loss: 3.0495\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4974 - val_loss: 1.7392\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2901 - val_loss: 0.8315\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.5327 - val_loss: 0.3476\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1956 - val_loss: 0.2497\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2238 - val_loss: 0.4465\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5206 - val_loss: 0.8106\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.9510 - val_loss: 1.2120\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3801 - val_loss: 1.5536\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7155 - val_loss: 1.7853\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9194 - val_loss: 1.8950\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9924 - val_loss: 1.8930\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9531 - val_loss: 1.7991\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.8252 - val_loss: 1.6368\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 194us/step - loss: 1.6338 - val_loss: 1.4298\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4040 - val_loss: 1.2008\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1597 - val_loss: 0.9697\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.9218 - val_loss: 0.7526\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7068 - val_loss: 0.5611\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5257 - val_loss: 0.4021\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3836 - val_loss: 0.2780\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2805 - val_loss: 0.1878\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2125 - val_loss: 0.1276\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1736 - val_loss: 0.0923\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1568 - val_loss: 0.0763\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1552 - val_loss: 0.0739\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1629 - val_loss: 0.0800\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1747 - val_loss: 0.0903\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1868 - val_loss: 0.1015\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1964 - val_loss: 0.1109\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2017 - val_loss: 0.1170\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2017 - val_loss: 0.1188\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1962 - val_loss: 0.1162\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1855 - val_loss: 0.1095\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1705 - val_loss: 0.0994\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1522 - val_loss: 0.0870\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1319 - val_loss: 0.0732\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.1109 - val_loss: 0.0610\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0920 - val_loss: 0.0487\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0736 - val_loss: 0.0370\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0565 - val_loss: 0.0266\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0414 - val_loss: 0.0179\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0289 - val_loss: 0.0112\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0194 - val_loss: 0.0065\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0037\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0138 - val_loss: 0.0122\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0090\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0094 - val_loss: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 8.0921e-04\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 5.1357e-04\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 4.2624e-04\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 5.0228e-04\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.9206e-04\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.4623e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.3933e-04\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 6.9103e-04\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0013 - val_loss: 5.6955e-04\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 4.7622e-04\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.0992e-04\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.6753e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8689e-04 - val_loss: 3.4473e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7469e-04 - val_loss: 3.3652e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7514e-04 - val_loss: 3.3789e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8263e-04 - val_loss: 3.4420e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9211e-04 - val_loss: 3.5154e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9948e-04 - val_loss: 3.5700e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.5863e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9716e-04 - val_loss: 3.5547e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8499e-04 - val_loss: 3.4742e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6554e-04 - val_loss: 3.3502e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3983e-04 - val_loss: 3.1931e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.0942e-04 - val_loss: 3.0159e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7606e-04 - val_loss: 2.8316e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4158e-04 - val_loss: 2.6530e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0766e-04 - val_loss: 2.4900e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7567e-04 - val_loss: 2.3499e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4665e-04 - val_loss: 2.2371e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2121e-04 - val_loss: 2.1523e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9961e-04 - val_loss: 2.0939e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8176e-04 - val_loss: 2.0581e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6727e-04 - val_loss: 2.0396e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5562e-04 - val_loss: 2.0326e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4613e-04 - val_loss: 2.0310e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3811e-04 - val_loss: 2.0295e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3093e-04 - val_loss: 2.0235e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2402e-04 - val_loss: 2.0096e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1695e-04 - val_loss: 1.9861e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0940e-04 - val_loss: 1.9518e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0122e-04 - val_loss: 1.9076e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9234e-04 - val_loss: 1.8546e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8286e-04 - val_loss: 1.7947e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7288e-04 - val_loss: 1.7301e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6258e-04 - val_loss: 1.6635e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5219e-04 - val_loss: 1.5970e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4190e-04 - val_loss: 1.5328e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3186e-04 - val_loss: 1.4723e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2223e-04 - val_loss: 1.4167e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1310e-04 - val_loss: 1.3666e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0451e-04 - val_loss: 1.3223e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9646e-04 - val_loss: 1.2835e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8894e-04 - val_loss: 1.2497e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8189e-04 - val_loss: 1.2202e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7523e-04 - val_loss: 1.1943e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6888e-04 - val_loss: 1.1711e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6276e-04 - val_loss: 1.1497e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5680e-04 - val_loss: 1.1297e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5093e-04 - val_loss: 1.1103e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4512e-04 - val_loss: 1.0913e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3932e-04 - val_loss: 1.0725e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3353e-04 - val_loss: 1.0533e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2775e-04 - val_loss: 1.0343e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2199e-04 - val_loss: 1.0152e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1626e-04 - val_loss: 9.9635e-05\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1060e-04 - val_loss: 9.7766e-05\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0500e-04 - val_loss: 9.5940e-05\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9951e-04 - val_loss: 9.4169e-05\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9415e-04 - val_loss: 9.2457e-05\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8889e-04 - val_loss: 9.0803e-05\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8379e-04 - val_loss: 8.9220e-05\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7882e-04 - val_loss: 8.7698e-05\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7398e-04 - val_loss: 8.6232e-05\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6927e-04 - val_loss: 8.4818e-05\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6468e-04 - val_loss: 8.3449e-05\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6019e-04 - val_loss: 8.2113e-05\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5580e-04 - val_loss: 8.0807e-05\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5150e-04 - val_loss: 7.9520e-05\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4726e-04 - val_loss: 7.8255e-05\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4310e-04 - val_loss: 7.7007e-05\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3900e-04 - val_loss: 7.5781e-05\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3496e-04 - val_loss: 7.4565e-05\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3096e-04 - val_loss: 7.3371e-05\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2704e-04 - val_loss: 7.2196e-05\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2317e-04 - val_loss: 7.1039e-05\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1936e-04 - val_loss: 6.9918e-05\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1561e-04 - val_loss: 6.8818e-05\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1191e-04 - val_loss: 6.7757e-05\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0829e-04 - val_loss: 6.6715e-05\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0473e-04 - val_loss: 6.5710e-05\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0123e-04 - val_loss: 6.4736e-05\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9779e-04 - val_loss: 6.3786e-05\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9442e-04 - val_loss: 6.2862e-05\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9111e-04 - val_loss: 6.1965e-05\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8785e-04 - val_loss: 6.1082e-05\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8465e-04 - val_loss: 6.0225e-05\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8151e-04 - val_loss: 5.9382e-05\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7841e-04 - val_loss: 5.8549e-05\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7537e-04 - val_loss: 5.7729e-05\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7238e-04 - val_loss: 5.6923e-05\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6944e-04 - val_loss: 5.6122e-05\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6653e-04 - val_loss: 5.5333e-05\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6368e-04 - val_loss: 5.4553e-05\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6086e-04 - val_loss: 5.3778e-05\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 2.5810e-04 - val_loss: 5.3013e-05\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.5537e-04 - val_loss: 5.2257e-05\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5269e-04 - val_loss: 5.1508e-05\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5004e-04 - val_loss: 5.0777e-05\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4744e-04 - val_loss: 5.0049e-05\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4488e-04 - val_loss: 4.9342e-05\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4236e-04 - val_loss: 4.8642e-05\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.3988e-04 - val_loss: 4.7959e-05\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3744e-04 - val_loss: 4.7284e-05\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3503e-04 - val_loss: 4.6626e-05\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3266e-04 - val_loss: 4.5983e-05\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3034e-04 - val_loss: 4.5356e-05\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2804e-04 - val_loss: 4.4739e-05\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2578e-04 - val_loss: 4.4142e-05\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2355e-04 - val_loss: 4.3556e-05\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.2136e-04 - val_loss: 4.2989e-05\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1920e-04 - val_loss: 4.2437e-05\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1707e-04 - val_loss: 4.1894e-05\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1497e-04 - val_loss: 4.1371e-05\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1290e-04 - val_loss: 4.0856e-05\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1087e-04 - val_loss: 4.0357e-05\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0886e-04 - val_loss: 3.9873e-05\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0689e-04 - val_loss: 3.9403e-05\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0494e-04 - val_loss: 3.8941e-05\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0301e-04 - val_loss: 3.8496e-05\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0113e-04 - val_loss: 3.8056e-05\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 1.9926e-04 - val_loss: 3.7628e-05\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9742e-04 - val_loss: 3.7212e-05\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9561e-04 - val_loss: 3.6803e-05\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9383e-04 - val_loss: 3.6400e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9207e-04 - val_loss: 3.6011e-05\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9033e-04 - val_loss: 3.5626e-05\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8862e-04 - val_loss: 3.5251e-05\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8694e-04 - val_loss: 3.4878e-05\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8528e-04 - val_loss: 3.4517e-05\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8364e-04 - val_loss: 3.4162e-05\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8203e-04 - val_loss: 3.3812e-05\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8043e-04 - val_loss: 3.3471e-05\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7886e-04 - val_loss: 3.3133e-05\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7731e-04 - val_loss: 3.2801e-05\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7579e-04 - val_loss: 3.2477e-05\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7428e-04 - val_loss: 3.2161e-05\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 1.7279e-04 - val_loss: 3.1849e-05\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7133e-04 - val_loss: 3.1547e-05\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6989e-04 - val_loss: 3.1244e-05\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6847e-04 - val_loss: 3.0956e-05\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6706e-04 - val_loss: 3.0670e-05\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 1.6567e-04 - val_loss: 3.0392e-05\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6431e-04 - val_loss: 3.0120e-05\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6296e-04 - val_loss: 2.9855e-05\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6163e-04 - val_loss: 2.9600e-05\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6032e-04 - val_loss: 2.9346e-05\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5903e-04 - val_loss: 2.9106e-05\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5775e-04 - val_loss: 2.8865e-05\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5649e-04 - val_loss: 2.8630e-05\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5525e-04 - val_loss: 2.8412e-05\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5402e-04 - val_loss: 2.8190e-05\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5281e-04 - val_loss: 2.7981e-05\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5162e-04 - val_loss: 2.7772e-05\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5044e-04 - val_loss: 2.7574e-05\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 111us/step - loss: 1.4928e-04 - val_loss: 2.7379e-05\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4813e-04 - val_loss: 2.7193e-05\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4700e-04 - val_loss: 2.7008e-05\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4589e-04 - val_loss: 2.6831e-05\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4479e-04 - val_loss: 2.6656e-05\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4370e-04 - val_loss: 2.6489e-05\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4263e-04 - val_loss: 2.6326e-05\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4157e-04 - val_loss: 2.6162e-05\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4052e-04 - val_loss: 2.6013e-05\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3949e-04 - val_loss: 2.5861e-05\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3847e-04 - val_loss: 2.5712e-05\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3747e-04 - val_loss: 2.5570e-05\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3648e-04 - val_loss: 2.5430e-05\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3550e-04 - val_loss: 2.5295e-05\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3453e-04 - val_loss: 2.5161e-05\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3357e-04 - val_loss: 2.5033e-05\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3263e-04 - val_loss: 2.4910e-05\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3170e-04 - val_loss: 2.4785e-05\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3079e-04 - val_loss: 2.4666e-05\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2988e-04 - val_loss: 2.4551e-05\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2898e-04 - val_loss: 2.4437e-05\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2810e-04 - val_loss: 2.4329e-05\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2723e-04 - val_loss: 2.4225e-05\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2637e-04 - val_loss: 2.4121e-05\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2552e-04 - val_loss: 2.4021e-05\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2468e-04 - val_loss: 2.3924e-05\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2385e-04 - val_loss: 2.3831e-05\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2303e-04 - val_loss: 2.3742e-05\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2222e-04 - val_loss: 2.3653e-05\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2142e-04 - val_loss: 2.3569e-05\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 1.2064e-04 - val_loss: 2.3487e-05\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1986e-04 - val_loss: 2.3406e-05\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1909e-04 - val_loss: 2.3333e-05\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1833e-04 - val_loss: 2.3258e-05\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1758e-04 - val_loss: 2.3184e-05\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1684e-04 - val_loss: 2.3119e-05\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1611e-04 - val_loss: 2.3052e-05\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1538e-04 - val_loss: 2.2988e-05\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1467e-04 - val_loss: 2.2929e-05\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1396e-04 - val_loss: 2.2872e-05\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1327e-04 - val_loss: 2.2816e-05\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1258e-04 - val_loss: 2.2761e-05\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1190e-04 - val_loss: 2.2710e-05\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1123e-04 - val_loss: 2.2660e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1056e-04 - val_loss: 2.2614e-05\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0991e-04 - val_loss: 2.2569e-05\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0926e-04 - val_loss: 2.2526e-05\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0862e-04 - val_loss: 2.2485e-05\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0799e-04 - val_loss: 2.2445e-05\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0736e-04 - val_loss: 2.2410e-05\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0675e-04 - val_loss: 2.2372e-05\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0614e-04 - val_loss: 2.2337e-05\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0554e-04 - val_loss: 2.2308e-05\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0494e-04 - val_loss: 2.2274e-05\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0435e-04 - val_loss: 2.2246e-05\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 1.0377e-04 - val_loss: 2.2216e-05\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.0320e-04 - val_loss: 2.2193e-05\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0264e-04 - val_loss: 2.2166e-05\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0208e-04 - val_loss: 2.2145e-05\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0152e-04 - val_loss: 2.2122e-05\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 1.0097e-04 - val_loss: 2.2104e-05\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0043e-04 - val_loss: 2.2085e-05\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9899e-05 - val_loss: 2.2067e-05\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9370e-05 - val_loss: 2.2050e-05\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8847e-05 - val_loss: 2.2036e-05\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8331e-05 - val_loss: 2.2023e-05\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7822e-05 - val_loss: 2.2013e-05\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7317e-05 - val_loss: 2.2000e-05\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6817e-05 - val_loss: 2.1991e-05\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6327e-05 - val_loss: 2.1984e-05\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5838e-05 - val_loss: 2.1976e-05\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5358e-05 - val_loss: 2.1970e-05\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4883e-05 - val_loss: 2.1963e-05\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4409e-05 - val_loss: 2.1959e-05\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3951e-05 - val_loss: 2.1957e-05\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3490e-05 - val_loss: 2.1953e-05\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3032e-05 - val_loss: 2.1953e-05\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2584e-05 - val_loss: 2.1952e-05\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2137e-05 - val_loss: 2.1950e-05\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.1697e-05 - val_loss: 2.1957e-05\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1265e-05 - val_loss: 2.1961e-05\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0841e-05 - val_loss: 2.1962e-05\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0413e-05 - val_loss: 2.1968e-05\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9995e-05 - val_loss: 2.1973e-05\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9580e-05 - val_loss: 2.1976e-05\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9168e-05 - val_loss: 2.1985e-05\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8763e-05 - val_loss: 2.1994e-05\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.8366e-05 - val_loss: 2.2000e-05\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7967e-05 - val_loss: 2.2009e-05\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7572e-05 - val_loss: 2.2018e-05\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7187e-05 - val_loss: 2.2029e-05\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 8.6802e-05 - val_loss: 2.2039e-05\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6424e-05 - val_loss: 2.2051e-05\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6049e-05 - val_loss: 2.2064e-05\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5680e-05 - val_loss: 2.2078e-05\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5312e-05 - val_loss: 2.2092e-05\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4948e-05 - val_loss: 2.2106e-05\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4590e-05 - val_loss: 2.2119e-05\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4235e-05 - val_loss: 2.2135e-05\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3884e-05 - val_loss: 2.2149e-05\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3540e-05 - val_loss: 2.2166e-05\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3195e-05 - val_loss: 2.2183e-05\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2854e-05 - val_loss: 2.2199e-05\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2520e-05 - val_loss: 2.2215e-05\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2188e-05 - val_loss: 2.2234e-05\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1858e-05 - val_loss: 2.2254e-05\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1534e-05 - val_loss: 2.2273e-05\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1213e-05 - val_loss: 2.2290e-05\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0895e-05 - val_loss: 2.2313e-05\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0578e-05 - val_loss: 2.2333e-05\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0267e-05 - val_loss: 2.2354e-05\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9959e-05 - val_loss: 2.2370e-05\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9652e-05 - val_loss: 2.2392e-05\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9352e-05 - val_loss: 2.2415e-05\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9054e-05 - val_loss: 2.2435e-05\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8760e-05 - val_loss: 2.2455e-05\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8468e-05 - val_loss: 2.2477e-05\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8178e-05 - val_loss: 2.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7890e-05 - val_loss: 2.2519e-05\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7608e-05 - val_loss: 2.2542e-05\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7330e-05 - val_loss: 2.2566e-05\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7052e-05 - val_loss: 2.2587e-05\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6777e-05 - val_loss: 2.2610e-05\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6506e-05 - val_loss: 2.2635e-05\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6238e-05 - val_loss: 2.2656e-05\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5973e-05 - val_loss: 2.2680e-05\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5708e-05 - val_loss: 2.2706e-05\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5452e-05 - val_loss: 2.2731e-05\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5194e-05 - val_loss: 2.2752e-05\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4934e-05 - val_loss: 2.2777e-05\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4685e-05 - val_loss: 2.2800e-05\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4436e-05 - val_loss: 2.2825e-05\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4187e-05 - val_loss: 2.2853e-05\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3942e-05 - val_loss: 2.2877e-05\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3703e-05 - val_loss: 2.2902e-05\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3462e-05 - val_loss: 2.2924e-05\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.3221e-05 - val_loss: 2.2952e-05\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2988e-05 - val_loss: 2.2976e-05\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2753e-05 - val_loss: 2.3002e-05\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2526e-05 - val_loss: 2.3027e-05\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2297e-05 - val_loss: 2.3054e-05\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2073e-05 - val_loss: 2.3078e-05\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1849e-05 - val_loss: 2.3109e-05\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1628e-05 - val_loss: 2.3128e-05\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1406e-05 - val_loss: 2.3155e-05\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1189e-05 - val_loss: 2.3180e-05\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0977e-05 - val_loss: 2.3206e-05\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0765e-05 - val_loss: 2.3232e-05\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.0555e-05 - val_loss: 2.3258e-05\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0345e-05 - val_loss: 2.3278e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0138e-05 - val_loss: 2.3306e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9931e-05 - val_loss: 2.3329e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9734e-05 - val_loss: 2.3352e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9531e-05 - val_loss: 2.3379e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9333e-05 - val_loss: 2.3400e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9134e-05 - val_loss: 2.3427e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8940e-05 - val_loss: 2.3450e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8751e-05 - val_loss: 2.3473e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8559e-05 - val_loss: 2.3498e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8370e-05 - val_loss: 2.3520e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8180e-05 - val_loss: 2.3544e-05\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7996e-05 - val_loss: 2.3571e-05\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7810e-05 - val_loss: 2.3591e-05\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7629e-05 - val_loss: 2.3615e-05\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7450e-05 - val_loss: 2.3641e-05\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7269e-05 - val_loss: 2.3661e-05\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7094e-05 - val_loss: 2.3687e-05\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6917e-05 - val_loss: 2.3712e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6743e-05 - val_loss: 2.3736e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6571e-05 - val_loss: 2.3759e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6400e-05 - val_loss: 2.3781e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6235e-05 - val_loss: 2.3805e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6064e-05 - val_loss: 2.3830e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5899e-05 - val_loss: 2.3852e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5736e-05 - val_loss: 2.3877e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5571e-05 - val_loss: 2.3897e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5408e-05 - val_loss: 2.3926e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5250e-05 - val_loss: 2.3944e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5088e-05 - val_loss: 2.3969e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4933e-05 - val_loss: 2.3990e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4779e-05 - val_loss: 2.4010e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4626e-05 - val_loss: 2.4034e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4473e-05 - val_loss: 2.4053e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4322e-05 - val_loss: 2.4073e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4170e-05 - val_loss: 2.4095e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4019e-05 - val_loss: 2.4115e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3873e-05 - val_loss: 2.4134e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3729e-05 - val_loss: 2.4156e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3582e-05 - val_loss: 2.4174e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3440e-05 - val_loss: 2.4193e-05\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3296e-05 - val_loss: 2.4211e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3157e-05 - val_loss: 2.4234e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3014e-05 - val_loss: 2.4251e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2879e-05 - val_loss: 2.4268e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2740e-05 - val_loss: 2.4288e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2604e-05 - val_loss: 2.4305e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2467e-05 - val_loss: 2.4323e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2336e-05 - val_loss: 2.4341e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2202e-05 - val_loss: 2.4361e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2071e-05 - val_loss: 2.4377e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1939e-05 - val_loss: 2.4393e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1810e-05 - val_loss: 2.4410e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1682e-05 - val_loss: 2.4426e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1551e-05 - val_loss: 2.4443e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1428e-05 - val_loss: 2.4463e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1301e-05 - val_loss: 2.4478e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1178e-05 - val_loss: 2.4496e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1055e-05 - val_loss: 2.4511e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0929e-05 - val_loss: 2.4528e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0811e-05 - val_loss: 2.4546e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0690e-05 - val_loss: 2.4562e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0573e-05 - val_loss: 2.4575e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0453e-05 - val_loss: 2.4593e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0335e-05 - val_loss: 2.4609e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0220e-05 - val_loss: 2.4622e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 6.0104e-05 - val_loss: 2.4634e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9989e-05 - val_loss: 2.4651e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9879e-05 - val_loss: 2.4665e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9764e-05 - val_loss: 2.4677e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9651e-05 - val_loss: 2.4693e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9540e-05 - val_loss: 2.4708e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9430e-05 - val_loss: 2.4723e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9322e-05 - val_loss: 2.4733e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9213e-05 - val_loss: 2.4746e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9106e-05 - val_loss: 2.4758e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8999e-05 - val_loss: 2.4771e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.8894e-05 - val_loss: 2.4784e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8788e-05 - val_loss: 2.4796e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8685e-05 - val_loss: 2.4807e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8581e-05 - val_loss: 2.4816e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8476e-05 - val_loss: 2.4831e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8375e-05 - val_loss: 2.4838e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8275e-05 - val_loss: 2.4853e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8175e-05 - val_loss: 2.4861e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8077e-05 - val_loss: 2.4869e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7976e-05 - val_loss: 2.4879e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7876e-05 - val_loss: 2.4886e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7781e-05 - val_loss: 2.4897e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7685e-05 - val_loss: 2.4904e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7587e-05 - val_loss: 2.4910e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7493e-05 - val_loss: 2.4922e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7399e-05 - val_loss: 2.4928e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7303e-05 - val_loss: 2.4936e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7212e-05 - val_loss: 2.4942e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7118e-05 - val_loss: 2.4952e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7026e-05 - val_loss: 2.4959e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6932e-05 - val_loss: 2.4964e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6845e-05 - val_loss: 2.4967e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6751e-05 - val_loss: 2.4976e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6662e-05 - val_loss: 2.4985e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6575e-05 - val_loss: 2.4989e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6490e-05 - val_loss: 2.4994e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6404e-05 - val_loss: 2.5001e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6314e-05 - val_loss: 2.5006e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6226e-05 - val_loss: 2.5012e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6143e-05 - val_loss: 2.5015e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6057e-05 - val_loss: 2.5020e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5973e-05 - val_loss: 2.5023e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5885e-05 - val_loss: 2.5029e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5805e-05 - val_loss: 2.5031e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5723e-05 - val_loss: 2.5035e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.5637e-05 - val_loss: 2.5041e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5558e-05 - val_loss: 2.5043e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5477e-05 - val_loss: 2.5048e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5395e-05 - val_loss: 2.5050e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5314e-05 - val_loss: 2.5052e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5235e-05 - val_loss: 2.5057e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5155e-05 - val_loss: 2.5059e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5075e-05 - val_loss: 2.5062e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5001e-05 - val_loss: 2.5062e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4920e-05 - val_loss: 2.5064e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4845e-05 - val_loss: 2.5068e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4768e-05 - val_loss: 2.5068e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4689e-05 - val_loss: 2.5067e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4615e-05 - val_loss: 2.5068e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.4541e-05 - val_loss: 2.5068e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4463e-05 - val_loss: 2.5071e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4391e-05 - val_loss: 2.5067e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4315e-05 - val_loss: 2.5069e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4243e-05 - val_loss: 2.5066e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4171e-05 - val_loss: 2.5067e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4094e-05 - val_loss: 2.5068e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4026e-05 - val_loss: 2.5063e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.3955e-05 - val_loss: 2.5061e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3883e-05 - val_loss: 2.5061e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3811e-05 - val_loss: 2.5062e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3741e-05 - val_loss: 2.5060e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3670e-05 - val_loss: 2.5057e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3601e-05 - val_loss: 2.5057e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3531e-05 - val_loss: 2.5055e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3463e-05 - val_loss: 2.5052e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.3396e-05 - val_loss: 2.5049e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3326e-05 - val_loss: 2.5047e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.3259e-05 - val_loss: 2.5045e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3191e-05 - val_loss: 2.5042e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3124e-05 - val_loss: 2.5039e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3060e-05 - val_loss: 2.5036e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2993e-05 - val_loss: 2.5033e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2926e-05 - val_loss: 2.5025e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2860e-05 - val_loss: 2.5021e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2795e-05 - val_loss: 2.5013e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2731e-05 - val_loss: 2.5009e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2667e-05 - val_loss: 2.5003e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2603e-05 - val_loss: 2.4998e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2538e-05 - val_loss: 2.4996e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2476e-05 - val_loss: 2.4987e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2410e-05 - val_loss: 2.4982e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.2348e-05 - val_loss: 2.4973e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2285e-05 - val_loss: 2.4967e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2224e-05 - val_loss: 2.4963e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2164e-05 - val_loss: 2.4956e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2100e-05 - val_loss: 2.4950e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2039e-05 - val_loss: 2.4937e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1980e-05 - val_loss: 2.4934e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1916e-05 - val_loss: 2.4924e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1857e-05 - val_loss: 2.4916e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1800e-05 - val_loss: 2.4910e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1739e-05 - val_loss: 2.4904e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1682e-05 - val_loss: 2.4891e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1620e-05 - val_loss: 2.4885e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1561e-05 - val_loss: 2.4875e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1503e-05 - val_loss: 2.4865e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1444e-05 - val_loss: 2.4856e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1387e-05 - val_loss: 2.4851e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1331e-05 - val_loss: 2.4840e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1272e-05 - val_loss: 2.4833e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1215e-05 - val_loss: 2.4820e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1159e-05 - val_loss: 2.4810e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1100e-05 - val_loss: 2.4800e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1045e-05 - val_loss: 2.4790e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0989e-05 - val_loss: 2.4782e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0932e-05 - val_loss: 2.4772e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0879e-05 - val_loss: 2.4761e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0820e-05 - val_loss: 2.4748e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0766e-05 - val_loss: 2.4737e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0711e-05 - val_loss: 2.4726e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0657e-05 - val_loss: 2.4714e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.0605e-05 - val_loss: 2.4701e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0548e-05 - val_loss: 2.4691e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0496e-05 - val_loss: 2.4681e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0441e-05 - val_loss: 2.4665e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0387e-05 - val_loss: 2.4656e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0333e-05 - val_loss: 2.4645e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0282e-05 - val_loss: 2.4633e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0228e-05 - val_loss: 2.4619e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0178e-05 - val_loss: 2.4606e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0123e-05 - val_loss: 2.4596e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 5.0071e-05 - val_loss: 2.4584e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0020e-05 - val_loss: 2.4569e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9968e-05 - val_loss: 2.4554e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9916e-05 - val_loss: 2.4544e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9865e-05 - val_loss: 2.4528e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9814e-05 - val_loss: 2.4515e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9763e-05 - val_loss: 2.4503e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9713e-05 - val_loss: 2.4490e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9663e-05 - val_loss: 2.4474e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9611e-05 - val_loss: 2.4461e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9563e-05 - val_loss: 2.4448e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9512e-05 - val_loss: 2.4432e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9462e-05 - val_loss: 2.4416e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9411e-05 - val_loss: 2.4405e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9360e-05 - val_loss: 2.4386e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9313e-05 - val_loss: 2.4374e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9266e-05 - val_loss: 2.4357e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9216e-05 - val_loss: 2.4343e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 4.9168e-05 - val_loss: 2.4330e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9120e-05 - val_loss: 2.4310e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9070e-05 - val_loss: 2.4297e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9024e-05 - val_loss: 2.4281e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8976e-05 - val_loss: 2.4266e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8926e-05 - val_loss: 2.4249e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8880e-05 - val_loss: 2.4232e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8833e-05 - val_loss: 2.4216e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8785e-05 - val_loss: 2.4203e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8739e-05 - val_loss: 2.4183e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8690e-05 - val_loss: 2.4170e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8646e-05 - val_loss: 2.4154e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8600e-05 - val_loss: 2.4135e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8551e-05 - val_loss: 2.4122e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8507e-05 - val_loss: 2.4102e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8461e-05 - val_loss: 2.4088e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8414e-05 - val_loss: 2.4066e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8368e-05 - val_loss: 2.4052e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8323e-05 - val_loss: 2.4032e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8277e-05 - val_loss: 2.4019e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8233e-05 - val_loss: 2.3997e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8185e-05 - val_loss: 2.3981e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8142e-05 - val_loss: 2.3963e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8097e-05 - val_loss: 2.3947e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8052e-05 - val_loss: 2.3928e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8007e-05 - val_loss: 2.3911e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7962e-05 - val_loss: 2.3891e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7919e-05 - val_loss: 2.3875e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7875e-05 - val_loss: 2.3855e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7831e-05 - val_loss: 2.3838e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7786e-05 - val_loss: 2.3818e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7741e-05 - val_loss: 2.3801e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7699e-05 - val_loss: 2.3778e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7657e-05 - val_loss: 2.3761e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7611e-05 - val_loss: 2.3742e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7568e-05 - val_loss: 2.3721e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7526e-05 - val_loss: 2.3700e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7481e-05 - val_loss: 2.3685e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7439e-05 - val_loss: 2.3664e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.7395e-05 - val_loss: 2.3646e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7354e-05 - val_loss: 2.3628e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7312e-05 - val_loss: 2.3606e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7270e-05 - val_loss: 2.3586e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7227e-05 - val_loss: 2.3568e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7184e-05 - val_loss: 2.3548e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7141e-05 - val_loss: 2.3528e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7100e-05 - val_loss: 2.3507e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7059e-05 - val_loss: 2.3488e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7017e-05 - val_loss: 2.3467e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6975e-05 - val_loss: 2.3447e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6934e-05 - val_loss: 2.3426e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6893e-05 - val_loss: 2.3404e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6850e-05 - val_loss: 2.3386e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6808e-05 - val_loss: 2.3366e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6767e-05 - val_loss: 2.3342e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6728e-05 - val_loss: 2.3322e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6686e-05 - val_loss: 2.3302e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6647e-05 - val_loss: 2.3282e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6604e-05 - val_loss: 2.3263e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6566e-05 - val_loss: 2.3240e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6525e-05 - val_loss: 2.3220e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6485e-05 - val_loss: 2.3196e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6441e-05 - val_loss: 2.3174e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6402e-05 - val_loss: 2.3151e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6363e-05 - val_loss: 2.3136e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6324e-05 - val_loss: 2.3112e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6282e-05 - val_loss: 2.3086e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6243e-05 - val_loss: 2.3067e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6203e-05 - val_loss: 2.3048e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6164e-05 - val_loss: 2.3026e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6125e-05 - val_loss: 2.3002e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6085e-05 - val_loss: 2.2982e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6045e-05 - val_loss: 2.2961e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6008e-05 - val_loss: 2.2939e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5966e-05 - val_loss: 2.2918e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5929e-05 - val_loss: 2.2893e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5890e-05 - val_loss: 2.2872e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5850e-05 - val_loss: 2.2850e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5813e-05 - val_loss: 2.2827e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5773e-05 - val_loss: 2.2805e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5734e-05 - val_loss: 2.2779e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5697e-05 - val_loss: 2.2761e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.5658e-05 - val_loss: 2.2736e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5618e-05 - val_loss: 2.2715e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5581e-05 - val_loss: 2.2690e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5541e-05 - val_loss: 2.2669e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5505e-05 - val_loss: 2.2647e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5467e-05 - val_loss: 2.2626e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5429e-05 - val_loss: 2.2601e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5392e-05 - val_loss: 2.2583e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5353e-05 - val_loss: 2.2557e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5314e-05 - val_loss: 2.2532e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5279e-05 - val_loss: 2.2510e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5240e-05 - val_loss: 2.2486e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5201e-05 - val_loss: 2.2467e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5168e-05 - val_loss: 2.2442e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5129e-05 - val_loss: 2.2418e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5091e-05 - val_loss: 2.2398e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5054e-05 - val_loss: 2.2371e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5017e-05 - val_loss: 2.2351e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4979e-05 - val_loss: 2.2325e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4942e-05 - val_loss: 2.2303e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4904e-05 - val_loss: 2.2279e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4870e-05 - val_loss: 2.2256e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4833e-05 - val_loss: 2.2231e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4796e-05 - val_loss: 2.2208e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4757e-05 - val_loss: 2.2187e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4722e-05 - val_loss: 2.2165e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4687e-05 - val_loss: 2.2143e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4648e-05 - val_loss: 2.2117e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.4614e-05 - val_loss: 2.2094e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4579e-05 - val_loss: 2.2071e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4541e-05 - val_loss: 2.2046e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4505e-05 - val_loss: 2.2022e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4468e-05 - val_loss: 2.1997e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.4431e-05 - val_loss: 2.1974e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4397e-05 - val_loss: 2.1953e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4361e-05 - val_loss: 2.1927e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4326e-05 - val_loss: 2.1903e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4291e-05 - val_loss: 2.1879e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.4254e-05 - val_loss: 2.1853e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4216e-05 - val_loss: 2.1827e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4182e-05 - val_loss: 2.1808e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4146e-05 - val_loss: 2.1784e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4111e-05 - val_loss: 2.1763e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4076e-05 - val_loss: 2.1739e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4040e-05 - val_loss: 2.1716e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4005e-05 - val_loss: 2.1692e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3970e-05 - val_loss: 2.1666e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3937e-05 - val_loss: 2.1641e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3900e-05 - val_loss: 2.1618e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3865e-05 - val_loss: 2.1595e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3831e-05 - val_loss: 2.1570e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3796e-05 - val_loss: 2.1549e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3758e-05 - val_loss: 2.1523e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3725e-05 - val_loss: 2.1497e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3691e-05 - val_loss: 2.1472e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3655e-05 - val_loss: 2.1447e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3622e-05 - val_loss: 2.1424e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3587e-05 - val_loss: 2.1401e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3552e-05 - val_loss: 2.1379e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3518e-05 - val_loss: 2.1353e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3483e-05 - val_loss: 2.1331e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3449e-05 - val_loss: 2.1304e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3415e-05 - val_loss: 2.1280e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3381e-05 - val_loss: 2.1253e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3346e-05 - val_loss: 2.1231e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3312e-05 - val_loss: 2.1207e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3278e-05 - val_loss: 2.1185e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3245e-05 - val_loss: 2.1159e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3211e-05 - val_loss: 2.1134e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3177e-05 - val_loss: 2.1111e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3143e-05 - val_loss: 2.1086e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3107e-05 - val_loss: 2.1064e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3077e-05 - val_loss: 2.1037e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3042e-05 - val_loss: 2.1011e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3006e-05 - val_loss: 2.0989e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2974e-05 - val_loss: 2.0965e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2940e-05 - val_loss: 2.0941e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2906e-05 - val_loss: 2.0915e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2871e-05 - val_loss: 2.0891e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2839e-05 - val_loss: 2.0865e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2805e-05 - val_loss: 2.0844e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2774e-05 - val_loss: 2.0818e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2739e-05 - val_loss: 2.0794e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2707e-05 - val_loss: 2.0771e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2673e-05 - val_loss: 2.0746e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2640e-05 - val_loss: 2.0724e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2608e-05 - val_loss: 2.0698e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2575e-05 - val_loss: 2.0673e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.2541e-05 - val_loss: 2.0647e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2509e-05 - val_loss: 2.0623e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2474e-05 - val_loss: 2.0599e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2443e-05 - val_loss: 2.0574e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2408e-05 - val_loss: 2.0551e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2377e-05 - val_loss: 2.0526e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2343e-05 - val_loss: 2.0502e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2310e-05 - val_loss: 2.0475e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2277e-05 - val_loss: 2.0451e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2244e-05 - val_loss: 2.0428e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2212e-05 - val_loss: 2.0404e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2181e-05 - val_loss: 2.0382e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2149e-05 - val_loss: 2.0355e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2117e-05 - val_loss: 2.0332e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2082e-05 - val_loss: 2.0308e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2050e-05 - val_loss: 2.0281e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2018e-05 - val_loss: 2.0258e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1985e-05 - val_loss: 2.0234e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1954e-05 - val_loss: 2.0210e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1921e-05 - val_loss: 2.0184e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1890e-05 - val_loss: 2.0162e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1857e-05 - val_loss: 2.0136e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1825e-05 - val_loss: 2.0111e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1793e-05 - val_loss: 2.0087e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1760e-05 - val_loss: 2.0062e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1727e-05 - val_loss: 2.0039e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1697e-05 - val_loss: 2.0014e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1665e-05 - val_loss: 1.9991e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1633e-05 - val_loss: 1.9965e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1601e-05 - val_loss: 1.9944e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1569e-05 - val_loss: 1.9918e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1538e-05 - val_loss: 1.9896e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1506e-05 - val_loss: 1.9870e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1474e-05 - val_loss: 1.9846e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1443e-05 - val_loss: 1.9820e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1410e-05 - val_loss: 1.9795e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1381e-05 - val_loss: 1.9775e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1350e-05 - val_loss: 1.9749e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1317e-05 - val_loss: 1.9725e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1286e-05 - val_loss: 1.9701e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1256e-05 - val_loss: 1.9679e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1222e-05 - val_loss: 1.9654e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1190e-05 - val_loss: 1.9629e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1160e-05 - val_loss: 1.9606e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1130e-05 - val_loss: 1.9583e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1099e-05 - val_loss: 1.9555e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1066e-05 - val_loss: 1.9535e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1036e-05 - val_loss: 1.9509e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1002e-05 - val_loss: 1.9486e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0975e-05 - val_loss: 1.9461e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.0943e-05 - val_loss: 1.9436e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0911e-05 - val_loss: 1.9415e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0880e-05 - val_loss: 1.9390e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0850e-05 - val_loss: 1.9365e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0819e-05 - val_loss: 1.9339e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0787e-05 - val_loss: 1.9318e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0755e-05 - val_loss: 1.9293e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0726e-05 - val_loss: 1.9270e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0697e-05 - val_loss: 1.9250e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0666e-05 - val_loss: 1.9224e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0634e-05 - val_loss: 1.9202e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0603e-05 - val_loss: 1.9178e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0572e-05 - val_loss: 1.9151e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0542e-05 - val_loss: 1.9130e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0511e-05 - val_loss: 1.9106e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0481e-05 - val_loss: 1.9081e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0450e-05 - val_loss: 1.9059e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0421e-05 - val_loss: 1.9037e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0390e-05 - val_loss: 1.9009e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0359e-05 - val_loss: 1.8988e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0329e-05 - val_loss: 1.8964e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0298e-05 - val_loss: 1.8938e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0267e-05 - val_loss: 1.8917e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0237e-05 - val_loss: 1.8893e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0208e-05 - val_loss: 1.8870e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0176e-05 - val_loss: 1.8847e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0145e-05 - val_loss: 1.8826e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0119e-05 - val_loss: 1.8799e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0085e-05 - val_loss: 1.8775e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0057e-05 - val_loss: 1.8751e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0027e-05 - val_loss: 1.8729e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9996e-05 - val_loss: 1.8708e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9967e-05 - val_loss: 1.8685e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9936e-05 - val_loss: 1.8664e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9906e-05 - val_loss: 1.8638e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9877e-05 - val_loss: 1.8612e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9846e-05 - val_loss: 1.8589e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9817e-05 - val_loss: 1.8567e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9789e-05 - val_loss: 1.8544e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9758e-05 - val_loss: 1.8522e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9728e-05 - val_loss: 1.8498e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9698e-05 - val_loss: 1.8475e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9669e-05 - val_loss: 1.8454e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9639e-05 - val_loss: 1.8429e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9611e-05 - val_loss: 1.8404e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9580e-05 - val_loss: 1.8382e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9548e-05 - val_loss: 1.8361e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9520e-05 - val_loss: 1.8340e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9492e-05 - val_loss: 1.8315e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9463e-05 - val_loss: 1.8291e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 3.9434e-05 - val_loss: 1.8271e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9404e-05 - val_loss: 1.8245e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9372e-05 - val_loss: 1.8225e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9344e-05 - val_loss: 1.8200e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9315e-05 - val_loss: 1.8179e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9286e-05 - val_loss: 1.8157e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9256e-05 - val_loss: 1.8133e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9228e-05 - val_loss: 1.8111e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9196e-05 - val_loss: 1.8089e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9168e-05 - val_loss: 1.8066e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9139e-05 - val_loss: 1.8043e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9111e-05 - val_loss: 1.8018e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9082e-05 - val_loss: 1.7997e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9052e-05 - val_loss: 1.7975e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9022e-05 - val_loss: 1.7953e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8994e-05 - val_loss: 1.7932e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8966e-05 - val_loss: 1.7911e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8936e-05 - val_loss: 1.7890e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.8908e-05 - val_loss: 1.7862e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8879e-05 - val_loss: 1.7843e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8849e-05 - val_loss: 1.7817e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8819e-05 - val_loss: 1.7794e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8790e-05 - val_loss: 1.7773e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8763e-05 - val_loss: 1.7752e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8735e-05 - val_loss: 1.7731e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8705e-05 - val_loss: 1.7706e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8678e-05 - val_loss: 1.7686e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8648e-05 - val_loss: 1.7666e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8620e-05 - val_loss: 1.7643e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8591e-05 - val_loss: 1.7621e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8562e-05 - val_loss: 1.7599e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8532e-05 - val_loss: 1.7579e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8506e-05 - val_loss: 1.7554e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8477e-05 - val_loss: 1.7533e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8447e-05 - val_loss: 1.7510e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8420e-05 - val_loss: 1.7490e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8391e-05 - val_loss: 1.7468e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8365e-05 - val_loss: 1.7446e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8335e-05 - val_loss: 1.7423e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8304e-05 - val_loss: 1.7403e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8276e-05 - val_loss: 1.7379e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8248e-05 - val_loss: 1.7360e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8222e-05 - val_loss: 1.7338e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8194e-05 - val_loss: 1.7316e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8166e-05 - val_loss: 1.7293e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8135e-05 - val_loss: 1.7274e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8107e-05 - val_loss: 1.7251e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8080e-05 - val_loss: 1.7230e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8051e-05 - val_loss: 1.7208e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8024e-05 - val_loss: 1.7187e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7996e-05 - val_loss: 1.7165e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7968e-05 - val_loss: 1.7145e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7940e-05 - val_loss: 1.7123e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7911e-05 - val_loss: 1.7104e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7883e-05 - val_loss: 1.7079e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7856e-05 - val_loss: 1.7061e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7828e-05 - val_loss: 1.7039e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7800e-05 - val_loss: 1.7017e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7771e-05 - val_loss: 1.6996e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7746e-05 - val_loss: 1.6974e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7714e-05 - val_loss: 1.6955e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7688e-05 - val_loss: 1.6934e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7660e-05 - val_loss: 1.6910e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7631e-05 - val_loss: 1.6889e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7604e-05 - val_loss: 1.6870e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7577e-05 - val_loss: 1.6850e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7550e-05 - val_loss: 1.6827e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7520e-05 - val_loss: 1.6807e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7494e-05 - val_loss: 1.6787e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7465e-05 - val_loss: 1.6767e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7438e-05 - val_loss: 1.6744e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7410e-05 - val_loss: 1.6725e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7384e-05 - val_loss: 1.6704e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7357e-05 - val_loss: 1.6686e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7330e-05 - val_loss: 1.6664e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7301e-05 - val_loss: 1.6641e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7275e-05 - val_loss: 1.6621e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7245e-05 - val_loss: 1.6600e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7219e-05 - val_loss: 1.6582e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7192e-05 - val_loss: 1.6559e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7164e-05 - val_loss: 1.6540e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7138e-05 - val_loss: 1.6521e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7109e-05 - val_loss: 1.6501e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7084e-05 - val_loss: 1.6479e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7055e-05 - val_loss: 1.6459e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7027e-05 - val_loss: 1.6440e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7000e-05 - val_loss: 1.6419e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6973e-05 - val_loss: 1.6398e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6947e-05 - val_loss: 1.6378e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6919e-05 - val_loss: 1.6359e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6891e-05 - val_loss: 1.6341e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6865e-05 - val_loss: 1.6320e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6839e-05 - val_loss: 1.6300e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6811e-05 - val_loss: 1.6279e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6784e-05 - val_loss: 1.6261e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6757e-05 - val_loss: 1.6239e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6731e-05 - val_loss: 1.6219e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6703e-05 - val_loss: 1.6200e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6674e-05 - val_loss: 1.6178e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6647e-05 - val_loss: 1.6158e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6620e-05 - val_loss: 1.6140e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6594e-05 - val_loss: 1.6122e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6569e-05 - val_loss: 1.6100e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6541e-05 - val_loss: 1.6081e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6514e-05 - val_loss: 1.6062e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6488e-05 - val_loss: 1.6042e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6460e-05 - val_loss: 1.6021e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6433e-05 - val_loss: 1.6003e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6405e-05 - val_loss: 1.5982e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6380e-05 - val_loss: 1.5963e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6352e-05 - val_loss: 1.5944e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6327e-05 - val_loss: 1.5924e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6300e-05 - val_loss: 1.5907e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6274e-05 - val_loss: 1.5887e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6248e-05 - val_loss: 1.5868e-05\n",
      "7.079119768604869e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.6535375 , -1.3886149 , -1.1965309 ,  0.26288807, -1.4442126 ],\n",
       "        [-0.46074045,  1.8943005 ,  2.036026  ,  0.42521158,  1.7579416 ],\n",
       "        [ 0.9220285 , -1.3722011 , -1.3530482 , -0.6036215 , -1.6836631 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.13367583,  1.2217376 ,  1.1613909 , -0.9290095 ,  1.1297528 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.98176455,  1.3423132 , -0.67828274,  0.1312533 ,  0.25808567,\n",
       "         -0.31067145,  1.3317345 ,  0.69519466, -0.5983292 , -0.93270844],\n",
       "        [ 0.8551645 ,  0.7156056 , -0.48553753,  1.1200254 ,  0.32801774,\n",
       "         -0.5242196 ,  0.48911062,  1.6404837 , -1.0881591 , -1.2810957 ],\n",
       "        [ 1.1387489 ,  1.3260375 , -0.80493057,  0.84101605,  0.86357874,\n",
       "         -1.2366945 ,  1.1583375 ,  1.0931104 , -1.0199695 , -0.73325634],\n",
       "        [ 0.41396034,  1.2593446 , -0.6614718 ,  0.41990593, -0.5334636 ,\n",
       "         -1.2404528 ,  0.2839458 ,  1.2886219 , -0.66249245, -0.2529815 ],\n",
       "        [ 1.256968  ,  1.1161442 , -1.512835  ,  0.91881466,  1.1004121 ,\n",
       "         -0.8217734 ,  1.1343219 ,  0.6616639 , -0.9658332 , -0.54235095]],\n",
       "       dtype=float32),\n",
       " array([ 0.94318354,  1.159546  , -0.8490373 ,  0.96766365,  0.54514366,\n",
       "        -0.26122406,  1.0073662 ,  1.1608934 , -0.38155264, -0.6041925 ],\n",
       "       dtype=float32),\n",
       " array([[0.66537017],\n",
       "        [1.2799741 ],\n",
       "        [0.3919923 ],\n",
       "        [0.58974594],\n",
       "        [0.48498487],\n",
       "        [0.77435124],\n",
       "        [0.65886676],\n",
       "        [1.4472876 ],\n",
       "        [0.7472429 ],\n",
       "        [0.72277176]], dtype=float32),\n",
       " array([0.8734052], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_sigmoid(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sigmoid_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 37.5182 - val_loss: 30.8450\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 31.6804 - val_loss: 23.4400\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 25.1129 - val_loss: 16.5904\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 18.8611 - val_loss: 10.7259\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 13.2025 - val_loss: 6.0672\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.2891 - val_loss: 2.7543\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3788 - val_loss: 0.8037\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7115 - val_loss: 0.1555\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4266 - val_loss: 0.5683\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4501 - val_loss: 1.5608\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2812 - val_loss: 2.5310\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2300 - val_loss: 3.0664\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7997 - val_loss: 3.0726\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8558 - val_loss: 2.6566\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4841 - val_loss: 2.0039\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8678 - val_loss: 1.2922\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1896 - val_loss: 0.6682\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5992 - val_loss: 0.2318\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1951 - val_loss: 0.0243\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0168 - val_loss: 0.0299\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0455 - val_loss: 0.1863\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.2177 - val_loss: 0.4069\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4482 - val_loss: 0.6087\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6546 - val_loss: 0.7322\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7790 - val_loss: 0.7525\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7975 - val_loss: 0.6768\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7180 - val_loss: 0.5343\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5703 - val_loss: 0.3640\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.3937 - val_loss: 0.2038\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2263 - val_loss: 0.0824\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0972 - val_loss: 0.0150\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0221 - val_loss: 0.0027\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0344\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0276 - val_loss: 0.0915\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0793 - val_loss: 0.1533\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1370 - val_loss: 0.2020\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1833 - val_loss: 0.2265\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2068 - val_loss: 0.2232\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2040 - val_loss: 0.1958\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1782 - val_loss: 0.1524\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1375 - val_loss: 0.1035\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0918 - val_loss: 0.0587\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0504 - val_loss: 0.0249\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0202 - val_loss: 0.0057\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 6.6110e-04\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0189\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0322\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0392 - val_loss: 0.0424\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0501 - val_loss: 0.0469\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0549 - val_loss: 0.0452\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0529 - val_loss: 0.0382\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0453 - val_loss: 0.0281\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0343 - val_loss: 0.0174\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0225 - val_loss: 0.0084\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0026\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0050 - val_loss: 5.1606e-04\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0103\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0146\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0116 - val_loss: 0.0176\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0142 - val_loss: 0.0186\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0151 - val_loss: 0.0176\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.9347e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.6576e-04\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.2836e-04\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 8.0505e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0021 - val_loss: 5.0716e-04\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 4.5806e-04\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.5268e-04\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9259e-04 - val_loss: 0.0010\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.9062e-04\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.4479e-04\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4665e-04 - val_loss: 5.7653e-04\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2863e-04 - val_loss: 4.7880e-04\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6194e-04 - val_loss: 4.3426e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 4.2197e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.2315e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.2515e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.2291e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.1817e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.1697e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 4.2666e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8380e-04 - val_loss: 4.5294e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3102e-04 - val_loss: 4.9788e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9355e-04 - val_loss: 5.5918e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7432e-04 - val_loss: 6.3067e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7178e-04 - val_loss: 7.0368e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8097e-04 - val_loss: 7.6894e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9541e-04 - val_loss: 8.1844e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0873e-04 - val_loss: 8.4679e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1616e-04 - val_loss: 8.5203e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1530e-04 - val_loss: 8.3543e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0616e-04 - val_loss: 8.0106e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9074e-04 - val_loss: 7.5452e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7221e-04 - val_loss: 7.0196e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5389e-04 - val_loss: 6.4898e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3851e-04 - val_loss: 5.9996e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2769e-04 - val_loss: 5.5774e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2172e-04 - val_loss: 5.2361e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1981e-04 - val_loss: 4.9771e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2042e-04 - val_loss: 4.7935e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2178e-04 - val_loss: 4.6757e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2229e-04 - val_loss: 4.6133e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2092e-04 - val_loss: 4.5991e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1728e-04 - val_loss: 4.6273e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1160e-04 - val_loss: 4.6941e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0457e-04 - val_loss: 4.7956e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9710e-04 - val_loss: 4.9263e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9002e-04 - val_loss: 5.0783e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8397e-04 - val_loss: 5.2414e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7923e-04 - val_loss: 5.4030e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7575e-04 - val_loss: 5.5505e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7323e-04 - val_loss: 5.6719e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7119e-04 - val_loss: 5.7580e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.6918e-04 - val_loss: 5.8032e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6683e-04 - val_loss: 5.8057e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6392e-04 - val_loss: 5.7684e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6040e-04 - val_loss: 5.6972e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5644e-04 - val_loss: 5.6003e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5224e-04 - val_loss: 5.4866e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4805e-04 - val_loss: 5.3657e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4407e-04 - val_loss: 5.2456e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4042e-04 - val_loss: 5.1329e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3715e-04 - val_loss: 5.0328e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3420e-04 - val_loss: 4.9484e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3148e-04 - val_loss: 4.8815e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2882e-04 - val_loss: 4.8326e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2615e-04 - val_loss: 4.8011e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2337e-04 - val_loss: 4.7858e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2044e-04 - val_loss: 4.7849e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1738e-04 - val_loss: 4.7964e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1423e-04 - val_loss: 4.8177e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1107e-04 - val_loss: 4.8459e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0796e-04 - val_loss: 4.8780e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0493e-04 - val_loss: 4.9106e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0202e-04 - val_loss: 4.9411e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9922e-04 - val_loss: 4.9665e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9650e-04 - val_loss: 4.9847e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9385e-04 - val_loss: 4.9942e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9120e-04 - val_loss: 4.9943e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8856e-04 - val_loss: 4.9848e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8589e-04 - val_loss: 4.9665e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8319e-04 - val_loss: 4.9406e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8048e-04 - val_loss: 4.9088e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7777e-04 - val_loss: 4.8732e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7508e-04 - val_loss: 4.8354e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7242e-04 - val_loss: 4.7972e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6980e-04 - val_loss: 4.7605e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6723e-04 - val_loss: 4.7266e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6469e-04 - val_loss: 4.6964e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6218e-04 - val_loss: 4.6705e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5970e-04 - val_loss: 4.6492e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5721e-04 - val_loss: 4.6325e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5472e-04 - val_loss: 4.6204e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5224e-04 - val_loss: 4.6122e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4977e-04 - val_loss: 4.6073e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4731e-04 - val_loss: 4.6048e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4486e-04 - val_loss: 4.6040e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4242e-04 - val_loss: 4.6041e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4001e-04 - val_loss: 4.6040e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3762e-04 - val_loss: 4.6032e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3524e-04 - val_loss: 4.6009e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3290e-04 - val_loss: 4.5969e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3056e-04 - val_loss: 4.5905e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2824e-04 - val_loss: 4.5820e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2594e-04 - val_loss: 4.5710e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2365e-04 - val_loss: 4.5582e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2137e-04 - val_loss: 4.5436e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.1910e-04 - val_loss: 4.5277e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1685e-04 - val_loss: 4.5109e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1460e-04 - val_loss: 4.4936e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 374us/step - loss: 6.1237e-04 - val_loss: 4.4764e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.1016e-04 - val_loss: 4.4598e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0797e-04 - val_loss: 4.4437e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0580e-04 - val_loss: 4.4289e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0364e-04 - val_loss: 4.4154e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0149e-04 - val_loss: 4.4028e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9935e-04 - val_loss: 4.3916e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9724e-04 - val_loss: 4.3816e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9512e-04 - val_loss: 4.3727e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9303e-04 - val_loss: 4.3645e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9095e-04 - val_loss: 4.3569e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8887e-04 - val_loss: 4.3499e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8682e-04 - val_loss: 4.3429e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8477e-04 - val_loss: 4.3360e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8274e-04 - val_loss: 4.3288e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8073e-04 - val_loss: 4.3214e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7872e-04 - val_loss: 4.3134e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7673e-04 - val_loss: 4.3049e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7475e-04 - val_loss: 4.2959e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7279e-04 - val_loss: 4.2863e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7083e-04 - val_loss: 4.2764e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6888e-04 - val_loss: 4.2661e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6695e-04 - val_loss: 4.2554e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6503e-04 - val_loss: 4.2447e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6313e-04 - val_loss: 4.2340e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6123e-04 - val_loss: 4.2234e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.5934e-04 - val_loss: 4.2128e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.5747e-04 - val_loss: 4.2027e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.5560e-04 - val_loss: 4.1930e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.5376e-04 - val_loss: 4.1834e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.5192e-04 - val_loss: 4.1742e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.5009e-04 - val_loss: 4.1655e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4827e-04 - val_loss: 4.1569e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4646e-04 - val_loss: 4.1489e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4467e-04 - val_loss: 4.1409e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4287e-04 - val_loss: 4.1333e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.4110e-04 - val_loss: 4.1256e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3934e-04 - val_loss: 4.1180e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3758e-04 - val_loss: 4.1105e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3584e-04 - val_loss: 4.1029e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3410e-04 - val_loss: 4.0953e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3239e-04 - val_loss: 4.0874e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3066e-04 - val_loss: 4.0796e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2896e-04 - val_loss: 4.0716e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2727e-04 - val_loss: 4.0636e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2558e-04 - val_loss: 4.0556e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2391e-04 - val_loss: 4.0474e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2224e-04 - val_loss: 4.0393e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2059e-04 - val_loss: 4.0311e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1894e-04 - val_loss: 4.0230e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1730e-04 - val_loss: 4.0149e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1568e-04 - val_loss: 4.0071e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1406e-04 - val_loss: 3.9993e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1244e-04 - val_loss: 3.9915e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1085e-04 - val_loss: 3.9841e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0926e-04 - val_loss: 3.9765e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0767e-04 - val_loss: 3.9693e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0611e-04 - val_loss: 3.9621e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0453e-04 - val_loss: 3.9550e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0298e-04 - val_loss: 3.9481e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0143e-04 - val_loss: 3.9411e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9989e-04 - val_loss: 3.9341e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9836e-04 - val_loss: 3.9273e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9684e-04 - val_loss: 3.9205e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9532e-04 - val_loss: 3.9136e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9382e-04 - val_loss: 3.9068e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9232e-04 - val_loss: 3.9000e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9083e-04 - val_loss: 3.8931e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8935e-04 - val_loss: 3.8863e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8788e-04 - val_loss: 3.8796e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8641e-04 - val_loss: 3.8728e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8495e-04 - val_loss: 3.8660e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8350e-04 - val_loss: 3.8593e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8206e-04 - val_loss: 3.8527e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8063e-04 - val_loss: 3.8461e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7920e-04 - val_loss: 3.8396e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7779e-04 - val_loss: 3.8329e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7637e-04 - val_loss: 3.8264e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7497e-04 - val_loss: 3.8200e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7357e-04 - val_loss: 3.8137e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7218e-04 - val_loss: 3.8074e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7080e-04 - val_loss: 3.8011e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6942e-04 - val_loss: 3.7948e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6805e-04 - val_loss: 3.7888e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6670e-04 - val_loss: 3.7827e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6535e-04 - val_loss: 3.7766e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6400e-04 - val_loss: 3.7705e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6266e-04 - val_loss: 3.7647e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6133e-04 - val_loss: 3.7587e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6000e-04 - val_loss: 3.7529e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5868e-04 - val_loss: 3.7468e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5737e-04 - val_loss: 3.7410e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5607e-04 - val_loss: 3.7351e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5477e-04 - val_loss: 3.7293e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5348e-04 - val_loss: 3.7236e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5220e-04 - val_loss: 3.7178e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5091e-04 - val_loss: 3.7120e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4964e-04 - val_loss: 3.7062e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4837e-04 - val_loss: 3.7005e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4711e-04 - val_loss: 3.6949e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4586e-04 - val_loss: 3.6891e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4461e-04 - val_loss: 3.6836e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4337e-04 - val_loss: 3.6780e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4214e-04 - val_loss: 3.6726e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4091e-04 - val_loss: 3.6671e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3968e-04 - val_loss: 3.6617e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3847e-04 - val_loss: 3.6562e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3725e-04 - val_loss: 3.6509e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3606e-04 - val_loss: 3.6456e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3485e-04 - val_loss: 3.6403e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3367e-04 - val_loss: 3.6350e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3248e-04 - val_loss: 3.6296e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3130e-04 - val_loss: 3.6245e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3012e-04 - val_loss: 3.6194e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2895e-04 - val_loss: 3.6141e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2779e-04 - val_loss: 3.6090e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2663e-04 - val_loss: 3.6039e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2548e-04 - val_loss: 3.5988e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2433e-04 - val_loss: 3.5936e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2319e-04 - val_loss: 3.5886e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2205e-04 - val_loss: 3.5835e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2092e-04 - val_loss: 3.5786e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1980e-04 - val_loss: 3.5736e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1867e-04 - val_loss: 3.5685e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1756e-04 - val_loss: 3.5638e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1645e-04 - val_loss: 3.5588e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1534e-04 - val_loss: 3.5540e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1425e-04 - val_loss: 3.5493e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1315e-04 - val_loss: 3.5445e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1206e-04 - val_loss: 3.5395e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1098e-04 - val_loss: 3.5349e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0991e-04 - val_loss: 3.5301e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0883e-04 - val_loss: 3.5254e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0777e-04 - val_loss: 3.5207e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0670e-04 - val_loss: 3.5161e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0563e-04 - val_loss: 3.5115e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0458e-04 - val_loss: 3.5069e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0354e-04 - val_loss: 3.5022e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0249e-04 - val_loss: 3.4976e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0145e-04 - val_loss: 3.4931e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0042e-04 - val_loss: 3.4885e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9939e-04 - val_loss: 3.4839e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9836e-04 - val_loss: 3.4794e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9734e-04 - val_loss: 3.4751e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9633e-04 - val_loss: 3.4706e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9531e-04 - val_loss: 3.4662e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9431e-04 - val_loss: 3.4617e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9330e-04 - val_loss: 3.4574e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9231e-04 - val_loss: 3.4531e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9132e-04 - val_loss: 3.4487e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9033e-04 - val_loss: 3.4444e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8934e-04 - val_loss: 3.4401e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8836e-04 - val_loss: 3.4358e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8739e-04 - val_loss: 3.4316e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8642e-04 - val_loss: 3.4273e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8545e-04 - val_loss: 3.4230e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8448e-04 - val_loss: 3.4189e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8352e-04 - val_loss: 3.4147e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8258e-04 - val_loss: 3.4105e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8162e-04 - val_loss: 3.4063e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8068e-04 - val_loss: 3.4023e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7973e-04 - val_loss: 3.3982e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7880e-04 - val_loss: 3.3940e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7786e-04 - val_loss: 3.3900e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7693e-04 - val_loss: 3.3860e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7601e-04 - val_loss: 3.3819e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7509e-04 - val_loss: 3.3779e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7417e-04 - val_loss: 3.3739e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7326e-04 - val_loss: 3.3700e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7235e-04 - val_loss: 3.3660e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7144e-04 - val_loss: 3.3617e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7054e-04 - val_loss: 3.3572e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6962e-04 - val_loss: 3.3528e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6871e-04 - val_loss: 3.3484e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6781e-04 - val_loss: 3.3440e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6691e-04 - val_loss: 3.3395e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6601e-04 - val_loss: 3.3352e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6512e-04 - val_loss: 3.3309e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6423e-04 - val_loss: 3.3265e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6334e-04 - val_loss: 3.3221e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6246e-04 - val_loss: 3.3177e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6157e-04 - val_loss: 3.3134e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.6070e-04 - val_loss: 3.3091e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5982e-04 - val_loss: 3.3048e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5895e-04 - val_loss: 3.3005e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5808e-04 - val_loss: 3.2963e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5722e-04 - val_loss: 3.2920e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5636e-04 - val_loss: 3.2878e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5550e-04 - val_loss: 3.2837e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5465e-04 - val_loss: 3.2795e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5380e-04 - val_loss: 3.2754e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5296e-04 - val_loss: 3.2713e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5212e-04 - val_loss: 3.2672e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5128e-04 - val_loss: 3.2631e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5044e-04 - val_loss: 3.2591e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4961e-04 - val_loss: 3.2550e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4878e-04 - val_loss: 3.2511e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4795e-04 - val_loss: 3.2471e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4713e-04 - val_loss: 3.2430e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4632e-04 - val_loss: 3.2391e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4550e-04 - val_loss: 3.2351e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4469e-04 - val_loss: 3.2312e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4388e-04 - val_loss: 3.2273e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4307e-04 - val_loss: 3.2234e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4227e-04 - val_loss: 3.2195e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4147e-04 - val_loss: 3.2156e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4068e-04 - val_loss: 3.2117e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3988e-04 - val_loss: 3.2079e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3909e-04 - val_loss: 3.2041e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3831e-04 - val_loss: 3.2003e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3753e-04 - val_loss: 3.1965e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3675e-04 - val_loss: 3.1928e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3598e-04 - val_loss: 3.1891e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3521e-04 - val_loss: 3.1853e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3443e-04 - val_loss: 3.1816e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3367e-04 - val_loss: 3.1779e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3291e-04 - val_loss: 3.1742e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3215e-04 - val_loss: 3.1706e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3139e-04 - val_loss: 3.1670e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3063e-04 - val_loss: 3.1633e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2989e-04 - val_loss: 3.1597e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2914e-04 - val_loss: 3.1561e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2840e-04 - val_loss: 3.1524e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2765e-04 - val_loss: 3.1488e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2692e-04 - val_loss: 3.1453e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2618e-04 - val_loss: 3.1418e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2545e-04 - val_loss: 3.1383e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2472e-04 - val_loss: 3.1347e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2399e-04 - val_loss: 3.1312e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2327e-04 - val_loss: 3.1277e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2255e-04 - val_loss: 3.1242e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2183e-04 - val_loss: 3.1208e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2111e-04 - val_loss: 3.1173e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2040e-04 - val_loss: 3.1139e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1969e-04 - val_loss: 3.1104e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1898e-04 - val_loss: 3.1069e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.1827e-04 - val_loss: 3.1037e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1758e-04 - val_loss: 3.1002e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1688e-04 - val_loss: 3.0969e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1618e-04 - val_loss: 3.0935e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1548e-04 - val_loss: 3.0902e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1479e-04 - val_loss: 3.0868e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1409e-04 - val_loss: 3.0835e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1340e-04 - val_loss: 3.0801e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1271e-04 - val_loss: 3.0768e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1202e-04 - val_loss: 3.0735e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1133e-04 - val_loss: 3.0701e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1065e-04 - val_loss: 3.0668e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0997e-04 - val_loss: 3.0635e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0929e-04 - val_loss: 3.0601e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.0861e-04 - val_loss: 3.0567e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0794e-04 - val_loss: 3.0535e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0726e-04 - val_loss: 3.0502e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0659e-04 - val_loss: 3.0468e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0592e-04 - val_loss: 3.0436e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0525e-04 - val_loss: 3.0403e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0459e-04 - val_loss: 3.0370e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0393e-04 - val_loss: 3.0339e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0328e-04 - val_loss: 3.0306e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0262e-04 - val_loss: 3.0275e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.0197e-04 - val_loss: 3.0242e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0131e-04 - val_loss: 3.0211e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0066e-04 - val_loss: 3.0179e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0001e-04 - val_loss: 3.0148e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9936e-04 - val_loss: 3.0116e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9871e-04 - val_loss: 3.0085e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9806e-04 - val_loss: 3.0053e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9741e-04 - val_loss: 3.0021e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9678e-04 - val_loss: 2.9989e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9613e-04 - val_loss: 2.9957e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9549e-04 - val_loss: 2.9926e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9486e-04 - val_loss: 2.9893e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9422e-04 - val_loss: 2.9862e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9359e-04 - val_loss: 2.9829e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9295e-04 - val_loss: 2.9796e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9233e-04 - val_loss: 2.9766e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9170e-04 - val_loss: 2.9733e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9108e-04 - val_loss: 2.9702e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9046e-04 - val_loss: 2.9672e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8984e-04 - val_loss: 2.9640e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8922e-04 - val_loss: 2.9610e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8860e-04 - val_loss: 2.9579e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8799e-04 - val_loss: 2.9549e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8738e-04 - val_loss: 2.9518e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8678e-04 - val_loss: 2.9488e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8617e-04 - val_loss: 2.9458e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8556e-04 - val_loss: 2.9428e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8497e-04 - val_loss: 2.9398e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8437e-04 - val_loss: 2.9368e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8377e-04 - val_loss: 2.9338e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8317e-04 - val_loss: 2.9308e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8258e-04 - val_loss: 2.9278e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8200e-04 - val_loss: 2.9248e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8141e-04 - val_loss: 2.9219e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8082e-04 - val_loss: 2.9189e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8024e-04 - val_loss: 2.9160e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7966e-04 - val_loss: 2.9131e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.7908e-04 - val_loss: 2.9100e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7850e-04 - val_loss: 2.9072e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7793e-04 - val_loss: 2.9042e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7736e-04 - val_loss: 2.9013e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7679e-04 - val_loss: 2.8984e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7622e-04 - val_loss: 2.8954e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7565e-04 - val_loss: 2.8926e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7509e-04 - val_loss: 2.8898e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7453e-04 - val_loss: 2.8869e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7397e-04 - val_loss: 2.8841e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7341e-04 - val_loss: 2.8812e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7286e-04 - val_loss: 2.8784e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7230e-04 - val_loss: 2.8755e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7175e-04 - val_loss: 2.8727e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7120e-04 - val_loss: 2.8699e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7065e-04 - val_loss: 2.8672e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7011e-04 - val_loss: 2.8644e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6956e-04 - val_loss: 2.8614e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6902e-04 - val_loss: 2.8587e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6848e-04 - val_loss: 2.8559e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6795e-04 - val_loss: 2.8531e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6741e-04 - val_loss: 2.8503e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6688e-04 - val_loss: 2.8475e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6634e-04 - val_loss: 2.8449e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6582e-04 - val_loss: 2.8420e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6528e-04 - val_loss: 2.8393e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6476e-04 - val_loss: 2.8365e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6423e-04 - val_loss: 2.8338e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6371e-04 - val_loss: 2.8311e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.6319e-04 - val_loss: 2.8285e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6267e-04 - val_loss: 2.8257e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6216e-04 - val_loss: 2.8230e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6164e-04 - val_loss: 2.8203e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6113e-04 - val_loss: 2.8176e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6062e-04 - val_loss: 2.8149e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.6011e-04 - val_loss: 2.8121e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5960e-04 - val_loss: 2.8096e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5910e-04 - val_loss: 2.8069e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5859e-04 - val_loss: 2.8043e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5809e-04 - val_loss: 2.8015e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5759e-04 - val_loss: 2.7989e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5709e-04 - val_loss: 2.7963e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5659e-04 - val_loss: 2.7936e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5610e-04 - val_loss: 2.7910e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5560e-04 - val_loss: 2.7884e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5511e-04 - val_loss: 2.7857e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5462e-04 - val_loss: 2.7831e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5413e-04 - val_loss: 2.7806e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5364e-04 - val_loss: 2.7779e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5316e-04 - val_loss: 2.7754e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5268e-04 - val_loss: 2.7728e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5219e-04 - val_loss: 2.7701e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5172e-04 - val_loss: 2.7674e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5123e-04 - val_loss: 2.7649e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5076e-04 - val_loss: 2.7623e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5028e-04 - val_loss: 2.7597e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4981e-04 - val_loss: 2.7571e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4933e-04 - val_loss: 2.7546e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4887e-04 - val_loss: 2.7521e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4839e-04 - val_loss: 2.7495e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4793e-04 - val_loss: 2.7470e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4746e-04 - val_loss: 2.7445e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.4700e-04 - val_loss: 2.7418e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4653e-04 - val_loss: 2.7393e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4607e-04 - val_loss: 2.7369e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4561e-04 - val_loss: 2.7344e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4516e-04 - val_loss: 2.7318e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4470e-04 - val_loss: 2.7292e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4424e-04 - val_loss: 2.7267e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4379e-04 - val_loss: 2.7243e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4334e-04 - val_loss: 2.7216e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4288e-04 - val_loss: 2.7191e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4243e-04 - val_loss: 2.7167e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.4199e-04 - val_loss: 2.7142e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4154e-04 - val_loss: 2.7117e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4109e-04 - val_loss: 2.7092e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4065e-04 - val_loss: 2.7067e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4021e-04 - val_loss: 2.7043e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3977e-04 - val_loss: 2.7017e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3933e-04 - val_loss: 2.6993e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3889e-04 - val_loss: 2.6968e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3846e-04 - val_loss: 2.6943e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3802e-04 - val_loss: 2.6919e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3758e-04 - val_loss: 2.6895e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3715e-04 - val_loss: 2.6871e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3672e-04 - val_loss: 2.6846e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3629e-04 - val_loss: 2.6821e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3587e-04 - val_loss: 2.6796e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3544e-04 - val_loss: 2.6772e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3501e-04 - val_loss: 2.6748e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3458e-04 - val_loss: 2.6723e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.3416e-04 - val_loss: 2.6698e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3374e-04 - val_loss: 2.6674e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3332e-04 - val_loss: 2.6651e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3290e-04 - val_loss: 2.6627e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3248e-04 - val_loss: 2.6601e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3206e-04 - val_loss: 2.6578e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3165e-04 - val_loss: 2.6555e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3124e-04 - val_loss: 2.6531e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3083e-04 - val_loss: 2.6506e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3041e-04 - val_loss: 2.6482e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3001e-04 - val_loss: 2.6458e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2959e-04 - val_loss: 2.6434e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2918e-04 - val_loss: 2.6410e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2878e-04 - val_loss: 2.6386e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2838e-04 - val_loss: 2.6362e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2797e-04 - val_loss: 2.6338e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2757e-04 - val_loss: 2.6314e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2717e-04 - val_loss: 2.6290e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2676e-04 - val_loss: 2.6267e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2637e-04 - val_loss: 2.6243e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2597e-04 - val_loss: 2.6218e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2557e-04 - val_loss: 2.6196e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2518e-04 - val_loss: 2.6172e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2478e-04 - val_loss: 2.6148e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2439e-04 - val_loss: 2.6124e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2400e-04 - val_loss: 2.6102e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2361e-04 - val_loss: 2.6079e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2322e-04 - val_loss: 2.6054e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2283e-04 - val_loss: 2.6031e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.2244e-04 - val_loss: 2.6008e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2206e-04 - val_loss: 2.5984e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2167e-04 - val_loss: 2.5961e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.2129e-04 - val_loss: 2.5937e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2091e-04 - val_loss: 2.5914e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2052e-04 - val_loss: 2.5890e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2014e-04 - val_loss: 2.5866e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1977e-04 - val_loss: 2.5843e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1939e-04 - val_loss: 2.5821e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1901e-04 - val_loss: 2.5796e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1863e-04 - val_loss: 2.5774e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1826e-04 - val_loss: 2.5750e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1788e-04 - val_loss: 2.5727e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1751e-04 - val_loss: 2.5703e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1714e-04 - val_loss: 2.5681e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1677e-04 - val_loss: 2.5658e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1640e-04 - val_loss: 2.5635e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1603e-04 - val_loss: 2.5612e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1566e-04 - val_loss: 2.5588e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1530e-04 - val_loss: 2.5565e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1493e-04 - val_loss: 2.5542e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1457e-04 - val_loss: 2.5519e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1420e-04 - val_loss: 2.5496e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1384e-04 - val_loss: 2.5473e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1348e-04 - val_loss: 2.5450e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1312e-04 - val_loss: 2.5427e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1276e-04 - val_loss: 2.5404e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1240e-04 - val_loss: 2.5381e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1205e-04 - val_loss: 2.5359e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1169e-04 - val_loss: 2.5335e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1133e-04 - val_loss: 2.5313e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1098e-04 - val_loss: 2.5290e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1062e-04 - val_loss: 2.5267e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1027e-04 - val_loss: 2.5245e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0993e-04 - val_loss: 2.5221e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0957e-04 - val_loss: 2.5198e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0923e-04 - val_loss: 2.5176e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0888e-04 - val_loss: 2.5154e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0853e-04 - val_loss: 2.5130e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0818e-04 - val_loss: 2.5107e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0784e-04 - val_loss: 2.5085e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0749e-04 - val_loss: 2.5063e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0715e-04 - val_loss: 2.5039e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0681e-04 - val_loss: 2.5018e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0647e-04 - val_loss: 2.4994e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0612e-04 - val_loss: 2.4973e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0579e-04 - val_loss: 2.4949e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0545e-04 - val_loss: 2.4926e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0510e-04 - val_loss: 2.4903e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0477e-04 - val_loss: 2.4881e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0444e-04 - val_loss: 2.4859e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0410e-04 - val_loss: 2.4836e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0377e-04 - val_loss: 2.4813e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0343e-04 - val_loss: 2.4791e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0310e-04 - val_loss: 2.4768e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0277e-04 - val_loss: 2.4747e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0244e-04 - val_loss: 2.4723e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.0211e-04 - val_loss: 2.4701e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0178e-04 - val_loss: 2.4679e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0145e-04 - val_loss: 2.4657e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0113e-04 - val_loss: 2.4634e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0080e-04 - val_loss: 2.4612e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0047e-04 - val_loss: 2.4589e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0015e-04 - val_loss: 2.4567e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.9982e-04 - val_loss: 2.4545e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9950e-04 - val_loss: 2.4523e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9918e-04 - val_loss: 2.4500e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9886e-04 - val_loss: 2.4478e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9854e-04 - val_loss: 2.4456e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 1.9822e-04 - val_loss: 2.4433e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9790e-04 - val_loss: 2.4411e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9758e-04 - val_loss: 2.4389e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9726e-04 - val_loss: 2.4366e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9695e-04 - val_loss: 2.4344e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9663e-04 - val_loss: 2.4322e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.9632e-04 - val_loss: 2.4300e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9601e-04 - val_loss: 2.4277e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9569e-04 - val_loss: 2.4255e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9538e-04 - val_loss: 2.4233e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9507e-04 - val_loss: 2.4211e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9476e-04 - val_loss: 2.4188e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9445e-04 - val_loss: 2.4167e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9414e-04 - val_loss: 2.4144e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9383e-04 - val_loss: 2.4122e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9352e-04 - val_loss: 2.4101e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9322e-04 - val_loss: 2.4078e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9291e-04 - val_loss: 2.4056e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9261e-04 - val_loss: 2.4034e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9230e-04 - val_loss: 2.4011e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9200e-04 - val_loss: 2.3990e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9170e-04 - val_loss: 2.3968e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9140e-04 - val_loss: 2.3945e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9110e-04 - val_loss: 2.3924e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.9079e-04 - val_loss: 2.3901e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9049e-04 - val_loss: 2.3878e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9020e-04 - val_loss: 2.3856e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8990e-04 - val_loss: 2.3834e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8960e-04 - val_loss: 2.3813e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8930e-04 - val_loss: 2.3789e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 1.8901e-04 - val_loss: 2.3769e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8871e-04 - val_loss: 2.3746e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8842e-04 - val_loss: 2.3726e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8812e-04 - val_loss: 2.3702e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8783e-04 - val_loss: 2.3681e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8754e-04 - val_loss: 2.3659e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 1.8725e-04 - val_loss: 2.3638e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8695e-04 - val_loss: 2.3615e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8667e-04 - val_loss: 2.3594e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8637e-04 - val_loss: 2.3573e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8609e-04 - val_loss: 2.3550e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8580e-04 - val_loss: 2.3527e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8551e-04 - val_loss: 2.3506e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8522e-04 - val_loss: 2.3483e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8494e-04 - val_loss: 2.3462e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.8465e-04 - val_loss: 2.3440e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8437e-04 - val_loss: 2.3418e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8409e-04 - val_loss: 2.3397e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8381e-04 - val_loss: 2.3374e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8352e-04 - val_loss: 2.3352e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8324e-04 - val_loss: 2.3330e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8296e-04 - val_loss: 2.3309e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8268e-04 - val_loss: 2.3286e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8240e-04 - val_loss: 2.3265e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8212e-04 - val_loss: 2.3243e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8184e-04 - val_loss: 2.3222e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8156e-04 - val_loss: 2.3200e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8128e-04 - val_loss: 2.3178e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8101e-04 - val_loss: 2.3156e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8073e-04 - val_loss: 2.3134e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8046e-04 - val_loss: 2.3112e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8018e-04 - val_loss: 2.3091e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7991e-04 - val_loss: 2.3069e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7964e-04 - val_loss: 2.3047e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7937e-04 - val_loss: 2.3026e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7909e-04 - val_loss: 2.3004e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7882e-04 - val_loss: 2.2982e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7855e-04 - val_loss: 2.2960e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7828e-04 - val_loss: 2.2939e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7801e-04 - val_loss: 2.2917e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7774e-04 - val_loss: 2.2895e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7747e-04 - val_loss: 2.2874e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 1.7721e-04 - val_loss: 2.2852e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7694e-04 - val_loss: 2.2830e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7667e-04 - val_loss: 2.2808e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7641e-04 - val_loss: 2.2787e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7614e-04 - val_loss: 2.2764e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7588e-04 - val_loss: 2.2743e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7561e-04 - val_loss: 2.2721e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7535e-04 - val_loss: 2.2700e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7509e-04 - val_loss: 2.2678e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7483e-04 - val_loss: 2.2656e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7457e-04 - val_loss: 2.2634e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7430e-04 - val_loss: 2.2612e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7405e-04 - val_loss: 2.2591e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7378e-04 - val_loss: 2.2569e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7353e-04 - val_loss: 2.2548e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7327e-04 - val_loss: 2.2526e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7301e-04 - val_loss: 2.2505e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7275e-04 - val_loss: 2.2483e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7249e-04 - val_loss: 2.2461e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7224e-04 - val_loss: 2.2440e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7199e-04 - val_loss: 2.2418e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7173e-04 - val_loss: 2.2397e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7147e-04 - val_loss: 2.2375e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7122e-04 - val_loss: 2.2353e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7097e-04 - val_loss: 2.2332e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7072e-04 - val_loss: 2.2310e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7046e-04 - val_loss: 2.2289e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7021e-04 - val_loss: 2.2267e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6996e-04 - val_loss: 2.2245e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6971e-04 - val_loss: 2.2224e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.6946e-04 - val_loss: 2.2202e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6921e-04 - val_loss: 2.2180e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6896e-04 - val_loss: 2.2159e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6872e-04 - val_loss: 2.2137e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6846e-04 - val_loss: 2.2116e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6822e-04 - val_loss: 2.2094e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6797e-04 - val_loss: 2.2073e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.6773e-04 - val_loss: 2.2051e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6748e-04 - val_loss: 2.2030e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6724e-04 - val_loss: 2.2008e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6700e-04 - val_loss: 2.1987e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6675e-04 - val_loss: 2.1966e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6651e-04 - val_loss: 2.1944e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6626e-04 - val_loss: 2.1923e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6602e-04 - val_loss: 2.1901e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6578e-04 - val_loss: 2.1880e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6554e-04 - val_loss: 2.1859e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 1.6530e-04 - val_loss: 2.1836e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.6506e-04 - val_loss: 2.1815e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6481e-04 - val_loss: 2.1793e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6458e-04 - val_loss: 2.1772e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6434e-04 - val_loss: 2.1751e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6410e-04 - val_loss: 2.1730e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6387e-04 - val_loss: 2.1708e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6363e-04 - val_loss: 2.1686e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6339e-04 - val_loss: 2.1665e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6316e-04 - val_loss: 2.1644e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6292e-04 - val_loss: 2.1622e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6268e-04 - val_loss: 2.1601e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6245e-04 - val_loss: 2.1579e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6222e-04 - val_loss: 2.1558e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6198e-04 - val_loss: 2.1536e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6175e-04 - val_loss: 2.1515e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6152e-04 - val_loss: 2.1493e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6128e-04 - val_loss: 2.1472e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6105e-04 - val_loss: 2.1450e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6082e-04 - val_loss: 2.1430e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6060e-04 - val_loss: 2.1409e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6036e-04 - val_loss: 2.1386e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6013e-04 - val_loss: 2.1365e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5990e-04 - val_loss: 2.1343e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.5967e-04 - val_loss: 2.1322e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5945e-04 - val_loss: 2.1302e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5922e-04 - val_loss: 2.1280e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 1.5899e-04 - val_loss: 2.1259e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5876e-04 - val_loss: 2.1237e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5854e-04 - val_loss: 2.1216e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5831e-04 - val_loss: 2.1195e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5809e-04 - val_loss: 2.1174e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5786e-04 - val_loss: 2.1152e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5764e-04 - val_loss: 2.1130e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5741e-04 - val_loss: 2.1110e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5719e-04 - val_loss: 2.1088e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5697e-04 - val_loss: 2.1067e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5675e-04 - val_loss: 2.1046e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5653e-04 - val_loss: 2.1024e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5630e-04 - val_loss: 2.1002e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5608e-04 - val_loss: 2.0982e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5586e-04 - val_loss: 2.0960e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.5564e-04 - val_loss: 2.0939e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5542e-04 - val_loss: 2.0918e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5520e-04 - val_loss: 2.0897e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5498e-04 - val_loss: 2.0875e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5477e-04 - val_loss: 2.0854e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5455e-04 - val_loss: 2.0833e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5433e-04 - val_loss: 2.0811e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5411e-04 - val_loss: 2.0790e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5390e-04 - val_loss: 2.0768e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5368e-04 - val_loss: 2.0748e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5346e-04 - val_loss: 2.0726e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5325e-04 - val_loss: 2.0705e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 1.5303e-04 - val_loss: 2.0684e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5282e-04 - val_loss: 2.0663e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5260e-04 - val_loss: 2.0642e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.5239e-04 - val_loss: 2.0620e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5218e-04 - val_loss: 2.0600e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5197e-04 - val_loss: 2.0578e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5176e-04 - val_loss: 2.0557e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5155e-04 - val_loss: 2.0535e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5133e-04 - val_loss: 2.0515e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5112e-04 - val_loss: 2.0493e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5091e-04 - val_loss: 2.0472e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5070e-04 - val_loss: 2.0451e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5049e-04 - val_loss: 2.0430e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5028e-04 - val_loss: 2.0409e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5007e-04 - val_loss: 2.0387e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4986e-04 - val_loss: 2.0367e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4965e-04 - val_loss: 2.0345e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4945e-04 - val_loss: 2.0324e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4924e-04 - val_loss: 2.0303e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4904e-04 - val_loss: 2.0282e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4883e-04 - val_loss: 2.0261e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4862e-04 - val_loss: 2.0238e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4841e-04 - val_loss: 2.0219e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4821e-04 - val_loss: 2.0197e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4801e-04 - val_loss: 2.0176e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4780e-04 - val_loss: 2.0155e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4760e-04 - val_loss: 2.0135e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4739e-04 - val_loss: 2.0114e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4719e-04 - val_loss: 2.0092e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4699e-04 - val_loss: 2.0071e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4678e-04 - val_loss: 2.0050e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4658e-04 - val_loss: 2.0028e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.4638e-04 - val_loss: 2.0008e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4618e-04 - val_loss: 1.9986e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4598e-04 - val_loss: 1.9965e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4578e-04 - val_loss: 1.9945e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4558e-04 - val_loss: 1.9924e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4538e-04 - val_loss: 1.9903e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4518e-04 - val_loss: 1.9882e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4498e-04 - val_loss: 1.9861e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4478e-04 - val_loss: 1.9840e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4458e-04 - val_loss: 1.9819e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4439e-04 - val_loss: 1.9798e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4419e-04 - val_loss: 1.9777e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4399e-04 - val_loss: 1.9756e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4380e-04 - val_loss: 1.9735e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4360e-04 - val_loss: 1.9714e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4340e-04 - val_loss: 1.9693e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4321e-04 - val_loss: 1.9672e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4301e-04 - val_loss: 1.9652e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4282e-04 - val_loss: 1.9631e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4263e-04 - val_loss: 1.9609e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4243e-04 - val_loss: 1.9588e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4223e-04 - val_loss: 1.9567e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4204e-04 - val_loss: 1.9547e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4185e-04 - val_loss: 1.9526e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4166e-04 - val_loss: 1.9505e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4146e-04 - val_loss: 1.9484e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4128e-04 - val_loss: 1.9463e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4108e-04 - val_loss: 1.9443e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.4089e-04 - val_loss: 1.9421e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4070e-04 - val_loss: 1.9400e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4051e-04 - val_loss: 1.9379e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4032e-04 - val_loss: 1.9359e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4013e-04 - val_loss: 1.9338e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3994e-04 - val_loss: 1.9317e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3976e-04 - val_loss: 1.9296e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3957e-04 - val_loss: 1.9275e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3938e-04 - val_loss: 1.9255e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3919e-04 - val_loss: 1.9234e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3900e-04 - val_loss: 1.9213e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3882e-04 - val_loss: 1.9192e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3863e-04 - val_loss: 1.9172e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3844e-04 - val_loss: 1.9151e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3826e-04 - val_loss: 1.9130e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3807e-04 - val_loss: 1.9110e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3789e-04 - val_loss: 1.9089e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3770e-04 - val_loss: 1.9068e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3752e-04 - val_loss: 1.9047e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3733e-04 - val_loss: 1.9026e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3715e-04 - val_loss: 1.9006e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3696e-04 - val_loss: 1.8984e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3678e-04 - val_loss: 1.8963e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3660e-04 - val_loss: 1.8944e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3641e-04 - val_loss: 1.8923e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3623e-04 - val_loss: 1.8902e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3605e-04 - val_loss: 1.8881e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3587e-04 - val_loss: 1.8860e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3569e-04 - val_loss: 1.8840e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3550e-04 - val_loss: 1.8819e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3533e-04 - val_loss: 1.8799e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3515e-04 - val_loss: 1.8778e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3497e-04 - val_loss: 1.8757e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3479e-04 - val_loss: 1.8737e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3461e-04 - val_loss: 1.8717e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 1.3443e-04 - val_loss: 1.8696e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3425e-04 - val_loss: 1.8675e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3407e-04 - val_loss: 1.8655e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3389e-04 - val_loss: 1.8634e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3372e-04 - val_loss: 1.8613e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3354e-04 - val_loss: 1.8592e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3336e-04 - val_loss: 1.8572e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3319e-04 - val_loss: 1.8552e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3301e-04 - val_loss: 1.8531e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3283e-04 - val_loss: 1.8510e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3266e-04 - val_loss: 1.8490e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3248e-04 - val_loss: 1.8470e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3231e-04 - val_loss: 1.8449e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3213e-04 - val_loss: 1.8428e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3196e-04 - val_loss: 1.8408e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3178e-04 - val_loss: 1.8388e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3161e-04 - val_loss: 1.8367e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3144e-04 - val_loss: 1.8346e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3126e-04 - val_loss: 1.8326e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3109e-04 - val_loss: 1.8305e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3091e-04 - val_loss: 1.8285e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3075e-04 - val_loss: 1.8264e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3057e-04 - val_loss: 1.8244e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3040e-04 - val_loss: 1.8223e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3023e-04 - val_loss: 1.8203e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3006e-04 - val_loss: 1.8183e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2989e-04 - val_loss: 1.8163e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2972e-04 - val_loss: 1.8142e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2955e-04 - val_loss: 1.8122e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2938e-04 - val_loss: 1.8102e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2921e-04 - val_loss: 1.8081e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2904e-04 - val_loss: 1.8061e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2887e-04 - val_loss: 1.8041e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2870e-04 - val_loss: 1.8020e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2853e-04 - val_loss: 1.8000e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2837e-04 - val_loss: 1.7980e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2820e-04 - val_loss: 1.7960e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2803e-04 - val_loss: 1.7939e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2787e-04 - val_loss: 1.7919e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2770e-04 - val_loss: 1.7899e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2753e-04 - val_loss: 1.7879e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2736e-04 - val_loss: 1.7857e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2720e-04 - val_loss: 1.7837e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2703e-04 - val_loss: 1.7818e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2687e-04 - val_loss: 1.7797e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2670e-04 - val_loss: 1.7777e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2654e-04 - val_loss: 1.7757e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2638e-04 - val_loss: 1.7736e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2621e-04 - val_loss: 1.7717e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2605e-04 - val_loss: 1.7697e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2588e-04 - val_loss: 1.7676e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2572e-04 - val_loss: 1.7656e-04\n",
      "9.893293463392183e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0465508e+00, -1.4650474e+00,  1.4114271e-01, -4.4207135e-01,\n",
       "          8.9004320e-01],\n",
       "        [-1.2652401e+00,  1.1972096e+00,  3.6841333e-01,  4.4438806e-01,\n",
       "          3.1295884e-01],\n",
       "        [-1.3317440e+00,  1.3738480e+00,  3.4802479e-01, -1.3916385e-01,\n",
       "         -2.0155884e-04]], dtype=float32),\n",
       " array([ 0.89825976,  0.88887954, -0.5107071 , -0.22366881, -0.04528725],\n",
       "       dtype=float32),\n",
       " array([[-0.76697904, -1.448889  , -1.0987976 , -0.9460639 , -0.34702334,\n",
       "          1.0991843 , -0.7522915 , -0.16459979, -1.180037  , -1.4943328 ],\n",
       "        [-0.30475706, -0.34500203, -0.8159195 , -0.5207732 , -1.000115  ,\n",
       "          1.159038  , -0.79182225, -0.9740061 , -1.0370418 , -0.79821754],\n",
       "        [-0.19086751, -0.29096138, -1.0594194 , -0.73945284, -0.88356906,\n",
       "          0.29974064, -0.871569  , -0.7992014 , -0.13457952, -0.8283284 ],\n",
       "        [-0.97150177, -1.1779838 , -0.26703128, -0.5569972 , -0.68908614,\n",
       "          0.23136744, -0.3791112 , -0.01633957, -0.89030725, -1.0521837 ],\n",
       "        [-0.03983178, -0.28141204, -0.54243666, -0.5924334 , -0.37500352,\n",
       "          0.8073937 , -0.62555975, -0.34960917, -0.7557494 , -0.4133635 ]],\n",
       "       dtype=float32),\n",
       " array([-0.6992663 , -0.8169207 , -0.8285397 , -0.79246396, -0.8828977 ,\n",
       "         0.79902804, -0.82013714, -0.7012717 , -0.8300832 , -0.8322386 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.40603393],\n",
       "        [-0.6510724 ],\n",
       "        [-1.1135669 ],\n",
       "        [-0.32612145],\n",
       "        [-0.48156613],\n",
       "        [ 0.7503969 ],\n",
       "        [-0.45559135],\n",
       "        [ 0.06129204],\n",
       "        [-1.0222932 ],\n",
       "        [-0.99416786]], dtype=float32),\n",
       " array([0.6847369], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_tanh(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_tanh_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
