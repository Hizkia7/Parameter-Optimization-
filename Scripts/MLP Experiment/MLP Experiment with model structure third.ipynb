{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_1(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_2(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_3(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_4(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_5(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_6(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 413us/step - loss: 15317.4708 - val_loss: 14826.0740\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13199.1920 - val_loss: 10830.1970\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7548.7327 - val_loss: 4004.6608\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 1821.3219 - val_loss: 406.9082\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 123.1755 - val_loss: 33.4875\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 30.8943 - val_loss: 27.6433\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.9342 - val_loss: 25.5017\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.1464 - val_loss: 25.0558\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.6510 - val_loss: 24.9279\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.4477 - val_loss: 24.8659\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2550 - val_loss: 24.9768\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2510 - val_loss: 25.0695\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.3337 - val_loss: 25.9111\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2783 - val_loss: 25.2197\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9530 - val_loss: 25.3693\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0479 - val_loss: 25.2232\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1722 - val_loss: 25.9181\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0398 - val_loss: 25.5784\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.9905 - val_loss: 25.3881\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9579 - val_loss: 25.4492\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9755 - val_loss: 26.0249\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0914 - val_loss: 25.2423\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.9492 - val_loss: 25.8195\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0219 - val_loss: 25.2632\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2395 - val_loss: 25.4436\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0449 - val_loss: 25.7857\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1577 - val_loss: 25.7662\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9849 - val_loss: 25.3981\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9730 - val_loss: 25.3699\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.2196 - val_loss: 25.8033\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0657 - val_loss: 25.6601\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9939 - val_loss: 25.5292\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9265 - val_loss: 25.2077\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.9706 - val_loss: 25.4227\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1538 - val_loss: 25.5212\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1933 - val_loss: 25.3239\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9228 - val_loss: 26.5258\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.1937 - val_loss: 26.2302\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.9956 - val_loss: 25.5055\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.7301 - val_loss: 25.4061\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1877 - val_loss: 26.0185\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.2248 - val_loss: 25.6255\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1134 - val_loss: 25.7966\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0249 - val_loss: 26.5786\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0968 - val_loss: 25.9994\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.9795 - val_loss: 25.7530\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0174 - val_loss: 25.6796\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8277 - val_loss: 25.5279\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1362 - val_loss: 27.7103\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.0283 - val_loss: 25.7524\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9452 - val_loss: 25.6615\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.3223 - val_loss: 26.3828\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8928 - val_loss: 25.5121\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8093 - val_loss: 26.1963\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8007 - val_loss: 25.3191\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0785 - val_loss: 26.4807\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9913 - val_loss: 26.3791\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.7475 - val_loss: 25.6380\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.6175 - val_loss: 25.7062\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.8678 - val_loss: 25.6952\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.8250 - val_loss: 26.2145\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.8446 - val_loss: 26.4099\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0028 - val_loss: 25.9600\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.8078 - val_loss: 25.7905\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 103us/step - loss: 21.8189 - val_loss: 25.8302\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6687 - val_loss: 25.5780\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8684 - val_loss: 25.4291\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2347 - val_loss: 25.9070\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2256 - val_loss: 27.0164\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6548 - val_loss: 25.2628\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0248 - val_loss: 26.1881\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1866 - val_loss: 26.7755\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1624 - val_loss: 25.4510\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.6232 - val_loss: 25.7696\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9165 - val_loss: 26.4423\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9247 - val_loss: 27.1496\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.2442 - val_loss: 28.4419\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.7891 - val_loss: 27.1831\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8658 - val_loss: 25.6288\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.8831 - val_loss: 25.4652\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.2043 - val_loss: 26.1609\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.4432 - val_loss: 26.7534\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.7348 - val_loss: 26.0958\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4746 - val_loss: 26.2959\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.9710 - val_loss: 26.3053\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.4532 - val_loss: 25.7044\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8432 - val_loss: 25.8829\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7991 - val_loss: 25.7787\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9626 - val_loss: 26.0649\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6013 - val_loss: 25.8439\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7909 - val_loss: 25.8314\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9772 - val_loss: 25.8086\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7054 - val_loss: 25.8807\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 22.99 - 0s 85us/step - loss: 21.6792 - val_loss: 25.6461\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8324 - val_loss: 26.1490\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.8257 - val_loss: 26.1742\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8900 - val_loss: 26.1673\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7769 - val_loss: 26.0211\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8143 - val_loss: 26.0114\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.8695 - val_loss: 25.4187\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9344 - val_loss: 25.6580\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6505 - val_loss: 27.4715\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3059 - val_loss: 27.0349\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8321 - val_loss: 25.5779\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2850 - val_loss: 27.3195\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.6069 - val_loss: 25.5730\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3452 - val_loss: 26.3425\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.0039 - val_loss: 26.3650\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3988 - val_loss: 26.0595\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.0251 - val_loss: 27.1697\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8735 - val_loss: 26.2313\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7120 - val_loss: 25.7164\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.3553 - val_loss: 27.5235\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0446 - val_loss: 25.6751\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3772 - val_loss: 25.4206\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1607 - val_loss: 25.7847\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7258 - val_loss: 25.9130\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2368 - val_loss: 26.0463\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2996 - val_loss: 27.4971\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0545 - val_loss: 26.0576\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9409 - val_loss: 25.7732\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5750 - val_loss: 25.3072\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.5033 - val_loss: 26.8203\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8949 - val_loss: 25.4525\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.5200 - val_loss: 28.6536\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2443 - val_loss: 25.5978\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9652 - val_loss: 27.3960\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6921 - val_loss: 27.5699\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.4006 - val_loss: 25.3380\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 21.9777 - val_loss: 25.7651\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.4676 - val_loss: 27.2122\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7060 - val_loss: 25.8491\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.1863 - val_loss: 25.5209\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.6933 - val_loss: 29.4533\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.6664 - val_loss: 25.2672\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6165 - val_loss: 25.2869\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.2451 - val_loss: 25.9008\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.1001 - val_loss: 25.2164\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9242 - val_loss: 25.4220\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.9409 - val_loss: 25.3485\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8431 - val_loss: 25.2772\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1705 - val_loss: 25.7889\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9447 - val_loss: 26.4543\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9474 - val_loss: 28.5328\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.5222 - val_loss: 25.6529\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.3511 - val_loss: 25.1365\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5129 - val_loss: 25.2407\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.1355 - val_loss: 25.4170\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.9209 - val_loss: 25.0676\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2406 - val_loss: 25.9163\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.5185 - val_loss: 25.2470\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1344 - val_loss: 25.3713\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 23.15 - 0s 87us/step - loss: 21.7339 - val_loss: 25.7568\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.2808 - val_loss: 25.0704\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.6187 - val_loss: 25.0484\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2188 - val_loss: 25.5088\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0400 - val_loss: 24.4372\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.2168 - val_loss: 25.6435\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.7785 - val_loss: 24.6572\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.9860 - val_loss: 24.4444\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.8589 - val_loss: 24.8271\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 20.9917 - val_loss: 24.6571\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.9018 - val_loss: 24.7030\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.9350 - val_loss: 27.5686\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.0415 - val_loss: 25.3300\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.5008 - val_loss: 24.3995\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.9973 - val_loss: 24.6277\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.9651 - val_loss: 26.4096\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 20.6853 - val_loss: 24.8085\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.0265 - val_loss: 24.8400\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.4051 - val_loss: 23.5670\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.9052 - val_loss: 23.8617\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.1339 - val_loss: 24.0030\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.8148 - val_loss: 22.9865\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.3496 - val_loss: 25.5567\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.4910 - val_loss: 23.7033\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.2754 - val_loss: 24.0671\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3560 - val_loss: 23.6173\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1870 - val_loss: 25.5461\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.6035 - val_loss: 22.7188\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7576 - val_loss: 23.9905\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.1510 - val_loss: 23.3697\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.9242 - val_loss: 22.1626\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3512 - val_loss: 22.7026\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.4619 - val_loss: 23.2827\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.4557 - val_loss: 21.9341\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3236 - val_loss: 23.0337\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4372 - val_loss: 22.8444\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.8991 - val_loss: 21.4288\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9569 - val_loss: 21.9574\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0233 - val_loss: 21.7552\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.4327 - val_loss: 20.8209\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7482 - val_loss: 21.6185\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0452 - val_loss: 21.7592\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3899 - val_loss: 20.9260\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.0354 - val_loss: 20.1581\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0598 - val_loss: 20.0975\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.8853 - val_loss: 20.6612\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.8789 - val_loss: 20.4593\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1873 - val_loss: 20.2135\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 16.66 - 0s 89us/step - loss: 17.1037 - val_loss: 21.2987\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8870 - val_loss: 19.6995\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1331 - val_loss: 20.8329\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.7758 - val_loss: 18.8667\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5466 - val_loss: 19.1441\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.3425 - val_loss: 19.4549\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7992 - val_loss: 19.5446\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1903 - val_loss: 19.8550\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.8144 - val_loss: 21.6998\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.7386 - val_loss: 19.7552\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.4098 - val_loss: 19.4340\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.0833 - val_loss: 18.3422\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.4444 - val_loss: 20.0450\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2366 - val_loss: 19.3935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.4091 - val_loss: 19.3091\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.2331 - val_loss: 18.7772\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.1009 - val_loss: 18.9124\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.1182 - val_loss: 17.9723\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.2945 - val_loss: 18.0153\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.1028 - val_loss: 18.6424\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.1527 - val_loss: 20.3667\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.1241 - val_loss: 18.2488\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.9012 - val_loss: 17.8857\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 15.6502 - val_loss: 18.0920\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.6240 - val_loss: 17.9265\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 16.0926 - val_loss: 17.5262\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 15.8832 - val_loss: 17.7249\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.7294 - val_loss: 17.0034\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 15.6081 - val_loss: 17.7936\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 16.0661 - val_loss: 19.7318\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.1363 - val_loss: 18.6649\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9084 - val_loss: 18.0425\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.4795 - val_loss: 17.5608\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 15.5226 - val_loss: 17.2214\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3544 - val_loss: 17.1025\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.4117 - val_loss: 17.9386\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2564 - val_loss: 17.0554\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.1536 - val_loss: 18.4562\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.0142 - val_loss: 17.6876\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9917 - val_loss: 17.5916\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.4138 - val_loss: 17.1533\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 14.8344 - val_loss: 17.6081\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.9140 - val_loss: 18.1759\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7019 - val_loss: 17.7608\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.7913 - val_loss: 16.6966\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.6298 - val_loss: 19.0275\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6536 - val_loss: 17.6038\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5528 - val_loss: 18.2185\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.6490 - val_loss: 16.9964\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6870 - val_loss: 17.1449\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.7570 - val_loss: 20.7874\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.7657 - val_loss: 18.7175\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3468 - val_loss: 17.2825\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4493 - val_loss: 16.3372\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.6292 - val_loss: 18.5644\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1164 - val_loss: 16.8640\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.6977 - val_loss: 16.7160\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.7134 - val_loss: 18.9450\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9639 - val_loss: 17.3305\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.6582 - val_loss: 17.2596\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9980 - val_loss: 16.1174\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4693 - val_loss: 16.7328\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1902 - val_loss: 16.7656\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.1157 - val_loss: 16.2618\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7205 - val_loss: 16.9536\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5991 - val_loss: 17.2000\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.1097 - val_loss: 15.9299\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.1053 - val_loss: 16.7561\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.7889 - val_loss: 16.4454\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.0564 - val_loss: 16.9136\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.6125 - val_loss: 15.9493\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.9684 - val_loss: 21.3614\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5266 - val_loss: 15.7670\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5955 - val_loss: 15.3809\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.4926 - val_loss: 15.5086\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5544 - val_loss: 15.8120\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0892 - val_loss: 15.8080\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.3881 - val_loss: 16.5133\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.3096 - val_loss: 15.1233\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2108 - val_loss: 14.7197\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6443 - val_loss: 19.1481\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.2105 - val_loss: 15.0112\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6800 - val_loss: 16.5689\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8640 - val_loss: 14.1872\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.7960 - val_loss: 15.5866\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8115 - val_loss: 14.5121\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4014 - val_loss: 16.0482\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0034 - val_loss: 15.8289\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0195 - val_loss: 14.9286\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.6019 - val_loss: 14.0129\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.0357 - val_loss: 14.6469\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.4194 - val_loss: 14.3274\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1342 - val_loss: 13.8545\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0349 - val_loss: 14.4555\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2962 - val_loss: 16.2567\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4917 - val_loss: 14.9377\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 11.2923 - val_loss: 13.9733\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7739 - val_loss: 15.6253\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.2047 - val_loss: 15.5697\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.2250 - val_loss: 15.0000\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1064 - val_loss: 13.9958\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2240 - val_loss: 16.8052\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4235 - val_loss: 13.0073\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1848 - val_loss: 15.5765\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.8878 - val_loss: 12.9238\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.4528 - val_loss: 13.7832\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4916 - val_loss: 13.7141\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.3052 - val_loss: 12.4212\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.2904 - val_loss: 13.6643\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.8117 - val_loss: 12.1440\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3486 - val_loss: 12.9766\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.5228 - val_loss: 12.8400\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.7365 - val_loss: 13.2992\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3609 - val_loss: 13.4933\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0112 - val_loss: 13.3339\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4638 - val_loss: 13.0360\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9552 - val_loss: 12.0407\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.1465 - val_loss: 13.8917\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 10.5124 - val_loss: 13.7201\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0214 - val_loss: 16.2625\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9440 - val_loss: 14.1431\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.7572 - val_loss: 13.3778\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.8224 - val_loss: 12.3433\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.9689 - val_loss: 12.6130\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.1031 - val_loss: 11.8676\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.8281 - val_loss: 12.1337\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.5430 - val_loss: 12.6573\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6692 - val_loss: 12.0339\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.6953 - val_loss: 12.1815\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4404 - val_loss: 14.4317\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0410 - val_loss: 12.5094\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4484 - val_loss: 11.9979\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.1258 - val_loss: 11.3367\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.9647 - val_loss: 12.6578\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2939 - val_loss: 13.4668\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7624 - val_loss: 12.4559\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4313 - val_loss: 11.2659\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8052 - val_loss: 11.6469\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9036 - val_loss: 11.9584\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7229 - val_loss: 12.2776\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9270 - val_loss: 11.4371\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6124 - val_loss: 11.9520\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3102 - val_loss: 12.1188\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8272 - val_loss: 11.8508\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1551 - val_loss: 12.9673\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2333 - val_loss: 12.6691\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5866 - val_loss: 11.2296\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1307 - val_loss: 11.8037\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0718 - val_loss: 11.4334\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3570 - val_loss: 11.5019\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1625 - val_loss: 11.7402\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5169 - val_loss: 11.8302\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5517 - val_loss: 11.8612\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2505 - val_loss: 12.0327\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1466 - val_loss: 11.5375\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3296 - val_loss: 11.0897\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3147 - val_loss: 11.2834\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1524 - val_loss: 11.1789\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5254 - val_loss: 12.4296\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4454 - val_loss: 12.3356\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2033 - val_loss: 11.5306\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0536 - val_loss: 10.7717\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9195 - val_loss: 11.0804\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0312 - val_loss: 11.5554\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9238 - val_loss: 11.1365\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0453 - val_loss: 10.8836\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0098 - val_loss: 10.7702\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0887 - val_loss: 10.9687\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9598 - val_loss: 11.9705\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0982 - val_loss: 10.7980\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8224 - val_loss: 12.4449\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0966 - val_loss: 11.0104\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8635 - val_loss: 11.2011\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9205 - val_loss: 10.6791\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7471 - val_loss: 12.2411\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0775 - val_loss: 12.2359\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.4529 - val_loss: 10.9014\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8686 - val_loss: 10.5043\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8949 - val_loss: 10.7053\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5187 - val_loss: 14.1536\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2838 - val_loss: 11.0572\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2864 - val_loss: 10.6962\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7195 - val_loss: 11.3548\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9865 - val_loss: 11.5120\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9189 - val_loss: 10.7375\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3361 - val_loss: 12.1266\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2096 - val_loss: 13.2922\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1529 - val_loss: 10.6086\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6197 - val_loss: 12.4956\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8663 - val_loss: 10.6412\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.7692 - val_loss: 10.7003\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6217 - val_loss: 10.5852\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9237 - val_loss: 10.6174\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7362 - val_loss: 11.1252\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8666 - val_loss: 10.5158\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0964 - val_loss: 11.7815\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8872 - val_loss: 11.2544\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9838 - val_loss: 10.4434\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9370 - val_loss: 10.6140\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6138 - val_loss: 10.4697\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6567 - val_loss: 11.0727\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9476 - val_loss: 10.4286\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5325 - val_loss: 10.5557\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0794 - val_loss: 10.4283\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6452 - val_loss: 10.3486\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8396 - val_loss: 11.5678\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0619 - val_loss: 12.1647\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8791 - val_loss: 10.7587\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7299 - val_loss: 10.8354\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8431 - val_loss: 10.7960\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9890 - val_loss: 10.6229\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0507 - val_loss: 11.3024\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7705 - val_loss: 10.9382\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9313 - val_loss: 11.7204\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8598 - val_loss: 10.3052\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4669 - val_loss: 10.9644\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9057 - val_loss: 10.5988\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1148 - val_loss: 11.0620\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6714 - val_loss: 11.0833\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.2310 - val_loss: 10.6418\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.0690 - val_loss: 10.3898\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8853 - val_loss: 10.3488\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9500 - val_loss: 11.4212\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6559 - val_loss: 10.4221\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6873 - val_loss: 10.7959\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0397 - val_loss: 13.3050\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.5404 - val_loss: 11.0270\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6331 - val_loss: 11.5221\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0496 - val_loss: 11.7500\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9611 - val_loss: 10.2388\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8907 - val_loss: 10.2115\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4931 - val_loss: 10.6243\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0578 - val_loss: 11.5833\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5519 - val_loss: 10.4849\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6549 - val_loss: 11.2626\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.4878 - val_loss: 10.6106\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7780 - val_loss: 10.2873\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5171 - val_loss: 10.9469\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7549 - val_loss: 10.3306\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 121us/step - loss: 8.7065 - val_loss: 11.2590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9376 - val_loss: 11.2786\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4942 - val_loss: 10.5827\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9826 - val_loss: 11.6620\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4914 - val_loss: 10.3510\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4824 - val_loss: 10.3629\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7235 - val_loss: 10.9767\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9224 - val_loss: 11.2876\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7960 - val_loss: 10.7493\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9566 - val_loss: 10.6727\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5135 - val_loss: 11.0065\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6440 - val_loss: 10.3351\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4052 - val_loss: 10.3522\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.7379 - val_loss: 10.3062\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4089 - val_loss: 10.4644\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6787 - val_loss: 13.0536\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9491 - val_loss: 10.7546\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4694 - val_loss: 10.5354\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3664 - val_loss: 9.9679\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6804 - val_loss: 10.3286\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6039 - val_loss: 11.0702\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5256 - val_loss: 11.0146\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5807 - val_loss: 10.2206\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4983 - val_loss: 9.9179\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7305 - val_loss: 11.1657\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9357 - val_loss: 10.3402\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7486 - val_loss: 10.4589\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3772 - val_loss: 9.8304\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4871 - val_loss: 10.1080\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4630 - val_loss: 10.2955\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6317 - val_loss: 10.1336\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5530 - val_loss: 10.3314\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6956 - val_loss: 12.2572\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5772 - val_loss: 10.4929\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3252 - val_loss: 10.8084\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4288 - val_loss: 12.1921\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6013 - val_loss: 11.1366\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7366 - val_loss: 11.0896\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.7639 - val_loss: 10.0674\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.6793 - val_loss: 13.1886\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2022 - val_loss: 10.2601\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.5473 - val_loss: 11.0401\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6066 - val_loss: 10.1508\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4970 - val_loss: 11.1018\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2824 - val_loss: 10.5846\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6988 - val_loss: 10.9843\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8390 - val_loss: 10.6627\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3340 - val_loss: 10.2169\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6294 - val_loss: 9.7996\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9440 - val_loss: 11.5639\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.6122 - val_loss: 10.0820\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6383 - val_loss: 10.4901\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7453 - val_loss: 10.1193\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7625 - val_loss: 10.3064\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3617 - val_loss: 9.7705\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9048 - val_loss: 10.5366\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3875 - val_loss: 9.9507\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5144 - val_loss: 11.3367\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4879 - val_loss: 10.2451\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4665 - val_loss: 10.4082\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3131 - val_loss: 11.2680\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8019 - val_loss: 10.0567\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8162 - val_loss: 9.8605\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4478 - val_loss: 10.2835\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4735 - val_loss: 10.1278\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5253 - val_loss: 11.0178\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6265 - val_loss: 10.0748\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.3306 - val_loss: 10.0413\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6159 - val_loss: 10.9896\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8238 - val_loss: 10.4868\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2642 - val_loss: 10.1636\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7217 - val_loss: 11.1033\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.2841 - val_loss: 9.6637\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5357 - val_loss: 10.7452\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.6191 - val_loss: 10.8130\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2854 - val_loss: 9.9253\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2335 - val_loss: 10.5976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.5294 - val_loss: 10.0805\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4740 - val_loss: 10.0850\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2456 - val_loss: 13.4059\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4880 - val_loss: 9.9872\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7349 - val_loss: 10.8582\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9053 - val_loss: 9.7355\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1539 - val_loss: 10.3087\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5796 - val_loss: 11.7549\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.5506 - val_loss: 9.8886\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4721 - val_loss: 9.8156\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4332 - val_loss: 10.5827\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2936 - val_loss: 10.5452\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4196 - val_loss: 10.0448\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 8.5226 - val_loss: 10.7926\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9017 - val_loss: 12.1135\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.3577 - val_loss: 9.7408\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3167 - val_loss: 10.6571\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4276 - val_loss: 9.8218\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3090 - val_loss: 10.3840\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3071 - val_loss: 11.9415\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6284 - val_loss: 10.0560\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4010 - val_loss: 10.1703\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4961 - val_loss: 10.5205\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4035 - val_loss: 10.9514\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3823 - val_loss: 10.3961\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5754 - val_loss: 10.5265\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5618 - val_loss: 10.5760\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6472 - val_loss: 10.3997\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5105 - val_loss: 10.1176\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.3965 - val_loss: 9.4584\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5044 - val_loss: 9.6172\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3818 - val_loss: 9.7272\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.1562 - val_loss: 10.1799\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2011 - val_loss: 12.0619\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.5643 - val_loss: 10.4616\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3734 - val_loss: 10.2007\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5355 - val_loss: 9.8925\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4321 - val_loss: 9.5037\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2579 - val_loss: 9.9384\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2492 - val_loss: 9.7248\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3316 - val_loss: 9.9953\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5241 - val_loss: 11.2226\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5593 - val_loss: 9.5836\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4197 - val_loss: 10.4492\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.3230 - val_loss: 11.5978\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8368 - val_loss: 9.7508\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2045 - val_loss: 10.2052\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7101 - val_loss: 9.6789\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7144 - val_loss: 11.5688\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.5673 - val_loss: 11.3005\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3500 - val_loss: 10.0535\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6644 - val_loss: 12.2923\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6707 - val_loss: 10.2989\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6797 - val_loss: 9.9273\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1609 - val_loss: 10.1844\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2401 - val_loss: 10.0182\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3391 - val_loss: 10.4075\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4832 - val_loss: 9.7790\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7515 - val_loss: 9.6472\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2674 - val_loss: 9.3735\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2109 - val_loss: 9.7106\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1494 - val_loss: 9.6759\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4878 - val_loss: 11.3053\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6173 - val_loss: 10.2948\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6822 - val_loss: 10.4851\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8409 - val_loss: 10.2726\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4808 - val_loss: 9.7804\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5614 - val_loss: 10.7979\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5407 - val_loss: 10.3251\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0421 - val_loss: 9.9897\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2991 - val_loss: 10.2087\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1519 - val_loss: 9.4947\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4659 - val_loss: 10.2154\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4200 - val_loss: 10.5751\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2299 - val_loss: 9.4938\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.4195 - val_loss: 10.3508\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5621 - val_loss: 10.4354\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3130 - val_loss: 9.8637\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8787 - val_loss: 10.6890\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2486 - val_loss: 10.6412\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3281 - val_loss: 10.6036\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4245 - val_loss: 12.5142\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3615 - val_loss: 9.5156\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4255 - val_loss: 9.4448\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3475 - val_loss: 10.6116\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1968 - val_loss: 10.9660\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6003 - val_loss: 11.1976\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1174 - val_loss: 9.4783\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3051 - val_loss: 11.5600\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5875 - val_loss: 10.0451\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4619 - val_loss: 9.5797\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1542 - val_loss: 11.5128\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.3285 - val_loss: 10.3387\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.4327 - val_loss: 9.4418\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6828 - val_loss: 12.3845\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4770 - val_loss: 9.6044\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9933 - val_loss: 10.5414\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2765 - val_loss: 10.3161\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.4786 - val_loss: 11.6033\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4999 - val_loss: 10.5503\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4734 - val_loss: 9.7478\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5386 - val_loss: 10.6107\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4476 - val_loss: 11.6799\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1808 - val_loss: 10.5504\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.1369 - val_loss: 9.6786\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5440 - val_loss: 10.1170\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6420 - val_loss: 9.4008\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3758 - val_loss: 10.5268\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0092 - val_loss: 9.8405\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3909 - val_loss: 10.1128\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2876 - val_loss: 9.7109\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3437 - val_loss: 9.9178\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4955 - val_loss: 9.3863\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4323 - val_loss: 9.3860\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6735 - val_loss: 10.2012\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7070 - val_loss: 10.1398\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7093 - val_loss: 10.6690\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.2127 - val_loss: 9.7152\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2253 - val_loss: 10.3612\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3738 - val_loss: 11.2397\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6788 - val_loss: 9.6469\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0827 - val_loss: 10.1661\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2053 - val_loss: 10.4577\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4034 - val_loss: 9.8907\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3005 - val_loss: 9.5666\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6477 - val_loss: 10.4313\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3105 - val_loss: 10.3362\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3684 - val_loss: 9.5742\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3355 - val_loss: 10.0861\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5220 - val_loss: 9.3939\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3565 - val_loss: 10.8206\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4822 - val_loss: 11.2183\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2279 - val_loss: 11.7434\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5939 - val_loss: 9.9444\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1231 - val_loss: 9.9286\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.2168 - val_loss: 9.6602\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6604 - val_loss: 10.8187\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3129 - val_loss: 9.6672\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3647 - val_loss: 9.7796\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6632 - val_loss: 11.6542\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3080 - val_loss: 9.6033\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1992 - val_loss: 9.3913\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2293 - val_loss: 10.3877\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2412 - val_loss: 9.9591\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4370 - val_loss: 9.8803\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.1617 - val_loss: 9.4103\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4759 - val_loss: 9.9686\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3797 - val_loss: 10.8319\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8226 - val_loss: 9.2578\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9828 - val_loss: 9.8011\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0759 - val_loss: 10.4318\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4191 - val_loss: 10.1145\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2175 - val_loss: 9.6052\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0709 - val_loss: 9.4978\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2615 - val_loss: 9.5133\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4026 - val_loss: 9.4125\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1575 - val_loss: 10.8081\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1364 - val_loss: 9.5035\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6204 - val_loss: 10.0469\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1375 - val_loss: 9.4981\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3411 - val_loss: 9.7904\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1693 - val_loss: 9.2843\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5650 - val_loss: 9.4515\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1593 - val_loss: 12.2245\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6681 - val_loss: 9.5477\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2340 - val_loss: 9.3286\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1902 - val_loss: 9.5912\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6219 - val_loss: 9.5333\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0640 - val_loss: 9.3934\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0260 - val_loss: 9.9689\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4834 - val_loss: 11.7437\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5272 - val_loss: 10.1709\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2384 - val_loss: 9.9909\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4632 - val_loss: 9.2830\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2833 - val_loss: 9.7144\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4107 - val_loss: 9.3353\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4003 - val_loss: 9.2895\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.3290 - val_loss: 9.3092\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1131 - val_loss: 9.3446\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.1467 - val_loss: 9.7971\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2507 - val_loss: 10.0039\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3995 - val_loss: 9.4624\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3272 - val_loss: 10.0464\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3560 - val_loss: 9.5708\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0643 - val_loss: 9.9093\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2485 - val_loss: 9.8582\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4766 - val_loss: 9.6374\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5341 - val_loss: 10.7878\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2424 - val_loss: 10.8750\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0506 - val_loss: 9.5931\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0768 - val_loss: 9.3348\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4680 - val_loss: 9.3645\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2445 - val_loss: 9.9969\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0934 - val_loss: 10.1210\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1463 - val_loss: 9.5640\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1978 - val_loss: 9.6330\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4239 - val_loss: 9.8940\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.5230 - val_loss: 11.3250\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0125 - val_loss: 9.3269\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2300 - val_loss: 10.6378\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4184 - val_loss: 10.3664\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0609 - val_loss: 9.8456\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4290 - val_loss: 9.7625\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2556 - val_loss: 9.7812\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.1376 - val_loss: 10.5879\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5178 - val_loss: 9.4663\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1703 - val_loss: 10.1978\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4895 - val_loss: 10.1354\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6304 - val_loss: 10.7131\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2430 - val_loss: 9.9276\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1391 - val_loss: 9.9982\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3621 - val_loss: 9.3363\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5619 - val_loss: 9.5652\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2493 - val_loss: 10.3166\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2274 - val_loss: 9.5359\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3855 - val_loss: 9.5082\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0815 - val_loss: 9.9319\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0823 - val_loss: 9.1405\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1155 - val_loss: 10.1524\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3515 - val_loss: 10.1640\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0624 - val_loss: 9.6722\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0014 - val_loss: 10.4286\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1228 - val_loss: 9.2444\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 137us/step - loss: 8.4480 - val_loss: 10.1663\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3388 - val_loss: 9.5763\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5055 - val_loss: 9.2692\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9918 - val_loss: 11.4220\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7090 - val_loss: 9.5206\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2287 - val_loss: 11.9286\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5341 - val_loss: 9.9358\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2565 - val_loss: 9.2276\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5396 - val_loss: 9.4354\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7299 - val_loss: 11.5559\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2918 - val_loss: 10.7911\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5837 - val_loss: 10.8651\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3889 - val_loss: 10.1249\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.0872 - val_loss: 9.8907\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3541 - val_loss: 9.1825\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.1960 - val_loss: 9.6154\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0853 - val_loss: 9.7169\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2274 - val_loss: 10.0607\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0771 - val_loss: 9.6269\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1215 - val_loss: 10.0421\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5408 - val_loss: 9.7328\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3242 - val_loss: 10.7060\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5724 - val_loss: 9.4029\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2180 - val_loss: 11.2727\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5493 - val_loss: 9.8218\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1493 - val_loss: 9.4402\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3149 - val_loss: 10.1105\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1007 - val_loss: 10.1008\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2120 - val_loss: 9.4942\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1572 - val_loss: 10.2573\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2018 - val_loss: 10.2843\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0695 - val_loss: 9.7183\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2415 - val_loss: 9.7958\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4058 - val_loss: 10.1230\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.0845 - val_loss: 9.1986\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9930 - val_loss: 9.4742\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3795 - val_loss: 10.0522\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3966 - val_loss: 9.2255\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2795 - val_loss: 9.4154\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4922 - val_loss: 10.6200\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3635 - val_loss: 9.5770\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0415 - val_loss: 9.5986\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2608 - val_loss: 11.7470\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3948 - val_loss: 11.4993\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8518 - val_loss: 11.0215\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4362 - val_loss: 9.1777\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3594 - val_loss: 11.1533\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3436 - val_loss: 9.4278\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0138 - val_loss: 9.3643\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0916 - val_loss: 9.0274\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6644 - val_loss: 11.1476\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2957 - val_loss: 12.0015\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3084 - val_loss: 10.3065\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.5959 - val_loss: 9.8726\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2645 - val_loss: 9.6985\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0118 - val_loss: 10.9998\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7199 - val_loss: 10.4390\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3134 - val_loss: 10.3073\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1718 - val_loss: 9.3375\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1381 - val_loss: 9.9965\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3022 - val_loss: 9.0083\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9336 - val_loss: 10.3462\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.1549 - val_loss: 11.8168\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3795 - val_loss: 9.2604\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0557 - val_loss: 9.3839\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1614 - val_loss: 11.4228\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.2028 - val_loss: 9.3507\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5632 - val_loss: 9.3222\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4949 - val_loss: 9.8717\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3323 - val_loss: 11.3854\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3625 - val_loss: 9.4024\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1557 - val_loss: 9.7183\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0445 - val_loss: 10.0253\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.3470 - val_loss: 9.1276\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4902 - val_loss: 9.7552\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0422 - val_loss: 9.7384\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2402 - val_loss: 10.1145\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1625 - val_loss: 10.1727\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1884 - val_loss: 9.4245\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0783 - val_loss: 9.5616\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.9180 - val_loss: 9.5190\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2609 - val_loss: 10.0803\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6713 - val_loss: 9.7574\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3535 - val_loss: 9.3647\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6118 - val_loss: 9.9119\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1845 - val_loss: 9.9741\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.0096 - val_loss: 9.6660\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1112 - val_loss: 11.8681\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4288 - val_loss: 9.5294\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0483 - val_loss: 9.9668\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3991 - val_loss: 8.9728\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2733 - val_loss: 9.2955\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2096 - val_loss: 9.7671\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3107 - val_loss: 9.8714\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7240 - val_loss: 9.2935\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3891 - val_loss: 9.1962\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0690 - val_loss: 9.5224\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0046 - val_loss: 9.6143\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1449 - val_loss: 9.1665\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.0699 - val_loss: 9.3648\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8920 - val_loss: 9.1223\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0822 - val_loss: 9.8218\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2324 - val_loss: 8.9611\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0836 - val_loss: 9.6384\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.9838 - val_loss: 9.3206\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 128us/step - loss: 8.0905 - val_loss: 9.4577\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0335 - val_loss: 9.3694\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0857 - val_loss: 9.4939\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.0069 - val_loss: 9.2734\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0038 - val_loss: 9.3585\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0925 - val_loss: 9.4143\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.0120 - val_loss: 9.9552\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5022 - val_loss: 9.4637\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.4181 - val_loss: 11.3846\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8430 - val_loss: 10.2936\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.5091 - val_loss: 9.5314\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3935 - val_loss: 9.6089\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.2731 - val_loss: 9.5911\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.2992 - val_loss: 9.1935\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9834 - val_loss: 9.7818\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2975 - val_loss: 9.3323\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.3139 - val_loss: 9.4254\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.2947 - val_loss: 10.5283\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2504 - val_loss: 9.7237\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2811 - val_loss: 10.3489\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1460 - val_loss: 9.9840\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0456 - val_loss: 9.1498\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0457 - val_loss: 9.6160\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.799 - 0s 81us/step - loss: 8.0743 - val_loss: 10.0229\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.4401 - val_loss: 9.2200\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.1911 - val_loss: 9.2127\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0235 - val_loss: 10.2910\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0301 - val_loss: 9.4474\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3523 - val_loss: 10.7208\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2109 - val_loss: 9.6332\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9927 - val_loss: 9.4731\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9615 - val_loss: 9.5387\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9559 - val_loss: 9.3076\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9309 - val_loss: 9.3886\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.0574 - val_loss: 9.6825\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.3002 - val_loss: 9.5925\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.0847 - val_loss: 9.1625\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0102 - val_loss: 10.9936\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6277 - val_loss: 9.6493\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5525 - val_loss: 10.3818\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0259 - val_loss: 9.3195\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2292 - val_loss: 9.8913\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3026 - val_loss: 9.7331\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.2138 - val_loss: 9.0408\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3251 - val_loss: 9.2069\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5741 - val_loss: 9.4610\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9856 - val_loss: 9.4468\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0303 - val_loss: 9.4554\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2647 - val_loss: 9.1139\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3273 - val_loss: 9.5600\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2191 - val_loss: 9.8694\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.0854 - val_loss: 10.1540\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1989 - val_loss: 9.9455\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9651 - val_loss: 9.6084\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0728 - val_loss: 9.8195\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1723 - val_loss: 9.1905\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5549 - val_loss: 12.1195\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2622 - val_loss: 9.2596\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7079 - val_loss: 9.2537\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0780 - val_loss: 9.9712\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.1443 - val_loss: 10.5614\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4144 - val_loss: 9.2361\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3185 - val_loss: 9.4750\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2322 - val_loss: 10.0994\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1929 - val_loss: 10.5023\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4718 - val_loss: 8.9873\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.1896 - val_loss: 10.6350\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1949 - val_loss: 9.9007\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.4914 - val_loss: 9.3975\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4171 - val_loss: 9.8440\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1675 - val_loss: 8.9485\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7716 - val_loss: 9.7401\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1253 - val_loss: 9.2916\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9867 - val_loss: 9.6586\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.2763 - val_loss: 9.1010\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2042 - val_loss: 10.0127\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1120 - val_loss: 9.2659\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0438 - val_loss: 10.2612\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.1004 - val_loss: 9.2591\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0941 - val_loss: 9.3927\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0137 - val_loss: 9.6358\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9852 - val_loss: 9.3495\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.3437 - val_loss: 9.0416\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 7.9403 - val_loss: 9.1386\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.0755 - val_loss: 9.5774\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 7.9923 - val_loss: 9.5712\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3546 - val_loss: 8.9223\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4447 - val_loss: 9.4830\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0731 - val_loss: 8.8406\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3210 - val_loss: 10.4542\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.2800 - val_loss: 9.3368\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2828 - val_loss: 9.1876\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.5805 - val_loss: 10.2582\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.1385 - val_loss: 9.3785\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0779 - val_loss: 9.4385\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1803 - val_loss: 9.1654\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1929 - val_loss: 9.4652\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0928 - val_loss: 8.9313\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0372 - val_loss: 9.2436\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.0088 - val_loss: 14.8849\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3570 - val_loss: 8.9383\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2126 - val_loss: 9.1350\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.4456 - val_loss: 8.9530\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.0612 - val_loss: 9.3880\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1947 - val_loss: 9.0975\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1880 - val_loss: 9.0012\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3954 - val_loss: 12.5860\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8199 - val_loss: 9.7741\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.9146 - val_loss: 9.2653\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2373 - val_loss: 9.6238\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.2338 - val_loss: 9.0593\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3466 - val_loss: 9.8493\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0835 - val_loss: 10.2509\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.5194 - val_loss: 9.6783\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 7.9978 - val_loss: 9.4344\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 7.9751 - val_loss: 10.3213\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.0863 - val_loss: 8.9706\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1241 - val_loss: 9.5111\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2324 - val_loss: 9.2352\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4086 - val_loss: 10.9877\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3606 - val_loss: 9.0487\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0639 - val_loss: 9.2705\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0742 - val_loss: 10.6441\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3683 - val_loss: 9.8048\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5711 - val_loss: 9.2550\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.2923 - val_loss: 10.1114\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1582 - val_loss: 9.8716\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.1190 - val_loss: 9.5295\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.9576 - val_loss: 9.3327\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1678 - val_loss: 10.4639\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.1096 - val_loss: 10.2543\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1724 - val_loss: 9.7887\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0855 - val_loss: 8.9587\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1421 - val_loss: 9.5087\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2025 - val_loss: 9.4070\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2269 - val_loss: 9.1249\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.1775 - val_loss: 10.6029\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6851 - val_loss: 9.8710\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3720 - val_loss: 8.9328\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2724 - val_loss: 9.0014\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.1778 - val_loss: 9.2118\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0406 - val_loss: 9.5693\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3825 - val_loss: 9.7631\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.0408 - val_loss: 9.5119\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2466 - val_loss: 9.5065\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 7.9361 - val_loss: 9.6847\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8426 - val_loss: 9.2505\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3678 - val_loss: 9.6305\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6975 - val_loss: 10.3910\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7696 - val_loss: 9.8246\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0505 - val_loss: 9.3855\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3978 - val_loss: 9.1158\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 7.9960 - val_loss: 9.7168\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1127 - val_loss: 9.3594\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1684 - val_loss: 9.0657\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9083 - val_loss: 11.1533\n",
      "8.789359480933806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.810115  ,  4.0667405 ,  0.16914245,  3.162663  , -0.7241936 ],\n",
       "        [-0.5076961 , -0.20897667,  0.19581285, -0.06318165, -1.4072537 ],\n",
       "        [-0.40682298,  0.7359196 ,  0.3011046 , -0.0130247 , -1.5635636 ],\n",
       "        [-0.0192558 , -0.13605331, -0.1302032 , -0.06391427,  0.25787455],\n",
       "        [ 0.29347178,  0.33252844,  0.18295312,  2.2943096 ,  0.28922522]],\n",
       "       dtype=float32),\n",
       " array([ 1.2996395 ,  4.9890785 , -1.3994079 ,  4.6891246 , -0.70023715],\n",
       "       dtype=float32),\n",
       " array([[ 0.20652682, -1.0497646 ,  1.0188239 ,  0.85498446,  1.1505967 ],\n",
       "        [-3.4394212 ,  2.8564396 , -3.1773133 , -2.0947242 , -2.672332  ],\n",
       "        [ 1.842096  , -2.9491358 ,  1.4664241 ,  2.847502  ,  2.6628861 ],\n",
       "        [-3.049095  ,  2.6243596 , -3.0126631 , -3.0480802 , -3.2229526 ],\n",
       "        [-0.31583336, -0.19730633, -1.0590692 , -1.187005  , -0.178946  ]],\n",
       "       dtype=float32),\n",
       " array([-2.5857222,  2.273334 , -2.3287945, -2.523248 , -2.6682775],\n",
       "       dtype=float32),\n",
       " array([[-2.4911938],\n",
       "        [ 3.0400937],\n",
       "        [-2.7434263],\n",
       "        [-2.2893348],\n",
       "        [-2.2098413]], dtype=float32),\n",
       " array([2.109121], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_1(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure1_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 189us/step - loss: 7268.8955 - val_loss: 588.2317\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 171.5133 - val_loss: 51.0742\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 36.1153 - val_loss: 28.7956\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 27.9141 - val_loss: 28.1558\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 26.3689 - val_loss: 27.8311\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 25.7804 - val_loss: 27.6446\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 24.8400 - val_loss: 27.9430\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.8831 - val_loss: 26.6230\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.6835 - val_loss: 26.5547\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 23.3892 - val_loss: 26.6928\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.4963 - val_loss: 26.9269\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.0521 - val_loss: 27.0763\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.9279 - val_loss: 25.7595\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.9285 - val_loss: 27.1700\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.9478 - val_loss: 27.1131\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.6686 - val_loss: 26.1799\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.7551 - val_loss: 26.0884\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.8731 - val_loss: 25.7323\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.6980 - val_loss: 27.2263\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.8437 - val_loss: 25.7628\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.4267 - val_loss: 26.4156\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.7230 - val_loss: 26.8903\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.9830 - val_loss: 26.4859\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.5488 - val_loss: 25.9582\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4617 - val_loss: 29.2406\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.1448 - val_loss: 26.3411\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5624 - val_loss: 27.1721\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.6274 - val_loss: 26.9594\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2783 - val_loss: 25.8910\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5262 - val_loss: 27.2622\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 21.47 - 0s 86us/step - loss: 22.3850 - val_loss: 26.4312\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2831 - val_loss: 26.9398\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.7355 - val_loss: 26.2276\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.4190 - val_loss: 27.1405\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.5932 - val_loss: 27.2269\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.4361 - val_loss: 25.7350\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.3832 - val_loss: 27.7297\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.0199 - val_loss: 26.0096\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.4693 - val_loss: 26.2941\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.8700 - val_loss: 26.2228\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.2405 - val_loss: 26.3483\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.0062 - val_loss: 25.9148\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.2993 - val_loss: 26.3475\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.1661 - val_loss: 26.4714\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1248 - val_loss: 25.8933\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0461 - val_loss: 25.8855\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0776 - val_loss: 25.8702\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.9754 - val_loss: 25.9280\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.0665 - val_loss: 26.3060\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.5070 - val_loss: 25.6741\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2058 - val_loss: 26.9769\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0131 - val_loss: 25.9373\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7429 - val_loss: 27.4554\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 22.2518 - val_loss: 25.9561\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6049 - val_loss: 25.7415\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8115 - val_loss: 26.1938\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.6990 - val_loss: 25.7595\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9845 - val_loss: 25.7392\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9219 - val_loss: 25.8388\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5112 - val_loss: 26.0888\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.5480 - val_loss: 25.9792\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.2038 - val_loss: 25.7439\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.1238 - val_loss: 25.6878\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 20.8304 - val_loss: 25.5542\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.0585 - val_loss: 25.7773\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.6695 - val_loss: 25.5453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.6521 - val_loss: 26.3383\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 20.7552 - val_loss: 25.5481\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.8277 - val_loss: 25.1402\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.1330 - val_loss: 24.8556\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.9762 - val_loss: 24.8127\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.1916 - val_loss: 24.3869\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.4102 - val_loss: 23.8619\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.3077 - val_loss: 24.0906\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.2462 - val_loss: 23.7728\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.0007 - val_loss: 23.5649\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.9305 - val_loss: 22.6350\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.1641 - val_loss: 22.9724\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4331 - val_loss: 22.3484\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.9448 - val_loss: 22.9733\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.8750 - val_loss: 22.1952\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 17.7003 - val_loss: 21.2835\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.5562 - val_loss: 21.7207\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6068 - val_loss: 22.1915\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8474 - val_loss: 21.8592\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.2474 - val_loss: 20.2667\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1128 - val_loss: 20.5794\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9702 - val_loss: 20.7727\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.1936 - val_loss: 20.8145\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 17.3051 - val_loss: 19.6954\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.2365 - val_loss: 20.5710\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.0599 - val_loss: 19.9668\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.1734 - val_loss: 20.1202\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2066 - val_loss: 19.8433\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.4061 - val_loss: 19.0761\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.1526 - val_loss: 19.1954\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.2850 - val_loss: 20.8524\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.9625 - val_loss: 19.1847\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.1842 - val_loss: 19.1857\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.0654 - val_loss: 18.8171\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.8053 - val_loss: 18.8382\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0051 - val_loss: 18.4572\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.0124 - val_loss: 18.8988\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.5145 - val_loss: 17.6489\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.8405 - val_loss: 17.9138\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.3051 - val_loss: 19.3983\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 15.3065 - val_loss: 17.7295\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.3886 - val_loss: 18.9918\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.1366 - val_loss: 18.6933\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.3618 - val_loss: 17.6573\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 15.5808 - val_loss: 20.3012\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.0658 - val_loss: 17.3828\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.4738 - val_loss: 18.4467\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.8388 - val_loss: 19.4841\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.2106 - val_loss: 17.4548\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.9680 - val_loss: 17.8944\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.0718 - val_loss: 17.5938\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.6537 - val_loss: 17.6707\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8163 - val_loss: 17.7415\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.9787 - val_loss: 17.6298\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.7956 - val_loss: 18.2872\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.0925 - val_loss: 17.3005\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5048 - val_loss: 18.1470\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.1120 - val_loss: 18.2542\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.9772 - val_loss: 18.5724\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.3443 - val_loss: 16.7057\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.4083 - val_loss: 18.1292\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.7794 - val_loss: 18.0227\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.0514 - val_loss: 17.6752\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.1732 - val_loss: 16.8427\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.8869 - val_loss: 16.6889\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.4815 - val_loss: 17.1100\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7907 - val_loss: 16.8972\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.1202 - val_loss: 17.6273\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.2835 - val_loss: 18.9970\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.5003 - val_loss: 17.8998\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7648 - val_loss: 16.4300\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6391 - val_loss: 16.5130\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6483 - val_loss: 15.6298\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8059 - val_loss: 16.6176\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7200 - val_loss: 18.6112\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.1983 - val_loss: 17.2161\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.4008 - val_loss: 16.6903\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0282 - val_loss: 17.6244\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6634 - val_loss: 15.1846\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.8961 - val_loss: 16.6296\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.8617 - val_loss: 15.8365\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.2763 - val_loss: 15.7743\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.9562 - val_loss: 17.5477\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5139 - val_loss: 14.9249\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.3383 - val_loss: 16.2471\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.4261 - val_loss: 15.4721\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.3936 - val_loss: 15.8505\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1309 - val_loss: 14.6789\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0311 - val_loss: 15.6033\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.3144 - val_loss: 18.5155\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.2673 - val_loss: 15.8151\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1633 - val_loss: 14.6572\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.4091 - val_loss: 15.1604\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7439 - val_loss: 14.2042\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.6475 - val_loss: 15.0139\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1492 - val_loss: 16.1418\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.1389 - val_loss: 16.7802\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.4388 - val_loss: 14.7806\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.2781 - val_loss: 13.8668\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9732 - val_loss: 16.2425\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2814 - val_loss: 14.6054\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1868 - val_loss: 14.4096\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4934 - val_loss: 15.0086\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.7598 - val_loss: 15.5221\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3816 - val_loss: 14.5441\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0022 - val_loss: 14.2960\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.1310 - val_loss: 13.3859\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.8068 - val_loss: 15.8616\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1041 - val_loss: 13.3389\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.0586 - val_loss: 13.5529\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.9598 - val_loss: 13.5977\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.7284 - val_loss: 15.0117\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.0528 - val_loss: 13.8725\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.7534 - val_loss: 13.2695\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.3793 - val_loss: 13.7972\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.2691 - val_loss: 13.7041\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.6782 - val_loss: 12.5011\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.4823 - val_loss: 13.1840\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.5124 - val_loss: 13.6955\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.6070 - val_loss: 13.5698\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.2385 - val_loss: 15.5254\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5667 - val_loss: 14.9756\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.9730 - val_loss: 13.9964\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.1139 - val_loss: 13.6762\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.3349 - val_loss: 13.1998\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2788 - val_loss: 12.2545\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.1668 - val_loss: 14.3027\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.3342 - val_loss: 13.8461\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4497 - val_loss: 12.3037\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8540 - val_loss: 12.4690\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3457 - val_loss: 12.8701\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9572 - val_loss: 12.8052\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0634 - val_loss: 14.9063\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0652 - val_loss: 11.9096\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0659 - val_loss: 14.4786\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0288 - val_loss: 12.6963\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.5659 - val_loss: 12.2748\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5252 - val_loss: 12.7604\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0587 - val_loss: 13.0646\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9937 - val_loss: 12.1741\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2777 - val_loss: 12.5721\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9267 - val_loss: 14.3734\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.5034 - val_loss: 13.2460\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7110 - val_loss: 12.2888\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.5583 - val_loss: 12.6123\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.6786 - val_loss: 12.3801\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.1848 - val_loss: 12.6545\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2178 - val_loss: 11.4414\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3556 - val_loss: 11.7456\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 9.4976 - val_loss: 11.8766\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.2515 - val_loss: 12.7849\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5771 - val_loss: 13.0380\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3011 - val_loss: 12.1941\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2599 - val_loss: 12.2450\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6466 - val_loss: 12.9941\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7286 - val_loss: 15.0525\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9976 - val_loss: 11.6805\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8784 - val_loss: 11.8130\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4565 - val_loss: 11.6692\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5974 - val_loss: 11.5779\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3572 - val_loss: 11.1310\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3957 - val_loss: 11.8099\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2179 - val_loss: 11.6497\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8116 - val_loss: 12.4133\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3944 - val_loss: 11.8288\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.1135 - val_loss: 12.8151\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5858 - val_loss: 11.5704\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6380 - val_loss: 11.4209\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3950 - val_loss: 13.8571\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3243 - val_loss: 11.2671\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2019 - val_loss: 11.8965\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0366 - val_loss: 11.5228\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1011 - val_loss: 12.2022\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2422 - val_loss: 10.8444\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0404 - val_loss: 12.0748\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1337 - val_loss: 11.5463\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1701 - val_loss: 11.1515\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7895 - val_loss: 11.9135\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1552 - val_loss: 11.5884\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2447 - val_loss: 11.6855\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1209 - val_loss: 11.8781\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0571 - val_loss: 11.2554\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2045 - val_loss: 10.9824\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3292 - val_loss: 13.3159\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0879 - val_loss: 10.7342\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1188 - val_loss: 11.2465\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8453 - val_loss: 10.5919\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9279 - val_loss: 10.5305\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9377 - val_loss: 14.2657\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2153 - val_loss: 12.0280\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8707 - val_loss: 11.7543\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5520 - val_loss: 11.4098\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4537 - val_loss: 10.7521\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8312 - val_loss: 11.6394\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9718 - val_loss: 10.7223\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9966 - val_loss: 10.6653\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7104 - val_loss: 12.2415\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.3368 - val_loss: 11.0410\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7774 - val_loss: 10.8936\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.0259 - val_loss: 11.0321\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.6675 - val_loss: 11.7451\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.9013 - val_loss: 11.1493\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0833 - val_loss: 10.9509\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8312 - val_loss: 12.4763\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9104 - val_loss: 10.7274\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0036 - val_loss: 10.6933\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0211 - val_loss: 11.2394\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1484 - val_loss: 11.6863\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1313 - val_loss: 10.7636\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8023 - val_loss: 10.9627\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5295 - val_loss: 10.6351\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9721 - val_loss: 10.8058\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0676 - val_loss: 11.0257\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9371 - val_loss: 10.7958\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0069 - val_loss: 11.0739\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8232 - val_loss: 10.6666\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7643 - val_loss: 10.9184\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0399 - val_loss: 10.6121\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9587 - val_loss: 10.6902\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.9000 - val_loss: 10.9251\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.8882 - val_loss: 10.1551\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1588 - val_loss: 11.8107\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6521 - val_loss: 11.0437\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8631 - val_loss: 11.4291\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8485 - val_loss: 10.6524\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2692 - val_loss: 10.9554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4253 - val_loss: 11.8808\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.9571 - val_loss: 10.9171\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7015 - val_loss: 11.1073\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7883 - val_loss: 10.5478\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6160 - val_loss: 11.3605\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1475 - val_loss: 10.0956\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5105 - val_loss: 11.5995\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9146 - val_loss: 11.6933\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6635 - val_loss: 10.9313\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7972 - val_loss: 12.7049\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1006 - val_loss: 10.3592\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.0230 - val_loss: 11.2966\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5091 - val_loss: 10.5531\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9818 - val_loss: 10.1041\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9288 - val_loss: 10.6631\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9697 - val_loss: 10.4880\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6949 - val_loss: 10.5375\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5681 - val_loss: 10.6571\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6764 - val_loss: 10.8891\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9579 - val_loss: 10.3268\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7337 - val_loss: 12.0015\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6265 - val_loss: 10.6458\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7026 - val_loss: 10.2169\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7902 - val_loss: 10.1093\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.7111 - val_loss: 10.4594\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1201 - val_loss: 10.5435\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5932 - val_loss: 10.3687\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7615 - val_loss: 10.2636\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9605 - val_loss: 10.4495\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9266 - val_loss: 11.2521\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3788 - val_loss: 11.0011\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7078 - val_loss: 10.2714\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7392 - val_loss: 10.0768\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9041 - val_loss: 10.1241\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8661 - val_loss: 10.7478\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9453 - val_loss: 10.3916\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8968 - val_loss: 10.0963\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8088 - val_loss: 10.9696\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0976 - val_loss: 11.3027\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4074 - val_loss: 10.1737\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.5488 - val_loss: 10.4088\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5580 - val_loss: 11.0169\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7112 - val_loss: 10.5209\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6668 - val_loss: 10.5282\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6232 - val_loss: 10.0278\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5456 - val_loss: 11.1845\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8085 - val_loss: 10.1781\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8941 - val_loss: 10.6349\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5999 - val_loss: 11.0250\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4708 - val_loss: 11.4437\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0860 - val_loss: 9.9075\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6881 - val_loss: 9.9129\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6084 - val_loss: 12.1012\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0065 - val_loss: 10.2548\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9354 - val_loss: 10.3085\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7553 - val_loss: 11.5633\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5191 - val_loss: 10.1687\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5718 - val_loss: 10.5839\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3590 - val_loss: 10.1504\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7464 - val_loss: 10.4727\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6906 - val_loss: 11.3544\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4469 - val_loss: 10.3559\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7335 - val_loss: 10.3244\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6761 - val_loss: 10.8098\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4941 - val_loss: 10.0747\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.5605 - val_loss: 10.0378\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3646 - val_loss: 10.0640\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7035 - val_loss: 10.3490\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4152 - val_loss: 10.0118\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5237 - val_loss: 10.4088\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5903 - val_loss: 10.6606\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6764 - val_loss: 9.8103\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6024 - val_loss: 13.5856\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1238 - val_loss: 10.5209\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0285 - val_loss: 9.9149\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6378 - val_loss: 10.7284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.5584 - val_loss: 9.9881\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5845 - val_loss: 10.6858\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5179 - val_loss: 10.4205\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3555 - val_loss: 10.4197\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3746 - val_loss: 10.6274\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5066 - val_loss: 11.4089\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7331 - val_loss: 10.1713\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5584 - val_loss: 10.3089\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6970 - val_loss: 10.2790\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3256 - val_loss: 10.3298\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4516 - val_loss: 11.1375\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6292 - val_loss: 9.6586\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7298 - val_loss: 9.8762\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1979 - val_loss: 12.3733\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9558 - val_loss: 10.6647\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4020 - val_loss: 10.1547\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6725 - val_loss: 9.9038\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6248 - val_loss: 10.4555\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4282 - val_loss: 10.6292\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7171 - val_loss: 10.5553\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1502 - val_loss: 10.9344\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7205 - val_loss: 10.0156\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5736 - val_loss: 9.7754\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9305 - val_loss: 10.2828\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4431 - val_loss: 10.2189\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8685 - val_loss: 9.8777\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4812 - val_loss: 9.8841\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7305 - val_loss: 9.8672\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6024 - val_loss: 9.9205\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5274 - val_loss: 10.3195\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2181 - val_loss: 10.5389\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6910 - val_loss: 10.3713\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5630 - val_loss: 10.9647\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3937 - val_loss: 10.3768\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5120 - val_loss: 9.8634\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3762 - val_loss: 9.6075\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4965 - val_loss: 10.6953\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8507 - val_loss: 10.9103\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6524 - val_loss: 10.2615\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8880 - val_loss: 9.9101\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1682 - val_loss: 11.5921\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4029 - val_loss: 11.4605\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6709 - val_loss: 10.9421\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2515 - val_loss: 10.0400\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4364 - val_loss: 10.1964\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3472 - val_loss: 10.3494\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7815 - val_loss: 9.8628\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5298 - val_loss: 9.8747\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4445 - val_loss: 10.5247\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4135 - val_loss: 9.8148\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4508 - val_loss: 10.1893\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7041 - val_loss: 10.0480\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5353 - val_loss: 10.9175\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7739 - val_loss: 10.2038\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7384 - val_loss: 9.9562\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5130 - val_loss: 9.9770\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3702 - val_loss: 9.9745\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4249 - val_loss: 9.6243\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3179 - val_loss: 9.7957\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3133 - val_loss: 9.7488\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3242 - val_loss: 10.6769\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6761 - val_loss: 9.9643\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5387 - val_loss: 11.6377\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1795 - val_loss: 9.9838\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3663 - val_loss: 10.7297\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4115 - val_loss: 10.0560\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6188 - val_loss: 11.3963\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5285 - val_loss: 12.0723\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4840 - val_loss: 10.3910\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1837 - val_loss: 10.1529\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2860 - val_loss: 9.7861\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5755 - val_loss: 9.8001\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4593 - val_loss: 9.5865\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7977 - val_loss: 9.8291\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8455 - val_loss: 10.4569\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8755 - val_loss: 9.8460\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2529 - val_loss: 10.7293\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8048 - val_loss: 11.5045\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4591 - val_loss: 11.4325\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5154 - val_loss: 9.6831\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4572 - val_loss: 9.6241\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4110 - val_loss: 9.9761\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3024 - val_loss: 10.2801\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5238 - val_loss: 9.7283\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8040 - val_loss: 10.9402\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2077 - val_loss: 9.8353\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6511 - val_loss: 10.3616\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2324 - val_loss: 10.2314\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7646 - val_loss: 11.7479\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9333 - val_loss: 9.7441\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5665 - val_loss: 10.3767\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3782 - val_loss: 9.9200\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1957 - val_loss: 9.5058\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7773 - val_loss: 9.5184\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4241 - val_loss: 11.9036\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3637 - val_loss: 10.1297\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4433 - val_loss: 9.9586\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4064 - val_loss: 9.7950\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4170 - val_loss: 9.4782\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3556 - val_loss: 9.5727\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5110 - val_loss: 11.0367\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0692 - val_loss: 9.8053\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3774 - val_loss: 10.4055\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4812 - val_loss: 10.8681\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4280 - val_loss: 9.4254\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5732 - val_loss: 13.3495\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0579 - val_loss: 10.5232\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4358 - val_loss: 10.2362\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4644 - val_loss: 9.3722\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5684 - val_loss: 10.4574\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4947 - val_loss: 9.9794\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4631 - val_loss: 10.6296\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6494 - val_loss: 9.7234\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2255 - val_loss: 11.5573\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3452 - val_loss: 11.4928\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3331 - val_loss: 10.9965\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.4433 - val_loss: 9.5514\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1866 - val_loss: 9.5931\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3652 - val_loss: 10.3982\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0606 - val_loss: 9.9639\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4285 - val_loss: 9.8804\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3805 - val_loss: 10.2014\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6932 - val_loss: 10.0836\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7603 - val_loss: 9.6843\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4297 - val_loss: 9.5062\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8659 - val_loss: 9.8312\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5783 - val_loss: 10.2118\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8634 - val_loss: 9.5553\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3649 - val_loss: 9.5587\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2104 - val_loss: 9.6936\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2483 - val_loss: 9.2666\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6494 - val_loss: 11.0550\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6920 - val_loss: 9.8484\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4966 - val_loss: 9.3778\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2364 - val_loss: 9.9446\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6923 - val_loss: 11.8514\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9240 - val_loss: 10.3418\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9609 - val_loss: 12.7403\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5069 - val_loss: 9.8907\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3475 - val_loss: 11.2531\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8135 - val_loss: 10.5010\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4205 - val_loss: 10.5476\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6005 - val_loss: 9.8852\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.1033 - val_loss: 9.7715\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2635 - val_loss: 9.5230\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5313 - val_loss: 10.5790\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3602 - val_loss: 9.8935\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0892 - val_loss: 9.6598\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1838 - val_loss: 9.4146\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4190 - val_loss: 10.1725\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7431 - val_loss: 9.7621\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.5884 - val_loss: 9.4955\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1990 - val_loss: 11.2331\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5745 - val_loss: 9.8550\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4584 - val_loss: 10.0217\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6494 - val_loss: 10.6696\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3300 - val_loss: 9.3969\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1048 - val_loss: 9.4560\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5925 - val_loss: 9.5892\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2033 - val_loss: 9.7522\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.2281 - val_loss: 10.4756\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.5480 - val_loss: 9.7931\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1522 - val_loss: 9.5327\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2677 - val_loss: 11.4076\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.7628 - val_loss: 9.6478\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.6812 - val_loss: 9.7935\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.7191 - val_loss: 10.5538\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3067 - val_loss: 9.3123\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1026 - val_loss: 10.1557\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0701 - val_loss: 9.9524\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3214 - val_loss: 9.5112\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1923 - val_loss: 9.9215\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3831 - val_loss: 9.8469\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4242 - val_loss: 10.0158\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2848 - val_loss: 9.8659\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2220 - val_loss: 10.5741\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1776 - val_loss: 10.1576\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7574 - val_loss: 9.1781\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6191 - val_loss: 9.2672\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2679 - val_loss: 9.5632\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2145 - val_loss: 11.0903\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3069 - val_loss: 9.4837\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2273 - val_loss: 9.5656\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1236 - val_loss: 9.5748\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1738 - val_loss: 9.9182\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0716 - val_loss: 9.8572\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5617 - val_loss: 9.3390\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2529 - val_loss: 9.4481\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8842 - val_loss: 9.3802\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1298 - val_loss: 9.8337\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4246 - val_loss: 9.5609\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3487 - val_loss: 9.5854\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7564 - val_loss: 9.4960\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2860 - val_loss: 10.0976\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1111 - val_loss: 9.9229\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6599 - val_loss: 10.6113\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7971 - val_loss: 11.0442\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3416 - val_loss: 9.5125\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6587 - val_loss: 10.3007\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2182 - val_loss: 9.6170\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6715 - val_loss: 9.6100\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5340 - val_loss: 10.2139\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2125 - val_loss: 10.5232\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8519 - val_loss: 10.1818\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6090 - val_loss: 11.5606\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2709 - val_loss: 9.3835\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2297 - val_loss: 9.5009\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4624 - val_loss: 10.3225\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3230 - val_loss: 13.8389\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3397 - val_loss: 9.7733\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2808 - val_loss: 9.6564\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3161 - val_loss: 10.9889\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7095 - val_loss: 10.5921\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6263 - val_loss: 9.2099\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3373 - val_loss: 9.9246\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0181 - val_loss: 10.3716\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1708 - val_loss: 9.5614\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5982 - val_loss: 9.3951\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1185 - val_loss: 9.7231\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0809 - val_loss: 10.7179\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3306 - val_loss: 10.0233\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3210 - val_loss: 9.3255\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3379 - val_loss: 9.4366\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3798 - val_loss: 9.8868\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2966 - val_loss: 9.6167\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3877 - val_loss: 9.8389\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6894 - val_loss: 10.5157\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3517 - val_loss: 9.3575\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0294 - val_loss: 9.7755\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6472 - val_loss: 9.6027\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3281 - val_loss: 10.3527\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3002 - val_loss: 9.4500\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3381 - val_loss: 9.2634\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4785 - val_loss: 12.0601\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7376 - val_loss: 10.0453\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1002 - val_loss: 9.4916\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4604 - val_loss: 9.2142\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0616 - val_loss: 9.6215\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2414 - val_loss: 10.4314\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7612 - val_loss: 10.8388\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8540 - val_loss: 10.3585\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2438 - val_loss: 9.4434\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0921 - val_loss: 9.8671\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3532 - val_loss: 9.2028\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6471 - val_loss: 10.7669\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2127 - val_loss: 9.2040\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1743 - val_loss: 10.0688\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0828 - val_loss: 11.9109\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5113 - val_loss: 10.0320\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2516 - val_loss: 9.8289\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2364 - val_loss: 11.8836\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6951 - val_loss: 9.1607\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3515 - val_loss: 9.4511\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2919 - val_loss: 10.2282\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6577 - val_loss: 9.8259\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5304 - val_loss: 9.2373\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1504 - val_loss: 11.8551\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6372 - val_loss: 9.8791\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2937 - val_loss: 9.4659\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5139 - val_loss: 10.0066\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8999 - val_loss: 9.7039\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5641 - val_loss: 9.7897\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4353 - val_loss: 10.2388\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1980 - val_loss: 9.4363\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0920 - val_loss: 9.3416\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4753 - val_loss: 10.0857\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3268 - val_loss: 9.5429\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 130us/step - loss: 8.2192 - val_loss: 11.2464\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4425 - val_loss: 9.6793\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2299 - val_loss: 9.7995\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.5919 - val_loss: 11.5053\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2605 - val_loss: 10.7993\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4166 - val_loss: 10.5188\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7331 - val_loss: 9.0588\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2555 - val_loss: 10.1371\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1161 - val_loss: 9.6346\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5689 - val_loss: 10.2878\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3285 - val_loss: 10.1621\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2868 - val_loss: 11.2228\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3292 - val_loss: 9.3037\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0901 - val_loss: 9.8796\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4937 - val_loss: 9.8506\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0998 - val_loss: 9.1727\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1630 - val_loss: 9.3225\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0067 - val_loss: 9.1786\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2453 - val_loss: 9.2652\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2247 - val_loss: 10.0374\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3057 - val_loss: 12.1989\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5537 - val_loss: 10.1928\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4712 - val_loss: 9.7756\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2880 - val_loss: 9.7634\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3587 - val_loss: 10.1227\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5870 - val_loss: 11.1862\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3696 - val_loss: 9.5533\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2994 - val_loss: 9.1519\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7184 - val_loss: 11.3968\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4610 - val_loss: 9.8387\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3291 - val_loss: 9.9682\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5420 - val_loss: 9.5011\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1316 - val_loss: 9.2525\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1908 - val_loss: 15.5903\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8589 - val_loss: 9.3551\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2365 - val_loss: 10.5983\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1726 - val_loss: 9.8804\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3691 - val_loss: 9.4560\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8956 - val_loss: 9.0683\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4351 - val_loss: 10.0939\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1947 - val_loss: 9.5235\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1164 - val_loss: 10.0751\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1304 - val_loss: 10.6593\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2735 - val_loss: 11.1339\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1859 - val_loss: 9.0727\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1558 - val_loss: 9.7328\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3481 - val_loss: 10.9481\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5699 - val_loss: 9.4914\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3120 - val_loss: 9.9268\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0737 - val_loss: 10.0208\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2818 - val_loss: 9.7990\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3287 - val_loss: 10.1203\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2888 - val_loss: 9.3259\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3704 - val_loss: 9.9604\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.5495 - 0s 86us/step - loss: 8.2568 - val_loss: 9.2402\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5144 - val_loss: 9.3681\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1709 - val_loss: 9.6130\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3029 - val_loss: 10.3153\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0852 - val_loss: 10.2921\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1902 - val_loss: 9.7554\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1267 - val_loss: 10.0303\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5678 - val_loss: 9.1978\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1892 - val_loss: 10.8669\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3912 - val_loss: 9.8222\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3548 - val_loss: 9.3726\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1485 - val_loss: 10.5304\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6261 - val_loss: 9.2018\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2037 - val_loss: 10.3139\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7783 - val_loss: 10.5818\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2212 - val_loss: 9.2830\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1975 - val_loss: 9.5903\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1196 - val_loss: 9.4131\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3717 - val_loss: 9.5381\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2000 - val_loss: 9.4231\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1665 - val_loss: 8.9415\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0455 - val_loss: 11.7287\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3003 - val_loss: 9.0964\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0656 - val_loss: 9.0267\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9577 - val_loss: 9.5931\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1199 - val_loss: 12.5068\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2740 - val_loss: 10.1572\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9574 - val_loss: 9.9784\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6790 - val_loss: 10.1484\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6353 - val_loss: 9.0619\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7734 - val_loss: 9.2024\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5038 - val_loss: 9.4077\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0682 - val_loss: 9.7318\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4547 - val_loss: 9.0422\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0412 - val_loss: 9.3318\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2058 - val_loss: 9.4593\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1678 - val_loss: 10.4613\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3885 - val_loss: 9.0445\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0287 - val_loss: 9.7353\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6422 - val_loss: 9.8138\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7526 - val_loss: 9.3028\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2974 - val_loss: 9.4108\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3940 - val_loss: 9.4991\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1312 - val_loss: 10.2098\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1245 - val_loss: 9.3279\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2208 - val_loss: 9.3648\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5221 - val_loss: 9.7861\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2704 - val_loss: 9.0560\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1019 - val_loss: 10.7621\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4653 - val_loss: 9.5644\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2080 - val_loss: 9.1470\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9863 - val_loss: 10.4139\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0598 - val_loss: 8.9337\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3963 - val_loss: 9.6623\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1969 - val_loss: 10.4856\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4551 - val_loss: 9.9171\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8959 - val_loss: 13.0361\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5412 - val_loss: 9.2709\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3368 - val_loss: 9.4905\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6099 - val_loss: 10.1828\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1231 - val_loss: 9.2433\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0632 - val_loss: 10.3897\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1482 - val_loss: 10.0361\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3104 - val_loss: 9.2326\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2089 - val_loss: 9.9834\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0537 - val_loss: 9.3207\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2231 - val_loss: 11.8079\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6433 - val_loss: 9.8077\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1252 - val_loss: 9.2967\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7352 - val_loss: 10.0537\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8988 - val_loss: 11.7732\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1663 - val_loss: 9.2679\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0060 - val_loss: 10.2427\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4612 - val_loss: 9.1821\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0854 - val_loss: 9.3640\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3766 - val_loss: 12.9269\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6020 - val_loss: 9.0814\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0515 - val_loss: 9.0793\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9982 - val_loss: 9.6559\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3956 - val_loss: 9.5832\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2363 - val_loss: 9.4608\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3910 - val_loss: 10.4263\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3533 - val_loss: 9.2742\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4106 - val_loss: 10.2724\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0890 - val_loss: 8.9541\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2701 - val_loss: 9.4185\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.7175 - val_loss: 9.4966\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9456 - val_loss: 9.1959\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.9751 - val_loss: 9.6069\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3998 - val_loss: 9.2931\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2644 - val_loss: 11.2227\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3694 - val_loss: 9.1912\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.471 - 0s 94us/step - loss: 8.0284 - val_loss: 9.9642\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4862 - val_loss: 9.4109\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0438 - val_loss: 9.1441\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0487 - val_loss: 9.4543\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5980 - val_loss: 9.6032\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3843 - val_loss: 9.7959\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7403 - val_loss: 9.2990\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6767 - val_loss: 10.1830\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0096 - val_loss: 9.2911\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8724 - val_loss: 12.8162\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3731 - val_loss: 9.3664\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1889 - val_loss: 9.3936\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1801 - val_loss: 9.5190\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2560 - val_loss: 9.6933\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5468 - val_loss: 10.8004\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5596 - val_loss: 8.9212\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9472 - val_loss: 9.0883\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1128 - val_loss: 9.0412\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3257 - val_loss: 9.7942\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2356 - val_loss: 10.5712\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3986 - val_loss: 11.8910\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2946 - val_loss: 9.2594\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0282 - val_loss: 9.2307\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0414 - val_loss: 9.5788\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0563 - val_loss: 10.1655\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1202 - val_loss: 9.7995\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3209 - val_loss: 9.0278\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2334 - val_loss: 9.9524\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3472 - val_loss: 9.7480\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0643 - val_loss: 9.2152\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0463 - val_loss: 8.9387\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0435 - val_loss: 9.6735\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2143 - val_loss: 10.0669\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3290 - val_loss: 9.3035\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1702 - val_loss: 10.0837\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3884 - val_loss: 9.9057\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 8.1063 - val_loss: 9.8560\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5247 - val_loss: 9.2059\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.7109 - val_loss: 10.4272\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2090 - val_loss: 9.0865\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6433 - val_loss: 9.8327\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5115 - val_loss: 10.3207\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4326 - val_loss: 9.5916\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1463 - val_loss: 10.6148\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6708 - val_loss: 8.9477\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3857 - val_loss: 9.8790\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0077 - val_loss: 10.3369\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5471 - val_loss: 9.9398\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2701 - val_loss: 9.1274\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4282 - val_loss: 10.0108\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1799 - val_loss: 9.1844\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7566 - val_loss: 9.3118\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3981 - val_loss: 9.2889\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2898 - val_loss: 9.0980\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0564 - val_loss: 9.3870\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0261 - val_loss: 10.1990\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7126 - val_loss: 8.9809\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2324 - val_loss: 9.7808\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9663 - val_loss: 9.3276\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2020 - val_loss: 9.6162\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2182 - val_loss: 9.4010\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0751 - val_loss: 9.4081\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3591 - val_loss: 9.3172\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3317 - val_loss: 9.1788\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9227 - val_loss: 9.3992\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9306 - val_loss: 10.1832\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2630 - val_loss: 10.1026\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3045 - val_loss: 9.0499\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0330 - val_loss: 9.4823\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9874 - val_loss: 9.2408\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9728 - val_loss: 9.0989\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2176 - val_loss: 10.4069\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9038 - val_loss: 10.0030\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.423 - 0s 86us/step - loss: 9.1853 - val_loss: 9.9761\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0421 - val_loss: 9.2488\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1497 - val_loss: 9.1748\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2652 - val_loss: 9.4284\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2253 - val_loss: 9.7699\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5725 - val_loss: 9.0726\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2713 - val_loss: 10.2599\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2435 - val_loss: 9.5258\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1604 - val_loss: 9.6419\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7230 - val_loss: 9.9487\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4301 - val_loss: 9.4036\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9346 - val_loss: 9.0852\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1427 - val_loss: 9.1165\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8422 - val_loss: 10.4618\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0804 - val_loss: 10.1384\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1060 - val_loss: 11.2214\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0988 - val_loss: 10.5542\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0912 - val_loss: 9.1279\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0225 - val_loss: 9.4229\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5063 - val_loss: 9.4083\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3094 - val_loss: 10.1603\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5583 - val_loss: 10.5302\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2693 - val_loss: 10.0653\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5211 - val_loss: 11.1221\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2933 - val_loss: 9.3527\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4419 - val_loss: 11.0112\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1452 - val_loss: 8.8747\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3188 - val_loss: 9.5037\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5920 - val_loss: 9.8629\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2130 - val_loss: 10.6124\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8940 - val_loss: 8.8093\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2025 - val_loss: 9.3327\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1435 - val_loss: 10.2076\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4663 - val_loss: 9.2061\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3930 - val_loss: 10.0929\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0575 - val_loss: 9.0594\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3749 - val_loss: 9.4801\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0136 - val_loss: 9.3395\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1867 - val_loss: 9.9903\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3198 - val_loss: 9.5386\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5002 - val_loss: 9.2310\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0590 - val_loss: 9.1260\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2975 - val_loss: 9.2147\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2439 - val_loss: 11.9406\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8880 - val_loss: 8.8222\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0674 - val_loss: 9.5608\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9967 - val_loss: 9.1428\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1330 - val_loss: 9.8152\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0844 - val_loss: 10.1372\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2976 - val_loss: 9.9998\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1942 - val_loss: 9.1891\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2006 - val_loss: 9.9403\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0829 - val_loss: 10.4732\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2750 - val_loss: 9.0838\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0495 - val_loss: 9.8408\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1637 - val_loss: 9.4891\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9875 - val_loss: 8.9578\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0548 - val_loss: 9.2143\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2785 - val_loss: 11.4662\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2875 - val_loss: 9.2421\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7853 - val_loss: 9.0015\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0368 - val_loss: 8.9873\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4942 - val_loss: 9.6586\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2213 - val_loss: 9.6459\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1479 - val_loss: 11.4606\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3124 - val_loss: 8.8465\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2025 - val_loss: 11.9512\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9761 - val_loss: 8.8626\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5038 - val_loss: 9.1024\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6540 - val_loss: 8.9080\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3309 - val_loss: 10.8775\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1226 - val_loss: 9.0881\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1790 - val_loss: 9.5382\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0943 - val_loss: 9.8423\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2236 - val_loss: 9.8006\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1222 - val_loss: 9.8832\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3387 - val_loss: 9.7770\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7312 - val_loss: 9.6374\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2409 - val_loss: 10.9905\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5628 - val_loss: 9.5712\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2236 - val_loss: 10.6935\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3841 - val_loss: 10.0064\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0893 - val_loss: 9.0273\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3257 - val_loss: 9.0775\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1480 - val_loss: 9.2675\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2338 - val_loss: 9.0066\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9794 - val_loss: 9.0129\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0414 - val_loss: 9.4782\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5318 - val_loss: 11.1724\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0028 - val_loss: 9.0786\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1255 - val_loss: 9.0291\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9587 - val_loss: 9.5712\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9714 - val_loss: 9.3358\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9342 - val_loss: 9.4959\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0753 - val_loss: 9.1172\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0308 - val_loss: 8.9838\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.6214 - val_loss: 9.2773\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6835 - val_loss: 10.8452\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4785 - val_loss: 9.1251\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2548 - val_loss: 11.5217\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3841 - val_loss: 9.1954\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4171 - val_loss: 10.4641\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0326 - val_loss: 9.5303\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3555 - val_loss: 11.2444\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0924 - val_loss: 9.4745\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1341 - val_loss: 10.7384\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7154 - val_loss: 9.0643\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3055 - val_loss: 9.6336\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3631 - val_loss: 8.9883\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9611 - val_loss: 11.0759\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1314 - val_loss: 9.0609\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9429 - val_loss: 9.5327\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0003 - val_loss: 9.7421\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1454 - val_loss: 8.8507\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8421 - val_loss: 9.1434\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0371 - val_loss: 8.9171\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9817 - val_loss: 10.4891\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3651 - val_loss: 9.7069\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5639 - val_loss: 9.1836\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5478 - val_loss: 9.4226\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2822 - val_loss: 9.3243\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9154 - val_loss: 9.0199\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0042 - val_loss: 9.6143\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7015 - val_loss: 11.5872\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2088 - val_loss: 9.3087\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0416 - val_loss: 10.4447\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1524 - val_loss: 9.2050\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1187 - val_loss: 8.8649\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1899 - val_loss: 9.4459\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1833 - val_loss: 8.9990\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3699 - val_loss: 9.5650\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4390 - val_loss: 10.5148\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0902 - val_loss: 9.6319\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1306 - val_loss: 8.8837\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2879 - val_loss: 9.8624\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0816 - val_loss: 9.1856\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5889 - val_loss: 9.2462\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3211 - val_loss: 10.1244\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1106 - val_loss: 9.5220\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3878 - val_loss: 10.6449\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1029 - val_loss: 8.8305\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0460 - val_loss: 10.2840\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1578 - val_loss: 8.8679\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2792 - val_loss: 9.7190\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1465 - val_loss: 9.3227\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1915 - val_loss: 9.8542\n",
      "8.449622314588158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-3.37024   , -1.8646775 ,  3.9129682 ,  0.7887742 ,  0.16711254],\n",
       "        [ 0.08870032,  0.51897234, -0.2069316 ,  1.6172274 ,  0.16246352],\n",
       "        [ 0.02301222,  0.41476265,  0.7276812 ,  1.7831668 ,  0.28526914],\n",
       "        [ 0.07521304,  0.01172149, -0.14392282, -0.2910428 , -0.11031183],\n",
       "        [-2.422672  , -0.30629653,  0.31992775, -0.46970576,  0.16660307]],\n",
       "       dtype=float32),\n",
       " array([-4.8658543, -1.3226448,  4.880152 ,  0.745566 , -1.1464118],\n",
       "       dtype=float32),\n",
       " array([[ 1.3732266 , -1.8020537 , -2.286285  ,  1.5273933 ,  1.7434138 ,\n",
       "          1.1416508 ,  2.2840726 ,  1.5929793 , -2.0280218 ,  1.6114348 ],\n",
       "        [-0.25837895,  0.42347786,  0.47322845, -0.96187097, -0.6763954 ,\n",
       "         -0.7621005 , -0.30140808, -0.8166893 ,  0.72778213, -0.6212528 ],\n",
       "        [-2.1621978 ,  2.522412  ,  2.075805  , -1.8423162 , -1.9116014 ,\n",
       "         -1.8033962 , -2.2672977 , -2.008114  ,  2.4968674 , -1.8061601 ],\n",
       "        [ 0.64213854, -0.7641411 ,  0.07502489, -0.3540214 ,  0.09564161,\n",
       "         -0.01587222,  0.6938604 ,  0.4204908 , -0.0587671 ,  0.5794066 ],\n",
       "        [ 1.2686046 , -1.3273523 , -1.2143794 ,  1.5177127 ,  1.7452382 ,\n",
       "          0.8276635 ,  1.4522659 ,  0.5170131 , -1.6093585 ,  1.441425  ]],\n",
       "       dtype=float32),\n",
       " array([-2.2031963,  2.278285 ,  2.2673917, -2.195193 , -2.2497764,\n",
       "        -2.1078062, -2.289865 , -2.1038287,  2.2859435, -2.213098 ],\n",
       "       dtype=float32),\n",
       " array([[-1.6342468],\n",
       "        [ 2.0981236],\n",
       "        [ 2.0391843],\n",
       "        [-1.6304826],\n",
       "        [-1.8959308],\n",
       "        [-1.5516796],\n",
       "        [-2.2019696],\n",
       "        [-1.416256 ],\n",
       "        [ 2.1583605],\n",
       "        [-1.6728582]], dtype=float32),\n",
       " array([2.4504998], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_2(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure2_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 136\n",
      "Trainable params: 136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 213us/step - loss: 6920.8399 - val_loss: 362.2699\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 96.3875 - val_loss: 34.8239\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 33.6502 - val_loss: 29.1389\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 30.4926 - val_loss: 28.3789\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 29.0651 - val_loss: 27.3903\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 28.5628 - val_loss: 27.4592\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 27.6811 - val_loss: 26.4323\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 26.9141 - val_loss: 26.3280\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 26.4007 - val_loss: 26.1580\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 26.1637 - val_loss: 26.3389\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 25.8605 - val_loss: 26.2423\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 25.9605 - val_loss: 25.8941\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 25.1181 - val_loss: 25.8462\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 25.4407 - val_loss: 25.7151\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 25.0137 - val_loss: 26.0179\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.4586 - val_loss: 26.2530\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.6456 - val_loss: 25.5201\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.2651 - val_loss: 25.6580\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 24.3484 - val_loss: 25.8709\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.8904 - val_loss: 25.4866\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 24.0689 - val_loss: 26.5999\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.7666 - val_loss: 25.7967\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.3626 - val_loss: 25.5582\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.5247 - val_loss: 25.6629\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.1673 - val_loss: 27.0661\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.0012 - val_loss: 25.3990\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.5590 - val_loss: 25.6965\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4260 - val_loss: 25.5684\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0779 - val_loss: 25.5911\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2841 - val_loss: 25.0373\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5742 - val_loss: 24.8543\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.3701 - val_loss: 26.5874\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.3337 - val_loss: 25.0258\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.3978 - val_loss: 25.3217\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.2935 - val_loss: 24.7278\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.9073 - val_loss: 25.1120\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.8562 - val_loss: 23.9946\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.4900 - val_loss: 24.2904\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.2674 - val_loss: 24.5628\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1504 - val_loss: 24.1877\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1147 - val_loss: 24.0764\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6709 - val_loss: 23.9620\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5021 - val_loss: 23.7531\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4586 - val_loss: 24.1549\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.2629 - val_loss: 23.4144\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6867 - val_loss: 24.2311\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.6649 - val_loss: 23.0826\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.9163 - val_loss: 22.8719\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.0292 - val_loss: 23.3698\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.0073 - val_loss: 23.1245\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4450 - val_loss: 23.8039\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9645 - val_loss: 22.9308\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6988 - val_loss: 23.0799\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.8577 - val_loss: 22.1717\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6155 - val_loss: 21.9451\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3232 - val_loss: 21.9794\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1028 - val_loss: 21.7155\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1871 - val_loss: 21.6738\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8795 - val_loss: 22.0180\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1563 - val_loss: 21.2631\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8005 - val_loss: 21.7815\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.8496 - val_loss: 20.6423\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.4114 - val_loss: 20.6878\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.6837 - val_loss: 20.5621\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.2964 - val_loss: 20.6372\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.2825 - val_loss: 20.5546\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.8512 - val_loss: 22.1974\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.6209 - val_loss: 19.8053\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.1418 - val_loss: 19.8559\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.8433 - val_loss: 19.7265\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.7838 - val_loss: 19.1839\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.6668 - val_loss: 19.3731\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.6559 - val_loss: 18.9092\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.6605 - val_loss: 19.3108\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.4723 - val_loss: 19.0944\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.5641 - val_loss: 18.9445\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.5502 - val_loss: 18.7239\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2102 - val_loss: 18.6814\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.4487 - val_loss: 19.5982\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.2576 - val_loss: 18.0521\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.3628 - val_loss: 18.8640\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.0196 - val_loss: 18.5809\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.5183 - val_loss: 17.7192\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1406 - val_loss: 18.4257\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.1075 - val_loss: 17.6654\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.3257 - val_loss: 17.7489\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6611 - val_loss: 17.6953\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8826 - val_loss: 17.0782\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2819 - val_loss: 18.0659\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3325 - val_loss: 17.1460\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4673 - val_loss: 18.4624\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.9677 - val_loss: 17.5369\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.9390 - val_loss: 16.8363\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7503 - val_loss: 16.5152\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6029 - val_loss: 16.9074\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6257 - val_loss: 17.0530\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7679 - val_loss: 16.7520\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6671 - val_loss: 18.2186\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5237 - val_loss: 16.6987\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1347 - val_loss: 16.4731\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.4314 - val_loss: 16.7546\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8973 - val_loss: 16.8044\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8112 - val_loss: 15.9952\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0211 - val_loss: 15.7613\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5847 - val_loss: 17.1990\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8693 - val_loss: 18.3975\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6193 - val_loss: 18.0974\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7778 - val_loss: 15.9559\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.6586 - val_loss: 15.6262\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6706 - val_loss: 16.1817\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7485 - val_loss: 16.0953\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.7400 - val_loss: 16.6036\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.2896 - val_loss: 15.7875\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3591 - val_loss: 15.4493\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.7336 - val_loss: 15.4373\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.1323 - val_loss: 16.1803\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.6470 - val_loss: 15.1813\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1946 - val_loss: 15.6994\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.1745 - val_loss: 15.5154\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.9406 - val_loss: 15.4412\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.5102 - val_loss: 14.9842\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8899 - val_loss: 15.2549\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9969 - val_loss: 15.2486\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0263 - val_loss: 14.9648\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8984 - val_loss: 15.4047\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2725 - val_loss: 14.5782\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4289 - val_loss: 15.5434\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2588 - val_loss: 14.6836\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 128us/step - loss: 11.5383 - val_loss: 15.9991\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.0859 - val_loss: 16.0968\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1054 - val_loss: 16.4694\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6800 - val_loss: 14.7975\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9026 - val_loss: 14.9572\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8367 - val_loss: 15.6634\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.0178 - val_loss: 15.0379\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1152 - val_loss: 14.3304\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8861 - val_loss: 15.0531\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2746 - val_loss: 15.5410\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9275 - val_loss: 14.2971\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7312 - val_loss: 14.5168\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6807 - val_loss: 14.5908\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.6328 - val_loss: 14.6304\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6214 - val_loss: 14.5312\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3396 - val_loss: 13.9855\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.6969 - val_loss: 14.6622\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.3914 - val_loss: 13.9142\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.0772 - val_loss: 13.5802\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3965 - val_loss: 14.6678\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5762 - val_loss: 13.5769\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5596 - val_loss: 14.2433\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0836 - val_loss: 13.4792\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.7770 - val_loss: 15.1288\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.7262 - val_loss: 14.2624\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.0244 - val_loss: 13.1266\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0529 - val_loss: 13.1192\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9941 - val_loss: 15.4227\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3563 - val_loss: 14.3759\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.0647 - val_loss: 13.5879\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4581 - val_loss: 13.5043\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4418 - val_loss: 12.7382\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9791 - val_loss: 14.8628\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1841 - val_loss: 14.6860\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0032 - val_loss: 14.7288\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.3022 - val_loss: 14.2244\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4324 - val_loss: 15.6392\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.9249 - val_loss: 14.7588\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7564 - val_loss: 13.2483\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6362 - val_loss: 13.4700\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2871 - val_loss: 12.9547\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3098 - val_loss: 13.8032\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.4967 - val_loss: 13.5497\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1095 - val_loss: 12.4531\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6722 - val_loss: 14.8091\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1930 - val_loss: 14.0792\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7071 - val_loss: 14.9224\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.9040 - val_loss: 16.0122\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1430 - val_loss: 14.6407\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1095 - val_loss: 15.0332\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7569 - val_loss: 14.7086\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.5282 - val_loss: 13.3299\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8406 - val_loss: 13.4894\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.0543 - val_loss: 13.3356\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0926 - val_loss: 12.8700\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9417 - val_loss: 12.3419\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.4913 - val_loss: 12.1917\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6567 - val_loss: 12.9193\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9621 - val_loss: 16.5442\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9334 - val_loss: 13.9627\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2439 - val_loss: 12.9306\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7969 - val_loss: 12.8826\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4833 - val_loss: 12.3151\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3805 - val_loss: 13.1540\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0485 - val_loss: 14.4490\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5867 - val_loss: 13.6257\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2663 - val_loss: 12.9520\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.5390 - val_loss: 12.6799\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.7702 - val_loss: 12.5557\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6608 - val_loss: 15.4526\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8276 - val_loss: 13.0345\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.6550 - val_loss: 12.5074\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1607 - val_loss: 11.9159\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5287 - val_loss: 12.9918\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2493 - val_loss: 12.4450\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.4913 - val_loss: 12.1061\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.8430 - val_loss: 12.3629\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7446 - val_loss: 12.5919\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1660 - val_loss: 12.3844\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1019 - val_loss: 13.6302\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3684 - val_loss: 12.4003\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.6397 - val_loss: 12.2482\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2776 - val_loss: 12.3882\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1438 - val_loss: 13.5288\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1278 - val_loss: 12.4871\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1458 - val_loss: 13.3069\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2375 - val_loss: 12.1421\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1444 - val_loss: 12.7591\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1204 - val_loss: 12.1757\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4031 - val_loss: 12.1821\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8621 - val_loss: 12.3079\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1921 - val_loss: 12.2251\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3782 - val_loss: 12.4062\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6167 - val_loss: 12.2659\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0440 - val_loss: 12.2011\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0319 - val_loss: 11.9119\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7746 - val_loss: 12.7299\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6333 - val_loss: 11.5057\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6465 - val_loss: 12.2027\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8745 - val_loss: 13.6373\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2798 - val_loss: 11.6376\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5030 - val_loss: 12.4050\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0064 - val_loss: 11.9091\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7421 - val_loss: 11.6423\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9747 - val_loss: 12.0432\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8864 - val_loss: 11.6427\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5739 - val_loss: 11.4244\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4468 - val_loss: 13.8119\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0763 - val_loss: 11.5047\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7370 - val_loss: 12.5536\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7875 - val_loss: 11.4106\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7081 - val_loss: 11.4996\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7178 - val_loss: 13.1183\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6419 - val_loss: 11.6986\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4759 - val_loss: 11.6685\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2161 - val_loss: 12.6184\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2509 - val_loss: 11.9987\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7935 - val_loss: 11.1455\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5692 - val_loss: 11.2442\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4070 - val_loss: 11.5926\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1238 - val_loss: 12.4150\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0225 - val_loss: 11.1527\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7446 - val_loss: 11.4414\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3388 - val_loss: 11.9710\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6873 - val_loss: 12.7270\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2869 - val_loss: 11.7223\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2469 - val_loss: 13.5716\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1944 - val_loss: 11.7426\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4825 - val_loss: 12.8313\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3002 - val_loss: 10.7805\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8601 - val_loss: 11.8021\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2171 - val_loss: 11.0763\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0457 - val_loss: 10.5696\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8111 - val_loss: 10.7888\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9244 - val_loss: 11.2186\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5636 - val_loss: 11.2170\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3860 - val_loss: 11.0335\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5311 - val_loss: 10.1211\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8236 - val_loss: 11.2875\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3860 - val_loss: 9.9701\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5709 - val_loss: 10.1168\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9104 - val_loss: 10.7069\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7351 - val_loss: 10.6665\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7052 - val_loss: 10.0372\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0865 - val_loss: 9.6560\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2408 - val_loss: 9.8540\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4411 - val_loss: 10.6538\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6151 - val_loss: 10.5445\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2483 - val_loss: 10.6084\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8995 - val_loss: 10.7385\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7324 - val_loss: 9.9769\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2885 - val_loss: 9.4353\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7299 - val_loss: 10.4109\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0534 - val_loss: 11.4275\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1554 - val_loss: 10.9865\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.5238 - val_loss: 9.5483\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3010 - val_loss: 9.5380\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3622 - val_loss: 9.6244\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3297 - val_loss: 10.3352\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2803 - val_loss: 10.7177\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3104 - val_loss: 10.1912\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7620 - val_loss: 15.6376\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0428 - val_loss: 10.9785\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2318 - val_loss: 10.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6377 - val_loss: 9.8146\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6088 - val_loss: 10.8688\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3971 - val_loss: 10.4111\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8407 - val_loss: 11.1344\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7871 - val_loss: 9.5014\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1950 - val_loss: 10.2397\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8130 - val_loss: 10.2329\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1247 - val_loss: 11.0063\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6598 - val_loss: 9.5322\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1285 - val_loss: 9.8899\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4930 - val_loss: 10.4451\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8112 - val_loss: 10.9157\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2598 - val_loss: 10.1231\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2327 - val_loss: 9.8163\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0579 - val_loss: 10.1924\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6506 - val_loss: 9.3278\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0694 - val_loss: 9.8632\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7926 - val_loss: 9.9103\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0085 - val_loss: 11.9933\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3358 - val_loss: 9.8107\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9948 - val_loss: 9.2941\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.9358 - val_loss: 9.9680\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6592 - val_loss: 9.2797\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5781 - val_loss: 9.2873\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1713 - val_loss: 9.5367\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3723 - val_loss: 9.7396\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2786 - val_loss: 10.0778\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3665 - val_loss: 9.5340\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0437 - val_loss: 9.2197\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6644 - val_loss: 9.9681\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1727 - val_loss: 9.1037\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1580 - val_loss: 9.4354\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0419 - val_loss: 10.7247\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3674 - val_loss: 9.6631\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1329 - val_loss: 9.7985\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9827 - val_loss: 9.7152\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 7.9118 - val_loss: 10.7379\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3981 - val_loss: 10.9305\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1525 - val_loss: 9.2429\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4768 - val_loss: 9.4200\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5946 - val_loss: 9.9547\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0357 - val_loss: 10.4321\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0258 - val_loss: 16.6650\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9877 - val_loss: 9.9290\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8685 - val_loss: 9.2847\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2153 - val_loss: 9.7639\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0185 - val_loss: 9.9076\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0034 - val_loss: 9.8076\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9988 - val_loss: 8.9182\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2674 - val_loss: 9.8784\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6667 - val_loss: 10.0177\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9387 - val_loss: 9.1995\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7265 - val_loss: 9.7024\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6190 - val_loss: 10.1628\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2003 - val_loss: 11.7357\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1685 - val_loss: 11.2439\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1911 - val_loss: 9.4697\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8965 - val_loss: 9.1710\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2899 - val_loss: 10.3698\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0119 - val_loss: 9.0496\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0264 - val_loss: 9.8377\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1191 - val_loss: 11.1330\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2636 - val_loss: 9.3602\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1179 - val_loss: 9.4731\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0864 - val_loss: 10.1605\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9640 - val_loss: 9.4149\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0121 - val_loss: 10.2080\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7883 - val_loss: 8.9505\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8037 - val_loss: 9.0221\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0656 - val_loss: 8.6231\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0598 - val_loss: 9.0561\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6776 - val_loss: 9.1918\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8826 - val_loss: 10.7148\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0673 - val_loss: 8.8093\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9048 - val_loss: 9.7045\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7975 - val_loss: 10.2338\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8838 - val_loss: 8.8322\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0989 - val_loss: 9.6013\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2582 - val_loss: 9.0569\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7187 - val_loss: 9.5888\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0924 - val_loss: 9.8845\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6140 - val_loss: 8.7775\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8223 - val_loss: 8.6617\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1395 - val_loss: 11.1284\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1728 - val_loss: 9.6006\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9451 - val_loss: 8.8364\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1244 - val_loss: 9.9788\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8714 - val_loss: 9.3414\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6565 - val_loss: 9.1732\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6116 - val_loss: 10.7826\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9390 - val_loss: 9.9847\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1073 - val_loss: 10.1343\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1073 - val_loss: 8.9617\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0148 - val_loss: 9.7281\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6070 - val_loss: 8.9768\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1715 - val_loss: 9.3917\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8535 - val_loss: 10.5797\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0147 - val_loss: 9.3194\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8530 - val_loss: 10.5037\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0266 - val_loss: 8.9024\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0041 - val_loss: 12.0162\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5202 - val_loss: 11.6762\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5216 - val_loss: 9.2783\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8633 - val_loss: 9.1533\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8311 - val_loss: 8.7113\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.6337 - val_loss: 8.7850\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8651 - val_loss: 10.7263\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6874 - val_loss: 9.9595\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0255 - val_loss: 9.2765\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0664 - val_loss: 10.3922\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0768 - val_loss: 8.9470\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8415 - val_loss: 10.3342\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9397 - val_loss: 8.7944\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9513 - val_loss: 9.3330\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1730 - val_loss: 9.9107\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0816 - val_loss: 9.6727\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7765 - val_loss: 10.3017\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9356 - val_loss: 9.5053\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7861 - val_loss: 8.8256\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9527 - val_loss: 9.0384\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9823 - val_loss: 9.2684\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8928 - val_loss: 9.8548\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8082 - val_loss: 9.0428\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5424 - val_loss: 8.7790\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6471 - val_loss: 8.9727\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9100 - val_loss: 8.8120\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5095 - val_loss: 8.7391\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2157 - val_loss: 9.3081\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9083 - val_loss: 9.8277\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7548 - val_loss: 8.9427\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0182 - val_loss: 9.2400\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8055 - val_loss: 10.4319\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6077 - val_loss: 9.5206\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7508 - val_loss: 9.3701\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6166 - val_loss: 10.6206\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.6424 - val_loss: 9.0296\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5116 - val_loss: 10.1696\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7548 - val_loss: 9.2135\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8851 - val_loss: 9.3574\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9042 - val_loss: 9.8831\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8058 - val_loss: 8.9228\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5642 - val_loss: 10.3609\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7812 - val_loss: 9.3328\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7458 - val_loss: 9.1786\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8304 - val_loss: 11.6017\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7508 - val_loss: 9.1006\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4959 - val_loss: 8.5055\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2495 - val_loss: 9.0075\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8643 - val_loss: 10.8561\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1717 - val_loss: 9.3548\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0741 - val_loss: 9.2379\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6286 - val_loss: 9.5731\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8033 - val_loss: 8.9108\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2355 - val_loss: 10.0883\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6757 - val_loss: 10.1178\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0464 - val_loss: 11.0395\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3316 - val_loss: 9.2204\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3813 - val_loss: 10.3840\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8935 - val_loss: 9.0883\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4830 - val_loss: 9.1370\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5914 - val_loss: 9.4628\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0547 - val_loss: 9.8121\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5603 - val_loss: 10.0498\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0901 - val_loss: 9.8774\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7254 - val_loss: 9.1307\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 7.8169 - val_loss: 9.3932\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5878 - val_loss: 9.2123\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.4850 - val_loss: 12.2169\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.7065 - val_loss: 9.5660\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1454 - val_loss: 10.4786\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0258 - val_loss: 10.4805\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0340 - val_loss: 9.4493\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7665 - val_loss: 8.7663\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6953 - val_loss: 9.2724\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1405 - val_loss: 9.7180\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.0062 - val_loss: 9.5984\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6238 - val_loss: 8.8465\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8505 - val_loss: 9.8696\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1415 - val_loss: 9.3647\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9463 - val_loss: 9.3287\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2186 - val_loss: 9.4586\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0401 - val_loss: 9.4468\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6802 - val_loss: 9.0089\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5692 - val_loss: 9.4376\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6754 - val_loss: 9.9413\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5049 - val_loss: 8.6698\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4632 - val_loss: 9.2408\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9914 - val_loss: 9.7577\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5165 - val_loss: 10.1932\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9926 - val_loss: 9.2638\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8140 - val_loss: 8.6958\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4170 - val_loss: 9.2582\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6945 - val_loss: 9.0712\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4249 - val_loss: 8.8759\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3955 - val_loss: 9.0659\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8010 - val_loss: 8.8675\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8358 - val_loss: 8.8124\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8828 - val_loss: 9.2039\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7432 - val_loss: 8.9844\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6577 - val_loss: 8.5955\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4257 - val_loss: 8.6741\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7361 - val_loss: 9.1927\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9207 - val_loss: 8.5838\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9291 - val_loss: 10.0011\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8430 - val_loss: 8.7998\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7828 - val_loss: 9.1847\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4865 - val_loss: 8.6492\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3336 - val_loss: 11.2151\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9129 - val_loss: 8.7343\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0241 - val_loss: 14.5422\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1349 - val_loss: 9.0792\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6360 - val_loss: 9.7192\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5339 - val_loss: 9.9443\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5095 - val_loss: 9.5438\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5749 - val_loss: 8.6088\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6346 - val_loss: 8.5533\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5853 - val_loss: 9.4540\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7462 - val_loss: 8.8543\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9307 - val_loss: 8.9728\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6317 - val_loss: 9.2926\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7041 - val_loss: 10.4334\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3355 - val_loss: 8.5211\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7511 - val_loss: 10.5100\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6938 - val_loss: 9.3024\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3908 - val_loss: 10.1488\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6126 - val_loss: 9.9310\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5496 - val_loss: 8.9589\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5982 - val_loss: 8.9452\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6314 - val_loss: 8.9798\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8503 - val_loss: 8.4897\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.7823 - val_loss: 8.9195\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4142 - val_loss: 10.5251\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7386 - val_loss: 9.0734\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3773 - val_loss: 8.7706\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7574 - val_loss: 9.7522\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6460 - val_loss: 8.7289\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9594 - val_loss: 10.0102\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9484 - val_loss: 10.4330\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8068 - val_loss: 8.6538\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8511 - val_loss: 9.4608\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7742 - val_loss: 9.8187\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9638 - val_loss: 9.6152\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2477 - val_loss: 12.3452\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7010 - val_loss: 9.0873\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5262 - val_loss: 9.6900\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2021 - val_loss: 9.3066\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5706 - val_loss: 9.9931\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5870 - val_loss: 9.0564\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4669 - val_loss: 9.0857\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6917 - val_loss: 9.2381\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3712 - val_loss: 8.4865\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5291 - val_loss: 9.6821\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3657 - val_loss: 10.3039\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7940 - val_loss: 8.8047\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4608 - val_loss: 9.3776\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0156 - val_loss: 11.6804\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6519 - val_loss: 9.2083\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9523 - val_loss: 11.2702\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5315 - val_loss: 8.5002\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1987 - val_loss: 9.3669\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7349 - val_loss: 9.3914\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8860 - val_loss: 9.6110\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5132 - val_loss: 9.0956\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6507 - val_loss: 9.3452\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6284 - val_loss: 8.9313\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.5897 - val_loss: 9.3835\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4564 - val_loss: 9.2521\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7792 - val_loss: 8.9261\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4320 - val_loss: 9.5611\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4040 - val_loss: 10.2688\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6414 - val_loss: 10.6710\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3960 - val_loss: 10.4438\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0569 - val_loss: 10.0561\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0106 - val_loss: 9.1193\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5083 - val_loss: 10.2535\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3686 - val_loss: 9.3115\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6202 - val_loss: 8.8622\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4718 - val_loss: 9.2042\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.4352 - val_loss: 9.0259\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6586 - val_loss: 9.1438\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8459 - val_loss: 9.3630\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2789 - val_loss: 9.1126\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2029 - val_loss: 11.4862\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6882 - val_loss: 8.4793\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6468 - val_loss: 9.1658\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3939 - val_loss: 9.2753\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6155 - val_loss: 8.8234\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4564 - val_loss: 9.1680\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8095 - val_loss: 9.1528\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5374 - val_loss: 8.6838\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4043 - val_loss: 8.4753\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4632 - val_loss: 8.6858\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7010 - val_loss: 9.7186\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7144 - val_loss: 8.5717\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8217 - val_loss: 10.9933\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0358 - val_loss: 10.7051\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0413 - val_loss: 10.0506\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0959 - val_loss: 9.7546\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6563 - val_loss: 9.4793\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4530 - val_loss: 8.8127\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6357 - val_loss: 9.9274\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7081 - val_loss: 9.0836\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3218 - val_loss: 9.3552\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5065 - val_loss: 9.2023\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3359 - val_loss: 9.2054\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9236 - val_loss: 8.7315\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4993 - val_loss: 9.0724\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6697 - val_loss: 8.7863\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4580 - val_loss: 8.5616\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8834 - val_loss: 11.1195\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7361 - val_loss: 9.9069\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2484 - val_loss: 9.6630\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.8389 - val_loss: 9.8778\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4940 - val_loss: 9.7149\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4848 - val_loss: 9.3047\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6595 - val_loss: 8.8643\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4213 - val_loss: 8.8235\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4498 - val_loss: 10.5442\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3694 - val_loss: 9.1071\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6441 - val_loss: 8.8906\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9171 - val_loss: 13.9675\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8988 - val_loss: 8.7244\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5291 - val_loss: 9.7225\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4874 - val_loss: 10.2240\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7507 - val_loss: 8.9885\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6169 - val_loss: 9.8284\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7884 - val_loss: 10.3928\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7210 - val_loss: 10.5569\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6929 - val_loss: 8.6076\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3487 - val_loss: 8.5860\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3720 - val_loss: 8.5279\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5655 - val_loss: 8.5067\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7997 - val_loss: 9.8130\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6227 - val_loss: 9.1598\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6479 - val_loss: 9.5294\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2413 - val_loss: 9.3906\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0306 - val_loss: 10.1161\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7306 - val_loss: 8.7351\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7334 - val_loss: 9.0286\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3941 - val_loss: 9.5219\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5496 - val_loss: 8.6640\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6204 - val_loss: 8.5956\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.7855 - val_loss: 9.2200\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3694 - val_loss: 9.4719\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9524 - val_loss: 8.6150\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5679 - val_loss: 8.9433\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4807 - val_loss: 8.6757\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4977 - val_loss: 9.6859\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5763 - val_loss: 8.7760\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6043 - val_loss: 9.2398\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9384 - val_loss: 9.8142\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4711 - val_loss: 9.6494\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6942 - val_loss: 12.6532\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8926 - val_loss: 9.4970\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5044 - val_loss: 8.9122\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0016 - val_loss: 9.2063\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7158 - val_loss: 9.0955\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.266 - 0s 87us/step - loss: 8.0841 - val_loss: 9.7603\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5571 - val_loss: 9.1444\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6884 - val_loss: 9.9859\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2640 - val_loss: 9.5226\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6232 - val_loss: 9.5020\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0038 - val_loss: 9.8488\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.3617 - val_loss: 8.4919\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5763 - val_loss: 10.9838\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6116 - val_loss: 9.0308\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3031 - val_loss: 9.1955\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7162 - val_loss: 9.3403\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8207 - val_loss: 8.9216\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6596 - val_loss: 9.3680\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8302 - val_loss: 9.6569\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5333 - val_loss: 8.4040\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8732 - val_loss: 9.4536\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5724 - val_loss: 8.5291\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4667 - val_loss: 8.6082\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4308 - val_loss: 8.8558\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7149 - val_loss: 9.9949\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4415 - val_loss: 8.9426\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1099 - val_loss: 9.1907\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6788 - val_loss: 8.8070\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8127 - val_loss: 8.3580\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7508 - val_loss: 8.9887\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5459 - val_loss: 9.2719\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3978 - val_loss: 9.0967\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7074 - val_loss: 9.6640\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4077 - val_loss: 8.6728\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7927 - val_loss: 10.2304\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8396 - val_loss: 8.3575\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5101 - val_loss: 9.9650\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7260 - val_loss: 9.1470\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1230 - val_loss: 9.0008\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4113 - val_loss: 8.9692\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2571 - val_loss: 8.8242\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4555 - val_loss: 9.6529\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3616 - val_loss: 9.5330\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5769 - val_loss: 9.1976\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1391 - val_loss: 9.0172\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8434 - val_loss: 9.0559\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9341 - val_loss: 9.3853\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4918 - val_loss: 8.7987\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3380 - val_loss: 9.7772\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.3772 - val_loss: 8.5154\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5157 - val_loss: 8.6400\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9752 - val_loss: 13.3850\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4238 - val_loss: 9.8177\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2069 - val_loss: 8.9296\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0953 - val_loss: 8.5923\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5643 - val_loss: 8.6653\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3254 - val_loss: 8.8045\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0088 - val_loss: 8.7533\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5433 - val_loss: 8.3247\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6649 - val_loss: 8.9670\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7800 - val_loss: 9.0178\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4467 - val_loss: 8.9023\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5886 - val_loss: 9.4895\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9726 - val_loss: 12.2287\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5021 - val_loss: 9.0936\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2625 - val_loss: 8.7897\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4596 - val_loss: 10.9971\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9245 - val_loss: 8.4317\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5853 - val_loss: 8.9589\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4645 - val_loss: 8.3235\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3144 - val_loss: 8.4755\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7349 - val_loss: 9.5214\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6469 - val_loss: 9.1732\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9045 - val_loss: 9.6535\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6146 - val_loss: 8.7087\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3800 - val_loss: 9.9487\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6101 - val_loss: 8.5791\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4686 - val_loss: 8.9447\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5693 - val_loss: 8.3959\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5422 - val_loss: 8.5607\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0734 - val_loss: 8.6102\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6196 - val_loss: 8.7451\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3618 - val_loss: 10.1698\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9495 - val_loss: 8.8418\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8722 - val_loss: 8.8077\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7734 - val_loss: 9.2143\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3679 - val_loss: 8.4085\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6526 - val_loss: 8.9195\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6601 - val_loss: 9.5251\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6655 - val_loss: 8.5755\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5766 - val_loss: 10.3400\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3803 - val_loss: 9.8275\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9883 - val_loss: 9.6714\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7698 - val_loss: 10.3405\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8001 - val_loss: 9.2520\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6482 - val_loss: 9.3138\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3908 - val_loss: 8.7602\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6337 - val_loss: 8.9461\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7190 - val_loss: 8.3427\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4787 - val_loss: 9.8897\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4782 - val_loss: 8.6744\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7416 - val_loss: 8.4406\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3261 - val_loss: 9.2843\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7084 - val_loss: 8.8239\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7200 - val_loss: 12.0851\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0865 - val_loss: 8.4977\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4169 - val_loss: 9.4073\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5269 - val_loss: 9.4155\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2050 - val_loss: 10.3421\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4698 - val_loss: 9.3928\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6281 - val_loss: 8.6749\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4892 - val_loss: 8.8792\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6193 - val_loss: 9.2099\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2798 - val_loss: 8.7354\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9395 - val_loss: 9.3915\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6959 - val_loss: 8.8972\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5834 - val_loss: 11.1813\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9298 - val_loss: 8.9500\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5457 - val_loss: 8.5378\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3286 - val_loss: 8.2716\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7924 - val_loss: 8.8300\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.6289 - val_loss: 8.7066\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3913 - val_loss: 8.7183\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2521 - val_loss: 8.4883\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1896 - val_loss: 8.6580\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2377 - val_loss: 8.6099\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9879 - val_loss: 9.5041\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4018 - val_loss: 8.9520\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7486 - val_loss: 9.7118\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6648 - val_loss: 9.2673\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7097 - val_loss: 8.8659\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7776 - val_loss: 8.4586\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7976 - val_loss: 9.2465\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8683 - val_loss: 9.6798\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6592 - val_loss: 9.8808\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4916 - val_loss: 9.3524\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7224 - val_loss: 9.2341\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0582 - val_loss: 9.4736\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1422 - val_loss: 9.9317\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5609 - val_loss: 8.2237\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4343 - val_loss: 8.7053\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5592 - val_loss: 9.0124\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7503 - val_loss: 8.8290\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6542 - val_loss: 8.3795\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1691 - val_loss: 8.1570\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5134 - val_loss: 8.3923\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2959 - val_loss: 8.5510\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6138 - val_loss: 8.4821\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9589 - val_loss: 9.0889\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7433 - val_loss: 9.2919\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1043 - val_loss: 9.3058\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8131 - val_loss: 8.8642\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0785 - val_loss: 8.5250\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4562 - val_loss: 8.7393\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4173 - val_loss: 8.5287\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4684 - val_loss: 9.1592\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6394 - val_loss: 8.6547\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1840 - val_loss: 9.5180\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.6895 - val_loss: 8.7042\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6075 - val_loss: 8.7299\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6337 - val_loss: 9.3526\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.6598 - val_loss: 8.8105\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.0557 - val_loss: 8.9688\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.8987 - val_loss: 9.4057\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4158 - val_loss: 8.5282\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5560 - val_loss: 8.6537\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4088 - val_loss: 8.7751\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.8199 - val_loss: 8.9040\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1329 - val_loss: 9.0633\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8113 - val_loss: 9.2456\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.6305 - val_loss: 9.3454\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9847 - val_loss: 10.0417\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6477 - val_loss: 8.7569\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6056 - val_loss: 9.2478\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7037 - val_loss: 8.6473\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6538 - val_loss: 10.0643\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7868 - val_loss: 9.0326\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6287 - val_loss: 8.2281\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5652 - val_loss: 9.9484\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5283 - val_loss: 9.2873\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0573 - val_loss: 8.7503\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7234 - val_loss: 9.6442\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3495 - val_loss: 8.5533\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6867 - val_loss: 9.4821\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7106 - val_loss: 8.7314\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4494 - val_loss: 8.3039\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0676 - val_loss: 9.8126\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2980 - val_loss: 9.1743\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4064 - val_loss: 10.0873\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5954 - val_loss: 9.8806\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4705 - val_loss: 8.7264\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4038 - val_loss: 9.1393\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2080 - val_loss: 8.9969\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4111 - val_loss: 9.5036\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3702 - val_loss: 8.6947\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6197 - val_loss: 8.2820\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2235 - val_loss: 8.4155\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1100 - val_loss: 9.7493\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0248 - val_loss: 8.1886\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4430 - val_loss: 9.8174\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8051 - val_loss: 8.9596\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1720 - val_loss: 8.6182\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1980 - val_loss: 9.7663\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5110 - val_loss: 9.1686\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6163 - val_loss: 8.3611\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4873 - val_loss: 8.7274\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6182 - val_loss: 8.7866\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8210 - val_loss: 9.8057\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6653 - val_loss: 9.0142\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9282 - val_loss: 10.7225\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8404 - val_loss: 9.6615\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5774 - val_loss: 9.2767\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3899 - val_loss: 8.8407\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6961 - val_loss: 8.8475\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1709 - val_loss: 10.2483\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7180 - val_loss: 8.3638\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3868 - val_loss: 8.4854\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1173 - val_loss: 8.2904\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7288 - val_loss: 9.2820\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8972 - val_loss: 9.0735\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7126 - val_loss: 9.4843\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2582 - val_loss: 11.6768\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2396 - val_loss: 9.8493\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5617 - val_loss: 8.6702\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7172 - val_loss: 8.9992\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6861 - val_loss: 9.4720\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7140 - val_loss: 9.0882\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3638 - val_loss: 9.5213\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5722 - val_loss: 8.7302\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3385 - val_loss: 8.4470\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5693 - val_loss: 8.8941\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.2488 - val_loss: 8.7625\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2368 - val_loss: 9.3832\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4479 - val_loss: 9.8638\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7799 - val_loss: 8.7274\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8297 - val_loss: 10.0654\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2448 - val_loss: 10.3559\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7541 - val_loss: 9.0154\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4066 - val_loss: 9.3646\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9437 - val_loss: 9.0132\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8203 - val_loss: 9.1320\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4347 - val_loss: 8.8094\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7507 - val_loss: 9.2247\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4488 - val_loss: 9.3059\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5970 - val_loss: 8.5060\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.5839 - val_loss: 9.1552\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6297 - val_loss: 8.1999\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7063 - val_loss: 8.3194\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5178 - val_loss: 9.1832\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3330 - val_loss: 9.2350\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7776 - val_loss: 8.5450\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7874 - val_loss: 8.4008\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2932 - val_loss: 8.6242\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2978 - val_loss: 9.4686\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3544 - val_loss: 9.1056\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.4368 - val_loss: 9.7124\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4195 - val_loss: 8.4086\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3312 - val_loss: 8.6147\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4754 - val_loss: 10.3001\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6725 - val_loss: 8.6203\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5897 - val_loss: 9.0609\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.3948 - val_loss: 8.5443\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5050 - val_loss: 10.3258\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7464 - val_loss: 8.7551\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5826 - val_loss: 9.1383\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0827 - val_loss: 9.1614\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3755 - val_loss: 9.2783\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4603 - val_loss: 9.7351\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2890 - val_loss: 9.8067\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6057 - val_loss: 8.9270\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4332 - val_loss: 8.8889\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4893 - val_loss: 10.4350\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8653 - val_loss: 8.6787\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3473 - val_loss: 8.4692\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8916 - val_loss: 9.5592\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1549 - val_loss: 10.0178\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0563 - val_loss: 8.7690\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4180 - val_loss: 9.7369\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5348 - val_loss: 9.1364\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9048 - val_loss: 9.2500\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5780 - val_loss: 9.6291\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6911 - val_loss: 9.7865\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7515 - val_loss: 8.5232\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4606 - val_loss: 8.2839\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1760 - val_loss: 11.5900\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7559 - val_loss: 8.3250\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5171 - val_loss: 9.3210\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3822 - val_loss: 9.2854\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.2405 - val_loss: 8.8481\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4355 - val_loss: 10.1120\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5197 - val_loss: 8.5417\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1016 - val_loss: 10.1013\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.4245 - val_loss: 8.6779\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1557 - val_loss: 8.7636\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2075 - val_loss: 8.4478\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5408 - val_loss: 9.2790\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9465 - val_loss: 9.0522\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7080 - val_loss: 9.1911\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7736 - val_loss: 8.2150\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5306 - val_loss: 9.2537\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6062 - val_loss: 8.6185\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5002 - val_loss: 9.5798\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4505 - val_loss: 8.7959\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3548 - val_loss: 9.0869\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5696 - val_loss: 10.0190\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7211 - val_loss: 8.9091\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9146 - val_loss: 8.7733\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.8005 - val_loss: 9.2596\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2834 - val_loss: 9.4821\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8847 - val_loss: 9.1527\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1983 - val_loss: 8.4078\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9716 - val_loss: 9.0492\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7158 - val_loss: 10.4063\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4997 - val_loss: 8.9311\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2399 - val_loss: 8.5300\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4223 - val_loss: 8.2981\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6805 - val_loss: 9.0024\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5974 - val_loss: 8.5051\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6275 - val_loss: 8.5520\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3693 - val_loss: 8.5370\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6011 - val_loss: 8.5579\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4248 - val_loss: 10.7535\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6444 - val_loss: 8.3237\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5605 - val_loss: 9.9476\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4793 - val_loss: 8.4560\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6025 - val_loss: 9.0821\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3734 - val_loss: 8.4855\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3510 - val_loss: 8.3197\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.4949 - val_loss: 8.5838\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.2700 - val_loss: 8.5976\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8652 - val_loss: 9.0175\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4907 - val_loss: 9.9729\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6574 - val_loss: 9.9845\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4568 - val_loss: 9.1954\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9439 - val_loss: 10.0103\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1677 - val_loss: 10.4508\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7686 - val_loss: 8.8410\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2700 - val_loss: 9.3975\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 7.5758 - val_loss: 9.3276\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5144 - val_loss: 8.4517\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4926 - val_loss: 8.2935\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3873 - val_loss: 8.3846\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4377 - val_loss: 8.8717\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7727 - val_loss: 10.7188\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1011 - val_loss: 9.2945\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8196 - val_loss: 8.8031\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8187 - val_loss: 9.0057\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2309 - val_loss: 9.7895\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4443 - val_loss: 9.4267\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0144 - val_loss: 8.7160\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7761 - val_loss: 9.0409\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3509 - val_loss: 9.8983\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7113 - val_loss: 9.6098\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9607 - val_loss: 8.7335\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8100 - val_loss: 9.4769\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4833 - val_loss: 8.5345\n",
      "7.253667548694442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.1592215 ,  2.7216642 ,  3.0954537 ,  2.01829   , -0.6039481 ],\n",
       "        [-0.24132442, -0.24869639, -0.11973082,  0.12322515, -0.2548509 ],\n",
       "        [-0.6290021 , -0.13947985,  1.0468621 ,  0.10290544,  0.6356868 ],\n",
       "        [ 0.0943072 , -0.10151696, -0.1323905 , -0.09238867,  0.03579548],\n",
       "        [-0.12589242,  0.2791103 ,  0.1332975 ,  1.3031863 , -1.2103715 ]],\n",
       "       dtype=float32),\n",
       " array([-0.2911458,  1.4950378,  4.6018014,  2.9649096, -1.0657979],\n",
       "       dtype=float32),\n",
       " array([[-8.0463886e-01,  7.0006633e-01,  8.8542283e-01, -1.0699587e+00,\n",
       "          9.8526567e-02,  7.7192599e-01,  4.9396464e-01, -1.0851717e+00,\n",
       "         -6.2383717e-01, -7.2217178e-01,  3.0238974e-01, -6.3772529e-01,\n",
       "          9.5855737e-01, -4.5049158e-01,  7.2859538e-01],\n",
       "        [ 8.3909827e-01, -1.0890035e-03, -7.8165668e-01,  5.8485681e-01,\n",
       "         -4.1357982e-01, -4.5805448e-01, -6.3674384e-01,  2.8160796e-01,\n",
       "          2.9775521e-01,  1.5908298e-01, -6.1002725e-01,  2.4680129e-01,\n",
       "         -6.5151989e-01, -1.2167998e-01, -5.2563590e-01],\n",
       "        [-1.4670278e+00,  1.6704071e+00,  2.0936162e+00, -1.5917908e+00,\n",
       "          1.5813882e+00,  2.4780138e+00,  2.3168566e+00, -2.2901161e+00,\n",
       "         -1.6050707e+00, -2.0214062e+00,  1.5296357e+00, -2.4264016e+00,\n",
       "          1.9003832e+00, -2.0845492e+00,  2.4801178e+00],\n",
       "        [-1.5445684e+00,  1.6669682e+00,  1.9553220e+00, -1.9672104e+00,\n",
       "          1.5046270e+00,  1.0437057e+00,  1.8752320e+00, -1.4921974e+00,\n",
       "         -1.0392624e+00, -1.3225527e+00,  1.9267806e+00, -1.8597225e+00,\n",
       "          1.4504075e+00, -1.0940492e+00,  1.9570187e+00],\n",
       "        [-1.2832445e-01,  1.4660992e-01,  7.0035940e-01, -8.9550652e-02,\n",
       "          9.8541111e-02,  6.2527411e-02,  2.3863441e-03, -4.3102255e-01,\n",
       "         -3.5443446e-01, -7.3644167e-01, -1.3283950e-01, -6.5926331e-01,\n",
       "          4.1463152e-01,  7.2171800e-02,  3.4656546e-01]], dtype=float32),\n",
       " array([-2.181723 ,  2.1542077,  2.187139 , -2.153302 ,  1.6716775,\n",
       "         2.2159336,  2.2263334, -2.2152524, -2.1611013, -2.1916175,\n",
       "         2.1535041, -2.2144926,  2.0922413, -2.08983  ,  2.238673 ],\n",
       "       dtype=float32),\n",
       " array([[-1.5632788],\n",
       "        [ 1.4504536],\n",
       "        [ 1.5293884],\n",
       "        [-1.4171664],\n",
       "        [ 1.0895959],\n",
       "        [ 1.9361115],\n",
       "        [ 1.9332724],\n",
       "        [-1.7965188],\n",
       "        [-1.5856653],\n",
       "        [-1.6265407],\n",
       "        [ 1.5465631],\n",
       "        [-1.6812778],\n",
       "        [ 1.3038456],\n",
       "        [-1.3744011],\n",
       "        [ 2.03482  ]], dtype=float32),\n",
       " array([2.358444], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_3(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure3_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 230us/step - loss: 7708.2314 - val_loss: 868.7010\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 169.5648 - val_loss: 46.3539\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 32.4699 - val_loss: 30.9848\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 26.1318 - val_loss: 29.1542\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.7673 - val_loss: 28.7171\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 24.1340 - val_loss: 28.2701\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.4523 - val_loss: 27.8083\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.0737 - val_loss: 26.8040\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.5005 - val_loss: 26.9447\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1817 - val_loss: 26.8338\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6299 - val_loss: 26.4359\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.1729 - val_loss: 26.2398\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.7601 - val_loss: 26.1865\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.3887 - val_loss: 26.1218\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.0131 - val_loss: 25.9101\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.8129 - val_loss: 25.4381\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.5138 - val_loss: 25.5166\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.1565 - val_loss: 25.1704\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.0493 - val_loss: 24.6759\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7793 - val_loss: 24.7244\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6738 - val_loss: 24.5756\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.6698 - val_loss: 24.9585\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5229 - val_loss: 24.1918\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4431 - val_loss: 24.1790\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5639 - val_loss: 24.4826\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0832 - val_loss: 23.7173\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0701 - val_loss: 23.7299\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1537 - val_loss: 23.7036\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1217 - val_loss: 23.2324\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9036 - val_loss: 22.9197\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8358 - val_loss: 23.1023\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6980 - val_loss: 22.9981\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.7090 - val_loss: 23.2523\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6844 - val_loss: 22.5382\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6166 - val_loss: 23.4521\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8860 - val_loss: 22.3886\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5827 - val_loss: 21.6725\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1866 - val_loss: 21.6043\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1499 - val_loss: 21.2947\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1883 - val_loss: 21.1706\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8985 - val_loss: 20.7137\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.6947 - val_loss: 20.6007\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.7798 - val_loss: 21.1402\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.6622 - val_loss: 20.2277\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.4627 - val_loss: 20.3319\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.3800 - val_loss: 19.9546\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.5535 - val_loss: 20.5295\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.6676 - val_loss: 19.7460\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.9319 - val_loss: 20.4988\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2892 - val_loss: 19.9974\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.7439 - val_loss: 20.7235\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.6280 - val_loss: 19.2060\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.9964 - val_loss: 19.2271\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.5871 - val_loss: 18.7197\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.3565 - val_loss: 18.7662\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.4624 - val_loss: 18.7128\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2820 - val_loss: 19.7215\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.9037 - val_loss: 18.4866\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.7065 - val_loss: 18.9421\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.1583 - val_loss: 18.7708\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.0351 - val_loss: 19.4763\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3188 - val_loss: 18.6989\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.0433 - val_loss: 18.6147\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9518 - val_loss: 18.1014\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.0680 - val_loss: 18.2916\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9100 - val_loss: 17.9413\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6723 - val_loss: 18.6771\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7482 - val_loss: 17.4464\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7385 - val_loss: 18.2627\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9484 - val_loss: 18.4233\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.0993 - val_loss: 17.5494\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3347 - val_loss: 18.0984\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9251 - val_loss: 17.1572\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.6063 - val_loss: 19.1451\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4885 - val_loss: 18.3102\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4340 - val_loss: 17.7059\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4204 - val_loss: 17.3163\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1949 - val_loss: 16.8158\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4164 - val_loss: 17.2691\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2043 - val_loss: 17.6958\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4875 - val_loss: 16.8022\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0267 - val_loss: 16.8774\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0508 - val_loss: 17.6371\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9075 - val_loss: 17.0652\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5055 - val_loss: 16.7175\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3931 - val_loss: 17.0603\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0926 - val_loss: 18.2038\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.3607 - val_loss: 16.9645\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8541 - val_loss: 16.3458\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0451 - val_loss: 16.8520\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5115 - val_loss: 16.8625\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6183 - val_loss: 16.7571\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9371 - val_loss: 17.2326\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.8713 - val_loss: 17.3696\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.9416 - val_loss: 17.5450\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6254 - val_loss: 16.5702\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5240 - val_loss: 18.1316\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.4696 - val_loss: 16.5702\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5576 - val_loss: 18.3786\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6898 - val_loss: 17.1778\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5271 - val_loss: 18.6933\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4518 - val_loss: 16.5197\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3516 - val_loss: 16.9550\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.5164 - val_loss: 16.2362\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6278 - val_loss: 16.7796\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.4612 - val_loss: 16.1611\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2611 - val_loss: 15.7907\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.2450 - val_loss: 15.6267\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9208 - val_loss: 16.1669\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.9999 - val_loss: 16.6217\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8340 - val_loss: 16.5673\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5383 - val_loss: 17.1616\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8648 - val_loss: 16.1309\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2780 - val_loss: 15.7706\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5874 - val_loss: 16.8838\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.5566 - val_loss: 15.4844\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7625 - val_loss: 15.7563\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7920 - val_loss: 15.4803\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7549 - val_loss: 16.1343\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6469 - val_loss: 15.2722\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6892 - val_loss: 15.8038\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1817 - val_loss: 15.9785\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4547 - val_loss: 15.2709\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8121 - val_loss: 16.6816\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6361 - val_loss: 18.0423\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1721 - val_loss: 17.1793\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1759 - val_loss: 15.4240\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.1002 - val_loss: 15.8168\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4708 - val_loss: 16.5568\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3074 - val_loss: 16.5535\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2411 - val_loss: 16.7479\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5470 - val_loss: 16.6108\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.5262 - val_loss: 16.5150\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7244 - val_loss: 18.9823\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9586 - val_loss: 15.2565\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 11.6949 - val_loss: 14.5838\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3979 - val_loss: 14.6235\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.3617 - val_loss: 15.0555\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8281 - val_loss: 13.8879\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.4536 - val_loss: 13.8921\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.3044 - val_loss: 15.5446\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 99us/step - loss: 12.3784 - val_loss: 14.7699\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.7007 - val_loss: 14.8595\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3505 - val_loss: 14.8699\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1963 - val_loss: 14.1974\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9086 - val_loss: 14.3775\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9211 - val_loss: 15.1848\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8625 - val_loss: 15.6891\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9348 - val_loss: 13.0638\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8488 - val_loss: 13.4029\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7760 - val_loss: 13.1397\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3281 - val_loss: 13.1135\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6547 - val_loss: 14.0837\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6241 - val_loss: 14.2259\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4480 - val_loss: 13.4273\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9997 - val_loss: 12.5200\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2293 - val_loss: 12.2248\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1478 - val_loss: 14.9554\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0662 - val_loss: 11.9826\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6062 - val_loss: 11.6832\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6759 - val_loss: 11.9104\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6507 - val_loss: 12.3572\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0376 - val_loss: 12.2610\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7424 - val_loss: 13.3904\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9952 - val_loss: 14.7173\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.3910 - val_loss: 13.4144\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4783 - val_loss: 13.8021\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5611 - val_loss: 12.1002\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9121 - val_loss: 11.6062\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3120 - val_loss: 11.6771\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3927 - val_loss: 12.6869\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9854 - val_loss: 11.3824\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1258 - val_loss: 11.4573\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1880 - val_loss: 12.5314\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8430 - val_loss: 10.9386\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8340 - val_loss: 11.9519\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5031 - val_loss: 12.4219\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8545 - val_loss: 11.1333\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2479 - val_loss: 10.8907\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8783 - val_loss: 10.6996\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8852 - val_loss: 11.3993\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0975 - val_loss: 10.9204\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0955 - val_loss: 11.1106\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0007 - val_loss: 10.6877\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2047 - val_loss: 10.1855\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7201 - val_loss: 12.6454\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7373 - val_loss: 12.3897\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1120 - val_loss: 10.5141\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1926 - val_loss: 10.5689\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0241 - val_loss: 10.5928\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7948 - val_loss: 12.0384\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3826 - val_loss: 12.4619\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1014 - val_loss: 12.2594\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9320 - val_loss: 9.9518\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0228 - val_loss: 11.6483\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1504 - val_loss: 11.0569\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6942 - val_loss: 11.2900\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4946 - val_loss: 10.5601\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6658 - val_loss: 10.7084\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7680 - val_loss: 11.0282\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6837 - val_loss: 13.1534\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8095 - val_loss: 11.8629\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6826 - val_loss: 10.3005\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7305 - val_loss: 10.4970\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3223 - val_loss: 10.3732\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7231 - val_loss: 10.4482\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6293 - val_loss: 10.3497\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6557 - val_loss: 10.4735\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4266 - val_loss: 11.1742\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4915 - val_loss: 9.9687\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1179 - val_loss: 9.8570\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5189 - val_loss: 11.5590\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9332 - val_loss: 10.3220\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4713 - val_loss: 10.3608\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5739 - val_loss: 9.9864\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3867 - val_loss: 10.1695\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7312 - val_loss: 10.3894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4358 - val_loss: 10.1153\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4396 - val_loss: 9.7094\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4304 - val_loss: 9.8664\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2414 - val_loss: 10.3432\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5393 - val_loss: 11.7304\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5389 - val_loss: 11.2897\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4710 - val_loss: 10.1635\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2858 - val_loss: 10.3395\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1297 - val_loss: 10.2709\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4046 - val_loss: 10.4631\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0217 - val_loss: 10.2762\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4890 - val_loss: 10.0523\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3644 - val_loss: 10.1093\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4767 - val_loss: 10.1760\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4494 - val_loss: 10.2678\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5251 - val_loss: 10.0478\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6780 - val_loss: 10.2089\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2673 - val_loss: 14.9237\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3155 - val_loss: 10.3116\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8187 - val_loss: 9.4689\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1412 - val_loss: 10.0671\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3817 - val_loss: 11.1395\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4472 - val_loss: 9.8193\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3305 - val_loss: 9.6986\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4898 - val_loss: 9.7607\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2043 - val_loss: 11.8834\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2281 - val_loss: 9.6930\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6571 - val_loss: 10.5585\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5299 - val_loss: 10.2538\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7818 - val_loss: 11.4953\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2994 - val_loss: 9.4535\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3681 - val_loss: 9.9046\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7740 - val_loss: 9.3935\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3291 - val_loss: 10.5892\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2340 - val_loss: 10.2971\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1964 - val_loss: 10.4208\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5033 - val_loss: 10.8795\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0487 - val_loss: 9.9680\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1322 - val_loss: 10.1508\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2459 - val_loss: 10.0641\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4036 - val_loss: 10.3230\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6693 - val_loss: 9.5489\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2043 - val_loss: 9.4358\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2157 - val_loss: 9.5658\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3011 - val_loss: 9.5792\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4144 - val_loss: 9.9952\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1531 - val_loss: 9.9548\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4119 - val_loss: 9.7795\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0663 - val_loss: 9.4047\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4426 - val_loss: 10.2040\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1853 - val_loss: 12.3727\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3368 - val_loss: 9.6933\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4774 - val_loss: 10.2385\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3016 - val_loss: 10.5046\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1940 - val_loss: 9.3694\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5189 - val_loss: 11.0351\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6407 - val_loss: 9.5730\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4322 - val_loss: 9.8494\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3930 - val_loss: 11.0511\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1757 - val_loss: 10.3577\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3036 - val_loss: 10.5494\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3311 - val_loss: 9.7888\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1551 - val_loss: 9.5510\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2467 - val_loss: 9.6798\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0078 - val_loss: 10.0654\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2687 - val_loss: 9.6394\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3588 - val_loss: 10.4468\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0286 - val_loss: 12.4539\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4864 - val_loss: 9.8492\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0149 - val_loss: 9.8861\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0721 - val_loss: 10.5518\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1808 - val_loss: 9.6601\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1160 - val_loss: 10.5829\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1700 - val_loss: 9.8832\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2519 - val_loss: 10.3993\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0885 - val_loss: 9.9914\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0294 - val_loss: 9.3895\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3591 - val_loss: 10.0686\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4104 - val_loss: 10.2780\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1250 - val_loss: 9.2946\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2751 - val_loss: 9.6055\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4049 - val_loss: 11.5794\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4748 - val_loss: 9.6444\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4957 - val_loss: 11.1378\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2689 - val_loss: 11.4461\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6777 - val_loss: 11.3721\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5873 - val_loss: 9.2756\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7612 - val_loss: 9.9879\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3217 - val_loss: 9.8063\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.4105 - val_loss: 9.4803\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2528 - val_loss: 10.1453\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4621 - val_loss: 9.9265\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6560 - val_loss: 9.8450\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6654 - val_loss: 10.1514\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.2247 - val_loss: 9.4462\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3788 - val_loss: 9.2523\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1002 - val_loss: 9.3018\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0659 - val_loss: 10.1189\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2618 - val_loss: 9.7419\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4675 - val_loss: 9.5016\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2079 - val_loss: 9.9085\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8196 - val_loss: 9.4023\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9229 - val_loss: 10.1834\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0417 - val_loss: 10.9467\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0485 - val_loss: 9.9149\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2218 - val_loss: 9.3872\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9644 - val_loss: 9.2777\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1174 - val_loss: 9.7334\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4031 - val_loss: 10.0001\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7058 - val_loss: 10.5889\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2206 - val_loss: 9.6628\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3247 - val_loss: 9.8830\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2504 - val_loss: 9.8445\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1966 - val_loss: 9.7718\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2695 - val_loss: 9.6685\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3419 - val_loss: 10.1958\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5209 - val_loss: 10.8298\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9009 - val_loss: 9.5128\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2177 - val_loss: 9.4601\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0386 - val_loss: 9.1843\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0577 - val_loss: 9.9075\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4761 - val_loss: 10.1292\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2071 - val_loss: 9.6105\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2148 - val_loss: 10.4955\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4377 - val_loss: 10.3497\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8231 - val_loss: 9.5266\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1722 - val_loss: 9.6140\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1713 - val_loss: 9.3377\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0747 - val_loss: 9.6515\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1565 - val_loss: 9.3742\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1689 - val_loss: 9.3284\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0988 - val_loss: 9.3228\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0459 - val_loss: 10.8105\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1405 - val_loss: 9.4614\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0476 - val_loss: 9.4184\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2700 - val_loss: 9.1841\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1634 - val_loss: 9.8388\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3206 - val_loss: 9.3078\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0369 - val_loss: 9.4698\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9402 - val_loss: 9.7354\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9443 - val_loss: 9.8302\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1595 - val_loss: 10.1941\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2339 - val_loss: 9.9864\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1990 - val_loss: 10.5787\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4628 - val_loss: 9.7103\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1433 - val_loss: 12.4392\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3410 - val_loss: 11.1000\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0748 - val_loss: 10.9884\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2551 - val_loss: 9.5415\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0552 - val_loss: 11.1451\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5269 - val_loss: 10.6890\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2855 - val_loss: 9.3432\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0417 - val_loss: 9.6759\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1526 - val_loss: 11.7365\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0836 - val_loss: 9.5882\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3833 - val_loss: 13.0221\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.1400 - val_loss: 9.6508\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3774 - val_loss: 9.5670\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4730 - val_loss: 9.6811\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1847 - val_loss: 10.4992\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0441 - val_loss: 11.3955\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1261 - val_loss: 9.9988\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3694 - val_loss: 10.0184\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1422 - val_loss: 9.3157\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4015 - val_loss: 9.6591\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3419 - val_loss: 9.2968\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6997 - val_loss: 9.9764\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3899 - val_loss: 9.3759\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2056 - val_loss: 10.9838\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5168 - val_loss: 9.5501\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9946 - val_loss: 9.6236\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3836 - val_loss: 11.4128\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4895 - val_loss: 9.7020\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.1491 - val_loss: 9.3223\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1280 - val_loss: 9.9742\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9590 - val_loss: 9.1843\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3455 - val_loss: 10.1836\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5669 - val_loss: 9.2335\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0326 - val_loss: 9.3588\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0662 - val_loss: 10.9649\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4146 - val_loss: 10.1262\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2043 - val_loss: 9.8676\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4623 - val_loss: 9.6942\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5979 - val_loss: 10.4540\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.1720 - val_loss: 9.6750\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9775 - val_loss: 9.3113\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6843 - val_loss: 10.6869\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3491 - val_loss: 9.2304\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1205 - val_loss: 9.1884\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9875 - val_loss: 10.4423\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1560 - val_loss: 9.6543\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0708 - val_loss: 10.2543\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9671 - val_loss: 10.3202\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4417 - val_loss: 9.7712\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2388 - val_loss: 9.2342\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9207 - val_loss: 9.1516\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9431 - val_loss: 9.2607\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0239 - val_loss: 9.3085\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9096 - val_loss: 9.5647\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2158 - val_loss: 13.3047\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3577 - val_loss: 10.6370\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9862 - val_loss: 11.2025\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0302 - val_loss: 9.3302\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9401 - val_loss: 9.5621\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1255 - val_loss: 9.9722\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0375 - val_loss: 9.1375\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1185 - val_loss: 9.5661\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9088 - val_loss: 9.4461\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2413 - val_loss: 10.6808\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0079 - val_loss: 9.1013\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1803 - val_loss: 9.4387\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.6536 - val_loss: 9.8521\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8867 - val_loss: 10.0971\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.8512 - val_loss: 9.4901\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.1299 - val_loss: 10.5460\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2474 - val_loss: 10.1523\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5565 - val_loss: 9.9030\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.1991 - val_loss: 10.2317\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.2215 - val_loss: 9.9959\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 7.8549 - val_loss: 8.8997\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.0409 - val_loss: 10.7683\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.1145 - val_loss: 9.9599\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0095 - val_loss: 9.7711\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1235 - val_loss: 9.4078\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1704 - val_loss: 9.1592\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9085 - val_loss: 9.8509\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8513 - val_loss: 9.2293\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8748 - val_loss: 10.2954\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0649 - val_loss: 9.5945\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8951 - val_loss: 10.0130\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3087 - val_loss: 9.4032\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6053 - val_loss: 10.8742\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1616 - val_loss: 9.8001\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0245 - val_loss: 9.0570\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1700 - val_loss: 13.0878\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2605 - val_loss: 9.4467\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1489 - val_loss: 10.0817\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3345 - val_loss: 10.6081\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0692 - val_loss: 9.2046\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0453 - val_loss: 10.3875\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9529 - val_loss: 9.4787\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8771 - val_loss: 9.2699\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8313 - val_loss: 10.3550\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9452 - val_loss: 9.5808\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1202 - val_loss: 9.3497\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8978 - val_loss: 9.6466\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2017 - val_loss: 9.3708\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1201 - val_loss: 9.0628\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0907 - val_loss: 9.4963\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3195 - val_loss: 11.0010\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1859 - val_loss: 9.7674\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9076 - val_loss: 9.0301\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9925 - val_loss: 10.1032\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9205 - val_loss: 9.7268\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2786 - val_loss: 9.0575\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9671 - val_loss: 10.1650\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7398 - val_loss: 9.4338\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1703 - val_loss: 10.1576\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9858 - val_loss: 9.2609\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9595 - val_loss: 9.6963\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9375 - val_loss: 9.1274\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5500 - val_loss: 9.6136\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2115 - val_loss: 9.3321\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9605 - val_loss: 9.3683\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3219 - val_loss: 9.0163\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5643 - val_loss: 9.6476\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0430 - val_loss: 9.2265\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7749 - val_loss: 9.5277\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7277 - val_loss: 9.2716\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0351 - val_loss: 9.4696\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8966 - val_loss: 10.0939\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9548 - val_loss: 9.1985\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7606 - val_loss: 10.2090\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0478 - val_loss: 9.2025\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1965 - val_loss: 9.4131\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2331 - val_loss: 10.4401\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9843 - val_loss: 9.4783\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9128 - val_loss: 9.3664\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8594 - val_loss: 9.1107\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1151 - val_loss: 9.6044\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0367 - val_loss: 9.3469\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0230 - val_loss: 10.1587\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8949 - val_loss: 9.2778\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0139 - val_loss: 10.1658\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0698 - val_loss: 10.1592\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7298 - val_loss: 9.0624\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0141 - val_loss: 10.8911\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8022 - val_loss: 11.7551\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8004 - val_loss: 9.0819\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7988 - val_loss: 12.5807\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9019 - val_loss: 10.9811\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1366 - val_loss: 9.4256\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7386 - val_loss: 9.8675\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1082 - val_loss: 9.0460\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1073 - val_loss: 9.3403\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8107 - val_loss: 9.4397\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8888 - val_loss: 10.6793\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0990 - val_loss: 9.6058\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8404 - val_loss: 9.0558\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0383 - val_loss: 9.8222\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8210 - val_loss: 11.2190\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9108 - val_loss: 11.5169\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6015 - val_loss: 10.8777\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2899 - val_loss: 9.2839\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7623 - val_loss: 10.2098\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1621 - val_loss: 10.7910\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3319 - val_loss: 9.4990\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2127 - val_loss: 9.6256\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2646 - val_loss: 8.9601\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8708 - val_loss: 10.6199\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9943 - val_loss: 9.3093\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2740 - val_loss: 10.0259\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0043 - val_loss: 9.3163\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1109 - val_loss: 8.8976\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1101 - val_loss: 10.1448\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0192 - val_loss: 9.3039\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9929 - val_loss: 8.8482\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9909 - val_loss: 8.9979\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8324 - val_loss: 9.5124\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7143 - val_loss: 9.1277\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8281 - val_loss: 9.3102\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 132us/step - loss: 8.4757 - val_loss: 9.7625\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8364 - val_loss: 9.5621\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8103 - val_loss: 9.3948\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0863 - val_loss: 10.0511\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9463 - val_loss: 8.7889\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.013 - 0s 84us/step - loss: 8.3121 - val_loss: 11.4924\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0310 - val_loss: 9.9340\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9715 - val_loss: 9.2384\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7080 - val_loss: 9.4803\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0663 - val_loss: 9.3190\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9547 - val_loss: 11.0769\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9952 - val_loss: 9.9775\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5626 - val_loss: 9.2595\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0053 - val_loss: 9.3857\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2699 - val_loss: 9.1908\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0787 - val_loss: 9.2771\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9166 - val_loss: 8.9841\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9049 - val_loss: 9.1747\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8703 - val_loss: 9.8893\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9108 - val_loss: 8.9292\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6047 - val_loss: 10.9167\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7354 - val_loss: 9.1112\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.8178 - val_loss: 9.4252\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7953 - val_loss: 9.6322\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8976 - val_loss: 9.0583\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8313 - val_loss: 10.0622\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8302 - val_loss: 9.3859\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9904 - val_loss: 9.3507\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3145 - val_loss: 9.4075\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0911 - val_loss: 8.9394\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7819 - val_loss: 9.2789\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7657 - val_loss: 9.7004\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9142 - val_loss: 9.1653\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9272 - val_loss: 8.9870\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7662 - val_loss: 8.9219\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1244 - val_loss: 9.7345\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6309 - val_loss: 12.1149\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2884 - val_loss: 9.8712\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9058 - val_loss: 9.4364\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9027 - val_loss: 9.4191\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1255 - val_loss: 9.2644\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9680 - val_loss: 8.8226\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1063 - val_loss: 10.4537\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9079 - val_loss: 9.8683\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8008 - val_loss: 9.1887\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6806 - val_loss: 9.6846\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8800 - val_loss: 10.0261\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0568 - val_loss: 9.0938\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0465 - val_loss: 9.1179\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8495 - val_loss: 10.4002\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9219 - val_loss: 9.0397\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8389 - val_loss: 8.8524\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7822 - val_loss: 9.1176\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8069 - val_loss: 8.7801\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4204 - val_loss: 13.0359\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0085 - val_loss: 9.8637\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9861 - val_loss: 8.9374\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9858 - val_loss: 8.9936\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7383 - val_loss: 9.8744\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9962 - val_loss: 9.0806\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8488 - val_loss: 9.1575\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0937 - val_loss: 9.8148\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9919 - val_loss: 9.7084\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4588 - val_loss: 11.0858\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0416 - val_loss: 9.1624\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9364 - val_loss: 9.6114\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0987 - val_loss: 10.6101\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5322 - val_loss: 9.0186\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8752 - val_loss: 9.2392\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9771 - val_loss: 9.7204\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8752 - val_loss: 10.4247\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7049 - val_loss: 9.2156\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7964 - val_loss: 9.8477\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3348 - val_loss: 9.3768\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5599 - val_loss: 10.4942\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3270 - val_loss: 9.6925\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0844 - val_loss: 9.3311\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3350 - val_loss: 9.4329\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0416 - val_loss: 9.5795\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0089 - val_loss: 9.0824\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8129 - val_loss: 9.9828\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0343 - val_loss: 8.8633\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0757 - val_loss: 9.7482\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9600 - val_loss: 8.8128\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7142 - val_loss: 9.9869\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7988 - val_loss: 10.2430\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1528 - val_loss: 9.4172\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.8757 - val_loss: 9.3223\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8861 - val_loss: 8.7753\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4601 - val_loss: 10.2321\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9410 - val_loss: 9.1000\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1067 - val_loss: 8.9638\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8112 - val_loss: 8.7626\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4573 - val_loss: 10.5781\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3239 - val_loss: 8.9181\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.0267 - val_loss: 8.6657\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.8271 - val_loss: 9.9023\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0359 - val_loss: 10.1169\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0633 - val_loss: 9.6280\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.0734 - val_loss: 9.0260\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8016 - val_loss: 8.9481\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7107 - val_loss: 8.6818\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 7.6094 - val_loss: 8.8019\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0621 - val_loss: 9.6321\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0690 - val_loss: 8.9741\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8904 - val_loss: 9.3085\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7684 - val_loss: 9.1025\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0327 - val_loss: 9.3848\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9948 - val_loss: 9.3269\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7137 - val_loss: 8.9524\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9799 - val_loss: 9.2263\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0293 - val_loss: 9.3131\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9477 - val_loss: 9.2283\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0348 - val_loss: 9.0900\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8856 - val_loss: 10.6761\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2925 - val_loss: 8.9410\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9529 - val_loss: 9.0080\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7447 - val_loss: 9.1487\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0279 - val_loss: 9.1454\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2648 - val_loss: 9.0212\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8503 - val_loss: 9.8460\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9620 - val_loss: 10.1022\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7046 - val_loss: 9.0014\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6802 - val_loss: 9.1830\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2807 - val_loss: 10.0851\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.6610 - val_loss: 8.7646\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8774 - val_loss: 8.9297\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9210 - val_loss: 9.1999\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2121 - val_loss: 8.7651\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8948 - val_loss: 10.1562\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7688 - val_loss: 10.2105\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9086 - val_loss: 8.8852\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1748 - val_loss: 9.6775\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1138 - val_loss: 11.0421\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6730 - val_loss: 9.7584\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0175 - val_loss: 8.8197\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1352 - val_loss: 9.5548\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2928 - val_loss: 9.0614\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0620 - val_loss: 9.5260\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1630 - val_loss: 10.6609\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2293 - val_loss: 9.7552\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8728 - val_loss: 9.0037\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8396 - val_loss: 9.2331\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9402 - val_loss: 10.1180\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7819 - val_loss: 9.0170\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8490 - val_loss: 10.3912\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8114 - val_loss: 9.5007\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8329 - val_loss: 9.8613\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7757 - val_loss: 8.8565\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7354 - val_loss: 9.1924\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6673 - val_loss: 9.1855\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8372 - val_loss: 8.8627\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9726 - val_loss: 10.3431\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9112 - val_loss: 8.9114\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1499 - val_loss: 9.7165\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1961 - val_loss: 9.6839\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9244 - val_loss: 9.1893\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.389 - 0s 87us/step - loss: 8.1788 - val_loss: 9.8571\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7646 - val_loss: 8.7272\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7325 - val_loss: 8.6713\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8227 - val_loss: 9.0535\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8002 - val_loss: 9.2614\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8142 - val_loss: 9.5271\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2969 - val_loss: 9.0622\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2850 - val_loss: 8.8680\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9070 - val_loss: 10.7821\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1628 - val_loss: 9.4450\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2650 - val_loss: 8.8130\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7469 - val_loss: 8.7549\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6415 - val_loss: 9.1210\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6797 - val_loss: 9.8788\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4370 - val_loss: 8.7612\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1994 - val_loss: 8.5208\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6628 - val_loss: 8.6712\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0027 - val_loss: 8.5412\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7568 - val_loss: 8.8515\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7402 - val_loss: 8.9731\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7978 - val_loss: 11.0058\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9193 - val_loss: 8.8959\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9071 - val_loss: 8.6885\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0612 - val_loss: 10.5023\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9499 - val_loss: 8.4530\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8201 - val_loss: 9.4505\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1459 - val_loss: 9.3913\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2083 - val_loss: 8.9530\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4692 - val_loss: 8.8261\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6183 - val_loss: 8.9118\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5920 - val_loss: 11.4166\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0795 - val_loss: 9.6314\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0817 - val_loss: 9.0429\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7486 - val_loss: 8.6003\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8500 - val_loss: 10.8607\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0137 - val_loss: 9.6723\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9799 - val_loss: 8.7871\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8783 - val_loss: 9.4555\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7989 - val_loss: 9.5279\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6165 - val_loss: 9.1195\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7015 - val_loss: 9.0385\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6499 - val_loss: 8.5058\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9836 - val_loss: 10.4008\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6971 - val_loss: 8.6000\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8707 - val_loss: 8.5632\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9051 - val_loss: 11.1567\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9464 - val_loss: 9.1155\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3104 - val_loss: 9.0412\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0435 - val_loss: 9.4941\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0436 - val_loss: 8.9642\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5746 - val_loss: 9.2584\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6375 - val_loss: 9.4250\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7553 - val_loss: 8.3841\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5920 - val_loss: 8.4622\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2517 - val_loss: 9.8937\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9098 - val_loss: 9.1219\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8171 - val_loss: 9.1783\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.7509 - val_loss: 8.5392\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7504 - val_loss: 8.5309\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9633 - val_loss: 9.0423\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9724 - val_loss: 8.6091\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8439 - val_loss: 8.3766\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9750 - val_loss: 8.6102\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7963 - val_loss: 9.7344\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9417 - val_loss: 8.4903\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9529 - val_loss: 9.6644\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9402 - val_loss: 8.7917\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7143 - val_loss: 9.2256\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7735 - val_loss: 10.0902\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2187 - val_loss: 9.9537\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8509 - val_loss: 8.4778\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9594 - val_loss: 9.6566\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0110 - val_loss: 9.2818\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5725 - val_loss: 8.8365\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5940 - val_loss: 8.3853\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6895 - val_loss: 8.4926\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7643 - val_loss: 8.4023\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7106 - val_loss: 8.7091\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6825 - val_loss: 9.2087\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6526 - val_loss: 8.7731\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8034 - val_loss: 8.9496\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9783 - val_loss: 9.9442\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9068 - val_loss: 10.4530\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1538 - val_loss: 8.8815\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9127 - val_loss: 8.9231\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6391 - val_loss: 9.1016\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8221 - val_loss: 8.8832\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7448 - val_loss: 8.5320\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0162 - val_loss: 9.0850\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7587 - val_loss: 9.2099\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4008 - val_loss: 8.9399\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9440 - val_loss: 9.3922\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1283 - val_loss: 9.3728\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7656 - val_loss: 9.4741\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6715 - val_loss: 8.9148\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5777 - val_loss: 8.5273\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8748 - val_loss: 9.7955\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.9686 - val_loss: 8.7604\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8913 - val_loss: 8.4917\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9261 - val_loss: 9.2355\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6342 - val_loss: 8.7884\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5092 - val_loss: 9.3686\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6028 - val_loss: 8.3797\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7776 - val_loss: 8.7114\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5958 - val_loss: 8.5261\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7105 - val_loss: 9.1000\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8017 - val_loss: 9.1632\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8136 - val_loss: 10.5513\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.7627 - val_loss: 8.6779\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.7292 - val_loss: 8.4867\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.5682 - val_loss: 9.1369\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.7804 - val_loss: 9.2767\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4695 - val_loss: 13.3015\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.1728 - val_loss: 8.4531\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5977 - val_loss: 9.3915\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.5642 - val_loss: 9.2383\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7034 - val_loss: 9.5779\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8305 - val_loss: 8.7132\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8707 - val_loss: 11.2436\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7462 - val_loss: 8.7570\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9054 - val_loss: 9.5559\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8055 - val_loss: 9.0537\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.6269 - val_loss: 8.5509\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.8505 - val_loss: 8.6382\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2777 - val_loss: 8.5726\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2599 - val_loss: 9.5008\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6718 - val_loss: 8.6054\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8514 - val_loss: 9.0846\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0014 - val_loss: 8.5616\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6697 - val_loss: 8.5790\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8244 - val_loss: 9.4946\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6457 - val_loss: 8.6803\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7420 - val_loss: 8.8203\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5324 - val_loss: 8.6396\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5348 - val_loss: 8.8138\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5930 - val_loss: 8.3698\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7278 - val_loss: 8.8195\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8493 - val_loss: 9.0456\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6359 - val_loss: 9.0975\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7238 - val_loss: 8.6109\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8806 - val_loss: 8.4606\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8648 - val_loss: 8.6873\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7077 - val_loss: 8.8228\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9216 - val_loss: 9.4112\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5541 - val_loss: 10.5455\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1695 - val_loss: 8.4805\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6334 - val_loss: 8.8440\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7984 - val_loss: 9.8430\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9301 - val_loss: 8.4256\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7749 - val_loss: 9.2526\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7932 - val_loss: 8.5830\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5644 - val_loss: 9.0425\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4273 - val_loss: 8.6190\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8498 - val_loss: 8.6416\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6814 - val_loss: 8.8211\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.7915 - val_loss: 8.8965\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.4754 - val_loss: 9.2718\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5908 - val_loss: 8.7583\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7087 - val_loss: 8.7210\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.8185 - val_loss: 8.4441\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5569 - val_loss: 8.5014\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7980 - val_loss: 8.5653\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7457 - val_loss: 8.6715\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5676 - val_loss: 8.3909\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8126 - val_loss: 9.6195\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5926 - val_loss: 8.5176\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5953 - val_loss: 8.6307\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7387 - val_loss: 8.4179\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5710 - val_loss: 9.1177\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6547 - val_loss: 9.3019\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6117 - val_loss: 9.3560\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.7732 - val_loss: 8.5242\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4824 - val_loss: 8.8202\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5237 - val_loss: 8.6787\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6724 - val_loss: 9.0473\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.4596 - val_loss: 8.5440\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6052 - val_loss: 8.8714\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6279 - val_loss: 8.3176\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1592 - val_loss: 9.0773\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5074 - val_loss: 9.2657\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9826 - val_loss: 9.7571\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8683 - val_loss: 8.5104\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7301 - val_loss: 8.2995\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6105 - val_loss: 8.7326\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6895 - val_loss: 8.4820\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6356 - val_loss: 9.9998\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1924 - val_loss: 9.1849\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1220 - val_loss: 8.5673\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9657 - val_loss: 9.2663\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7780 - val_loss: 9.1618\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.5967 - val_loss: 8.3230\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6609 - val_loss: 9.1900\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7992 - val_loss: 8.6443\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5594 - val_loss: 8.4999\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6420 - val_loss: 8.9855\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7083 - val_loss: 10.3320\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.6775 - val_loss: 8.9384\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.7282 - val_loss: 10.4691\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0648 - val_loss: 8.8593\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9056 - val_loss: 9.2142\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7402 - val_loss: 9.3840\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5971 - val_loss: 9.0145\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4193 - val_loss: 8.7406\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8891 - val_loss: 8.8618\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5685 - val_loss: 8.7403\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6191 - val_loss: 8.9583\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7910 - val_loss: 9.2320\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4536 - val_loss: 8.8459\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4282 - val_loss: 8.9795\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7315 - val_loss: 8.6621\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4979 - val_loss: 8.6590\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5048 - val_loss: 8.7529\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7972 - val_loss: 8.9751\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9600 - val_loss: 8.7861\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3348 - val_loss: 8.7773\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3777 - val_loss: 8.8163\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7558 - val_loss: 9.4894\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6997 - val_loss: 8.9867\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1553 - val_loss: 10.3744\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8678 - val_loss: 8.4721\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8077 - val_loss: 10.5111\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9279 - val_loss: 8.6296\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6738 - val_loss: 9.4708\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5692 - val_loss: 9.0155\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4825 - val_loss: 9.7961\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7535 - val_loss: 8.5881\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6320 - val_loss: 8.8666\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 7.6783 - val_loss: 9.2812\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5562 - val_loss: 8.5368\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7929 - val_loss: 8.4581\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7296 - val_loss: 8.8591\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5645 - val_loss: 9.1608\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4362 - val_loss: 8.8579\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5100 - val_loss: 9.1816\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5434 - val_loss: 8.9858\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6201 - val_loss: 9.0469\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1707 - val_loss: 9.0634\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5043 - val_loss: 8.7054\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3191 - val_loss: 9.1630\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0475 - val_loss: 9.6279\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0361 - val_loss: 8.8925\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5396 - val_loss: 10.4347\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7415 - val_loss: 9.5320\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4113 - val_loss: 8.6286\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3611 - val_loss: 9.0333\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4358 - val_loss: 9.7862\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5197 - val_loss: 10.0477\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6558 - val_loss: 9.0726\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8323 - val_loss: 9.7578\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6946 - val_loss: 9.6962\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7284 - val_loss: 8.9630\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0762 - val_loss: 9.1975\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6126 - val_loss: 8.5515\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6103 - val_loss: 8.4466\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7860 - val_loss: 8.5676\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0242 - val_loss: 8.5936\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9380 - val_loss: 11.4124\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7338 - val_loss: 8.6733\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.6614 - val_loss: 9.4828\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5751 - val_loss: 8.9529\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6231 - val_loss: 8.9596\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5397 - val_loss: 8.8407\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6557 - val_loss: 9.8311\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3911 - val_loss: 9.2497\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6491 - val_loss: 8.7548\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2886 - val_loss: 9.8573\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4798 - val_loss: 8.8126\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4730 - val_loss: 9.0198\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3490 - val_loss: 10.8545\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8251 - val_loss: 8.5211\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6371 - val_loss: 9.9310\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4576 - val_loss: 10.2355\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7588 - val_loss: 8.6857\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.3674 - val_loss: 8.6042\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4278 - val_loss: 8.9560\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.6783 - val_loss: 9.2896\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4544 - val_loss: 9.6337\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5577 - val_loss: 8.7361\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6809 - val_loss: 8.9116\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5326 - val_loss: 8.8297\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6671 - val_loss: 8.5689\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8250 - val_loss: 8.9646\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8563 - val_loss: 8.5993\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5810 - val_loss: 9.4839\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5733 - val_loss: 9.4875\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4459 - val_loss: 8.6366\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3368 - val_loss: 9.1941\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4932 - val_loss: 8.6597\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6968 - val_loss: 9.3397\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2640 - val_loss: 8.8419\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3551 - val_loss: 8.5069\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5332 - val_loss: 10.0772\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5298 - val_loss: 9.3818\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5374 - val_loss: 8.8131\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8817 - val_loss: 9.8838\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3245 - val_loss: 12.9003\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5480 - val_loss: 8.6853\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5543 - val_loss: 10.3584\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5595 - val_loss: 8.7141\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4393 - val_loss: 8.8113\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5082 - val_loss: 9.0453\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3768 - val_loss: 8.8290\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3606 - val_loss: 8.8558\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3799 - val_loss: 8.5425\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8171 - val_loss: 9.6305\n",
      "7.09261953725224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.29754686, -4.5374136 , -1.8018076 , -0.48563626, -0.40350598,\n",
       "          0.43346035,  4.8322835 ,  0.47281808, -0.22530831, -2.5244021 ],\n",
       "        [ 0.16159979, -0.1929506 ,  0.08117052, -0.0918889 , -1.6149272 ,\n",
       "          0.9668325 , -0.16320778,  0.4064741 , -0.07328901,  0.20474364],\n",
       "        [ 0.3463221 , -0.33221087,  0.7638202 , -0.3557692 , -1.954208  ,\n",
       "          1.4365307 ,  1.1966695 ,  0.57852226, -0.26220226,  0.22818694],\n",
       "        [-0.97523445,  0.176037  , -0.653972  ,  0.14045495,  0.29302204,\n",
       "          0.2096561 , -0.21638705, -1.0314046 ,  0.939379  ,  0.05163943],\n",
       "        [ 0.4154829 , -3.722454  ,  0.29697382, -0.60596424,  0.7041925 ,\n",
       "          0.56830657,  0.3034414 ,  0.3608603 , -0.4313825 , -0.21422835]],\n",
       "       dtype=float32),\n",
       " array([-3.9069293 , -5.3981533 , -4.4114375 ,  0.27840617, -1.1511276 ,\n",
       "        -4.455686  ,  5.6199117 , -3.8311985 ,  4.14112   , -1.3430954 ],\n",
       "       dtype=float32),\n",
       " array([[-9.8712832e-01,  1.7560444e+00,  2.3376446e+00,  1.9221249e+00,\n",
       "         -1.3323882e+00],\n",
       "        [-7.5126028e-01,  8.0697626e-01,  9.2050087e-01,  1.0836252e-01,\n",
       "         -1.5011665e+00],\n",
       "        [-1.1859010e+00,  2.3512416e+00,  2.0760460e+00,  2.1464193e+00,\n",
       "         -1.5819725e+00],\n",
       "        [ 8.8968896e-04, -1.0681537e+00, -7.9563707e-01, -3.5646391e-01,\n",
       "          8.1304359e-01],\n",
       "        [ 9.5221594e-02, -8.2913184e-01, -1.1845273e+00, -1.8114193e-01,\n",
       "          1.5595232e-01],\n",
       "        [-8.1585217e-01,  1.3322552e+00,  2.2297769e+00,  1.0574883e+00,\n",
       "         -1.9062312e+00],\n",
       "        [ 1.4563955e+00, -3.0735407e+00, -2.2965362e+00, -1.6280861e+00,\n",
       "          2.8951457e+00],\n",
       "        [-1.5327781e+00,  2.1161716e+00,  1.7671008e+00,  1.1217247e+00,\n",
       "         -2.1723056e+00],\n",
       "        [ 1.6877667e+00, -1.7991016e+00, -2.3172123e+00, -1.3466938e+00,\n",
       "          2.1448231e+00],\n",
       "        [ 6.6879374e-01, -1.1004336e+00, -9.6543306e-01, -1.0274787e+00,\n",
       "          6.3183826e-01]], dtype=float32),\n",
       " array([ 1.6963397, -2.117602 , -2.132734 , -1.9406831,  2.091373 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.0749362],\n",
       "        [-2.076768 ],\n",
       "        [-2.4328105],\n",
       "        [-1.3689171],\n",
       "        [ 2.0469565]], dtype=float32),\n",
       " array([2.3123596], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_4(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure4_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 181\n",
      "Trainable params: 181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 243us/step - loss: 6589.9610 - val_loss: 446.9285\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 156.7046 - val_loss: 41.9371\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 35.3970 - val_loss: 30.4113\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 27.7459 - val_loss: 27.8500\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.7603 - val_loss: 26.2272\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.2084 - val_loss: 25.2989\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1212 - val_loss: 24.1102\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.1006 - val_loss: 24.0096\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.8677 - val_loss: 23.1739\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.3120 - val_loss: 22.4679\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5246 - val_loss: 23.2588\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9398 - val_loss: 21.4211\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5954 - val_loss: 22.3092\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3400 - val_loss: 21.0275\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2670 - val_loss: 21.3542\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9372 - val_loss: 21.4467\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.5946 - val_loss: 21.3045\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.7081 - val_loss: 20.4032\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.3963 - val_loss: 21.4623\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.1192 - val_loss: 20.5241\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.1890 - val_loss: 20.0269\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 136us/step - loss: 15.7667 - val_loss: 19.7405\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.7505 - val_loss: 19.9814\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.9308 - val_loss: 19.3215\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.8440 - val_loss: 18.9614\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6640 - val_loss: 19.3368\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.6524 - val_loss: 19.5018\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.5783 - val_loss: 18.9796\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.4196 - val_loss: 19.4923\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.4359 - val_loss: 18.8145\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1538 - val_loss: 19.2012\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.3032 - val_loss: 18.0901\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.2795 - val_loss: 18.3554\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7669 - val_loss: 18.1739\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2438 - val_loss: 18.4692\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.1475 - val_loss: 17.6062\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8849 - val_loss: 17.9214\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.1223 - val_loss: 18.4540\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7597 - val_loss: 18.5385\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9304 - val_loss: 18.9225\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.8122 - val_loss: 19.0829\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6505 - val_loss: 17.9820\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4891 - val_loss: 19.1695\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.0989 - val_loss: 18.5050\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4571 - val_loss: 18.3612\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3729 - val_loss: 18.0237\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5142 - val_loss: 18.0910\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4622 - val_loss: 17.4277\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5710 - val_loss: 18.6313\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4641 - val_loss: 18.1310\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5471 - val_loss: 17.7825\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4938 - val_loss: 17.3301\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.2639 - val_loss: 17.1142\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6362 - val_loss: 17.7807\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0106 - val_loss: 17.3483\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.9610 - val_loss: 18.3412\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2740 - val_loss: 17.2480\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.2172 - val_loss: 17.2700\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0091 - val_loss: 17.6362\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8496 - val_loss: 17.2165\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2490 - val_loss: 16.5852\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9543 - val_loss: 18.5520\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8564 - val_loss: 17.9715\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5526 - val_loss: 16.8178\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0455 - val_loss: 16.8635\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3808 - val_loss: 16.8678\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9165 - val_loss: 16.7549\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9349 - val_loss: 17.0671\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0035 - val_loss: 18.4682\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.4367 - val_loss: 16.7486\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2649 - val_loss: 17.3470\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7686 - val_loss: 16.4662\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6939 - val_loss: 17.6556\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4045 - val_loss: 16.2460\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.2750 - val_loss: 16.8770\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.4931 - val_loss: 16.6730\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7323 - val_loss: 19.5042\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6493 - val_loss: 17.4770\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3988 - val_loss: 16.7962\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1978 - val_loss: 16.7510\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3716 - val_loss: 16.7047\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5130 - val_loss: 18.7342\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9801 - val_loss: 17.0191\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2918 - val_loss: 16.9883\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1627 - val_loss: 17.3947\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.4732 - val_loss: 17.3496\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.7954 - val_loss: 16.5373\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.0692 - val_loss: 16.6721\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1367 - val_loss: 17.1011\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.1087 - val_loss: 15.6327\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8360 - val_loss: 16.9724\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1743 - val_loss: 18.0617\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5087 - val_loss: 18.9377\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.9770 - val_loss: 16.0871\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.2993 - val_loss: 20.3643\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4412 - val_loss: 17.9058\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1558 - val_loss: 20.4232\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6998 - val_loss: 14.8959\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2306 - val_loss: 14.9539\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4810 - val_loss: 16.4302\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.8757 - val_loss: 15.5171\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1475 - val_loss: 16.7859\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8194 - val_loss: 15.2709\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9225 - val_loss: 14.9746\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1415 - val_loss: 15.6133\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6173 - val_loss: 17.3057\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8809 - val_loss: 15.0792\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7659 - val_loss: 14.1052\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2198 - val_loss: 15.1811\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.8543 - val_loss: 15.7916\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7472 - val_loss: 15.0327\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6174 - val_loss: 16.7757\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7127 - val_loss: 15.0847\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7662 - val_loss: 16.3776\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0820 - val_loss: 14.0259\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0777 - val_loss: 15.1474\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3992 - val_loss: 15.7358\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.1650 - val_loss: 14.6902\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 11.1820 - val_loss: 13.6608\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.4279 - val_loss: 14.1037\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.0588 - val_loss: 13.8832\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 10.7351 - val_loss: 15.2743\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 10.7485 - val_loss: 13.4610\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.8388 - val_loss: 15.6102\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9590 - val_loss: 14.5791\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7327 - val_loss: 13.5171\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4736 - val_loss: 13.7935\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.2815 - val_loss: 13.2832\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.0723 - val_loss: 14.6779\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 10.3447 - val_loss: 12.3877\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.2292 - val_loss: 13.5501\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 10.2378 - val_loss: 13.1276\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.6578 - val_loss: 12.3793\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 10.2948 - val_loss: 12.1999\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 10.3016 - val_loss: 14.8142\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.0916 - val_loss: 12.2625\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.7005 - val_loss: 12.4008\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0767 - val_loss: 12.3708\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7125 - val_loss: 11.9611\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6064 - val_loss: 11.9931\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5512 - val_loss: 12.2136\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3035 - val_loss: 11.3482\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3199 - val_loss: 12.3512\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4082 - val_loss: 11.5237\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5921 - val_loss: 11.5009\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4691 - val_loss: 14.3723\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7703 - val_loss: 12.0054\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9200 - val_loss: 11.3656\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3100 - val_loss: 13.6796\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5045 - val_loss: 11.7841\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0402 - val_loss: 11.2548\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2203 - val_loss: 12.1474\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9841 - val_loss: 11.4109\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0651 - val_loss: 10.9627\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8969 - val_loss: 11.1111\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3759 - val_loss: 11.2707\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1667 - val_loss: 11.0603\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3778 - val_loss: 11.0808\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1678 - val_loss: 11.4804\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3658 - val_loss: 11.8458\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6209 - val_loss: 11.0808\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0177 - val_loss: 12.7625\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8960 - val_loss: 10.8582\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4568 - val_loss: 13.6574\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5861 - val_loss: 11.5979\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5618 - val_loss: 14.0978\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2968 - val_loss: 12.1895\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7886 - val_loss: 12.2208\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2283 - val_loss: 11.9215\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5737 - val_loss: 12.2950\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9908 - val_loss: 12.0091\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2641 - val_loss: 10.4711\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0582 - val_loss: 11.1741\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7013 - val_loss: 11.6289\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6528 - val_loss: 10.5102\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8215 - val_loss: 12.6421\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0824 - val_loss: 12.0813\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9288 - val_loss: 10.5785\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1361 - val_loss: 11.2578\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0989 - val_loss: 12.7115\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2439 - val_loss: 11.3605\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2150 - val_loss: 12.4885\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1286 - val_loss: 11.1245\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8711 - val_loss: 11.3020\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9455 - val_loss: 11.5569\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9774 - val_loss: 11.2269\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6304 - val_loss: 10.1222\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0140 - val_loss: 10.2262\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4461 - val_loss: 11.1177\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5532 - val_loss: 10.2226\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8629 - val_loss: 10.1371\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1409 - val_loss: 11.2881\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7436 - val_loss: 11.2167\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9339 - val_loss: 12.0036\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1645 - val_loss: 10.1711\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9209 - val_loss: 13.1813\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5944 - val_loss: 14.4902\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0406 - val_loss: 10.7866\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7233 - val_loss: 10.2797\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6886 - val_loss: 10.7392\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6951 - val_loss: 10.9417\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6534 - val_loss: 9.9392\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0339 - val_loss: 11.6324\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1929 - val_loss: 11.5085\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9052 - val_loss: 11.5683\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8643 - val_loss: 11.0790\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8527 - val_loss: 10.1490\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5820 - val_loss: 9.6334\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2417 - val_loss: 10.6205\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5536 - val_loss: 9.5809\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0641 - val_loss: 12.8386\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4986 - val_loss: 9.8267\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6301 - val_loss: 9.9854\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4443 - val_loss: 11.5346\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9734 - val_loss: 10.2827\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5391 - val_loss: 10.2847\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6050 - val_loss: 10.1361\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8080 - val_loss: 10.9657\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2481 - val_loss: 9.9716\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1592 - val_loss: 10.1301\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9822 - val_loss: 11.6855\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6531 - val_loss: 10.0216\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4770 - val_loss: 9.8717\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6715 - val_loss: 9.7647\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4632 - val_loss: 11.5566\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8660 - val_loss: 9.8385\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3073 - val_loss: 10.1570\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9947 - val_loss: 10.8349\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6346 - val_loss: 10.6357\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7566 - val_loss: 9.8499\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2476 - val_loss: 9.9462\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4270 - val_loss: 9.5521\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8956 - val_loss: 10.5604\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7066 - val_loss: 10.3924\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7710 - val_loss: 12.1484\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5994 - val_loss: 9.8466\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6350 - val_loss: 9.5109\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6932 - val_loss: 10.0797\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6308 - val_loss: 11.6064\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0906 - val_loss: 12.4255\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1237 - val_loss: 10.3413\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4437 - val_loss: 9.1953\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1304 - val_loss: 9.4968\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5655 - val_loss: 9.3371\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2995 - val_loss: 9.3871\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1781 - val_loss: 12.0531\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9225 - val_loss: 9.4442\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2056 - val_loss: 10.1873\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5366 - val_loss: 10.1736\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7627 - val_loss: 13.3063\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4622 - val_loss: 9.9963\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5562 - val_loss: 10.5622\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4614 - val_loss: 9.2157\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9172 - val_loss: 9.2929\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2202 - val_loss: 9.8094\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7979 - val_loss: 9.5811\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7049 - val_loss: 10.0935\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3980 - val_loss: 9.5833\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4108 - val_loss: 9.8378\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6086 - val_loss: 9.6473\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4111 - val_loss: 9.3847\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3458 - val_loss: 9.0889\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7592 - val_loss: 10.5756\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1605 - val_loss: 9.1134\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5885 - val_loss: 9.7395\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7914 - val_loss: 10.3957\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3908 - val_loss: 9.0399\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3891 - val_loss: 9.5970\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7583 - val_loss: 9.4258\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2638 - val_loss: 9.0569\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4365 - val_loss: 9.9876\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0617 - val_loss: 9.2193\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2812 - val_loss: 8.7714\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4404 - val_loss: 9.5765\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6643 - val_loss: 8.7550\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5279 - val_loss: 9.3332\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7600 - val_loss: 12.1966\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3412 - val_loss: 9.9773\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0452 - val_loss: 9.2228\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1228 - val_loss: 9.5495\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5345 - val_loss: 10.6368\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2295 - val_loss: 8.9420\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0618 - val_loss: 9.1148\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5950 - val_loss: 9.4025\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1660 - val_loss: 9.1729\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6059 - val_loss: 9.5837\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9775 - val_loss: 9.3862\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4338 - val_loss: 10.7248\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2499 - val_loss: 9.3419\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0760 - val_loss: 10.6529\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1488 - val_loss: 9.3248\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9565 - val_loss: 8.6894\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1436 - val_loss: 10.4591\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9680 - val_loss: 9.2967\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4390 - val_loss: 10.0623\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8995 - val_loss: 9.2059\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0028 - val_loss: 8.8332\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3026 - val_loss: 9.6711\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1124 - val_loss: 8.8523\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6262 - val_loss: 9.9803\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1254 - val_loss: 9.6091\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9059 - val_loss: 9.2817\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1402 - val_loss: 9.4902\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.2352 - val_loss: 12.0390\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.0546 - val_loss: 8.6285\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0046 - val_loss: 9.3447\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4197 - val_loss: 10.3350\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.3128 - val_loss: 9.1776\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0406 - val_loss: 13.3406\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9942 - val_loss: 9.9818\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9587 - val_loss: 9.7371\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5228 - val_loss: 10.1797\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0747 - val_loss: 8.8209\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0321 - val_loss: 9.4324\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8877 - val_loss: 9.2743\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2955 - val_loss: 9.7858\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7980 - val_loss: 9.0293\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7846 - val_loss: 8.7566\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9157 - val_loss: 8.7324\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9912 - val_loss: 8.5776\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1582 - val_loss: 9.6326\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4895 - val_loss: 8.7253\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7093 - val_loss: 9.1737\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6694 - val_loss: 8.4465\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9386 - val_loss: 8.5880\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7865 - val_loss: 8.3957\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5884 - val_loss: 8.5146\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2867 - val_loss: 10.6908\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8519 - val_loss: 9.6507\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9750 - val_loss: 8.6887\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9177 - val_loss: 8.8001\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5396 - val_loss: 8.3505\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4522 - val_loss: 9.0602\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7944 - val_loss: 8.8376\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5310 - val_loss: 9.3476\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8924 - val_loss: 9.9447\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9895 - val_loss: 13.3114\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6307 - val_loss: 8.4182\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4647 - val_loss: 8.0958\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6803 - val_loss: 8.7030\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2507 - val_loss: 8.4637\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3765 - val_loss: 8.4675\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4940 - val_loss: 9.8912\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5990 - val_loss: 8.2496\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7178 - val_loss: 8.8707\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5009 - val_loss: 8.3742\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7398 - val_loss: 9.1430\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7200 - val_loss: 8.4448\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6479 - val_loss: 8.0645\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6612 - val_loss: 8.9454\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4108 - val_loss: 8.1018\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7882 - val_loss: 8.2080\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4551 - val_loss: 10.4494\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5149 - val_loss: 8.3868\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4026 - val_loss: 8.1521\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5944 - val_loss: 9.2031\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5293 - val_loss: 8.5644\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7543 - val_loss: 9.0036\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5224 - val_loss: 9.7499\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1032 - val_loss: 8.1257\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9406 - val_loss: 8.1771\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1812 - val_loss: 8.6000\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3264 - val_loss: 8.5430\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7418 - val_loss: 9.5032\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5604 - val_loss: 9.1155\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8586 - val_loss: 9.2775\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.110 - 0s 86us/step - loss: 7.3975 - val_loss: 10.5738\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5997 - val_loss: 8.2813\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9131 - val_loss: 11.1458\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6132 - val_loss: 9.2378\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8046 - val_loss: 8.7599\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.3669 - val_loss: 8.7426\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5035 - val_loss: 10.0185\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8370 - val_loss: 8.7443\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1837 - val_loss: 8.4054\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3853 - val_loss: 10.4292\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3729 - val_loss: 8.1768\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3358 - val_loss: 8.6644\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3075 - val_loss: 8.6311\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5582 - val_loss: 8.3109\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2136 - val_loss: 8.5258\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2685 - val_loss: 8.6389\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4136 - val_loss: 8.0324\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7896 - val_loss: 8.1585\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2975 - val_loss: 9.0439\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3207 - val_loss: 8.9309\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2852 - val_loss: 9.2244\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3810 - val_loss: 8.3830\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2431 - val_loss: 8.7333\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6471 - val_loss: 9.3261\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6432 - val_loss: 12.3237\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3499 - val_loss: 10.5052\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5934 - val_loss: 8.3030\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8184 - val_loss: 8.6798\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8620 - val_loss: 8.7323\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2559 - val_loss: 8.5470\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1791 - val_loss: 8.7435\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6459 - val_loss: 9.0369\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6356 - val_loss: 9.8289\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9337 - val_loss: 8.3523\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5867 - val_loss: 8.0704\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3193 - val_loss: 8.4304\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3828 - val_loss: 8.7095\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2594 - val_loss: 9.2508\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3883 - val_loss: 8.4826\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2824 - val_loss: 8.8031\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1159 - val_loss: 8.5079\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.422 - 0s 88us/step - loss: 7.1886 - val_loss: 8.9354\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2915 - val_loss: 8.7548\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2211 - val_loss: 8.2256\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2887 - val_loss: 9.8580\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6046 - val_loss: 9.5054\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4847 - val_loss: 9.5411\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4755 - val_loss: 10.3271\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2403 - val_loss: 9.1423\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3312 - val_loss: 9.3739\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3828 - val_loss: 8.0863\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3931 - val_loss: 9.2864\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2163 - val_loss: 8.4166\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3285 - val_loss: 9.3100\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2227 - val_loss: 8.3194\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7498 - val_loss: 9.5142\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4686 - val_loss: 8.9504\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1095 - val_loss: 9.1213\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6777 - val_loss: 9.2562\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2853 - val_loss: 8.3793\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9515 - val_loss: 10.5573\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8104 - val_loss: 10.2255\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2001 - val_loss: 8.6672\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4765 - val_loss: 9.5506\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3226 - val_loss: 9.6622\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5172 - val_loss: 9.1479\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3327 - val_loss: 8.7430\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6380 - val_loss: 10.9895\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8304 - val_loss: 9.3830\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7221 - val_loss: 9.9826\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6784 - val_loss: 10.3538\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5432 - val_loss: 9.6370\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7124 - val_loss: 8.4303\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2206 - val_loss: 8.1195\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5885 - val_loss: 8.2751\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0629 - val_loss: 8.5038\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0140 - val_loss: 8.4802\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4156 - val_loss: 8.4462\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3489 - val_loss: 8.0537\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5096 - val_loss: 9.5174\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0691 - val_loss: 9.6579\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1128 - val_loss: 8.6581\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1706 - val_loss: 10.3757\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7188 - val_loss: 8.1556\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1850 - val_loss: 8.6355\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0529 - val_loss: 8.2388\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1274 - val_loss: 8.7425\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1783 - val_loss: 9.2298\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3715 - val_loss: 8.2658\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4912 - val_loss: 9.3676\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3397 - val_loss: 7.9835\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1215 - val_loss: 8.4475\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5274 - val_loss: 8.6361\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7049 - val_loss: 8.6999\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4847 - val_loss: 8.4705\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1481 - val_loss: 9.2167\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1682 - val_loss: 9.2400\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1517 - val_loss: 9.1404\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5182 - val_loss: 8.8843\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1673 - val_loss: 8.9085\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2048 - val_loss: 8.2781\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1242 - val_loss: 8.5137\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0332 - val_loss: 9.3295\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4464 - val_loss: 10.8560\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1429 - val_loss: 8.5053\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.1161 - val_loss: 8.1961\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.2407 - val_loss: 8.3751\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.3103 - val_loss: 9.0586\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.1238 - val_loss: 8.8750\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2354 - val_loss: 9.0619\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9931 - val_loss: 8.5650\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2053 - val_loss: 8.7601\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.1445 - val_loss: 8.3365\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2424 - val_loss: 9.1367\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.9675 - val_loss: 8.1053\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1477 - val_loss: 11.3031\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2873 - val_loss: 9.0423\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8221 - val_loss: 8.0520\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9306 - val_loss: 9.4362\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3389 - val_loss: 8.5900\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6478 - val_loss: 8.6771\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2719 - val_loss: 8.3786\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9026 - val_loss: 8.3083\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1051 - val_loss: 8.8378\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2168 - val_loss: 8.8601\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0331 - val_loss: 9.1831\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9710 - val_loss: 9.2478\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0646 - val_loss: 10.3993\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0590 - val_loss: 9.0346\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7657 - val_loss: 8.8206\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2448 - val_loss: 8.2376\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6958 - val_loss: 8.3299\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9367 - val_loss: 8.6034\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8884 - val_loss: 8.3581\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0776 - val_loss: 8.0227\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4012 - val_loss: 10.0225\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3191 - val_loss: 8.3460\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6517 - val_loss: 8.8974\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5482 - val_loss: 8.3804\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3708 - val_loss: 9.0531\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9957 - val_loss: 8.5177\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9348 - val_loss: 9.5921\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2951 - val_loss: 9.0235\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.9945 - val_loss: 8.6533\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0277 - val_loss: 8.2100\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1623 - val_loss: 8.2317\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0311 - val_loss: 8.6564\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4824 - val_loss: 8.6959\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0034 - val_loss: 8.6682\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2946 - val_loss: 8.7029\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3805 - val_loss: 8.5104\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1463 - val_loss: 8.4512\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5341 - val_loss: 8.4344\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0554 - val_loss: 8.2238\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5579 - val_loss: 9.1800\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5360 - val_loss: 8.7070\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8366 - val_loss: 9.6987\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6281 - val_loss: 8.3177\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4851 - val_loss: 8.2572\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1449 - val_loss: 8.2121\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0453 - val_loss: 8.8596\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2133 - val_loss: 8.3320\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1307 - val_loss: 8.4154\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1632 - val_loss: 8.6835\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5781 - val_loss: 8.7374\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2914 - val_loss: 10.9407\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1908 - val_loss: 8.5954\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9629 - val_loss: 8.5459\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4149 - val_loss: 8.1058\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1321 - val_loss: 8.8446\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4782 - val_loss: 9.5416\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3562 - val_loss: 8.6993\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0198 - val_loss: 8.2642\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1588 - val_loss: 9.1294\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8612 - val_loss: 8.6417\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1810 - val_loss: 8.2361\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9927 - val_loss: 8.7262\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.0204 - val_loss: 8.2527\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9190 - val_loss: 8.0352\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9687 - val_loss: 8.4304\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0693 - val_loss: 8.9802\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5403 - val_loss: 8.7285\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1393 - val_loss: 8.0561\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.8446 - val_loss: 7.9690\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6350 - val_loss: 8.5797\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7810 - val_loss: 8.6382\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2129 - val_loss: 9.5460\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8558 - val_loss: 8.4654\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5537 - val_loss: 9.0590\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0596 - val_loss: 9.0454\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1576 - val_loss: 8.8240\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1929 - val_loss: 8.8823\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9238 - val_loss: 8.9683\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5623 - val_loss: 8.3231\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9045 - val_loss: 8.0129\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9397 - val_loss: 8.4683\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8877 - val_loss: 8.3583\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6147 - val_loss: 8.6686\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9793 - val_loss: 8.3487\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1527 - val_loss: 8.9659\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0684 - val_loss: 8.5326\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1502 - val_loss: 8.8179\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5618 - val_loss: 7.9691\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9254 - val_loss: 9.7097\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1329 - val_loss: 9.3047\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9437 - val_loss: 8.6520\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1566 - val_loss: 8.0663\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0885 - val_loss: 9.7456\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6507 - val_loss: 8.4066\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9613 - val_loss: 8.2797\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1190 - val_loss: 8.7193\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8789 - val_loss: 10.5843\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9055 - val_loss: 7.9894\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3570 - val_loss: 9.1522\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0451 - val_loss: 8.8258\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8763 - val_loss: 8.4454\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4377 - val_loss: 8.8067\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2008 - val_loss: 10.2853\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8193 - val_loss: 8.6003\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0532 - val_loss: 8.3139\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0118 - val_loss: 8.3829\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8525 - val_loss: 7.9236\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8207 - val_loss: 9.7344\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1102 - val_loss: 8.4956\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8245 - val_loss: 8.5363\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0139 - val_loss: 8.5591\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2977 - val_loss: 8.6195\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7247 - val_loss: 7.9387\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4622 - val_loss: 7.9064\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7945 - val_loss: 7.7868\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1939 - val_loss: 8.3339\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.1283 - val_loss: 8.0608\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4039 - val_loss: 9.4133\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8825 - val_loss: 7.9644\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2667 - val_loss: 8.4430\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7607 - val_loss: 7.9917\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9685 - val_loss: 7.9015\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8017 - val_loss: 8.4302\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1422 - val_loss: 9.7083\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1631 - val_loss: 10.2381\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2723 - val_loss: 8.7674\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9660 - val_loss: 8.0256\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7516 - val_loss: 8.1230\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8338 - val_loss: 8.2830\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0359 - val_loss: 9.2737\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9719 - val_loss: 8.3827\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6012 - val_loss: 7.7904\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9475 - val_loss: 8.6664\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8561 - val_loss: 10.6350\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4125 - val_loss: 8.8200\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9442 - val_loss: 8.1641\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7196 - val_loss: 7.7069\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2018 - val_loss: 8.6842\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3359 - val_loss: 8.3769\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7734 - val_loss: 8.0456\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8628 - val_loss: 7.9556\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9009 - val_loss: 9.0325\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2454 - val_loss: 8.0566\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9179 - val_loss: 8.1560\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7218 - val_loss: 7.9303\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7174 - val_loss: 7.7207\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1925 - val_loss: 9.3083\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1574 - val_loss: 8.7382\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0331 - val_loss: 8.6037\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7708 - val_loss: 7.7559\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8497 - val_loss: 8.4505\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0701 - val_loss: 9.6186\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7533 - val_loss: 7.8579\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0574 - val_loss: 8.2890\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8161 - val_loss: 8.2932\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9538 - val_loss: 9.4543\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1443 - val_loss: 7.6094\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5576 - val_loss: 8.4563\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9945 - val_loss: 9.1495\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3387 - val_loss: 11.4020\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.9697 - val_loss: 7.5679\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.8616 - val_loss: 8.7165\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0471 - val_loss: 9.1137\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.4849 - val_loss: 8.1535\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.5611 - val_loss: 8.0333\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.9198 - val_loss: 8.9658\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.6054 - val_loss: 7.4140\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.5541 - val_loss: 7.5318\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 6.8182 - val_loss: 8.2740\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.0684 - val_loss: 8.0393\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7506 - val_loss: 8.1189\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2787 - val_loss: 7.8207\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6694 - val_loss: 8.4285\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4306 - val_loss: 8.1295\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6993 - val_loss: 7.3242\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8640 - val_loss: 7.7581\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6321 - val_loss: 7.5098\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8482 - val_loss: 8.1136\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6634 - val_loss: 7.5104\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8882 - val_loss: 6.5841\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.4056 - val_loss: 7.6538\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0685 - val_loss: 6.9003\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.2099 - val_loss: 6.7723\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1706 - val_loss: 7.2623\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3508 - val_loss: 11.1893\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9692 - val_loss: 6.9678\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0460 - val_loss: 7.8243\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4461 - val_loss: 6.9898\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.7611 - val_loss: 8.1201\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5394 - val_loss: 6.8918\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0522 - val_loss: 6.7711\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1308 - val_loss: 6.6408\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9581 - val_loss: 6.6926\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4824 - val_loss: 8.0607\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8500 - val_loss: 7.5112\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2250 - val_loss: 8.5155\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3061 - val_loss: 6.5997\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2965 - val_loss: 6.3929\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5186 - val_loss: 6.4489\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.774 - 0s 85us/step - loss: 6.2276 - val_loss: 6.7558\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1894 - val_loss: 6.9700\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.3250 - val_loss: 6.4560\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.2407 - val_loss: 7.0032\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3953 - val_loss: 6.9079\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2620 - val_loss: 7.0987\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9361 - val_loss: 6.4361\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0021 - val_loss: 6.9062\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0593 - val_loss: 6.4836\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1457 - val_loss: 7.9103\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9457 - val_loss: 6.8840\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1996 - val_loss: 6.9077\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1150 - val_loss: 8.2652\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5377 - val_loss: 8.0066\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3796 - val_loss: 6.2974\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2540 - val_loss: 7.4658\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1198 - val_loss: 7.4245\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9565 - val_loss: 7.3220\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0384 - val_loss: 7.4595\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4702 - val_loss: 8.3353\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1185 - val_loss: 6.8749\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1790 - val_loss: 7.2980\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0396 - val_loss: 6.6649\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1955 - val_loss: 6.3181\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8337 - val_loss: 6.3568\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3098 - val_loss: 6.5663\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2358 - val_loss: 6.7076\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9381 - val_loss: 6.3823\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9669 - val_loss: 7.6097\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0328 - val_loss: 6.6233\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0396 - val_loss: 7.5352\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5012 - val_loss: 8.4273\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9867 - val_loss: 7.3271\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4924 - val_loss: 9.4367\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0742 - val_loss: 6.2543\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2217 - val_loss: 7.9328\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2474 - val_loss: 7.1186\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9646 - val_loss: 7.1625\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9263 - val_loss: 6.5853\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0053 - val_loss: 8.4444\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0955 - val_loss: 6.2428\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8356 - val_loss: 7.0653\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8044 - val_loss: 6.7095\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7422 - val_loss: 6.5413\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6507 - val_loss: 6.6262\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1645 - val_loss: 7.6095\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1993 - val_loss: 6.8826\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0295 - val_loss: 7.5769\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2370 - val_loss: 7.3713\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3979 - val_loss: 6.7803\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0136 - val_loss: 6.4606\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1703 - val_loss: 6.3069\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4263 - val_loss: 7.4080\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9461 - val_loss: 6.1721\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0387 - val_loss: 6.3239\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8982 - val_loss: 7.0413\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7586 - val_loss: 6.6606\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9280 - val_loss: 6.6149\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0244 - val_loss: 6.3166\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7277 - val_loss: 6.4307\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9841 - val_loss: 8.1275\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3918 - val_loss: 7.9666\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3825 - val_loss: 6.8759\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0228 - val_loss: 7.8688\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8864 - val_loss: 6.8027\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8243 - val_loss: 7.5622\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9837 - val_loss: 6.5815\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7065 - val_loss: 6.6332\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6653 - val_loss: 6.0095\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7027 - val_loss: 6.6058\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1489 - val_loss: 6.1026\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1395 - val_loss: 6.9404\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9735 - val_loss: 7.4024\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4334 - val_loss: 7.3495\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0460 - val_loss: 6.0840\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7173 - val_loss: 6.5417\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7198 - val_loss: 6.1341\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9236 - val_loss: 6.4056\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8224 - val_loss: 7.1282\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5169 - val_loss: 7.1266\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0225 - val_loss: 6.9859\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.0795 - val_loss: 8.1618\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6333 - val_loss: 6.4958\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6653 - val_loss: 6.4172\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6246 - val_loss: 6.9538\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8719 - val_loss: 6.3030\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6507 - val_loss: 6.6763\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8855 - val_loss: 7.0493\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9177 - val_loss: 7.4775\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1200 - val_loss: 6.4172\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6865 - val_loss: 6.3237\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7378 - val_loss: 5.9931\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7822 - val_loss: 6.5749\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3515 - val_loss: 6.3792\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5597 - val_loss: 6.5029\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4864 - val_loss: 6.5063\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6723 - val_loss: 6.1198\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9210 - val_loss: 6.9872\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8682 - val_loss: 6.6552\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0125 - val_loss: 5.9735\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4464 - val_loss: 6.4345\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5170 - val_loss: 6.5395\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1430 - val_loss: 8.2994\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2127 - val_loss: 6.3363\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6859 - val_loss: 6.0720\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4816 - val_loss: 7.5903\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7902 - val_loss: 6.4764\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7074 - val_loss: 5.9732\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 5.4994 - val_loss: 6.0749\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.7682 - val_loss: 6.2288\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8627 - val_loss: 7.3838\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.2462 - val_loss: 6.1960\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5172 - val_loss: 5.9584\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8072 - val_loss: 6.3086\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.3888 - val_loss: 6.9276\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6434 - val_loss: 7.6094\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6986 - val_loss: 7.8946\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1688 - val_loss: 6.4998\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8087 - val_loss: 7.0868\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4983 - val_loss: 6.7046\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6763 - val_loss: 6.4312\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7084 - val_loss: 7.0161\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8387 - val_loss: 6.7158\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6448 - val_loss: 6.2996\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6748 - val_loss: 6.8315\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9504 - val_loss: 7.8953\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8737 - val_loss: 7.4297\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9253 - val_loss: 6.8409\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5905 - val_loss: 7.9801\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2680 - val_loss: 6.5613\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6717 - val_loss: 6.3847\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.7576 - val_loss: 6.6753\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.5488 - val_loss: 5.9134\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.6701 - val_loss: 6.7487\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.7658 - val_loss: 6.5827\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.7908 - val_loss: 7.5268\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.1457 - val_loss: 6.7575\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.2242 - val_loss: 6.8883\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.6617 - val_loss: 6.3386\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8644 - val_loss: 6.7149\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7701 - val_loss: 7.0267\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8820 - val_loss: 6.1361\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5145 - val_loss: 6.7740\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5922 - val_loss: 6.2571\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6073 - val_loss: 6.0503\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6818 - val_loss: 6.1882\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6532 - val_loss: 6.8136\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0830 - val_loss: 7.8821\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1121 - val_loss: 6.7204\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9365 - val_loss: 5.9652\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7479 - val_loss: 5.9378\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5729 - val_loss: 6.1087\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6958 - val_loss: 6.3672\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6671 - val_loss: 6.6735\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.6860 - val_loss: 6.5461\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.7024 - val_loss: 6.1299\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4414 - val_loss: 5.9854\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4730 - val_loss: 6.1373\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9975 - val_loss: 5.9382\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2790 - val_loss: 6.1827\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5356 - val_loss: 5.6835\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4372 - val_loss: 6.1313\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0303 - val_loss: 8.0697\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1710 - val_loss: 6.1015\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8194 - val_loss: 6.3555\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7769 - val_loss: 6.3301\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4854 - val_loss: 6.1434\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2856 - val_loss: 7.0298\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7194 - val_loss: 7.5161\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8640 - val_loss: 9.2463\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7642 - val_loss: 6.5048\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3203 - val_loss: 6.1840\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1373 - val_loss: 5.9591\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6038 - val_loss: 6.5644\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7658 - val_loss: 5.9988\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6212 - val_loss: 6.6754\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5968 - val_loss: 5.9648\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7522 - val_loss: 8.6603\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3190 - val_loss: 6.9917\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9476 - val_loss: 6.5970\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9154 - val_loss: 7.0657\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7351 - val_loss: 6.4501\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4428 - val_loss: 6.0788\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5775 - val_loss: 6.1119\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8226 - val_loss: 6.5458\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6958 - val_loss: 7.0459\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7887 - val_loss: 6.1899\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3785 - val_loss: 5.7626\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5677 - val_loss: 6.1574\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8106 - val_loss: 8.4823\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1366 - val_loss: 8.2357\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7266 - val_loss: 6.5183\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0279 - val_loss: 5.8288\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7616 - val_loss: 6.7156\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8368 - val_loss: 6.5244\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5960 - val_loss: 6.1621\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6261 - val_loss: 5.7539\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4823 - val_loss: 5.7756\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4947 - val_loss: 8.2067\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2004 - val_loss: 6.5659\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9594 - val_loss: 6.4082\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8719 - val_loss: 5.9889\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6429 - val_loss: 5.8684\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0431 - val_loss: 6.3930\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8988 - val_loss: 7.0220\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.054 - 0s 88us/step - loss: 5.2679 - val_loss: 5.8727\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3548 - val_loss: 6.7490\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.9008 - val_loss: 7.1894\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9012 - val_loss: 6.6108\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.4271 - val_loss: 6.7800\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.3235 - val_loss: 6.2626\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6702 - val_loss: 5.8819\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3036 - val_loss: 5.8492\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7668 - val_loss: 6.8873\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.7027 - val_loss: 7.4657\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8178 - val_loss: 6.1895\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6075 - val_loss: 5.6696\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8129 - val_loss: 5.7261\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.4670 - val_loss: 6.4196\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.5776 - val_loss: 6.7561\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7515 - val_loss: 6.9267\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4587 - val_loss: 5.7877\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.3730 - val_loss: 6.2196\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4832 - val_loss: 5.7972\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0994 - val_loss: 7.6965\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0543 - val_loss: 5.8133\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6260 - val_loss: 5.5127\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6201 - val_loss: 6.0474\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7215 - val_loss: 7.3808\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3453 - val_loss: 5.5765\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5083 - val_loss: 5.9807\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7336 - val_loss: 6.6179\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1048 - val_loss: 6.6175\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6269 - val_loss: 5.9364\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5430 - val_loss: 6.0558\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5163 - val_loss: 6.0085\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8201 - val_loss: 5.8758\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3547 - val_loss: 5.7291\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4852 - val_loss: 6.1075\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5412 - val_loss: 5.8713\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4118 - val_loss: 5.9135\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.4774 - val_loss: 5.9985\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0030 - val_loss: 5.5935\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4492 - val_loss: 7.9523\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 5.7904 - val_loss: 6.3007\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5498 - val_loss: 5.8463\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1319 - val_loss: 5.7667\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 5.7196 - val_loss: 6.9881\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6875 - val_loss: 7.8681\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7537 - val_loss: 6.0046\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.3743 - val_loss: 6.3313\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8223 - val_loss: 7.0123\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7261 - val_loss: 6.1541\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6843 - val_loss: 8.0010\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5689 - val_loss: 5.8937\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4784 - val_loss: 5.5260\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.4035 - val_loss: 6.0189\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.7758 - val_loss: 5.6907\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4336 - val_loss: 6.0441\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6719 - val_loss: 6.2564\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.5568 - val_loss: 11.9138\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0198 - val_loss: 6.3408\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7103 - val_loss: 8.7227\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1681 - val_loss: 6.2522\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8998 - val_loss: 6.0598\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0612 - val_loss: 7.4798\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7066 - val_loss: 5.7024\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3602 - val_loss: 5.8437\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9885 - val_loss: 5.7704\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6736 - val_loss: 6.0469\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4799 - val_loss: 6.5414\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1168 - val_loss: 7.5417\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8267 - val_loss: 6.8844\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7685 - val_loss: 7.5248\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8521 - val_loss: 6.6947\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6156 - val_loss: 6.1389\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8328 - val_loss: 7.1019\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6580 - val_loss: 6.4825\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9015 - val_loss: 6.2117\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4304 - val_loss: 6.4348\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4483 - val_loss: 5.7654\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4464 - val_loss: 5.9339\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3705 - val_loss: 6.3687\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7944 - val_loss: 6.2856\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6959 - val_loss: 6.8529\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4627 - val_loss: 5.4866\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6626 - val_loss: 5.7923\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3493 - val_loss: 5.9992\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3158 - val_loss: 7.1705\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.675 - 0s 82us/step - loss: 5.6866 - val_loss: 5.6212\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8816 - val_loss: 5.8946\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8760 - val_loss: 5.8271\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3024 - val_loss: 5.5965\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4021 - val_loss: 5.6765\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8277 - val_loss: 5.6824\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4984 - val_loss: 5.8527\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.8516 - val_loss: 6.3511\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8506 - val_loss: 6.0835\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.8016 - val_loss: 8.0876\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0019 - val_loss: 6.5943\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6720 - val_loss: 6.3669\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7851 - val_loss: 5.3237\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.4257 - val_loss: 5.5493\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4376 - val_loss: 5.4502\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6196 - val_loss: 5.8631\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5497 - val_loss: 5.9774\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0211 - val_loss: 7.4310\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6088 - val_loss: 7.5876\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5630 - val_loss: 5.6513\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6404 - val_loss: 5.7778\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1282 - val_loss: 5.7481\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5166 - val_loss: 5.8315\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3353 - val_loss: 5.7296\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2464 - val_loss: 5.8061\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0013 - val_loss: 5.6653\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5558 - val_loss: 6.0705\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4555 - val_loss: 6.0662\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3767 - val_loss: 7.8729\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6450 - val_loss: 6.2467\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.2581 - val_loss: 5.7062\n",
      "5.612648900631255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-4.54894   ,  0.756763  , -3.8925295 ,  3.8499572 , -0.9689762 ,\n",
       "         -0.74325883,  3.0303266 , -2.8322222 ,  0.4462247 , -0.24653126],\n",
       "        [ 0.18181923,  0.40499443, -0.01979484, -0.13261867, -0.8788064 ,\n",
       "         -0.72159886,  0.4383766 ,  0.06843939,  1.008557  , -0.49589366],\n",
       "        [-0.2688333 ,  0.7279026 ,  0.08457325,  1.4294361 , -0.24042922,\n",
       "         -0.67887473,  1.9895313 , -0.16964094,  2.0019002 , -1.6644448 ],\n",
       "        [ 0.39877042, -0.9538043 , -0.08044741, -0.17802957,  0.31061208,\n",
       "          1.0346493 , -0.13067292,  0.08017372,  0.31834114,  0.10459998],\n",
       "        [-4.4781966 ,  1.0186802 , -1.2349389 , -0.08900424, -1.3028768 ,\n",
       "         -0.46460965,  0.40499592, -0.24094865,  0.6062392 ,  0.09481625]],\n",
       "       dtype=float32),\n",
       " array([-5.4819655, -2.6828554, -4.714987 ,  5.7202344, -0.5550474,\n",
       "         4.9839916,  3.4100168, -1.5411057, -5.476604 , -1.1657927],\n",
       "       dtype=float32),\n",
       " array([[-2.7653232e-01, -1.5489629e-01, -8.0517429e-01,  3.7374225e-01,\n",
       "         -2.2458227e-04,  6.7335457e-01,  5.1132339e-01,  5.4129437e-02,\n",
       "         -6.2728429e-01,  2.9014906e-01],\n",
       "        [-7.2537327e-01,  6.4521164e-02, -2.2204643e-01, -7.2879148e-01,\n",
       "          2.3495689e-01, -2.6534759e-02,  5.7080658e-03,  4.4899267e-01,\n",
       "         -3.3019221e-01,  6.0477209e-01],\n",
       "        [-2.3457661e+00,  5.5929657e-02, -1.7568581e+00,  1.6723355e+00,\n",
       "         -1.7108490e+00,  2.0146344e+00,  1.8042554e+00,  1.7576437e+00,\n",
       "         -1.4928657e+00,  1.9997261e+00],\n",
       "        [ 2.0902138e+00, -1.2975340e-02,  2.0460057e+00, -1.2214946e+00,\n",
       "          1.8956262e+00, -2.4250402e+00, -2.2698703e+00, -2.4944477e+00,\n",
       "          2.1568484e+00, -1.5508382e+00],\n",
       "        [ 1.9038169e-01,  7.0110686e-02,  4.8728010e-01,  8.2734585e-02,\n",
       "          3.4998533e-01, -8.2199156e-01, -5.2933985e-01, -4.3059662e-01,\n",
       "          1.6252948e-01, -1.6167574e-01],\n",
       "        [ 1.8922776e+00,  2.9670498e-01,  1.0743687e+00, -7.5624233e-01,\n",
       "          1.2702506e+00, -1.7903334e+00, -1.8599368e+00, -1.8154489e+00,\n",
       "          1.3571652e+00, -1.6137477e+00],\n",
       "        [ 9.2615086e-01,  1.1703931e-02,  5.1301390e-01,  6.9162577e-02,\n",
       "          1.7915222e-01, -9.2675394e-01, -2.0218945e-01, -6.4330876e-01,\n",
       "          4.3795103e-01, -9.1779703e-01],\n",
       "        [ 8.0461234e-01,  8.4473029e-02,  6.4164370e-01, -6.2899965e-01,\n",
       "          8.1784147e-01, -1.2374727e+00, -4.3730617e-01, -9.7826809e-01,\n",
       "          1.2768393e+00, -6.2532866e-01],\n",
       "        [-1.9411925e+00,  4.3204111e-01, -1.5184642e+00,  1.4229434e+00,\n",
       "         -1.4673986e+00,  1.5179744e+00,  1.5655352e+00,  1.3195267e+00,\n",
       "         -1.7024322e+00,  1.3298262e+00],\n",
       "        [ 9.8627642e-02,  5.8739636e-02,  8.4138423e-01, -8.8116401e-01,\n",
       "          6.9971061e-01, -4.7840536e-01, -3.7674868e-01, -7.2916335e-01,\n",
       "          6.2014353e-01, -9.5307493e-01]], dtype=float32),\n",
       " array([ 2.1086142,  0.152615 ,  2.0418906, -1.7919773,  1.0940242,\n",
       "        -2.0949266, -1.9920007, -2.1165223,  2.0514336, -2.0377347],\n",
       "       dtype=float32),\n",
       " array([[ 1.8929905 ],\n",
       "        [-0.00236131],\n",
       "        [ 1.4859313 ],\n",
       "        [-0.9278093 ],\n",
       "        [ 0.9170969 ],\n",
       "        [-1.7926222 ],\n",
       "        [-1.4119108 ],\n",
       "        [-1.9036041 ],\n",
       "        [ 1.5084703 ],\n",
       "        [-1.4283909 ]], dtype=float32),\n",
       " array([2.3567178], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_5(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure5_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 264us/step - loss: 6222.2906 - val_loss: 812.8789\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 163.2692 - val_loss: 41.3416\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 32.4977 - val_loss: 30.4617\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 24.0417 - val_loss: 26.4658\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.4494 - val_loss: 24.7005\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.9219 - val_loss: 24.1193\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1915 - val_loss: 23.5257\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5689 - val_loss: 22.6118\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3343 - val_loss: 22.6256\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2765 - val_loss: 21.6165\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.8999 - val_loss: 21.3724\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.3314 - val_loss: 21.3037\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1413 - val_loss: 21.0111\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.2623 - val_loss: 20.6293\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.9785 - val_loss: 20.5516\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.1742 - val_loss: 21.1254\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.4972 - val_loss: 21.1375\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.5416 - val_loss: 19.8873\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.2188 - val_loss: 20.0652\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.2445 - val_loss: 20.0338\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.2301 - val_loss: 19.4282\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9733 - val_loss: 19.9091\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7510 - val_loss: 19.6901\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6411 - val_loss: 19.1356\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6902 - val_loss: 18.5594\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6933 - val_loss: 18.9103\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3205 - val_loss: 18.6324\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2200 - val_loss: 18.2185\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3208 - val_loss: 17.8796\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0856 - val_loss: 18.0172\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9356 - val_loss: 17.8693\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.1663 - val_loss: 18.1266\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9077 - val_loss: 18.3148\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7322 - val_loss: 17.9235\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8251 - val_loss: 17.8946\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6786 - val_loss: 17.5415\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4787 - val_loss: 17.0146\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3174 - val_loss: 16.9321\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.4556 - val_loss: 18.6938\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9745 - val_loss: 17.6337\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.2643 - val_loss: 18.1293\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.0704 - val_loss: 16.6903\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.9340 - val_loss: 16.6307\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8195 - val_loss: 16.2793\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9543 - val_loss: 16.1955\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 12.6568 - val_loss: 16.2811\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 13.3560 - val_loss: 18.2527\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 12.3685 - val_loss: 17.7372\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.8433 - val_loss: 16.0900\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 12.4550 - val_loss: 16.4103\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 12.5686 - val_loss: 17.2562\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.4108 - val_loss: 15.3884\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.2316 - val_loss: 16.2089\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 12.0673 - val_loss: 15.7110\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 12.0492 - val_loss: 15.8740\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3811 - val_loss: 15.4812\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9530 - val_loss: 17.5395\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2011 - val_loss: 15.9228\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4098 - val_loss: 14.4928\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0668 - val_loss: 14.8378\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6135 - val_loss: 15.5620\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0967 - val_loss: 14.4733\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7051 - val_loss: 14.3973\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7706 - val_loss: 14.7428\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2059 - val_loss: 14.8219\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1996 - val_loss: 14.2605\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5437 - val_loss: 13.8580\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0222 - val_loss: 13.3494\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7669 - val_loss: 13.7037\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9134 - val_loss: 13.3723\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6771 - val_loss: 12.4935\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7026 - val_loss: 12.2793\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3515 - val_loss: 12.7129\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0240 - val_loss: 11.9841\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8368 - val_loss: 12.4332\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9484 - val_loss: 11.6757\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7407 - val_loss: 11.9909\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7216 - val_loss: 12.0570\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6295 - val_loss: 10.9650\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3514 - val_loss: 11.0223\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4702 - val_loss: 11.2906\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3923 - val_loss: 14.0698\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6851 - val_loss: 11.2702\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1330 - val_loss: 11.2658\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3400 - val_loss: 11.7276\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.8021 - val_loss: 12.5021\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4089 - val_loss: 13.0708\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1802 - val_loss: 11.7228\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0391 - val_loss: 9.8038\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7146 - val_loss: 10.6437\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9654 - val_loss: 11.1587\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3539 - val_loss: 10.8367\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4389 - val_loss: 10.5135\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6130 - val_loss: 10.1820\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9422 - val_loss: 9.5530\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6356 - val_loss: 10.2454\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1567 - val_loss: 10.2252\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5766 - val_loss: 11.3006\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5951 - val_loss: 10.1025\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3722 - val_loss: 9.9090\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4963 - val_loss: 9.4292\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9446 - val_loss: 11.0738\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1932 - val_loss: 11.1739\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4730 - val_loss: 12.3038\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6925 - val_loss: 11.2569\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8796 - val_loss: 10.4905\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5003 - val_loss: 9.6099\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4774 - val_loss: 11.6588\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8720 - val_loss: 10.5155\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3004 - val_loss: 9.2359\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7949 - val_loss: 10.2091\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1835 - val_loss: 9.2030\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0925 - val_loss: 10.0016\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1589 - val_loss: 9.4820\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4724 - val_loss: 9.6233\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3492 - val_loss: 9.4890\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3031 - val_loss: 8.8523\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2962 - val_loss: 10.9310\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9275 - val_loss: 10.6116\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4077 - val_loss: 10.1688\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6307 - val_loss: 9.5972\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1362 - val_loss: 10.1136\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2945 - val_loss: 10.1652\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4798 - val_loss: 9.2768\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7142 - val_loss: 9.3027\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5706 - val_loss: 9.3530\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8744 - val_loss: 10.9763\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7186 - val_loss: 9.5680\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4196 - val_loss: 9.7698\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3034 - val_loss: 8.9323\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9407 - val_loss: 10.4955\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5778 - val_loss: 12.2395\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6201 - val_loss: 10.6308\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2999 - val_loss: 8.8469\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.7966 - val_loss: 8.9523\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.3947 - val_loss: 10.6823\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7178 - val_loss: 12.0717\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.1773 - val_loss: 9.1734\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1525 - val_loss: 9.0062\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.8089 - val_loss: 8.9752\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6575 - val_loss: 10.9753\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0220 - val_loss: 8.5628\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0691 - val_loss: 11.4400\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0513 - val_loss: 10.0370\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1593 - val_loss: 8.5590\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8440 - val_loss: 8.8009\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0731 - val_loss: 9.0106\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1084 - val_loss: 10.4891\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6464 - val_loss: 10.1711\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9633 - val_loss: 8.5759\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4278 - val_loss: 9.0228\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5241 - val_loss: 10.5268\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1179 - val_loss: 10.7278\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7116 - val_loss: 8.5398\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8215 - val_loss: 9.3878\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5664 - val_loss: 8.4236\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7730 - val_loss: 10.5296\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3957 - val_loss: 11.2944\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3407 - val_loss: 10.9078\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4868 - val_loss: 8.3248\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7650 - val_loss: 9.1741\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4568 - val_loss: 10.6532\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.8368 - val_loss: 8.5575\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7967 - val_loss: 9.2537\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9648 - val_loss: 8.0972\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9172 - val_loss: 9.8595\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5467 - val_loss: 9.9006\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3240 - val_loss: 8.8030\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5057 - val_loss: 9.8952\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5761 - val_loss: 9.4088\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7027 - val_loss: 8.6784\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6962 - val_loss: 9.9312\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2316 - val_loss: 9.0624\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7769 - val_loss: 8.8814\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6556 - val_loss: 8.4166\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5382 - val_loss: 9.0023\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8332 - val_loss: 8.7450\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5172 - val_loss: 8.3857\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8871 - val_loss: 10.1242\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8658 - val_loss: 9.2561\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7411 - val_loss: 8.1721\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5389 - val_loss: 10.4675\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6938 - val_loss: 11.5472\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.135 - 0s 92us/step - loss: 8.6430 - val_loss: 9.1329\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4296 - val_loss: 8.8848\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5052 - val_loss: 8.6390\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2815 - val_loss: 9.9521\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.2716 - val_loss: 8.2501\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1371 - val_loss: 8.6523\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4310 - val_loss: 8.9531\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3331 - val_loss: 8.0670\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.7954 - val_loss: 11.1003\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8576 - val_loss: 8.8959\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6249 - val_loss: 9.2210\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9878 - val_loss: 8.9025\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4158 - val_loss: 8.4745\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3518 - val_loss: 8.6269\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9383 - val_loss: 8.7335\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7254 - val_loss: 11.9286\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5631 - val_loss: 11.1560\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2428 - val_loss: 9.4968\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5917 - val_loss: 9.3675\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0680 - val_loss: 8.1213\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2901 - val_loss: 8.0310\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8489 - val_loss: 8.1907\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1340 - val_loss: 8.2964\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8609 - val_loss: 9.9011\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2406 - val_loss: 8.7530\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2545 - val_loss: 8.5207\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1881 - val_loss: 8.4983\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9325 - val_loss: 8.6573\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4355 - val_loss: 9.3518\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2141 - val_loss: 8.0685\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.3200 - val_loss: 8.0262\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7802 - val_loss: 8.8220\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.2229 - val_loss: 9.0305\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3568 - val_loss: 8.4939\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0313 - val_loss: 11.0880\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9296 - val_loss: 9.6600\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7239 - val_loss: 7.9962\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1559 - val_loss: 8.8249\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2146 - val_loss: 8.6822\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4438 - val_loss: 10.2214\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3045 - val_loss: 7.9629\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1947 - val_loss: 8.5502\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0591 - val_loss: 9.8903\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7344 - val_loss: 9.7342\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7340 - val_loss: 8.4455\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.2330 - val_loss: 7.5247\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0924 - val_loss: 9.3857\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.2301 - val_loss: 12.8626\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5864 - val_loss: 7.6365\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0264 - val_loss: 7.3874\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0197 - val_loss: 8.4734\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7689 - val_loss: 9.8157\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6232 - val_loss: 9.1781\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8871 - val_loss: 7.6085\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7584 - val_loss: 7.8238\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8745 - val_loss: 8.8068\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0602 - val_loss: 8.2203\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5237 - val_loss: 9.0909\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9076 - val_loss: 8.2106\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5901 - val_loss: 7.6414\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3320 - val_loss: 7.9689\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 7.6269 - val_loss: 8.3742\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.6554 - val_loss: 8.8920\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0675 - val_loss: 9.3150\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 6.9998 - val_loss: 7.5519\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 6.6255 - val_loss: 8.7747\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.4853 - val_loss: 8.7756\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.3331 - val_loss: 8.4227\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.0202 - val_loss: 8.5968\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8730 - val_loss: 8.6157\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9950 - val_loss: 7.4501\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.8099 - val_loss: 8.7056\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.9673 - val_loss: 7.6768\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.7852 - val_loss: 8.6097\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6242 - val_loss: 7.5019\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.7795 - val_loss: 9.2895\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.7132 - val_loss: 7.7247\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5921 - val_loss: 7.7884\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.4976 - val_loss: 7.8383\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5165 - val_loss: 7.1100\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.6322 - val_loss: 7.3869\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5144 - val_loss: 9.2526\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3202 - val_loss: 8.2902\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.6554 - val_loss: 8.1289\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.2577 - val_loss: 8.1784\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.1971 - val_loss: 8.8455\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.1643 - val_loss: 8.2134\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4756 - val_loss: 8.8947\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.5954 - val_loss: 9.9535\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9899 - val_loss: 7.5571\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.6293 - val_loss: 8.5618\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3672 - val_loss: 7.4835\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5931 - val_loss: 7.7345\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7485 - val_loss: 7.6426\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.1307 - val_loss: 7.4893\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7854 - val_loss: 7.8053\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4169 - val_loss: 8.2349\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4050 - val_loss: 11.0162\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0852 - val_loss: 7.5428\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6435 - val_loss: 7.2338\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4348 - val_loss: 7.1011\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6586 - val_loss: 8.6869\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4877 - val_loss: 7.3304\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6022 - val_loss: 7.4775\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6164 - val_loss: 7.1967\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0547 - val_loss: 7.8441\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4938 - val_loss: 7.8154\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0562 - val_loss: 6.9736\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6838 - val_loss: 7.2725\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3487 - val_loss: 8.1006\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3363 - val_loss: 7.0177\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3347 - val_loss: 7.2811\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6024 - val_loss: 8.2179\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.5964 - val_loss: 7.1848\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.7308 - val_loss: 7.8411\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.6480 - val_loss: 8.4133\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 6.5275 - val_loss: 7.0430\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.6669 - val_loss: 7.0769\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8875 - val_loss: 7.6614\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.0369 - val_loss: 8.5731\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.2697 - val_loss: 8.0405\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 6.8811 - val_loss: 7.5470\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4377 - val_loss: 7.2459\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5933 - val_loss: 7.4447\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.8793 - val_loss: 8.3545\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.5129 - val_loss: 7.2507\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2899 - val_loss: 7.3772\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8313 - val_loss: 7.5482\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5304 - val_loss: 7.5250\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1710 - val_loss: 8.0529\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5783 - val_loss: 7.0991\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5512 - val_loss: 7.4487\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5943 - val_loss: 8.2464\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 133us/step - loss: 6.4664 - val_loss: 7.0535\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5663 - val_loss: 7.1016\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2683 - val_loss: 8.4300\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2307 - val_loss: 7.2573\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8370 - val_loss: 7.9177\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3004 - val_loss: 7.1314\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2781 - val_loss: 7.0614\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6372 - val_loss: 7.2906\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7569 - val_loss: 8.0439\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.400 - 0s 84us/step - loss: 6.4370 - val_loss: 7.8648\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7867 - val_loss: 7.8141\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4081 - val_loss: 7.4109\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1336 - val_loss: 7.0141\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6452 - val_loss: 6.6845\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4430 - val_loss: 7.2272\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5694 - val_loss: 6.9853\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7280 - val_loss: 8.6867\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1780 - val_loss: 7.2748\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4482 - val_loss: 7.0861\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6155 - val_loss: 8.2770\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7888 - val_loss: 7.7199\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7657 - val_loss: 7.5210\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6019 - val_loss: 6.8149\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4143 - val_loss: 7.4306\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0929 - val_loss: 8.7758\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3995 - val_loss: 7.2178\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8916 - val_loss: 7.1407\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5772 - val_loss: 6.9572\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3690 - val_loss: 7.4143\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2165 - val_loss: 10.3430\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0119 - val_loss: 7.2294\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5536 - val_loss: 6.6390\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0441 - val_loss: 7.1779\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4332 - val_loss: 7.2185\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1921 - val_loss: 7.8542\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0789 - val_loss: 7.1350\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1390 - val_loss: 7.0577\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4635 - val_loss: 6.6648\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0374 - val_loss: 8.8031\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2766 - val_loss: 7.4311\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1374 - val_loss: 7.7495\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3147 - val_loss: 7.4678\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5051 - val_loss: 7.1570\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5618 - val_loss: 6.6407\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.6609 - val_loss: 7.0136\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.3205 - val_loss: 6.8538\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0977 - val_loss: 7.0488\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1249 - val_loss: 6.9302\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1848 - val_loss: 8.0027\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2352 - val_loss: 7.3834\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1545 - val_loss: 6.6198\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.5504 - val_loss: 7.5183\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5435 - val_loss: 6.9814\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3718 - val_loss: 6.9660\n",
      "Epoch 371/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1544 - val_loss: 7.0168\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5410 - val_loss: 8.8315\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 6.5537 - val_loss: 8.6716\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.6611 - val_loss: 6.7573\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.4432 - val_loss: 7.0365\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2746 - val_loss: 7.6737\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.0565 - val_loss: 8.0921\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8877 - val_loss: 6.7501\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9140 - val_loss: 6.8275\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.9573 - val_loss: 7.4461\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.8846 - val_loss: 6.6772\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9651 - val_loss: 7.0480\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7116 - val_loss: 6.9372\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 6.1210 - val_loss: 6.4029\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 6.3312 - val_loss: 8.5270\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 6.4727 - val_loss: 6.5830\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8279 - val_loss: 6.7724\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1559 - val_loss: 6.8135\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9866 - val_loss: 7.0626\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2964 - val_loss: 8.0162\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2890 - val_loss: 7.1824\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7986 - val_loss: 7.2418\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1061 - val_loss: 6.5983\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0563 - val_loss: 6.4279\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2262 - val_loss: 6.9838\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1594 - val_loss: 8.8580\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3224 - val_loss: 8.6133\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.4036 - val_loss: 8.0578\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1048 - val_loss: 6.3653\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0768 - val_loss: 8.2883\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5224 - val_loss: 6.6582\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.4746 - val_loss: 7.3681\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9887 - val_loss: 6.5095\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 6.6040 - val_loss: 7.9220\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.4837 - val_loss: 6.8596\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1351 - val_loss: 6.5679\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1372 - val_loss: 7.7134\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9672 - val_loss: 7.8027\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.1994 - val_loss: 8.8433\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.4101 - val_loss: 6.4801\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8867 - val_loss: 7.8304\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.3718 - val_loss: 6.7510\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1194 - val_loss: 7.9610\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3513 - val_loss: 7.1221\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.9584 - val_loss: 6.7418\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2379 - val_loss: 9.7350\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0137 - val_loss: 7.2151\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9501 - val_loss: 8.0149\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1868 - val_loss: 7.4628\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5127 - val_loss: 6.3894\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8239 - val_loss: 6.5892\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.1735 - val_loss: 6.5014\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7659 - val_loss: 6.7652\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7880 - val_loss: 6.2330\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0978 - val_loss: 8.4888\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6837 - val_loss: 6.1674\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0524 - val_loss: 6.3193\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4950 - val_loss: 6.6221\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0167 - val_loss: 7.0920\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9551 - val_loss: 6.9477\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.6519 - val_loss: 6.8103\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0255 - val_loss: 7.0155\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.2024 - val_loss: 6.9983\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5463 - val_loss: 6.8652\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8088 - val_loss: 6.7840\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8889 - val_loss: 7.3066\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4048 - val_loss: 6.2714\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8536 - val_loss: 6.2999\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0073 - val_loss: 7.0595\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0484 - val_loss: 6.8112\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0589 - val_loss: 8.3757\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2639 - val_loss: 10.0607\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0575 - val_loss: 7.1806\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.8480 - val_loss: 6.9085\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.1557 - val_loss: 6.5009\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8091 - val_loss: 6.1816\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7333 - val_loss: 6.4334\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6368 - val_loss: 6.3353\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 133us/step - loss: 5.5783 - val_loss: 7.2269\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8177 - val_loss: 6.7384\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.9029 - val_loss: 7.9078\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9169 - val_loss: 7.4792\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9039 - val_loss: 6.9155\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7113 - val_loss: 7.3034\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7806 - val_loss: 6.5071\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7335 - val_loss: 7.4469\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1845 - val_loss: 6.2552\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7811 - val_loss: 6.3998\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2938 - val_loss: 6.9143\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.7673 - val_loss: 6.4365\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 5.7215 - val_loss: 6.0789\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 6.2503 - val_loss: 7.2021\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 5.8801 - val_loss: 6.4134\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 5.6952 - val_loss: 6.0837\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 5.7127 - val_loss: 6.9724\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 5.6474 - val_loss: 7.1983\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 121us/step - loss: 5.8308 - val_loss: 7.2123\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 127us/step - loss: 5.7055 - val_loss: 7.1142\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.5919 - val_loss: 7.0154\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8268 - val_loss: 6.5180\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6989 - val_loss: 7.7329\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0889 - val_loss: 8.4542\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0883 - val_loss: 6.7538\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7791 - val_loss: 6.0003\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5833 - val_loss: 6.1212\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7736 - val_loss: 6.7980\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6708 - val_loss: 6.6211\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7202 - val_loss: 7.5615\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6405 - val_loss: 6.3326\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8102 - val_loss: 7.2618\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9922 - val_loss: 6.1426\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7263 - val_loss: 8.0516\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0481 - val_loss: 6.2521\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2259 - val_loss: 7.3438\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2834 - val_loss: 6.9460\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8100 - val_loss: 6.7364\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7883 - val_loss: 6.6773\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0197 - val_loss: 6.1625\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7744 - val_loss: 6.0987\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9030 - val_loss: 7.9573\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7856 - val_loss: 6.3902\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1961 - val_loss: 6.5481\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8950 - val_loss: 6.3379\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7592 - val_loss: 6.2407\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1991 - val_loss: 6.2174\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7559 - val_loss: 6.0189\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0015 - val_loss: 6.9516\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7395 - val_loss: 5.8321\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4983 - val_loss: 6.5825\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8870 - val_loss: 5.8817\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8474 - val_loss: 6.6129\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5664 - val_loss: 6.2776\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4499 - val_loss: 6.1342\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7696 - val_loss: 6.4872\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8888 - val_loss: 5.9532\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1814 - val_loss: 7.0561\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8540 - val_loss: 6.1844\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5179 - val_loss: 6.4155\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6068 - val_loss: 6.9692\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7911 - val_loss: 6.0707\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8586 - val_loss: 6.1599\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8183 - val_loss: 8.8035\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6672 - val_loss: 6.4917\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8326 - val_loss: 6.5739\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7508 - val_loss: 6.2471\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7191 - val_loss: 5.9143\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5254 - val_loss: 7.1127\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4065 - val_loss: 7.4368\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0323 - val_loss: 6.4553\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7161 - val_loss: 5.9957\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4599 - val_loss: 6.5509\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6225 - val_loss: 5.7416\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8741 - val_loss: 6.6685\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3542 - val_loss: 5.9085\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4804 - val_loss: 6.1593\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7934 - val_loss: 6.0018\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1334 - val_loss: 5.9283\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5045 - val_loss: 6.3236\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9056 - val_loss: 7.3889\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6702 - val_loss: 5.7974\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4396 - val_loss: 6.2208\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3358 - val_loss: 5.8667\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5811 - val_loss: 6.1425\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7832 - val_loss: 5.9922\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3803 - val_loss: 6.1672\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6024 - val_loss: 7.0001\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4715 - val_loss: 6.9613\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5124 - val_loss: 5.7276\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5432 - val_loss: 6.4652\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5027 - val_loss: 5.8928\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4163 - val_loss: 6.1969\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5763 - val_loss: 6.4644\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6024 - val_loss: 6.0825\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5088 - val_loss: 5.8947\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4005 - val_loss: 5.8334\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5086 - val_loss: 5.9967\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3163 - val_loss: 6.4811\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4730 - val_loss: 5.8779\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5026 - val_loss: 6.2892\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4697 - val_loss: 7.6440\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5102 - val_loss: 6.1023\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4687 - val_loss: 5.5322\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7795 - val_loss: 5.6447\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3402 - val_loss: 10.2987\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5736 - val_loss: 6.8437\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4148 - val_loss: 5.6516\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.2837 - val_loss: 5.8832\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4387 - val_loss: 7.0000\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3178 - val_loss: 6.8273\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5812 - val_loss: 6.1586\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5219 - val_loss: 5.5479\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6486 - val_loss: 7.7227\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7172 - val_loss: 6.1091\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3729 - val_loss: 6.3693\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6661 - val_loss: 7.2895\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8487 - val_loss: 5.5165\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 136us/step - loss: 5.5170 - val_loss: 6.1834\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.1979 - val_loss: 5.8606\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9907 - val_loss: 7.4030\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5583 - val_loss: 5.6434\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3919 - val_loss: 5.8407\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7072 - val_loss: 9.3509\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9457 - val_loss: 6.5153\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 132us/step - loss: 5.7558 - val_loss: 6.7932\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5240 - val_loss: 5.9854\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3880 - val_loss: 5.5350\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4266 - val_loss: 7.8916\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7394 - val_loss: 6.5044\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3715 - val_loss: 5.9305\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5005 - val_loss: 8.3783\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 130us/step - loss: 5.9142 - val_loss: 6.9405\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.6887 - val_loss: 5.8186\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2429 - val_loss: 5.8694\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1980 - val_loss: 5.7440\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3727 - val_loss: 5.7748\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4084 - val_loss: 6.7145\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1813 - val_loss: 5.6865\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7917 - val_loss: 6.0630\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4319 - val_loss: 7.5799\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4688 - val_loss: 6.7134\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3774 - val_loss: 5.4978\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1180 - val_loss: 5.4990\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2297 - val_loss: 6.7454\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4658 - val_loss: 7.3450\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5568 - val_loss: 5.9760\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2765 - val_loss: 5.6868\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6327 - val_loss: 6.6196\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5735 - val_loss: 5.5507\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2997 - val_loss: 5.7444\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5161 - val_loss: 6.4284\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4446 - val_loss: 6.3820\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6671 - val_loss: 6.3363\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8733 - val_loss: 7.5814\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6647 - val_loss: 6.1879\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5456 - val_loss: 5.7090\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1846 - val_loss: 5.6510\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0082 - val_loss: 6.5653\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7232 - val_loss: 6.2513\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0566 - val_loss: 5.7182\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5146 - val_loss: 6.1288\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3034 - val_loss: 5.9203\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3820 - val_loss: 6.6971\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8828 - val_loss: 6.0160\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0718 - val_loss: 6.3683\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6622 - val_loss: 6.0349\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6862 - val_loss: 5.9001\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4133 - val_loss: 5.8432\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4453 - val_loss: 6.0851\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3114 - val_loss: 6.0684\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5869 - val_loss: 6.4943\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3351 - val_loss: 6.0582\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5180 - val_loss: 6.2368\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4160 - val_loss: 5.8159\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4410 - val_loss: 6.5496\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5731 - val_loss: 5.9526\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 5.5828 - val_loss: 7.4242\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1980 - val_loss: 5.9313\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.2012 - val_loss: 5.7507\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.0138 - val_loss: 5.5368\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.1531 - val_loss: 6.5400\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8335 - val_loss: 5.6911\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6125 - val_loss: 5.8276\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3360 - val_loss: 5.4917\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3219 - val_loss: 6.4863\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1805 - val_loss: 6.5773\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2476 - val_loss: 6.0231\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4317 - val_loss: 5.6547\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4171 - val_loss: 6.3196\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5256 - val_loss: 5.8931\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1207 - val_loss: 6.2736\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5903 - val_loss: 5.6654\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.6053 - val_loss: 6.1166\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.3248 - val_loss: 6.1071\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5.2791 - val_loss: 6.1981\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 5.4262 - val_loss: 5.4733\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3581 - val_loss: 5.6265\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4647 - val_loss: 6.3822\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5801 - val_loss: 6.2891\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1880 - val_loss: 6.2068\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7919 - val_loss: 6.2794\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6582 - val_loss: 5.4522\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.5313 - val_loss: 7.2060\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.1599 - val_loss: 6.1346\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.4668 - val_loss: 5.5806\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.7966 - val_loss: 5.8333\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4776 - val_loss: 5.4583\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1629 - val_loss: 6.2467\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.3646 - val_loss: 6.5896\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8805 - val_loss: 6.1300\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.2626 - val_loss: 5.9044\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.2605 - val_loss: 5.6478\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.0694 - val_loss: 5.6998\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.2916 - val_loss: 5.4531\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3763 - val_loss: 5.6917\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.1318 - val_loss: 5.4434\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.1557 - val_loss: 5.5309\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2985 - val_loss: 6.8799\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.3270 - val_loss: 6.6827\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3924 - val_loss: 6.2000\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3334 - val_loss: 6.7994\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5161 - val_loss: 5.9583\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3372 - val_loss: 5.7881\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.0330 - val_loss: 7.2306\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7270 - val_loss: 6.1009\n",
      "Epoch 675/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7687 - val_loss: 6.9714\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.5765 - val_loss: 5.7557\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4556 - val_loss: 5.6520\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.2866 - val_loss: 8.4029\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 6.6549 - val_loss: 5.3762\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7816 - val_loss: 5.6146\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3025 - val_loss: 5.9463\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3709 - val_loss: 6.0203\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.6479 - val_loss: 5.9487\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.2560 - val_loss: 5.5088\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0495 - val_loss: 7.1424\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8058 - val_loss: 6.3896\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4405 - val_loss: 5.2417\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2155 - val_loss: 6.3224\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.1139 - val_loss: 7.1403\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5492 - val_loss: 5.6042\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7420 - val_loss: 7.7941\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6933 - val_loss: 5.8527\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3623 - val_loss: 5.4261\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2122 - val_loss: 6.6133\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8547 - val_loss: 6.1979\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4926 - val_loss: 5.3978\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4040 - val_loss: 6.6084\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1871 - val_loss: 6.4030\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2590 - val_loss: 5.5896\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5874 - val_loss: 7.2126\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7518 - val_loss: 5.2348\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9603 - val_loss: 5.2161\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3621 - val_loss: 6.5245\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3357 - val_loss: 5.7129\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2298 - val_loss: 6.5544\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9305 - val_loss: 6.1839\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8376 - val_loss: 7.4997\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4902 - val_loss: 6.2108\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.3757 - val_loss: 5.7676\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.0036 - val_loss: 5.4844\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2048 - val_loss: 5.9705\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2201 - val_loss: 6.4067\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4688 - val_loss: 6.6174\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2552 - val_loss: 5.1504\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0631 - val_loss: 5.5618\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1299 - val_loss: 5.3298\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1588 - val_loss: 5.7695\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3415 - val_loss: 5.9325\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4874 - val_loss: 5.5554\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3590 - val_loss: 5.3714\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2566 - val_loss: 5.9688\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6124 - val_loss: 5.5898\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5147 - val_loss: 5.7552\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.9858 - val_loss: 5.5504\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7321 - val_loss: 5.7647\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5442 - val_loss: 6.6055\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2231 - val_loss: 5.3944\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.0656 - val_loss: 5.6576\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1694 - val_loss: 6.2900\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2601 - val_loss: 5.7956\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3401 - val_loss: 6.3033\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6081 - val_loss: 6.5265\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5071 - val_loss: 5.2130\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0309 - val_loss: 7.6594\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3760 - val_loss: 5.7613\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3951 - val_loss: 6.4747\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6104 - val_loss: 6.9369\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4981 - val_loss: 5.8057\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1692 - val_loss: 5.9694\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3090 - val_loss: 5.8067\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0971 - val_loss: 5.2015\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4290 - val_loss: 5.5675\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2702 - val_loss: 5.3239\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0041 - val_loss: 5.3930\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1105 - val_loss: 5.8602\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9987 - val_loss: 7.0564\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4504 - val_loss: 5.4454\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1159 - val_loss: 5.9084\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6765 - val_loss: 5.9831\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4689 - val_loss: 5.8046\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4954 - val_loss: 5.9034\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5246 - val_loss: 5.3447\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3409 - val_loss: 7.0784\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3999 - val_loss: 6.0439\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3835 - val_loss: 5.6755\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1325 - val_loss: 5.8073\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.0660 - val_loss: 5.5006\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5132 - val_loss: 5.4107\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2771 - val_loss: 7.0542\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8432 - val_loss: 5.4032\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0766 - val_loss: 5.8084\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3960 - val_loss: 6.5072\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2807 - val_loss: 6.3651\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1630 - val_loss: 6.1257\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3288 - val_loss: 5.6167\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3642 - val_loss: 6.4525\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5610 - val_loss: 6.0020\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3230 - val_loss: 5.3417\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3731 - val_loss: 6.4667\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5497 - val_loss: 5.6617\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0009 - val_loss: 5.3475\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9279 - val_loss: 5.7091\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2562 - val_loss: 5.7148\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4387 - val_loss: 6.1261\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1164 - val_loss: 5.8247\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.4342 - val_loss: 7.0267\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1292 - val_loss: 7.4129\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8362 - val_loss: 5.1809\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2994 - val_loss: 5.1086\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8649 - val_loss: 5.2903\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1841 - val_loss: 5.0085\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.9411 - val_loss: 5.3021\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4206 - val_loss: 5.3462\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3903 - val_loss: 6.4521\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.1856 - val_loss: 5.5419\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 5.0169 - val_loss: 5.3635\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.9868 - val_loss: 5.5288\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.9605 - val_loss: 5.4700\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.0660 - val_loss: 5.5942\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 5.1527 - val_loss: 5.5410\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.1550 - val_loss: 5.1246\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.3681 - val_loss: 5.5624\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4204 - val_loss: 5.0183\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.9099 - val_loss: 6.2257\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.1505 - val_loss: 5.5097\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.0276 - val_loss: 5.7283\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.9620 - val_loss: 5.5369\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3236 - val_loss: 5.9656\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7457 - val_loss: 5.8382\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2761 - val_loss: 5.2474\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5786 - val_loss: 6.1469\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3563 - val_loss: 6.2846\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9366 - val_loss: 7.1607\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2688 - val_loss: 5.2126\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1780 - val_loss: 5.7685\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5351 - val_loss: 5.5297\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1424 - val_loss: 5.6680\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0643 - val_loss: 6.3073\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7513 - val_loss: 5.3474\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.1380 - val_loss: 5.7583\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.9015 - val_loss: 6.3663\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1870 - val_loss: 5.2474\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9161 - val_loss: 5.3707\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1759 - val_loss: 5.2254\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.0876 - val_loss: 5.7103\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.7766 - val_loss: 5.8269\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9849 - val_loss: 5.4304\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2201 - val_loss: 6.7105\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9912 - val_loss: 5.8037\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2031 - val_loss: 5.2911\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.0968 - val_loss: 6.7071\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3060 - val_loss: 6.8472\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2088 - val_loss: 5.2976\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1046 - val_loss: 6.1391\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5094 - val_loss: 5.0832\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9287 - val_loss: 6.0849\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1363 - val_loss: 5.0006\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1859 - val_loss: 5.1717\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.0495 - val_loss: 5.0752\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9099 - val_loss: 5.3570\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.9449 - val_loss: 5.8890\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5213 - val_loss: 6.5549\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1677 - val_loss: 5.9382\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1563 - val_loss: 5.5431\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3019 - val_loss: 6.1061\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0843 - val_loss: 5.5843\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9517 - val_loss: 5.3035\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.0140 - val_loss: 5.3170\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6151 - val_loss: 6.8043\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0891 - val_loss: 5.0744\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8885 - val_loss: 6.8513\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1073 - val_loss: 5.4832\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9850 - val_loss: 5.3805\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3053 - val_loss: 5.0533\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1560 - val_loss: 4.9765\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9857 - val_loss: 5.2483\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2071 - val_loss: 5.3634\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2374 - val_loss: 5.3816\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9658 - val_loss: 5.6261\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4696 - val_loss: 5.2085\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3327 - val_loss: 6.2835\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1808 - val_loss: 5.8267\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3802 - val_loss: 5.2319\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0683 - val_loss: 5.5352\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2172 - val_loss: 6.7582\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8156 - val_loss: 5.6922\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8107 - val_loss: 5.4438\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6903 - val_loss: 6.2881\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2583 - val_loss: 6.0095\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1210 - val_loss: 5.1390\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2074 - val_loss: 7.1355\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3784 - val_loss: 5.8213\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3204 - val_loss: 5.0801\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4185 - val_loss: 5.7849\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2933 - val_loss: 5.8595\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0733 - val_loss: 5.1924\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8127 - val_loss: 5.2423\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.0223 - val_loss: 6.8428\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2740 - val_loss: 6.5235\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2935 - val_loss: 5.3384\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1407 - val_loss: 5.2415\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1022 - val_loss: 6.0709\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.8594 - val_loss: 5.2871\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.1029 - val_loss: 5.6932\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.0559 - val_loss: 5.2277\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8710 - val_loss: 5.7360\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8816 - val_loss: 5.0668\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2401 - val_loss: 5.4288\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3928 - val_loss: 5.7755\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1627 - val_loss: 5.2842\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1623 - val_loss: 5.3962\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8653 - val_loss: 5.0871\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.0959 - val_loss: 5.5230\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.1705 - val_loss: 5.1409\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3386 - val_loss: 6.1569\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7698 - val_loss: 5.6964\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0577 - val_loss: 6.4075\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3852 - val_loss: 6.3539\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1015 - val_loss: 5.4648\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1265 - val_loss: 5.5350\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3622 - val_loss: 5.0237\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9188 - val_loss: 6.3744\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3500 - val_loss: 5.9103\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1128 - val_loss: 5.2242\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.0822 - val_loss: 5.6956\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2236 - val_loss: 5.3131\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6179 - val_loss: 5.1708\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6375 - val_loss: 6.1576\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3994 - val_loss: 5.3851\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8816 - val_loss: 5.6017\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7261 - val_loss: 5.2780\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2905 - val_loss: 5.7344\n",
      "Epoch 903/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1594 - val_loss: 5.3330\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.7963 - val_loss: 5.3092\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3664 - val_loss: 5.3385\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2306 - val_loss: 5.6840\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.9137 - val_loss: 5.3474\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9092 - val_loss: 5.5185\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5226 - val_loss: 5.5262\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1131 - val_loss: 5.3397\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9431 - val_loss: 5.6887\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5436 - val_loss: 5.3016\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.1130 - val_loss: 5.6364\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9551 - val_loss: 5.6311\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1758 - val_loss: 4.9441\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9884 - val_loss: 5.3075\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9472 - val_loss: 5.3792\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8946 - val_loss: 5.3890\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9514 - val_loss: 5.4192\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1896 - val_loss: 6.7875\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0740 - val_loss: 5.3566\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1816 - val_loss: 5.2885\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2124 - val_loss: 7.1283\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1352 - val_loss: 5.3750\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7816 - val_loss: 5.2889\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.8879 - val_loss: 5.5761\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8393 - val_loss: 5.3470\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9508 - val_loss: 5.3105\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9865 - val_loss: 6.5792\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1488 - val_loss: 5.5072\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0375 - val_loss: 4.8708\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3605 - val_loss: 5.2917\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9821 - val_loss: 5.2388\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9657 - val_loss: 5.7558\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.446 - 0s 84us/step - loss: 5.0888 - val_loss: 5.1751\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2235 - val_loss: 5.6341\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0528 - val_loss: 5.3946\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4010 - val_loss: 5.7922\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.8975 - val_loss: 5.1480\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9742 - val_loss: 4.7727\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.9328 - val_loss: 5.4807\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2025 - val_loss: 5.1154\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.0914 - val_loss: 6.6723\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3397 - val_loss: 5.9061\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1468 - val_loss: 5.1201\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.0359 - val_loss: 5.8894\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1233 - val_loss: 4.9399\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.9373 - val_loss: 5.3145\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.0108 - val_loss: 6.3704\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4586 - val_loss: 6.5461\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9724 - val_loss: 5.0214\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.2718 - val_loss: 7.3319\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4455 - val_loss: 5.1060\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0541 - val_loss: 5.1660\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2488 - val_loss: 6.1903\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1305 - val_loss: 4.9643\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.8902 - val_loss: 4.8482\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2674 - val_loss: 5.6782\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1621 - val_loss: 6.1893\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.4581 - val_loss: 5.2818\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 5.2752 - val_loss: 5.3027\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.0299 - val_loss: 5.6951\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 4.8930 - val_loss: 4.9874\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 4.9338 - val_loss: 5.5444\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.9960 - val_loss: 5.6900\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.9935 - val_loss: 5.1813\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3436 - val_loss: 5.3205\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.9075 - val_loss: 5.3706\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3228 - val_loss: 5.9284\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.7897 - val_loss: 4.8016\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.9013 - val_loss: 5.0371\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8539 - val_loss: 5.1915\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.0851 - val_loss: 5.2168\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1014 - val_loss: 5.6584\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.0988 - val_loss: 4.9544\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1972 - val_loss: 5.6975\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0920 - val_loss: 5.9662\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3855 - val_loss: 5.5401\n",
      "Epoch 979/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1851 - val_loss: 5.4642\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0646 - val_loss: 4.8452\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.8691 - val_loss: 4.7939\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0935 - val_loss: 5.1617\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0309 - val_loss: 5.5500\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1455 - val_loss: 5.9252\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.3570 - val_loss: 6.7392\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2662 - val_loss: 5.2603\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7807 - val_loss: 5.5327\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.9358 - val_loss: 5.1495\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2307 - val_loss: 5.9916\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2447 - val_loss: 5.3942\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9370 - val_loss: 5.2060\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.0041 - val_loss: 7.4960\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4103 - val_loss: 4.7960\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.9362 - val_loss: 4.9945\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9997 - val_loss: 4.9701\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7613 - val_loss: 4.8669\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.0336 - val_loss: 5.7573\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.0546 - val_loss: 5.5326\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3001 - val_loss: 5.2331\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9776 - val_loss: 5.0550\n",
      "5.170618479230763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.6125572 ,  0.6085845 ,  2.7822814 , -2.4259644 ,  4.2845445 ,\n",
       "         -0.21569136,  3.9998188 ,  6.5871935 , -0.6558927 , -0.05071361],\n",
       "        [ 0.17132154,  1.0442256 , -0.19284351, -0.05391383, -0.41260397,\n",
       "          0.06051411,  0.9131112 , -0.2531927 , -0.7837451 , -0.5594172 ],\n",
       "        [ 0.05192109,  1.8361807 , -0.08993945, -0.27352968,  0.6893319 ,\n",
       "          0.83255756,  3.7348065 ,  0.14145748, -0.31194958, -2.0381355 ],\n",
       "        [ 0.3232264 , -0.35635132, -0.10920472,  0.19332628, -0.23116262,\n",
       "          0.15806773, -0.22525413, -0.04669935,  0.23658814,  0.0241079 ],\n",
       "        [ 0.14833792,  0.5581028 ,  2.536186  , -0.04362506,  0.31994945,\n",
       "         -1.1427736 , -0.0293513 ,  0.6382023 , -1.1412896 ,  1.021813  ]],\n",
       "       dtype=float32),\n",
       " array([ 3.644897  , -5.051995  ,  4.0899477 , -0.25660986,  5.363279  ,\n",
       "         2.338008  ,  5.258464  ,  3.7073808 , -0.39563835, -1.3181163 ],\n",
       "       dtype=float32),\n",
       " array([[-1.8507884 ,  1.1801091 ,  1.3356609 ,  1.8140212 ,  0.99688715,\n",
       "         -0.9753267 ,  1.7640891 , -1.443102  , -1.4449338 , -0.7846334 ,\n",
       "          1.885334  , -1.1375232 , -1.5437725 ,  1.8528974 ,  1.6932153 ],\n",
       "        [ 1.141087  , -0.6045499 , -0.9213907 , -1.1951383 , -0.5188649 ,\n",
       "          0.22349045, -1.4440236 ,  0.66969377,  1.2795087 ,  0.5689681 ,\n",
       "         -0.9468457 ,  1.6366173 ,  1.7121704 , -0.88723403, -1.1032295 ],\n",
       "        [-2.0254016 ,  1.4423037 ,  1.456991  ,  1.7183819 ,  1.480861  ,\n",
       "         -1.4933249 ,  1.1835864 , -1.7663668 , -1.8660717 , -1.4314787 ,\n",
       "          1.4129555 , -2.21306   , -2.1383882 ,  1.2921826 ,  1.6705028 ],\n",
       "        [ 0.02236189,  0.4104119 , -0.0663723 ,  0.40184385, -0.04467693,\n",
       "         -0.09043507, -0.15038383, -0.49272987, -0.01522683,  0.3690025 ,\n",
       "          0.5844873 , -0.6767726 , -0.6740739 ,  0.4710318 , -0.04510946],\n",
       "        [-1.7327173 ,  0.75944895,  0.8950842 ,  1.0055534 ,  1.152611  ,\n",
       "         -1.3914393 ,  1.474768  , -0.8400367 , -0.7049914 , -1.5086992 ,\n",
       "          1.7052791 , -1.4648709 , -1.625745  ,  1.4622117 ,  1.5571785 ],\n",
       "        [-0.3634998 ,  0.16610307,  0.86031467,  1.045006  ,  0.8296012 ,\n",
       "         -0.04111195,  0.5326034 , -0.06429254, -0.06252696, -0.6251309 ,\n",
       "          0.8663235 , -0.8238761 , -0.9524854 ,  0.66111094,  0.14073381],\n",
       "        [-0.97376174,  0.04805786, -0.2211643 ,  0.5836778 ,  0.46522257,\n",
       "         -0.22184697, -0.10345202, -0.5382251 , -0.61474913, -0.36609685,\n",
       "          0.63926995, -0.67374545, -0.63009274,  0.20683418,  0.02331956],\n",
       "        [ 0.29040867, -0.68155324, -0.69556445, -0.46502802, -0.6685811 ,\n",
       "          0.5798854 , -0.4539538 ,  0.36281753,  0.6133595 ,  0.46351853,\n",
       "         -0.27853492,  0.13004045,  0.627726  , -0.11428811,  0.030296  ],\n",
       "        [-0.33850527,  0.7561748 ,  0.4769128 ,  0.6209572 ,  0.67352784,\n",
       "         -0.4081694 ,  0.0622186 , -0.427396  , -0.10696106, -0.05979054,\n",
       "          0.2271049 , -0.7911729 , -0.7021674 ,  0.43227398,  0.26730618],\n",
       "        [-0.37274078,  0.03818255,  0.42738244,  0.76405776,  0.6077799 ,\n",
       "         -0.7276356 ,  0.37133825, -0.12257317, -0.13978629, -0.57772344,\n",
       "          0.50234956, -0.8331444 , -0.32735738,  0.56817436,  0.56129724]],\n",
       "       dtype=float32),\n",
       " array([-2.0114112,  1.7160324,  1.7721031,  1.9790679,  1.7754248,\n",
       "        -1.4496607,  1.8867671, -1.6930599, -1.8090904, -1.721369 ,\n",
       "         1.9690187, -2.0167556, -2.0532107,  1.9125072,  1.9180241],\n",
       "       dtype=float32),\n",
       " array([[-1.4524294 ],\n",
       "        [ 0.66749805],\n",
       "        [ 0.80193436],\n",
       "        [ 1.262064  ],\n",
       "        [ 0.7782502 ],\n",
       "        [-0.56502444],\n",
       "        [ 1.0865674 ],\n",
       "        [-0.77024746],\n",
       "        [-0.8909285 ],\n",
       "        [-0.7522904 ],\n",
       "        [ 1.2952236 ],\n",
       "        [-1.4452585 ],\n",
       "        [-1.6335762 ],\n",
       "        [ 1.099371  ],\n",
       "        [ 1.1764816 ]], dtype=float32),\n",
       " array([2.3091333], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_6(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure6_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 791us/step - loss: 483.4207 - val_loss: 290.4035\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 177.6521 - val_loss: 85.0528\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 70.4317 - val_loss: 33.2224\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 27.5399 - val_loss: 27.4244\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 21.1837 - val_loss: 18.6752\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.2697 - val_loss: 16.9049\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.3676 - val_loss: 14.9153\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.0127 - val_loss: 14.4305\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.8308 - val_loss: 13.8881\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 11.0640 - val_loss: 13.4061\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.2614 - val_loss: 12.4595\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 10.0150 - val_loss: 11.7789\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 9.5195 - val_loss: 11.5587\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.1589 - val_loss: 11.0121\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.0404 - val_loss: 10.8424\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.8185 - val_loss: 10.8284\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.7347 - val_loss: 10.1872\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.6019 - val_loss: 9.9177\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.6088 - val_loss: 9.9878\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.6468 - val_loss: 9.8650\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7792 - val_loss: 10.2362\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.8791 - val_loss: 9.7217\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1737 - val_loss: 10.4145\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.1673 - val_loss: 10.1003\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1551 - val_loss: 9.7872\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0630 - val_loss: 9.8074\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.9929 - val_loss: 10.1842\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8542 - val_loss: 9.7222\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8577 - val_loss: 9.8511\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7491 - val_loss: 9.8636\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8996 - val_loss: 10.1510\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7252 - val_loss: 10.0912\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6468 - val_loss: 10.0531\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7136 - val_loss: 9.8812\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7773 - val_loss: 10.1714\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6730 - val_loss: 9.8930\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6576 - val_loss: 10.2367\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5721 - val_loss: 10.2837\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5329 - val_loss: 9.7792\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5127 - val_loss: 9.8420\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4643 - val_loss: 9.7103\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3378 - val_loss: 9.7686\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3569 - val_loss: 9.8502\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.3387 - val_loss: 9.7913\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3464 - val_loss: 9.7261\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2663 - val_loss: 9.7359\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3444 - val_loss: 9.7041\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.3394 - val_loss: 9.9909\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3459 - val_loss: 9.7386\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3184 - val_loss: 9.5137\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3041 - val_loss: 9.6241\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5256 - val_loss: 9.7385\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3981 - val_loss: 9.7864\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3323 - val_loss: 9.9768\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3334 - val_loss: 9.7931\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2895 - val_loss: 9.7059\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2905 - val_loss: 9.8337\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2082 - val_loss: 9.7983\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2774 - val_loss: 9.8174\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3507 - val_loss: 9.6219\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3357 - val_loss: 9.7707\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2215 - val_loss: 9.7644\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1868 - val_loss: 9.7599\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2122 - val_loss: 9.7249\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1970 - val_loss: 9.6324\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2519 - val_loss: 9.3885\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3228 - val_loss: 9.5112\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2210 - val_loss: 9.5655\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 96us/step - loss: 7.1654 - val_loss: 9.5756\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1469 - val_loss: 9.6365\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1812 - val_loss: 9.6717\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.3573 - val_loss: 9.6414\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2169 - val_loss: 9.5676\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2365 - val_loss: 9.6420\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.3634 - val_loss: 9.5454\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3125 - val_loss: 9.7430\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1993 - val_loss: 9.5799\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1913 - val_loss: 9.3546\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2752 - val_loss: 9.5356\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1740 - val_loss: 9.6592\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2298 - val_loss: 9.6513\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1366 - val_loss: 9.6640\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.1888 - val_loss: 9.6997\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1611 - val_loss: 9.5613\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2705 - val_loss: 9.5270\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1575 - val_loss: 9.6261\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1876 - val_loss: 9.4631\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2213 - val_loss: 9.4412\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1539 - val_loss: 9.7007\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2633 - val_loss: 9.5310\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2123 - val_loss: 9.4847\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2867 - val_loss: 9.7860\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1409 - val_loss: 9.5104\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1665 - val_loss: 9.5551\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2194 - val_loss: 9.7119\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0966 - val_loss: 9.6510\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0883 - val_loss: 9.3969\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1284 - val_loss: 9.3355\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1311 - val_loss: 9.5614\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1398 - val_loss: 9.4962\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0571 - val_loss: 9.4679\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0903 - val_loss: 9.4538\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1662 - val_loss: 9.5141\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1182 - val_loss: 9.5770\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1073 - val_loss: 9.5450\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1207 - val_loss: 9.5897\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0803 - val_loss: 9.3791\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0680 - val_loss: 9.4301\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2600 - val_loss: 9.7099\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1281 - val_loss: 9.5499\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0582 - val_loss: 9.3501\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1230 - val_loss: 9.4106\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1081 - val_loss: 9.5590\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0519 - val_loss: 9.6832\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0903 - val_loss: 9.6903\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1201 - val_loss: 9.4777\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9528 - val_loss: 9.6260\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2680 - val_loss: 9.6609\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2071 - val_loss: 9.5999\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0735 - val_loss: 9.3967\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0629 - val_loss: 9.5281\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0575 - val_loss: 9.5362\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0496 - val_loss: 9.5432\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0811 - val_loss: 9.3658\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0190 - val_loss: 9.4528\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9990 - val_loss: 9.5235\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0322 - val_loss: 9.5283\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.0465 - val_loss: 9.6578\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1228 - val_loss: 9.7690\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1270 - val_loss: 9.6286\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1860 - val_loss: 9.6603\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1740 - val_loss: 9.5974\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.0730 - val_loss: 9.7336\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1478 - val_loss: 9.3678\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1218 - val_loss: 9.5981\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0569 - val_loss: 9.5443\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9716 - val_loss: 9.5618\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0333 - val_loss: 9.2977\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9759 - val_loss: 9.3175\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9570 - val_loss: 9.3712\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9926 - val_loss: 9.4593\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0204 - val_loss: 9.4470\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1215 - val_loss: 9.4586\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0966 - val_loss: 9.7626\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8788 - val_loss: 9.5192\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0044 - val_loss: 9.3191\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.9575 - val_loss: 9.4089\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9826 - val_loss: 9.4383\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9823 - val_loss: 9.2834\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0736 - val_loss: 9.4579\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9331 - val_loss: 9.6032\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0686 - val_loss: 9.4772\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9741 - val_loss: 9.4094\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9905 - val_loss: 9.3318\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9391 - val_loss: 9.4342\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9275 - val_loss: 9.5796\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9303 - val_loss: 9.4391\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9562 - val_loss: 9.3091\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8953 - val_loss: 9.2313\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9037 - val_loss: 9.6417\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8925 - val_loss: 9.4249\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0072 - val_loss: 9.4648\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9844 - val_loss: 9.3791\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9941 - val_loss: 9.5323\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0301 - val_loss: 9.4232\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1346 - val_loss: 9.6737\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1832 - val_loss: 9.5396\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8729 - val_loss: 9.8524\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1523 - val_loss: 9.5454\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0020 - val_loss: 9.3783\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0328 - val_loss: 9.4395\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9095 - val_loss: 9.6243\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9320 - val_loss: 9.6705\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9171 - val_loss: 9.2926\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9285 - val_loss: 9.2725\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9405 - val_loss: 9.5117\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9814 - val_loss: 9.4844\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9650 - val_loss: 9.2529\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9735 - val_loss: 9.4061\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8604 - val_loss: 9.5063\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8920 - val_loss: 9.2396\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8495 - val_loss: 9.3465\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0218 - val_loss: 9.3186\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8084 - val_loss: 9.5690\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9999 - val_loss: 9.3667\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9898 - val_loss: 9.2780\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0178 - val_loss: 9.5671\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8768 - val_loss: 9.4660\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8353 - val_loss: 9.4248\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9807 - val_loss: 9.1837\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9016 - val_loss: 9.5155\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9197 - val_loss: 9.1640\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8668 - val_loss: 9.5579\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9553 - val_loss: 9.2618\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9938 - val_loss: 9.3048\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8441 - val_loss: 9.4964\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7748 - val_loss: 9.2983\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7872 - val_loss: 9.2290\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9157 - val_loss: 9.4540\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8359 - val_loss: 9.4882\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8080 - val_loss: 9.4352\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8205 - val_loss: 9.3006\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7885 - val_loss: 9.3051\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7561 - val_loss: 9.3872\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7580 - val_loss: 9.1830\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9602 - val_loss: 9.2596\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9343 - val_loss: 9.2977\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8145 - val_loss: 9.3791\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8387 - val_loss: 9.1091\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8221 - val_loss: 8.9937\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7724 - val_loss: 9.3760\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0768 - val_loss: 9.4053\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9617 - val_loss: 9.2807\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8273 - val_loss: 9.2597\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.8021 - val_loss: 9.2640\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7485 - val_loss: 9.0872\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8003 - val_loss: 8.9879\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7731 - val_loss: 9.1003\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6549 - val_loss: 9.1465\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8758 - val_loss: 9.3562\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7664 - val_loss: 9.1951\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7480 - val_loss: 8.9952\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7433 - val_loss: 9.1130\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6860 - val_loss: 9.0443\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.7492 - val_loss: 9.4198\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7137 - val_loss: 9.1672\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8527 - val_loss: 8.9594\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6569 - val_loss: 9.1574\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7254 - val_loss: 9.1276\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7372 - val_loss: 9.0944\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6993 - val_loss: 8.9480\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7095 - val_loss: 9.1149\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7512 - val_loss: 9.2690\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6619 - val_loss: 9.1539\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6857 - val_loss: 9.2370\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6350 - val_loss: 9.0512\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5974 - val_loss: 9.1129\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6754 - val_loss: 9.1030\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6612 - val_loss: 9.2169\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7401 - val_loss: 9.0944\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7650 - val_loss: 9.0979\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9043 - val_loss: 9.2167\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8024 - val_loss: 9.4188\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9817 - val_loss: 9.3949\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7775 - val_loss: 9.8352\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5721 - val_loss: 9.3405\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8469 - val_loss: 8.9692\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8546 - val_loss: 9.2327\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6730 - val_loss: 9.2663\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6645 - val_loss: 9.0825\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6784 - val_loss: 9.0504\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7571 - val_loss: 9.1818\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6345 - val_loss: 9.0992\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6590 - val_loss: 8.9849\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5516 - val_loss: 9.2579\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6505 - val_loss: 9.2030\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6008 - val_loss: 9.1000\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.6631 - val_loss: 9.0287\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5475 - val_loss: 9.0742\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5791 - val_loss: 9.2178\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6470 - val_loss: 9.3063\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8242 - val_loss: 9.3089\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8630 - val_loss: 9.1134\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5897 - val_loss: 9.1043\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5694 - val_loss: 9.0497\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6686 - val_loss: 9.2506\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8513 - val_loss: 9.1872\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7939 - val_loss: 9.1455\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6039 - val_loss: 9.3532\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5419 - val_loss: 9.2107\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5653 - val_loss: 9.1217\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6143 - val_loss: 9.1037\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6101 - val_loss: 9.3275\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7667 - val_loss: 9.5038\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5576 - val_loss: 9.3864\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6173 - val_loss: 9.2278\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6654 - val_loss: 9.1343\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5036 - val_loss: 9.2338\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5056 - val_loss: 9.3400\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5008 - val_loss: 9.3509\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5382 - val_loss: 9.1569\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5427 - val_loss: 9.2155\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6825 - val_loss: 9.0030\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5849 - val_loss: 9.1366\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5634 - val_loss: 9.0276\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5694 - val_loss: 9.1266\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6697 - val_loss: 9.1512\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8660 - val_loss: 9.2126\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5985 - val_loss: 9.0396\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6120 - val_loss: 9.0330\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4420 - val_loss: 9.2186\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4087 - val_loss: 9.2860\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4325 - val_loss: 9.3365\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5213 - val_loss: 9.0825\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5432 - val_loss: 9.2466\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5160 - val_loss: 9.1031\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4375 - val_loss: 9.3595\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4153 - val_loss: 9.2863\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4441 - val_loss: 9.3606\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4692 - val_loss: 9.2991\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4109 - val_loss: 9.0523\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3964 - val_loss: 9.2661\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 92us/step - loss: 6.6248 - val_loss: 9.2368\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6978 - val_loss: 9.1925\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.5751 - val_loss: 9.3224\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4459 - val_loss: 9.3508\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4068 - val_loss: 9.2028\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3692 - val_loss: 9.2702\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4630 - val_loss: 9.1697\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4913 - val_loss: 9.1385\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6002 - val_loss: 9.1209\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7427 - val_loss: 9.1562\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4288 - val_loss: 9.3194\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4770 - val_loss: 9.3899\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7578 - val_loss: 9.2836\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5455 - val_loss: 9.3768\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3419 - val_loss: 9.7311\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.4194 - val_loss: 9.3829\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6117 - val_loss: 9.0661\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6639 - val_loss: 9.1336\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3742 - val_loss: 9.2915\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4289 - val_loss: 9.1714\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4176 - val_loss: 9.1295\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4290 - val_loss: 9.1652\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4622 - val_loss: 9.2611\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4322 - val_loss: 9.2314\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3745 - val_loss: 9.1706\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2966 - val_loss: 9.1290\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4459 - val_loss: 9.0069\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3664 - val_loss: 9.0278\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3407 - val_loss: 9.0115\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9378 - val_loss: 9.1961\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5297 - val_loss: 9.2307\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3393 - val_loss: 9.2312\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2959 - val_loss: 9.1609\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4492 - val_loss: 9.1018\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3179 - val_loss: 9.1157\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4545 - val_loss: 9.0533\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3674 - val_loss: 9.2001\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3495 - val_loss: 8.8287\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2454 - val_loss: 8.8836\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2876 - val_loss: 9.1013\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4241 - val_loss: 9.1132\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8087 - val_loss: 9.2736\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3020 - val_loss: 9.0088\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2432 - val_loss: 8.9177\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2580 - val_loss: 9.0889\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2964 - val_loss: 8.9470\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2184 - val_loss: 9.1442\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2648 - val_loss: 9.1958\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1979 - val_loss: 8.9612\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2618 - val_loss: 8.9819\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2211 - val_loss: 8.8923\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2181 - val_loss: 9.1168\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2551 - val_loss: 9.1413\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2932 - val_loss: 8.9986\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3042 - val_loss: 9.1228\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2095 - val_loss: 9.0037\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2644 - val_loss: 9.0483\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3786 - val_loss: 8.7172\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3882 - val_loss: 8.7818\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5750 - val_loss: 8.8754\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2346 - val_loss: 9.0443\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2685 - val_loss: 8.9511\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3063 - val_loss: 8.9712\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2515 - val_loss: 8.8930\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2122 - val_loss: 8.7597\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1328 - val_loss: 8.8506\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1538 - val_loss: 8.8917\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1702 - val_loss: 8.9364\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2823 - val_loss: 8.7473\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2788 - val_loss: 8.9145\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1850 - val_loss: 8.9912\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0955 - val_loss: 9.0518\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1489 - val_loss: 8.8241\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1730 - val_loss: 8.7841\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1447 - val_loss: 8.7480\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1101 - val_loss: 8.9075\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0862 - val_loss: 9.0698\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1759 - val_loss: 8.9392\n",
      "Epoch 381/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 92us/step - loss: 6.1265 - val_loss: 8.8301\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1297 - val_loss: 8.6167\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0942 - val_loss: 8.7342\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1126 - val_loss: 8.8169\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0866 - val_loss: 8.9298\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1512 - val_loss: 8.8840\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1007 - val_loss: 8.8844\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1612 - val_loss: 8.8653\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2152 - val_loss: 8.9018\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1241 - val_loss: 8.9109\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1492 - val_loss: 8.9513\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 212us/step - loss: 6.0828 - val_loss: 8.7727\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 6.2344 - val_loss: 8.9901\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9779 - val_loss: 8.8767\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.1178 - val_loss: 8.7545\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1081 - val_loss: 9.0248\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.0040 - val_loss: 8.9229\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0412 - val_loss: 8.7367\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0149 - val_loss: 8.8171\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9617 - val_loss: 8.8253\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1156 - val_loss: 8.6673\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0661 - val_loss: 8.8044\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2109 - val_loss: 8.8833\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1928 - val_loss: 8.9198\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.0796 - val_loss: 8.8175\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9792 - val_loss: 8.6470\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.9937 - val_loss: 8.6480\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0088 - val_loss: 8.8656\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9562 - val_loss: 8.8049\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2020 - val_loss: 8.7938\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0701 - val_loss: 8.7777\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9465 - val_loss: 8.8664\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9584 - val_loss: 8.9708\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9016 - val_loss: 8.7117\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0876 - val_loss: 8.6907\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0347 - val_loss: 8.6412\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0542 - val_loss: 8.9029\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0205 - val_loss: 8.8782\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9313 - val_loss: 8.7994\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9502 - val_loss: 8.6387\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0047 - val_loss: 8.8250\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9221 - val_loss: 8.7067\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9326 - val_loss: 8.7841\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9881 - val_loss: 8.6991\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9295 - val_loss: 8.7743\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9610 - val_loss: 8.5752\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9008 - val_loss: 8.6007\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9812 - val_loss: 8.7078\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9573 - val_loss: 9.0395\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8911 - val_loss: 8.7820\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2597 - val_loss: 8.6029\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.3369 - val_loss: 8.7638\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3041 - val_loss: 8.7668\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1027 - val_loss: 9.0632\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9533 - val_loss: 8.9739\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8683 - val_loss: 8.7996\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1349 - val_loss: 8.6811\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8932 - val_loss: 8.7968\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0366 - val_loss: 8.7152\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8711 - val_loss: 8.8556\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9340 - val_loss: 8.8124\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8925 - val_loss: 8.5713\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8807 - val_loss: 8.7812\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8887 - val_loss: 8.8869\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0157 - val_loss: 8.5727\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9356 - val_loss: 8.5755\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9692 - val_loss: 8.8074\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9044 - val_loss: 8.7436\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8807 - val_loss: 8.6926\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8514 - val_loss: 8.7563\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7738 - val_loss: 8.7051\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0378 - val_loss: 8.6426\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9284 - val_loss: 8.7092\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8990 - val_loss: 8.9700\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8557 - val_loss: 8.7190\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7861 - val_loss: 8.6469\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9383 - val_loss: 8.9098\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8295 - val_loss: 8.6349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7893 - val_loss: 8.5371\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9227 - val_loss: 8.6705\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8033 - val_loss: 8.7581\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7687 - val_loss: 8.5174\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8414 - val_loss: 8.7349\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7965 - val_loss: 8.8840\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7790 - val_loss: 8.5625\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8827 - val_loss: 8.7304\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8195 - val_loss: 8.6480\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7653 - val_loss: 8.6657\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7120 - val_loss: 8.7155\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7804 - val_loss: 8.6885\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9229 - val_loss: 8.6349\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1668 - val_loss: 8.7705\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5916 - val_loss: 8.6985\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.1044 - val_loss: 8.6527\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9901 - val_loss: 8.7173\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7638 - val_loss: 8.5775\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7607 - val_loss: 8.6010\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7494 - val_loss: 8.5793\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8959 - val_loss: 8.7666\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8826 - val_loss: 8.5468\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8271 - val_loss: 8.5936\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6308 - val_loss: 8.6075\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8079 - val_loss: 8.4746\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7494 - val_loss: 8.8488\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8229 - val_loss: 8.8778\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8197 - val_loss: 8.6523\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6915 - val_loss: 8.5955\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8350 - val_loss: 8.4455\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7247 - val_loss: 8.6405\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8920 - val_loss: 8.9666\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7554 - val_loss: 8.3831\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8072 - val_loss: 8.4355\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7009 - val_loss: 8.9209\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6747 - val_loss: 8.5554\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8159 - val_loss: 8.7350\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8915 - val_loss: 8.7372\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6889 - val_loss: 8.5991\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6930 - val_loss: 8.6710\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6593 - val_loss: 8.7044\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8631 - val_loss: 8.6768\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1446 - val_loss: 8.5376\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.0396 - val_loss: 8.6254\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8543 - val_loss: 8.6781\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6983 - val_loss: 8.7245\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6805 - val_loss: 8.8951\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7723 - val_loss: 8.7620\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7177 - val_loss: 8.5344\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8084 - val_loss: 8.6421\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6931 - val_loss: 8.5634\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7817 - val_loss: 8.5272\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7231 - val_loss: 8.7116\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6602 - val_loss: 8.7473\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7414 - val_loss: 8.8889\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7881 - val_loss: 8.6364\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6281 - val_loss: 8.6187\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7080 - val_loss: 8.7557\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6217 - val_loss: 8.5631\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6221 - val_loss: 8.6886\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8332 - val_loss: 8.5718\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0695 - val_loss: 8.9561\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7441 - val_loss: 8.8674\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6807 - val_loss: 8.6850\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6115 - val_loss: 8.7336\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6039 - val_loss: 8.6538\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6048 - val_loss: 8.7260\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6313 - val_loss: 8.6567\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6934 - val_loss: 8.7362\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7744 - val_loss: 8.5839\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7424 - val_loss: 8.6662\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6591 - val_loss: 8.6578\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6959 - val_loss: 8.6335\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8608 - val_loss: 8.6993\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8204 - val_loss: 8.7105\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6191 - val_loss: 8.7379\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6329 - val_loss: 8.8031\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6805 - val_loss: 8.8096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6529 - val_loss: 8.7819\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6243 - val_loss: 8.6254\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6169 - val_loss: 8.7957\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6993 - val_loss: 8.7237\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6485 - val_loss: 8.8237\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6792 - val_loss: 8.6563\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6262 - val_loss: 8.5401\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6132 - val_loss: 8.7072\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5856 - val_loss: 8.7329\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6197 - val_loss: 8.7228\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5869 - val_loss: 8.8772\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6475 - val_loss: 8.7501\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7152 - val_loss: 8.7695\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6397 - val_loss: 8.6480\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6155 - val_loss: 8.7005\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6154 - val_loss: 9.0628\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7214 - val_loss: 8.7396\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6267 - val_loss: 8.5815\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6225 - val_loss: 8.8808\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7563 - val_loss: 8.9580\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7507 - val_loss: 8.8219\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6095 - val_loss: 8.7876\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6736 - val_loss: 8.9716\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7961 - val_loss: 8.8968\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9467 - val_loss: 8.8040\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5812 - val_loss: 8.7228\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7311 - val_loss: 8.7100\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6995 - val_loss: 9.0490\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6216 - val_loss: 8.8241\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6569 - val_loss: 8.6709\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5754 - val_loss: 8.6433\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5397 - val_loss: 8.6141\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7206 - val_loss: 8.8551\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6546 - val_loss: 8.6758\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6085 - val_loss: 8.6707\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7051 - val_loss: 8.5998\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6216 - val_loss: 8.8003\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6837 - val_loss: 8.6971\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5707 - val_loss: 8.7635\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7053 - val_loss: 8.6200\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7319 - val_loss: 8.7418\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5779 - val_loss: 8.7425\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5758 - val_loss: 9.0844\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5104 - val_loss: 8.8092\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5945 - val_loss: 8.7221\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8615 - val_loss: 8.5915\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6256 - val_loss: 8.5916\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5545 - val_loss: 8.8673\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5053 - val_loss: 8.8850\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5522 - val_loss: 8.7552\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5864 - val_loss: 8.7275\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5263 - val_loss: 8.7064\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5512 - val_loss: 8.6475\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5726 - val_loss: 8.8739\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6114 - val_loss: 9.1091\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5349 - val_loss: 8.6629\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5338 - val_loss: 8.7049\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5742 - val_loss: 8.9767\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7355 - val_loss: 9.1504\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6287 - val_loss: 8.9395\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5234 - val_loss: 8.7890\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5436 - val_loss: 8.9764\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6132 - val_loss: 8.9379\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6201 - val_loss: 8.8837\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4859 - val_loss: 8.7832\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5556 - val_loss: 8.6699\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5433 - val_loss: 9.1367\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5364 - val_loss: 9.1005\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5890 - val_loss: 8.8848\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5746 - val_loss: 8.6262\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4983 - val_loss: 8.7386\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7060 - val_loss: 8.9362\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6289 - val_loss: 8.7803\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5885 - val_loss: 8.7741\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5914 - val_loss: 8.9416\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5412 - val_loss: 8.9802\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.382 - 0s 98us/step - loss: 5.7081 - val_loss: 9.0205\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.4826 - val_loss: 9.0334\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8127 - val_loss: 9.0650\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8066 - val_loss: 8.8054\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5481 - val_loss: 8.7369\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5423 - val_loss: 9.0677\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6312 - val_loss: 8.9868\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5230 - val_loss: 8.8977\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4888 - val_loss: 8.8571\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5698 - val_loss: 8.8206\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.4779 - val_loss: 8.9582\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4754 - val_loss: 8.7196\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5242 - val_loss: 8.8135\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5985 - val_loss: 9.0518\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5668 - val_loss: 8.8865\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5251 - val_loss: 9.0300\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5671 - val_loss: 9.2455\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6357 - val_loss: 8.7085\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5933 - val_loss: 8.9396\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5612 - val_loss: 9.0651\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4965 - val_loss: 9.0197\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5374 - val_loss: 8.9649\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4628 - val_loss: 8.8150\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5077 - val_loss: 8.7936\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5711 - val_loss: 9.0929\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4936 - val_loss: 9.1543\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4549 - val_loss: 8.9057\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6181 - val_loss: 8.8000\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5050 - val_loss: 9.1985\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5648 - val_loss: 9.0239\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4528 - val_loss: 8.8777\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6091 - val_loss: 8.8605\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8082 - val_loss: 8.8423\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7426 - val_loss: 8.9486\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4138 - val_loss: 8.9578\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5341 - val_loss: 9.1345\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5234 - val_loss: 9.0277\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8405 - val_loss: 9.2153\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6123 - val_loss: 9.0843\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5301 - val_loss: 8.8765\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4654 - val_loss: 8.9859\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5241 - val_loss: 8.9690\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5163 - val_loss: 8.7843\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5272 - val_loss: 8.9761\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4371 - val_loss: 8.9868\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7105 - val_loss: 8.9759\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5736 - val_loss: 9.1501\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4962 - val_loss: 9.1140\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4239 - val_loss: 9.0113\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4813 - val_loss: 8.8254\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4354 - val_loss: 8.9339\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5219 - val_loss: 9.1405\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5717 - val_loss: 8.9799\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4961 - val_loss: 8.8461\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4893 - val_loss: 8.8065\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6339 - val_loss: 8.9039\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4765 - val_loss: 9.0126\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5267 - val_loss: 9.1533\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6830 - val_loss: 9.1300\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7132 - val_loss: 8.9592\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5782 - val_loss: 9.0905\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6396 - val_loss: 9.0635\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8011 - val_loss: 8.9610\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7741 - val_loss: 8.8269\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7023 - val_loss: 9.1275\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6161 - val_loss: 9.1706\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4018 - val_loss: 9.2734\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5144 - val_loss: 9.0232\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8740 - val_loss: 9.0399\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9105 - val_loss: 8.9557\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7166 - val_loss: 8.8801\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5228 - val_loss: 9.1508\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6434 - val_loss: 8.8152\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5186 - val_loss: 8.8529\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5697 - val_loss: 8.8681\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4225 - val_loss: 9.0445\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4630 - val_loss: 9.0999\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4575 - val_loss: 8.9038\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4407 - val_loss: 9.0937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4458 - val_loss: 8.9351\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5465 - val_loss: 9.0282\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5129 - val_loss: 8.9963\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6010 - val_loss: 9.1300\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4480 - val_loss: 8.8513\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4571 - val_loss: 8.9504\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6087 - val_loss: 9.1801\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8187 - val_loss: 9.0559\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9141 - val_loss: 9.2475\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5882 - val_loss: 9.2189\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4707 - val_loss: 9.0544\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6109 - val_loss: 9.1076\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5392 - val_loss: 9.1515\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5064 - val_loss: 9.0872\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4614 - val_loss: 8.7960\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5302 - val_loss: 8.8708\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5402 - val_loss: 8.8165\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4114 - val_loss: 8.9973\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5264 - val_loss: 9.0913\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5134 - val_loss: 9.0518\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4347 - val_loss: 8.9375\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5393 - val_loss: 8.9397\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4957 - val_loss: 9.2120\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3965 - val_loss: 9.1548\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5206 - val_loss: 8.9116\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4673 - val_loss: 8.9861\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3968 - val_loss: 9.1038\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5003 - val_loss: 8.9399\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4898 - val_loss: 9.0124\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5095 - val_loss: 9.3081\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4424 - val_loss: 9.0469\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5473 - val_loss: 8.8920\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6372 - val_loss: 9.0329\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4794 - val_loss: 9.1667\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5390 - val_loss: 9.1779\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5865 - val_loss: 9.1376\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5017 - val_loss: 9.3923\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6347 - val_loss: 9.2025\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3811 - val_loss: 9.2235\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6211 - val_loss: 9.2751\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4663 - val_loss: 9.1718\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4833 - val_loss: 9.0181\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4912 - val_loss: 9.0686\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4960 - val_loss: 8.9843\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3832 - val_loss: 9.7441\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5532 - val_loss: 9.1551\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5399 - val_loss: 9.1568\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4810 - val_loss: 8.9465\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4791 - val_loss: 9.1257\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6212 - val_loss: 9.1167\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6677 - val_loss: 9.3136\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7022 - val_loss: 9.3566\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6000 - val_loss: 8.9770\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4696 - val_loss: 9.2749\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4590 - val_loss: 9.1359\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6219 - val_loss: 9.1615\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5172 - val_loss: 9.4990\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6490 - val_loss: 9.1593\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7606 - val_loss: 9.0211\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5576 - val_loss: 9.0590\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8236 - val_loss: 9.1251\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5792 - val_loss: 9.2971\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6161 - val_loss: 9.1333\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4898 - val_loss: 9.0756\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3858 - val_loss: 9.2932\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4135 - val_loss: 9.0845\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5816 - val_loss: 9.0669\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4539 - val_loss: 8.9726\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3938 - val_loss: 9.2130\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3880 - val_loss: 9.1986\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3688 - val_loss: 9.0558\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4525 - val_loss: 9.1428\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4467 - val_loss: 9.2524\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4246 - val_loss: 9.1340\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4596 - val_loss: 9.0433\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4678 - val_loss: 9.1788\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4311 - val_loss: 9.1585\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4254 - val_loss: 8.9811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5333 - val_loss: 9.1072\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4599 - val_loss: 9.1859\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4860 - val_loss: 9.1622\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3770 - val_loss: 9.3215\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4228 - val_loss: 9.2790\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4105 - val_loss: 9.2726\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3991 - val_loss: 9.2457\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4965 - val_loss: 9.0602\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4414 - val_loss: 9.2328\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4747 - val_loss: 9.2591\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6471 - val_loss: 9.1896\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5961 - val_loss: 9.3558\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3807 - val_loss: 9.3239\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4697 - val_loss: 9.2096\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5327 - val_loss: 9.2563\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5660 - val_loss: 9.0624\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7890 - val_loss: 8.9532\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7217 - val_loss: 8.9492\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4739 - val_loss: 9.4169\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5324 - val_loss: 9.3115\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5913 - val_loss: 9.3249\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3925 - val_loss: 9.1603\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4043 - val_loss: 9.5349\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5795 - val_loss: 8.9891\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4483 - val_loss: 9.0868\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4299 - val_loss: 9.4304\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4805 - val_loss: 9.3943\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4403 - val_loss: 9.3618\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4333 - val_loss: 9.2595\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3715 - val_loss: 9.3622\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4389 - val_loss: 9.3149\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3760 - val_loss: 9.1849\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4328 - val_loss: 8.9204\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4976 - val_loss: 9.1607\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3816 - val_loss: 9.0349\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4753 - val_loss: 9.3320\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7589 - val_loss: 9.3338\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9182 - val_loss: 9.2458\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7966 - val_loss: 9.4402\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8770 - val_loss: 9.7404\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5617 - val_loss: 9.3126\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4599 - val_loss: 9.4669\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4832 - val_loss: 9.1937\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5050 - val_loss: 9.3734\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4518 - val_loss: 9.2591\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3628 - val_loss: 9.2660\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3875 - val_loss: 9.3190\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3464 - val_loss: 9.3219\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3577 - val_loss: 9.2989\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3579 - val_loss: 9.3561\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4852 - val_loss: 9.2758\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4451 - val_loss: 9.2024\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3767 - val_loss: 9.2574\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3893 - val_loss: 9.1352\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6246 - val_loss: 9.6918\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6513 - val_loss: 9.3243\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6345 - val_loss: 9.3304\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4337 - val_loss: 9.2776\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3318 - val_loss: 9.1007\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4395 - val_loss: 9.4159\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3949 - val_loss: 9.3395\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4198 - val_loss: 9.3488\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4490 - val_loss: 9.4642\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6670 - val_loss: 9.2797\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4384 - val_loss: 9.3797\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4449 - val_loss: 9.0772\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4588 - val_loss: 9.2070\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3611 - val_loss: 9.2723\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3928 - val_loss: 9.4499\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4290 - val_loss: 9.1890\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3788 - val_loss: 9.2004\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5063 - val_loss: 9.1273\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4291 - val_loss: 8.9959\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4214 - val_loss: 9.4105\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3568 - val_loss: 9.3288\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3822 - val_loss: 9.1761\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3839 - val_loss: 9.0472\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4662 - val_loss: 9.2657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3654 - val_loss: 9.3777\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4176 - val_loss: 9.3345\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4050 - val_loss: 9.2642\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5295 - val_loss: 9.4127\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4043 - val_loss: 9.4440\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4335 - val_loss: 9.2308\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3505 - val_loss: 9.4313\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4410 - val_loss: 9.4292\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4517 - val_loss: 9.3366\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4264 - val_loss: 9.0964\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4920 - val_loss: 9.1948\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6809 - val_loss: 9.3429\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5721 - val_loss: 9.2485\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5043 - val_loss: 9.4585\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3602 - val_loss: 9.2469\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4422 - val_loss: 9.4956\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3571 - val_loss: 9.3486\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3679 - val_loss: 9.2291\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4041 - val_loss: 9.1421\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3831 - val_loss: 9.1324\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3781 - val_loss: 9.4240\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4089 - val_loss: 9.2885\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4163 - val_loss: 9.2480\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3528 - val_loss: 9.1510\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4109 - val_loss: 9.5333\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3629 - val_loss: 9.3694\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3532 - val_loss: 9.3365\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3911 - val_loss: 9.3249\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7122 - val_loss: 9.2425\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7719 - val_loss: 9.4456\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7236 - val_loss: 9.5106\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4518 - val_loss: 9.3132\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3557 - val_loss: 9.4591\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4470 - val_loss: 8.9842\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3596 - val_loss: 9.3483\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4190 - val_loss: 9.1773\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3600 - val_loss: 9.1706\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3649 - val_loss: 9.3194\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3877 - val_loss: 9.2677\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3484 - val_loss: 9.3425\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3877 - val_loss: 9.3390\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3279 - val_loss: 9.1965\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4065 - val_loss: 9.3467\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3994 - val_loss: 9.2408\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5818 - val_loss: 9.2983\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3833 - val_loss: 9.2263\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4183 - val_loss: 9.4528\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4901 - val_loss: 9.4810\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5026 - val_loss: 9.7290\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4822 - val_loss: 9.4581\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4104 - val_loss: 9.5955\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4269 - val_loss: 9.1444\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5444 - val_loss: 9.5311\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5572 - val_loss: 9.3956\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3676 - val_loss: 9.2920\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3606 - val_loss: 9.4705\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4504 - val_loss: 9.2725\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4205 - val_loss: 9.1747\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4028 - val_loss: 9.2849\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4746 - val_loss: 9.3852\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3885 - val_loss: 9.2688\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3818 - val_loss: 9.2345\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3457 - val_loss: 9.1958\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3966 - val_loss: 9.3535\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5476 - val_loss: 9.5144\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6522 - val_loss: 9.5165\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3012 - val_loss: 9.3754\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4870 - val_loss: 9.6991\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5446 - val_loss: 9.2420\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4012 - val_loss: 9.3227\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5064 - val_loss: 9.4026\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3550 - val_loss: 9.2256\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4352 - val_loss: 9.1774\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4574 - val_loss: 9.3780\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3638 - val_loss: 9.3663\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4408 - val_loss: 9.2194\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5107 - val_loss: 9.3083\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5190 - val_loss: 9.3001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4686 - val_loss: 9.5744\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4009 - val_loss: 9.3223\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3790 - val_loss: 9.3449\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4219 - val_loss: 9.3266\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.3543 - val_loss: 9.6408\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4928 - val_loss: 9.7386\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4778 - val_loss: 9.5614\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5193 - val_loss: 9.1687\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4711 - val_loss: 9.2697\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5270 - val_loss: 9.5362\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4069 - val_loss: 9.4371\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3735 - val_loss: 9.4600\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3876 - val_loss: 9.2778\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3802 - val_loss: 9.3791\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3784 - val_loss: 9.6213\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3951 - val_loss: 9.7249\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4080 - val_loss: 9.6772\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5130 - val_loss: 9.3628\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5826 - val_loss: 9.3622\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.4604 - val_loss: 9.4778\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4594 - val_loss: 9.6234\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4706 - val_loss: 9.1334\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5076 - val_loss: 9.4728\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3767 - val_loss: 9.4464\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3535 - val_loss: 9.2968\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3238 - val_loss: 9.4243\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5921 - val_loss: 9.3466\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5401 - val_loss: 9.3229\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4304 - val_loss: 9.3286\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3749 - val_loss: 9.6750\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5114 - val_loss: 9.4675\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4567 - val_loss: 9.4392\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4188 - val_loss: 9.2038\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4286 - val_loss: 9.4292\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4060 - val_loss: 9.3952\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4979 - val_loss: 9.6291\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3359 - val_loss: 9.4669\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3486 - val_loss: 9.5355\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5018 - val_loss: 9.5732\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5442 - val_loss: 9.4168\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6433 - val_loss: 9.4540\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.4209 - val_loss: 9.6689\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4797 - val_loss: 9.4338\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4251 - val_loss: 9.6636\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4195 - val_loss: 9.6948\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4840 - val_loss: 9.5589\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5756 - val_loss: 9.3167\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6752 - val_loss: 9.3284\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5982 - val_loss: 9.3895\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4215 - val_loss: 9.6590\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3632 - val_loss: 9.6104\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4240 - val_loss: 9.5522\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5667 - val_loss: 9.5133\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4195 - val_loss: 9.4599\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4323 - val_loss: 9.3612\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3429 - val_loss: 9.3745\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3065 - val_loss: 9.4583\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3468 - val_loss: 9.2944\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4153 - val_loss: 9.3424\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3237 - val_loss: 9.4475\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3326 - val_loss: 9.4200\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4094 - val_loss: 9.6853\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.4374 - val_loss: 9.6953\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.3222 - val_loss: 9.3534\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3808 - val_loss: 9.2377\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3451 - val_loss: 9.2244\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4622 - val_loss: 9.5340\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3972 - val_loss: 9.7459\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5865 - val_loss: 9.3145\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3963 - val_loss: 9.4596\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3552 - val_loss: 9.3952\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3284 - val_loss: 9.4772\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3647 - val_loss: 9.4807\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3710 - val_loss: 9.4559\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3278 - val_loss: 9.3630\n",
      "8.844416052608167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5274079 , -2.2242153 , -0.47249725,  3.0854359 ,  3.8636408 ],\n",
       "        [-0.07253052, -1.5150435 , -0.23374613,  1.5209925 , -2.3716407 ],\n",
       "        [-0.70851517,  0.2405941 ,  0.06291824, -0.63690674, -0.23099397],\n",
       "        [-0.31885052,  1.9019178 ,  0.5942567 , -1.3293526 ,  3.2043407 ],\n",
       "        [ 0.7839201 , -0.43210658,  0.35512224, -0.12916407, -0.09189379],\n",
       "        [-0.49207363,  3.7632198 ,  0.10980529,  1.5938578 , -1.1129472 ],\n",
       "        [-0.44705078,  2.754573  , -1.1258641 , -0.07482101, -0.253989  ]],\n",
       "       dtype=float32),\n",
       " array([-0.39699763,  3.5524423 , -1.4585446 ,  1.8059983 ,  0.79468274],\n",
       "       dtype=float32),\n",
       " array([[-0.7945633 ,  0.3808262 ,  0.9267694 ,  0.21312577, -0.4951309 ],\n",
       "        [-0.7461719 ,  0.5085992 ,  0.8118609 , -0.06394607,  0.4326445 ],\n",
       "        [ 1.0534099 , -1.0619574 , -1.3301113 , -0.21242328,  1.2452883 ],\n",
       "        [-0.08860403,  1.3125558 ,  1.3770329 ,  0.53465635, -0.6791965 ],\n",
       "        [ 0.9282504 , -0.9339215 , -0.9350389 , -0.57507706,  1.3703744 ]],\n",
       "       dtype=float32),\n",
       " array([-1.8094664,  1.814256 ,  1.8051581, -0.9115425, -1.8187284],\n",
       "       dtype=float32),\n",
       " array([[-1.7972524 ],\n",
       "        [ 1.6362798 ],\n",
       "        [ 1.8505561 ],\n",
       "        [-0.09570105],\n",
       "        [-1.8466204 ]], dtype=float32),\n",
       " array([1.8073522], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_1(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure1_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 872us/step - loss: 483.0827 - val_loss: 259.5897\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 164.6669 - val_loss: 55.7645\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 52.4768 - val_loss: 33.2967\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 28.7962 - val_loss: 26.4706\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 26.7206 - val_loss: 22.5035\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 21.7004 - val_loss: 20.7924\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 19.9780 - val_loss: 18.3130\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 16.3727 - val_loss: 18.1966\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 14.3070 - val_loss: 15.9139\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 11.8760 - val_loss: 14.3295\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.3412 - val_loss: 12.7678\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.1594 - val_loss: 11.2885\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3890 - val_loss: 10.6598\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.2015 - val_loss: 10.7132\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6887 - val_loss: 9.9298\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.7751 - val_loss: 9.7412\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.5322 - val_loss: 10.3484\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7797 - val_loss: 10.7773\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7704 - val_loss: 11.0771\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.0099 - val_loss: 10.6775\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5285 - val_loss: 10.8490\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4602 - val_loss: 10.5355\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3124 - val_loss: 10.7503\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.4373 - val_loss: 10.6514\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.8293 - val_loss: 10.8607\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2744 - val_loss: 10.3233\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3989 - val_loss: 10.4507\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7545 - val_loss: 10.4140\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4876 - val_loss: 10.3486\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1183 - val_loss: 10.6891\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2427 - val_loss: 10.2142\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4304 - val_loss: 10.2293\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1701 - val_loss: 10.3416\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0513 - val_loss: 10.3968\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0367 - val_loss: 10.2990\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0234 - val_loss: 10.2732\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9155 - val_loss: 10.4272\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0991 - val_loss: 10.2167\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0014 - val_loss: 10.0688\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9671 - val_loss: 9.9755\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9595 - val_loss: 10.2245\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9767 - val_loss: 10.0939\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8730 - val_loss: 9.9932\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9262 - val_loss: 9.6383\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1065 - val_loss: 10.0703\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9467 - val_loss: 9.9937\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6833 - val_loss: 9.8832\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9939 - val_loss: 10.0828\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9614 - val_loss: 9.9369\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8780 - val_loss: 10.1962\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8505 - val_loss: 9.7922\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9539 - val_loss: 9.9222\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7965 - val_loss: 9.5542\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8267 - val_loss: 9.5517\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7602 - val_loss: 9.7394\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8349 - val_loss: 9.6811\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9838 - val_loss: 9.5409\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9145 - val_loss: 9.6510\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7601 - val_loss: 9.5237\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7549 - val_loss: 9.9862\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8235 - val_loss: 9.4065\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8423 - val_loss: 9.6575\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8217 - val_loss: 9.5673\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8724 - val_loss: 9.5947\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.9406 - val_loss: 9.6632\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5825 - val_loss: 9.4283\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8415 - val_loss: 9.5001\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7011 - val_loss: 9.4764\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.7623 - val_loss: 9.3053\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8248 - val_loss: 9.4809\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7799 - val_loss: 9.4915\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6736 - val_loss: 9.4827\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6494 - val_loss: 9.5042\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8203 - val_loss: 9.6835\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8188 - val_loss: 9.3299\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7558 - val_loss: 9.3789\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6303 - val_loss: 9.3343\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7168 - val_loss: 9.3824\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6244 - val_loss: 9.4997\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6561 - val_loss: 9.3220\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7600 - val_loss: 9.2754\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6094 - val_loss: 9.3254\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5823 - val_loss: 9.3237\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7710 - val_loss: 9.6012\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8323 - val_loss: 9.2365\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6623 - val_loss: 9.3652\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6040 - val_loss: 9.2526\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6518 - val_loss: 9.1801\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6030 - val_loss: 9.1252\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5890 - val_loss: 9.2185\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7759 - val_loss: 9.2759\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6745 - val_loss: 9.3196\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5418 - val_loss: 9.4244\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6247 - val_loss: 9.2123\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5391 - val_loss: 9.2584\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6881 - val_loss: 9.1018\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6033 - val_loss: 9.2346\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6045 - val_loss: 9.2006\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5275 - val_loss: 9.1742\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5849 - val_loss: 9.2378\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6845 - val_loss: 9.1855\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6728 - val_loss: 9.3139\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6377 - val_loss: 9.1034\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0375 - val_loss: 9.1369\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9204 - val_loss: 9.2476\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6785 - val_loss: 9.3022\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7157 - val_loss: 9.5606\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4700 - val_loss: 9.0365\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6697 - val_loss: 9.5573\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5768 - val_loss: 9.2211\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5251 - val_loss: 9.0664\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5123 - val_loss: 9.1379\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5201 - val_loss: 9.0341\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6442 - val_loss: 9.0106\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5652 - val_loss: 8.9370\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5894 - val_loss: 9.2692\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4844 - val_loss: 8.9398\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4994 - val_loss: 8.9714\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4581 - val_loss: 9.0407\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4551 - val_loss: 9.0352\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4659 - val_loss: 9.2579\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4813 - val_loss: 9.0442\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4498 - val_loss: 9.0593\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4745 - val_loss: 9.1356\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4394 - val_loss: 9.0650\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5094 - val_loss: 8.9791\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8048 - val_loss: 9.1021\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7526 - val_loss: 9.1035\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5079 - val_loss: 9.1528\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4226 - val_loss: 8.9032\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4253 - val_loss: 9.2277\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5894 - val_loss: 9.0589\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5137 - val_loss: 9.0292\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4440 - val_loss: 9.0200\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4521 - val_loss: 9.1476\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4326 - val_loss: 8.9633\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4097 - val_loss: 9.0400\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.4155 - val_loss: 8.9731\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4523 - val_loss: 8.8351\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3959 - val_loss: 8.9532\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4137 - val_loss: 8.9435\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.4146 - val_loss: 8.9845\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3489 - val_loss: 9.1680\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5000 - val_loss: 8.9890\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4994 - val_loss: 9.0444\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.7822 - val_loss: 9.1620\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.7727 - val_loss: 9.2705\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8044 - val_loss: 9.0973\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.6389 - val_loss: 9.0863\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5772 - val_loss: 8.9084\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2875 - val_loss: 9.2659\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.3923 - val_loss: 8.9364\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5347 - val_loss: 9.0187\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4413 - val_loss: 8.9490\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3774 - val_loss: 9.0237\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5127 - val_loss: 8.9602\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3688 - val_loss: 9.1286\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3463 - val_loss: 8.9351\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4013 - val_loss: 8.9731\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3837 - val_loss: 8.8649\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4103 - val_loss: 8.8924\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3487 - val_loss: 9.0109\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3421 - val_loss: 9.0441\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5268 - val_loss: 9.2565\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5824 - val_loss: 8.9620\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4583 - val_loss: 9.0834\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3496 - val_loss: 9.4585\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3078 - val_loss: 9.0392\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5500 - val_loss: 9.2227\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3297 - val_loss: 9.1586\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3686 - val_loss: 9.1053\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3322 - val_loss: 9.2858\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4133 - val_loss: 9.0900\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3607 - val_loss: 9.1996\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2664 - val_loss: 9.0258\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4849 - val_loss: 9.0175\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4804 - val_loss: 8.9815\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2716 - val_loss: 8.9553\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3163 - val_loss: 8.9243\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2809 - val_loss: 9.1177\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4010 - val_loss: 9.0140\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3549 - val_loss: 9.2187\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2479 - val_loss: 8.8952\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3208 - val_loss: 9.0542\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4889 - val_loss: 9.1092\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5332 - val_loss: 9.1403\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4430 - val_loss: 9.1094\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4068 - val_loss: 9.0125\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4198 - val_loss: 9.3152\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3912 - val_loss: 8.9918\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1927 - val_loss: 9.4040\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3864 - val_loss: 8.8883\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3467 - val_loss: 9.1456\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2756 - val_loss: 9.0033\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2408 - val_loss: 9.0858\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3581 - val_loss: 9.0773\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2856 - val_loss: 9.0329\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2256 - val_loss: 9.0188\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2541 - val_loss: 9.1017\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5902 - val_loss: 8.9781\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2333 - val_loss: 9.0109\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2268 - val_loss: 9.2296\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2947 - val_loss: 9.0349\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2166 - val_loss: 8.9994\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2846 - val_loss: 8.9789\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5100 - val_loss: 8.9657\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7054 - val_loss: 9.1884\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2157 - val_loss: 9.1934\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2821 - val_loss: 8.9412\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2791 - val_loss: 9.1566\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2008 - val_loss: 9.0189\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3584 - val_loss: 9.1857\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3849 - val_loss: 9.0786\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2559 - val_loss: 9.1071\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1961 - val_loss: 9.4674\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3092 - val_loss: 9.0232\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2369 - val_loss: 9.0066\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1868 - val_loss: 8.8936\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2090 - val_loss: 9.2094\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2780 - val_loss: 9.1542\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1970 - val_loss: 9.3618\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1678 - val_loss: 9.1438\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1811 - val_loss: 9.0622\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1703 - val_loss: 9.0915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1947 - val_loss: 9.1367\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2139 - val_loss: 9.1769\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3630 - val_loss: 9.1433\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3021 - val_loss: 9.1130\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3711 - val_loss: 9.0433\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3400 - val_loss: 9.2219\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2365 - val_loss: 9.2372\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2748 - val_loss: 9.1607\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3251 - val_loss: 9.2243\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2890 - val_loss: 9.1763\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2389 - val_loss: 9.0359\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2479 - val_loss: 8.9490\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1667 - val_loss: 9.1323\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1977 - val_loss: 9.0197\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3640 - val_loss: 9.1891\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2619 - val_loss: 9.2292\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4612 - val_loss: 9.1303\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3679 - val_loss: 9.0960\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2798 - val_loss: 9.1017\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2745 - val_loss: 8.9775\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2439 - val_loss: 9.5354\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6108 - val_loss: 9.0056\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2165 - val_loss: 9.5203\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1754 - val_loss: 8.9964\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1397 - val_loss: 9.0962\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2365 - val_loss: 9.1086\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1855 - val_loss: 9.0888\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.1520 - val_loss: 9.2600\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1375 - val_loss: 8.9222\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2689 - val_loss: 9.0192\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1070 - val_loss: 9.1058\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1973 - val_loss: 9.1969\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1539 - val_loss: 9.0168\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1599 - val_loss: 9.1670\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2965 - val_loss: 9.1024\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.0938 - val_loss: 9.4725\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1944 - val_loss: 9.0311\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1941 - val_loss: 9.2966\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2878 - val_loss: 9.1736\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3174 - val_loss: 9.2348\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3096 - val_loss: 9.2946\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3963 - val_loss: 9.2951\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4373 - val_loss: 9.0982\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1437 - val_loss: 9.0355\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1412 - val_loss: 9.2051\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1923 - val_loss: 9.0932\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1846 - val_loss: 9.1509\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2250 - val_loss: 9.2211\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4264 - val_loss: 9.0288\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2608 - val_loss: 9.0016\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1936 - val_loss: 9.5367\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1466 - val_loss: 9.1408\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1521 - val_loss: 9.4022\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1392 - val_loss: 9.1991\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2331 - val_loss: 9.4456\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2309 - val_loss: 9.2159\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2226 - val_loss: 9.3519\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1934 - val_loss: 9.2694\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3318 - val_loss: 9.1908\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1891 - val_loss: 9.2275\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1808 - val_loss: 9.3391\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2123 - val_loss: 9.2519\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2593 - val_loss: 9.3262\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2048 - val_loss: 9.2250\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2629 - val_loss: 9.1988\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3195 - val_loss: 9.1768\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1839 - val_loss: 9.2660\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4815 - val_loss: 9.1853\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1673 - val_loss: 9.5207\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2790 - val_loss: 9.1876\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1636 - val_loss: 9.2809\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1755 - val_loss: 9.1375\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1971 - val_loss: 9.1551\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1856 - val_loss: 9.2593\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1599 - val_loss: 9.1259\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2407 - val_loss: 9.3657\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2932 - val_loss: 9.3872\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1978 - val_loss: 9.1648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2998 - val_loss: 9.2036\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1480 - val_loss: 9.1781\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1479 - val_loss: 9.3106\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3110 - val_loss: 9.1321\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0461 - val_loss: 9.2809\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0834 - val_loss: 9.0649\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1353 - val_loss: 9.2520\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3027 - val_loss: 9.1970\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3126 - val_loss: 9.1541\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0964 - val_loss: 9.5618\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2177 - val_loss: 9.1529\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2676 - val_loss: 9.3513\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3377 - val_loss: 9.2595\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3379 - val_loss: 9.3678\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0558 - val_loss: 9.3400\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1904 - val_loss: 9.1880\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1118 - val_loss: 9.3504\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0704 - val_loss: 9.2848\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1447 - val_loss: 9.2981\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3115 - val_loss: 9.4378\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2749 - val_loss: 9.2391\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3046 - val_loss: 9.2184\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1837 - val_loss: 9.3187\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1439 - val_loss: 9.0865\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3102 - val_loss: 9.3038\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1240 - val_loss: 9.1988\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0759 - val_loss: 9.3568\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1885 - val_loss: 9.2593\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2672 - val_loss: 9.1871\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1257 - val_loss: 9.2602\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1062 - val_loss: 9.2372\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1318 - val_loss: 9.1372\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2114 - val_loss: 9.2848\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1460 - val_loss: 9.2881\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4012 - val_loss: 9.3160\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1669 - val_loss: 9.3234\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2196 - val_loss: 9.1643\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0819 - val_loss: 9.2786\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.1014 - val_loss: 9.2481\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1338 - val_loss: 9.2190\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1164 - val_loss: 9.2511\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1820 - val_loss: 9.3397\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0923 - val_loss: 9.2433\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1360 - val_loss: 9.1887\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1029 - val_loss: 9.2618\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1060 - val_loss: 9.4418\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1065 - val_loss: 9.3492\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1179 - val_loss: 9.1641\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1768 - val_loss: 9.2336\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1505 - val_loss: 9.2227\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0751 - val_loss: 9.2624\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0999 - val_loss: 9.1135\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5092 - val_loss: 9.5787\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3359 - val_loss: 9.2549\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0984 - val_loss: 9.2940\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2124 - val_loss: 9.4600\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1061 - val_loss: 9.2952\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1445 - val_loss: 9.2742\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2226 - val_loss: 9.1419\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6606 - val_loss: 9.4930\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3497 - val_loss: 9.3141\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1973 - val_loss: 9.2333\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1222 - val_loss: 9.4601\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1865 - val_loss: 9.2686\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1421 - val_loss: 9.3927\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1343 - val_loss: 9.2739\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1215 - val_loss: 9.3478\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1393 - val_loss: 9.3466\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1704 - val_loss: 9.4793\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5769 - val_loss: 9.3503\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6282 - val_loss: 9.3011\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3451 - val_loss: 9.3054\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2630 - val_loss: 9.5647\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2367 - val_loss: 9.2592\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1595 - val_loss: 9.3880\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0590 - val_loss: 9.2718\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0861 - val_loss: 9.4374\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1325 - val_loss: 9.2086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0969 - val_loss: 9.2977\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1591 - val_loss: 9.3768\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0862 - val_loss: 9.3985\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0538 - val_loss: 9.4243\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0759 - val_loss: 9.4997\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1240 - val_loss: 9.3090\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0947 - val_loss: 9.3225\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0584 - val_loss: 9.4492\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1395 - val_loss: 9.3851\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2368 - val_loss: 9.2910\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0465 - val_loss: 9.2449\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3040 - val_loss: 9.2813\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0259 - val_loss: 9.5623\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0641 - val_loss: 9.2479\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1344 - val_loss: 9.2972\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1772 - val_loss: 9.2582\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2758 - val_loss: 9.3685\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1917 - val_loss: 9.1825\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2093 - val_loss: 9.4154\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1014 - val_loss: 9.2370\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0986 - val_loss: 9.2892\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0577 - val_loss: 9.3249\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1013 - val_loss: 9.3035\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1827 - val_loss: 9.2726\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3267 - val_loss: 9.3915\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5550 - val_loss: 9.4108\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4330 - val_loss: 9.3014\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3266 - val_loss: 9.2562\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3250 - val_loss: 9.4747\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2723 - val_loss: 9.3269\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2896 - val_loss: 9.3572\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1014 - val_loss: 9.2670\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0657 - val_loss: 9.4986\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1717 - val_loss: 9.3970\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0996 - val_loss: 9.3657\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0793 - val_loss: 9.4979\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1855 - val_loss: 9.3359\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2466 - val_loss: 9.3909\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0378 - val_loss: 9.2776\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0331 - val_loss: 9.3210\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0931 - val_loss: 9.2758\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0713 - val_loss: 9.3713\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1907 - val_loss: 9.2604\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0578 - val_loss: 9.3427\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0681 - val_loss: 9.2535\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0744 - val_loss: 9.3635\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0941 - val_loss: 9.4712\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0714 - val_loss: 9.3325\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1427 - val_loss: 9.4494\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1693 - val_loss: 9.3076\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0794 - val_loss: 9.4053\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1676 - val_loss: 9.3484\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0230 - val_loss: 9.4189\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1116 - val_loss: 9.2726\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1558 - val_loss: 9.5217\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0735 - val_loss: 9.6056\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4041 - val_loss: 9.3725\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1819 - val_loss: 9.4315\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0934 - val_loss: 9.2807\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0971 - val_loss: 9.3388\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2594 - val_loss: 9.4646\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1546 - val_loss: 9.3125\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0523 - val_loss: 9.1631\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3082 - val_loss: 9.3034\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2869 - val_loss: 9.4086\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4714 - val_loss: 9.5308\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1544 - val_loss: 9.6479\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1065 - val_loss: 9.2948\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1192 - val_loss: 9.3969\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.0254 - val_loss: 9.3500\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0849 - val_loss: 9.5554\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0065 - val_loss: 9.2137\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1525 - val_loss: 9.4616\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0914 - val_loss: 9.2668\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1065 - val_loss: 9.3130\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1168 - val_loss: 9.3790\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1858 - val_loss: 9.2650\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3520 - val_loss: 9.3387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4819 - val_loss: 9.3125\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9821 - val_loss: 9.5725\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0994 - val_loss: 9.2813\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0430 - val_loss: 9.4231\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0890 - val_loss: 9.2772\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1022 - val_loss: 9.3517\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1124 - val_loss: 9.2867\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1240 - val_loss: 9.4149\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0396 - val_loss: 9.3661\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0462 - val_loss: 9.4953\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0652 - val_loss: 9.3513\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0513 - val_loss: 9.3398\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0495 - val_loss: 9.5197\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1112 - val_loss: 9.3109\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0644 - val_loss: 9.3406\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0075 - val_loss: 9.3727\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0685 - val_loss: 9.1761\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0639 - val_loss: 9.4011\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2880 - val_loss: 9.3145\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3665 - val_loss: 9.4947\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2217 - val_loss: 9.5585\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1796 - val_loss: 9.4405\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0922 - val_loss: 9.3795\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0631 - val_loss: 9.3389\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0516 - val_loss: 9.3521\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9894 - val_loss: 9.2552\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1778 - val_loss: 9.3263\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1243 - val_loss: 9.3367\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0846 - val_loss: 9.3328\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0559 - val_loss: 9.4001\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0188 - val_loss: 9.3670\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9922 - val_loss: 9.6269\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0871 - val_loss: 9.3239\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0921 - val_loss: 9.3629\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1051 - val_loss: 9.2189\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0557 - val_loss: 9.3965\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.1431 - val_loss: 9.3969\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0522 - val_loss: 9.3560\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0446 - val_loss: 9.5378\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1096 - val_loss: 9.3010\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.2711 - val_loss: 9.2833\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2521 - val_loss: 9.3956\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1723 - val_loss: 9.2811\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0637 - val_loss: 9.4435\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1138 - val_loss: 9.5064\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1993 - val_loss: 9.3414\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1935 - val_loss: 9.3757\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1147 - val_loss: 9.4939\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.1815 - val_loss: 9.4044\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0260 - val_loss: 9.5109\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1014 - val_loss: 9.4170\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0635 - val_loss: 9.3830\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2536 - val_loss: 9.2975\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0535 - val_loss: 9.3531\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1039 - val_loss: 9.2745\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2725 - val_loss: 9.4268\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2205 - val_loss: 9.4071\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1823 - val_loss: 9.3848\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2356 - val_loss: 9.3808\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9584 - val_loss: 9.2571\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9642 - val_loss: 9.2747\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9525 - val_loss: 9.2838\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0587 - val_loss: 9.1851\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0263 - val_loss: 9.3421\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.9348 - val_loss: 9.2745\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1097 - val_loss: 9.2006\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2694 - val_loss: 9.4527\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2219 - val_loss: 9.2958\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1087 - val_loss: 9.4142\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2163 - val_loss: 9.3351\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0976 - val_loss: 9.5453\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0986 - val_loss: 9.2556\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9816 - val_loss: 9.4615\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0033 - val_loss: 9.2281\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0950 - val_loss: 9.4316\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1292 - val_loss: 9.1656\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.0065 - val_loss: 9.2852\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 6.2190 - val_loss: 9.2008\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1044 - val_loss: 9.1856\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0732 - val_loss: 9.3147\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9664 - val_loss: 9.3275\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.9319 - val_loss: 9.2574\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0184 - val_loss: 9.4051\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2297 - val_loss: 9.2180\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1013 - val_loss: 9.2850\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0204 - val_loss: 9.3314\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9795 - val_loss: 9.3114\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9777 - val_loss: 9.3907\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0088 - val_loss: 9.2003\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9375 - val_loss: 9.2412\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0533 - val_loss: 9.2645\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0653 - val_loss: 9.2567\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9512 - val_loss: 9.1944\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9588 - val_loss: 9.3247\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0143 - val_loss: 9.3060\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9299 - val_loss: 9.3514\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9924 - val_loss: 9.2841\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0614 - val_loss: 9.2510\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.9743 - val_loss: 9.0861\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9954 - val_loss: 9.1931\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9486 - val_loss: 9.1407\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9945 - val_loss: 9.1979\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2237 - val_loss: 9.4070\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3098 - val_loss: 9.1643\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0288 - val_loss: 9.2890\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9466 - val_loss: 9.2219\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9147 - val_loss: 9.2238\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9401 - val_loss: 9.4263\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9729 - val_loss: 9.2607\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0640 - val_loss: 9.2338\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9830 - val_loss: 9.2382\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9305 - val_loss: 9.4440\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0029 - val_loss: 9.1485\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9094 - val_loss: 9.4720\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8851 - val_loss: 9.1876\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9404 - val_loss: 9.2097\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9186 - val_loss: 9.1531\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0164 - val_loss: 9.1491\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9833 - val_loss: 9.1922\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9304 - val_loss: 9.2745\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9327 - val_loss: 9.0834\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8829 - val_loss: 9.2289\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0473 - val_loss: 9.3316\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9228 - val_loss: 9.1463\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0065 - val_loss: 9.1180\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9979 - val_loss: 9.3403\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8750 - val_loss: 9.0914\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1695 - val_loss: 9.4410\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9822 - val_loss: 9.1750\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0119 - val_loss: 9.3667\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9367 - val_loss: 9.3476\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9670 - val_loss: 9.2276\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9338 - val_loss: 9.1032\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2821 - val_loss: 9.3014\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3495 - val_loss: 9.2730\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0545 - val_loss: 9.2003\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0709 - val_loss: 9.1640\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0518 - val_loss: 9.2591\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1455 - val_loss: 9.2554\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0896 - val_loss: 9.3903\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0277 - val_loss: 9.2901\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2275 - val_loss: 9.3656\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9678 - val_loss: 9.1735\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9681 - val_loss: 9.2915\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8475 - val_loss: 9.3601\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9800 - val_loss: 9.1494\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3007 - val_loss: 9.3391\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9854 - val_loss: 9.3495\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8142 - val_loss: 9.2777\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1227 - val_loss: 9.3613\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0518 - val_loss: 9.3245\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1960 - val_loss: 9.2083\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0701 - val_loss: 9.3190\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9693 - val_loss: 9.3636\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9975 - val_loss: 9.1581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0455 - val_loss: 9.1800\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9466 - val_loss: 9.2600\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9160 - val_loss: 9.3500\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8849 - val_loss: 9.3610\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8875 - val_loss: 9.3560\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8987 - val_loss: 9.1844\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9331 - val_loss: 9.2034\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8639 - val_loss: 9.2454\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9493 - val_loss: 9.1720\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9052 - val_loss: 9.2924\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9514 - val_loss: 9.2033\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0789 - val_loss: 9.2043\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9585 - val_loss: 9.1994\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2814 - val_loss: 9.0541\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1087 - val_loss: 9.1069\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8907 - val_loss: 9.2739\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8755 - val_loss: 9.1947\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8622 - val_loss: 9.4254\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9317 - val_loss: 9.1259\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8967 - val_loss: 9.2767\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9294 - val_loss: 9.1745\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9963 - val_loss: 9.3231\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0805 - val_loss: 9.1160\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9426 - val_loss: 9.2188\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9836 - val_loss: 9.2300\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0546 - val_loss: 9.3416\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9222 - val_loss: 9.3177\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8815 - val_loss: 9.2764\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9419 - val_loss: 9.2363\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8683 - val_loss: 9.3211\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8590 - val_loss: 9.2576\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8885 - val_loss: 9.2898\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8576 - val_loss: 9.1320\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8959 - val_loss: 9.2432\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9589 - val_loss: 9.3067\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8442 - val_loss: 9.1936\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8473 - val_loss: 9.2787\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8380 - val_loss: 9.2692\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8468 - val_loss: 9.2717\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9298 - val_loss: 9.2044\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8168 - val_loss: 9.2257\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0855 - val_loss: 9.0540\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0907 - val_loss: 9.1754\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8655 - val_loss: 9.1218\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8228 - val_loss: 9.4697\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8363 - val_loss: 9.2175\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9038 - val_loss: 9.2202\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8663 - val_loss: 9.2997\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9088 - val_loss: 9.4125\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9530 - val_loss: 9.1758\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8691 - val_loss: 9.5538\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0406 - val_loss: 9.1828\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9667 - val_loss: 9.2928\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9096 - val_loss: 9.2093\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9172 - val_loss: 9.1429\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8751 - val_loss: 9.1690\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8598 - val_loss: 9.0569\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8593 - val_loss: 9.3784\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8629 - val_loss: 9.2251\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8771 - val_loss: 9.1963\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9521 - val_loss: 9.2341\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9915 - val_loss: 9.3617\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9669 - val_loss: 9.3425\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9076 - val_loss: 9.1836\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7949 - val_loss: 9.3797\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8774 - val_loss: 9.1087\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8758 - val_loss: 9.2964\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8780 - val_loss: 9.2381\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7990 - val_loss: 9.3176\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8874 - val_loss: 9.1242\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9595 - val_loss: 9.2207\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8215 - val_loss: 9.2000\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8557 - val_loss: 9.2489\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8648 - val_loss: 9.2340\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9163 - val_loss: 9.2987\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8351 - val_loss: 9.1752\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9906 - val_loss: 9.1340\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8169 - val_loss: 9.1094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8915 - val_loss: 9.4838\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2690 - val_loss: 9.3031\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9519 - val_loss: 9.3171\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8596 - val_loss: 9.1808\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8792 - val_loss: 9.2364\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8922 - val_loss: 9.2780\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1377 - val_loss: 9.2147\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8772 - val_loss: 9.2876\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9039 - val_loss: 9.1062\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9169 - val_loss: 9.4810\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8940 - val_loss: 9.4076\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8182 - val_loss: 9.2917\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8487 - val_loss: 9.1913\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0216 - val_loss: 9.3760\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8584 - val_loss: 9.2540\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0064 - val_loss: 9.2735\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9151 - val_loss: 9.4343\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8743 - val_loss: 9.2740\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8469 - val_loss: 9.4259\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8171 - val_loss: 9.1537\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8915 - val_loss: 9.3556\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9610 - val_loss: 9.2042\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9558 - val_loss: 9.2425\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8539 - val_loss: 9.3467\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8223 - val_loss: 9.3942\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8751 - val_loss: 9.2027\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0354 - val_loss: 9.3168\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7727 - val_loss: 9.3136\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9727 - val_loss: 9.4736\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7935 - val_loss: 9.3544\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8651 - val_loss: 9.1710\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8474 - val_loss: 9.2082\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8252 - val_loss: 9.1628\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8396 - val_loss: 9.1566\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1547 - val_loss: 9.1168\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8803 - val_loss: 9.2540\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2314 - val_loss: 9.2232\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0602 - val_loss: 9.3086\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0473 - val_loss: 9.3138\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9125 - val_loss: 9.3728\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8320 - val_loss: 9.2118\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8434 - val_loss: 9.4239\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8196 - val_loss: 9.3563\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8036 - val_loss: 9.3268\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8059 - val_loss: 9.2059\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7830 - val_loss: 9.1979\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7894 - val_loss: 9.3182\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8154 - val_loss: 9.3527\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8217 - val_loss: 9.2879\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8514 - val_loss: 9.3667\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8929 - val_loss: 9.2468\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8921 - val_loss: 9.4856\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9785 - val_loss: 9.3468\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0334 - val_loss: 9.2426\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9592 - val_loss: 9.5049\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8225 - val_loss: 9.3568\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8744 - val_loss: 9.2421\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8992 - val_loss: 9.3313\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8160 - val_loss: 9.2059\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7981 - val_loss: 9.3323\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8141 - val_loss: 9.2782\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8534 - val_loss: 9.2554\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8686 - val_loss: 9.2797\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8021 - val_loss: 9.3854\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0308 - val_loss: 9.2981\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0321 - val_loss: 9.4356\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9743 - val_loss: 9.3458\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9115 - val_loss: 9.6190\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7956 - val_loss: 9.3913\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8168 - val_loss: 9.2604\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8752 - val_loss: 9.4807\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0189 - val_loss: 9.2238\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8465 - val_loss: 9.3096\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8339 - val_loss: 9.4249\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8896 - val_loss: 9.3399\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8350 - val_loss: 9.3821\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8221 - val_loss: 9.3264\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8842 - val_loss: 9.3735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8648 - val_loss: 9.3303\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7571 - val_loss: 9.4868\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8602 - val_loss: 9.1795\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8436 - val_loss: 9.3297\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8601 - val_loss: 9.1927\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7829 - val_loss: 9.4093\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8350 - val_loss: 9.3354\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8616 - val_loss: 9.3145\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9127 - val_loss: 9.2872\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9300 - val_loss: 9.4119\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0322 - val_loss: 9.3144\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3041 - val_loss: 9.6129\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8196 - val_loss: 9.3286\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7850 - val_loss: 9.3826\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.9144 - val_loss: 9.2091\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8077 - val_loss: 9.4018\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8013 - val_loss: 9.3323\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9684 - val_loss: 9.5406\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9610 - val_loss: 9.4605\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7548 - val_loss: 9.3513\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8792 - val_loss: 9.5128\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8068 - val_loss: 9.5306\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7866 - val_loss: 9.4167\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7960 - val_loss: 9.3883\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8577 - val_loss: 9.3576\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9847 - val_loss: 9.4069\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8039 - val_loss: 9.3832\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8712 - val_loss: 9.4379\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8082 - val_loss: 9.4368\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8053 - val_loss: 9.2502\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8075 - val_loss: 9.5694\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8333 - val_loss: 9.5329\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9310 - val_loss: 9.6358\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8661 - val_loss: 9.3030\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8776 - val_loss: 9.3636\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7380 - val_loss: 9.4204\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7844 - val_loss: 9.3139\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9477 - val_loss: 9.6089\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8283 - val_loss: 9.3500\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7615 - val_loss: 9.3420\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8834 - val_loss: 9.6267\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8227 - val_loss: 9.3021\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7871 - val_loss: 9.4276\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8244 - val_loss: 9.4185\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8807 - val_loss: 9.2730\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8378 - val_loss: 9.4825\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7973 - val_loss: 9.3107\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7957 - val_loss: 9.4096\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7420 - val_loss: 9.3349\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7967 - val_loss: 9.3652\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8135 - val_loss: 9.4080\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7988 - val_loss: 9.2642\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8871 - val_loss: 9.2751\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8070 - val_loss: 9.3866\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7823 - val_loss: 9.4804\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7804 - val_loss: 9.4446\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7954 - val_loss: 9.6074\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8734 - val_loss: 9.2995\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0130 - val_loss: 9.5979\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8878 - val_loss: 9.5479\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8392 - val_loss: 9.4412\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7539 - val_loss: 9.5155\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7687 - val_loss: 9.4476\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7972 - val_loss: 9.4146\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9428 - val_loss: 9.3610\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8319 - val_loss: 9.4522\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7232 - val_loss: 9.6370\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8738 - val_loss: 9.4255\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8251 - val_loss: 9.4698\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7600 - val_loss: 9.4481\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8465 - val_loss: 9.5800\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9324 - val_loss: 9.3306\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8261 - val_loss: 9.3282\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8108 - val_loss: 9.3865\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7681 - val_loss: 9.5148\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1644 - val_loss: 9.3243\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8902 - val_loss: 9.5092\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8337 - val_loss: 9.5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9425 - val_loss: 9.7161\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7775 - val_loss: 9.3503\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9409 - val_loss: 9.6020\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8317 - val_loss: 9.4316\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7880 - val_loss: 9.4736\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8896 - val_loss: 9.3967\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8096 - val_loss: 9.4385\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8670 - val_loss: 9.3929\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7611 - val_loss: 9.4465\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7811 - val_loss: 9.3588\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8339 - val_loss: 9.6081\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8207 - val_loss: 9.5014\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8314 - val_loss: 9.4694\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9763 - val_loss: 9.4522\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8808 - val_loss: 9.4798\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8677 - val_loss: 9.3478\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7385 - val_loss: 9.6603\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7828 - val_loss: 9.7968\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8008 - val_loss: 9.4340\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8150 - val_loss: 9.4767\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9479 - val_loss: 9.6725\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7401 - val_loss: 9.3999\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9084 - val_loss: 9.5113\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9288 - val_loss: 9.4157\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9573 - val_loss: 9.5826\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8075 - val_loss: 9.5584\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7631 - val_loss: 9.4865\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7643 - val_loss: 9.4471\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7656 - val_loss: 9.5917\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7754 - val_loss: 9.4293\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8163 - val_loss: 9.7874\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7677 - val_loss: 9.6542\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7527 - val_loss: 9.5719\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7740 - val_loss: 9.4420\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7706 - val_loss: 9.4685\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8406 - val_loss: 9.5288\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7998 - val_loss: 9.4049\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8730 - val_loss: 9.3900\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7603 - val_loss: 9.5602\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9301 - val_loss: 9.4473\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8536 - val_loss: 9.7145\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8408 - val_loss: 9.6271\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7878 - val_loss: 9.3996\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9307 - val_loss: 9.7488\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7156 - val_loss: 9.6114\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7647 - val_loss: 9.4377\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8498 - val_loss: 9.4707\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9375 - val_loss: 9.6450\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9736 - val_loss: 9.4557\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8827 - val_loss: 9.4518\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9254 - val_loss: 9.5358\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9147 - val_loss: 9.6309\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9728 - val_loss: 9.4569\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8063 - val_loss: 9.5095\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8187 - val_loss: 9.4719\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7762 - val_loss: 9.5537\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7420 - val_loss: 9.6181\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7406 - val_loss: 9.4274\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9095 - val_loss: 9.5035\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7321 - val_loss: 9.5021\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8447 - val_loss: 9.4254\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7790 - val_loss: 9.4511\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7845 - val_loss: 9.4217\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7931 - val_loss: 9.4567\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7345 - val_loss: 9.4050\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7313 - val_loss: 9.4097\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8167 - val_loss: 9.6764\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8280 - val_loss: 9.4222\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7480 - val_loss: 9.5330\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7122 - val_loss: 9.6838\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7511 - val_loss: 9.5580\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7186 - val_loss: 9.6621\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7596 - val_loss: 9.3747\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8671 - val_loss: 9.6017\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9759 - val_loss: 9.4259\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8021 - val_loss: 9.6626\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7165 - val_loss: 9.6046\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8046 - val_loss: 9.7754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8002 - val_loss: 9.3408\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9355 - val_loss: 9.6990\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7653 - val_loss: 9.5184\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7390 - val_loss: 9.5268\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8148 - val_loss: 9.6185\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7838 - val_loss: 9.4309\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8798 - val_loss: 9.6976\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9729 - val_loss: 9.4546\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8452 - val_loss: 9.5767\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8867 - val_loss: 9.5060\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7811 - val_loss: 9.4856\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7589 - val_loss: 9.4733\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.7618 - val_loss: 9.5114\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7672 - val_loss: 9.5266\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8063 - val_loss: 9.5324\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7850 - val_loss: 9.5981\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8495 - val_loss: 9.6174\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7870 - val_loss: 9.5536\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8648 - val_loss: 9.6288\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7675 - val_loss: 9.4976\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7558 - val_loss: 9.6063\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9446 - val_loss: 9.6235\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8955 - val_loss: 9.8756\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7663 - val_loss: 9.5600\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8631 - val_loss: 9.6166\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9074 - val_loss: 9.8764\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8234 - val_loss: 9.5183\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7772 - val_loss: 9.4994\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8046 - val_loss: 9.5009\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7415 - val_loss: 9.5836\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7682 - val_loss: 9.6185\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8091 - val_loss: 9.5662\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7909 - val_loss: 9.8166\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6921 - val_loss: 9.5461\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7933 - val_loss: 9.5314\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7640 - val_loss: 9.5670\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7482 - val_loss: 9.6493\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7785 - val_loss: 9.7221\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7169 - val_loss: 9.5056\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8143 - val_loss: 9.6060\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7671 - val_loss: 9.6748\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7946 - val_loss: 9.5059\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8051 - val_loss: 9.6104\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6738 - val_loss: 9.4970\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8021 - val_loss: 9.5600\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7462 - val_loss: 9.5221\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8267 - val_loss: 9.4690\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7932 - val_loss: 9.5932\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7823 - val_loss: 9.6200\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9791 - val_loss: 9.3873\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8136 - val_loss: 9.6223\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8832 - val_loss: 9.5727\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8233 - val_loss: 9.6945\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8246 - val_loss: 9.7762\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7923 - val_loss: 9.5127\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7422 - val_loss: 9.3870\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7520 - val_loss: 9.4525\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7576 - val_loss: 9.4797\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1108 - val_loss: 9.7828\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0330 - val_loss: 9.5633\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7017 - val_loss: 9.4531\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8479 - val_loss: 9.8051\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7972 - val_loss: 9.5273\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9151 - val_loss: 9.7390\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7911 - val_loss: 9.7664\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8006 - val_loss: 9.7346\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7568 - val_loss: 9.6594\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7478 - val_loss: 9.5981\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7105 - val_loss: 9.7316\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7933 - val_loss: 9.6443\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7691 - val_loss: 9.6869\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8483 - val_loss: 9.6957\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7452 - val_loss: 9.7517\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7795 - val_loss: 9.5233\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8118 - val_loss: 9.7961\n",
      "7.564128625190865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.3467336e+00,  1.4211567e-01,  2.8313897e+00, -4.1423708e-01,\n",
       "          2.5285000e-01],\n",
       "        [-3.5401517e-01, -2.6235349e+00, -3.0402675e+00,  8.7620091e-01,\n",
       "         -7.2671734e-02],\n",
       "        [ 3.9375806e-01,  2.6986074e+00,  2.7425830e+00,  5.9640501e-05,\n",
       "         -6.4852637e-01],\n",
       "        [ 2.3905623e+00,  3.1529481e+00,  2.1616662e+00, -4.2550385e-01,\n",
       "         -1.3310755e+00],\n",
       "        [-3.9253780e-01, -9.6870571e-01,  5.9021419e-01,  6.3443786e-01,\n",
       "         -1.0992393e+00],\n",
       "        [-1.2700504e+00, -1.1725215e+00, -8.2102263e-01, -3.4282988e-01,\n",
       "          9.0340483e-01],\n",
       "        [-1.9713761e-01,  8.7818503e-01, -2.4003906e+00, -1.3872278e+00,\n",
       "         -2.4778748e-01]], dtype=float32),\n",
       " array([ 2.3409479, -0.6539924,  1.0343283, -2.7042737,  3.1972566],\n",
       "       dtype=float32),\n",
       " array([[-0.08755091, -0.5618288 ,  0.07350245,  0.8922274 , -0.46773246,\n",
       "          0.57798326, -0.6071717 , -0.59325105, -0.8586033 ,  0.7576529 ],\n",
       "        [ 0.21049668,  0.5123015 ,  0.7655772 ,  0.71277386,  0.6212597 ,\n",
       "          0.7503682 ,  0.40587246,  0.20454836, -0.38311106, -0.21312135],\n",
       "        [-0.02169051, -0.51696175,  0.7575134 ,  0.6839077 , -0.6750518 ,\n",
       "          0.12995622, -0.20580173, -0.08684859, -0.34960634,  0.5691562 ],\n",
       "        [ 1.1111002 ,  0.09125312,  1.2255924 ,  1.1310008 , -0.62251836,\n",
       "          1.0112572 ,  0.25921682,  0.02360569, -0.58888966,  0.10973115],\n",
       "        [-0.23537451,  0.18997079,  0.03861147, -0.5956302 , -0.06990997,\n",
       "         -0.7126117 , -0.26415774, -0.24282229,  0.2275461 , -0.15710762]],\n",
       "       dtype=float32),\n",
       " array([-1.6708925,  1.6742718, -1.6689736, -1.7062831,  1.5952178,\n",
       "        -1.6940966,  1.6365162,  1.2045182,  1.7623644, -1.7425402],\n",
       "       dtype=float32),\n",
       " array([[-1.2846975 ],\n",
       "        [ 0.56487364],\n",
       "        [-1.1423024 ],\n",
       "        [-1.522425  ],\n",
       "        [ 0.53423786],\n",
       "        [-1.4865304 ],\n",
       "        [ 0.35690787],\n",
       "        [ 0.16748288],\n",
       "        [ 0.99979997],\n",
       "        [-0.9644136 ]], dtype=float32),\n",
       " array([1.665311], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_2(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure2_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 920us/step - loss: 470.1106 - val_loss: 178.7733\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 97.4286 - val_loss: 65.2782\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 35.1701 - val_loss: 33.3425\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 19.2730 - val_loss: 16.5641\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.3433 - val_loss: 14.7824\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 11.7460 - val_loss: 15.2038\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 10.4616 - val_loss: 14.4141\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.0577 - val_loss: 13.2910\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 9.1050 - val_loss: 12.9770\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2440 - val_loss: 12.2304\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0413 - val_loss: 12.5525\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9991 - val_loss: 12.6386\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.0782 - val_loss: 12.1224\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1725 - val_loss: 11.9952\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4713 - val_loss: 12.1844\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0786 - val_loss: 11.4907\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5655 - val_loss: 11.5766\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4995 - val_loss: 11.7440\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4718 - val_loss: 11.5157\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6277 - val_loss: 11.7204\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7444 - val_loss: 11.8287\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7618 - val_loss: 13.5636\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2206 - val_loss: 13.0238\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2063 - val_loss: 11.5023\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3676 - val_loss: 11.2846\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3248 - val_loss: 11.2820\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5483 - val_loss: 11.9605\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2219 - val_loss: 11.9790\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3298 - val_loss: 11.2856\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0461 - val_loss: 11.7390\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8436 - val_loss: 11.6796\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 8.0187 - val_loss: 11.7080\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2711 - val_loss: 11.7545\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2766 - val_loss: 11.8333\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4100 - val_loss: 11.4302\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4686 - val_loss: 11.5273\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.4249 - val_loss: 11.3702\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2671 - val_loss: 11.0643\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.2916 - val_loss: 11.4439\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4804 - val_loss: 11.3718\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 7.7571 - val_loss: 11.7490\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5244 - val_loss: 11.2081\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5598 - val_loss: 11.6015\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2573 - val_loss: 11.5336\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2850 - val_loss: 11.1519\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2797 - val_loss: 11.1657\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6969 - val_loss: 11.2518\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 7.7865 - val_loss: 11.2603\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2854 - val_loss: 10.9352\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1384 - val_loss: 10.8712\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1178 - val_loss: 11.1274\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0875 - val_loss: 11.0884\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.4191 - val_loss: 11.0355\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.8233 - val_loss: 11.7301\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9566 - val_loss: 11.0851\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3469 - val_loss: 11.4888\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4836 - val_loss: 10.8910\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6649 - val_loss: 11.2485\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4400 - val_loss: 11.1893\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.4994 - val_loss: 10.9621\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1897 - val_loss: 10.9146\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0690 - val_loss: 11.1371\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1049 - val_loss: 11.0557\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0199 - val_loss: 11.0426\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0564 - val_loss: 10.8080\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0495 - val_loss: 10.9276\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1173 - val_loss: 10.8144\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 116us/step - loss: 7.5942 - val_loss: 10.7619\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.5763 - val_loss: 11.4313\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.7538 - val_loss: 11.2069\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 7.9884 - val_loss: 11.6083\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.5190 - val_loss: 11.4477\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9678 - val_loss: 11.4632\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.5793 - val_loss: 11.1382\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0080 - val_loss: 11.2672\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1500 - val_loss: 10.8927\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.0005 - val_loss: 10.8589\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9967 - val_loss: 10.6765\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.1091 - val_loss: 11.1085\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0101 - val_loss: 10.8399\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9725 - val_loss: 10.8801\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9538 - val_loss: 10.9026\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9739 - val_loss: 10.7783\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0225 - val_loss: 10.8625\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0644 - val_loss: 10.8092\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0076 - val_loss: 11.0976\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1560 - val_loss: 10.8379\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9285 - val_loss: 10.9231\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9636 - val_loss: 10.9164\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.9248 - val_loss: 10.8834\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2350 - val_loss: 10.8406\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0764 - val_loss: 10.9435\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1856 - val_loss: 11.0975\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.1374 - val_loss: 10.9607\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9202 - val_loss: 11.2334\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8624 - val_loss: 10.8998\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9137 - val_loss: 10.8118\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9256 - val_loss: 10.7813\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0640 - val_loss: 10.7887\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9057 - val_loss: 10.7457\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1825 - val_loss: 11.1941\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2761 - val_loss: 11.0724\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2323 - val_loss: 11.5101\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6396 - val_loss: 10.8960\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1149 - val_loss: 11.2592\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8779 - val_loss: 11.0355\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9022 - val_loss: 11.2374\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0272 - val_loss: 10.9136\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9452 - val_loss: 10.7943\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8667 - val_loss: 10.8263\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8438 - val_loss: 11.0007\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0118 - val_loss: 11.0724\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9379 - val_loss: 10.9264\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0738 - val_loss: 11.1001\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8887 - val_loss: 10.8082\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1483 - val_loss: 11.2557\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1156 - val_loss: 11.0610\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3366 - val_loss: 11.2121\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2716 - val_loss: 10.9721\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9783 - val_loss: 10.7311\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8950 - val_loss: 10.6267\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9773 - val_loss: 10.6819\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0434 - val_loss: 10.5645\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8313 - val_loss: 10.8745\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7794 - val_loss: 10.7518\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9478 - val_loss: 10.6815\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8157 - val_loss: 10.7383\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7608 - val_loss: 10.8486\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0469 - val_loss: 10.6578\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8753 - val_loss: 10.9699\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9886 - val_loss: 10.4937\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8529 - val_loss: 11.1678\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8358 - val_loss: 10.5675\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7743 - val_loss: 10.4450\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6995 - val_loss: 10.4759\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8238 - val_loss: 10.2607\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8955 - val_loss: 10.3244\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8154 - val_loss: 10.4574\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9051 - val_loss: 10.6362\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8610 - val_loss: 10.9235\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8793 - val_loss: 10.3832\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7022 - val_loss: 10.5559\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8641 - val_loss: 10.5394\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 8.1374 - val_loss: 10.4954\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 7.5344 - val_loss: 10.9598\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9177 - val_loss: 10.3767\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1095 - val_loss: 11.0250\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8196 - val_loss: 10.4080\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9003 - val_loss: 10.4945\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7272 - val_loss: 10.2194\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7745 - val_loss: 10.5570\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7420 - val_loss: 10.2252\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7657 - val_loss: 10.1094\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7241 - val_loss: 10.1298\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7928 - val_loss: 10.1948\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6245 - val_loss: 10.0281\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7716 - val_loss: 10.0105\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9667 - val_loss: 9.8416\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8437 - val_loss: 10.2636\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7683 - val_loss: 10.1266\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7391 - val_loss: 10.1448\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9007 - val_loss: 9.9074\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6342 - val_loss: 10.2696\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0660 - val_loss: 9.7968\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8984 - val_loss: 10.4346\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9646 - val_loss: 9.9256\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7973 - val_loss: 10.4272\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8034 - val_loss: 10.1250\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6299 - val_loss: 10.1009\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7505 - val_loss: 9.9628\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9579 - val_loss: 9.6994\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9007 - val_loss: 9.5210\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5677 - val_loss: 9.8766\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5466 - val_loss: 9.6725\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5546 - val_loss: 9.6324\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6192 - val_loss: 9.5739\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5972 - val_loss: 9.7485\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6798 - val_loss: 9.9149\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7217 - val_loss: 9.7224\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7040 - val_loss: 9.6073\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.5612 - val_loss: 9.6073\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4801 - val_loss: 9.9305\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5048 - val_loss: 9.7002\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5017 - val_loss: 9.5740\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5466 - val_loss: 9.3881\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5197 - val_loss: 9.8282\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6049 - val_loss: 9.7440\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5103 - val_loss: 9.7498\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5667 - val_loss: 9.3303\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7037 - val_loss: 9.5982\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7069 - val_loss: 9.6531\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7132 - val_loss: 9.5720\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5855 - val_loss: 9.3840\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9837 - val_loss: 9.5552\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1991 - val_loss: 9.5445\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0770 - val_loss: 9.4769\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0802 - val_loss: 9.5631\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8691 - val_loss: 9.1993\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6654 - val_loss: 9.4390\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4421 - val_loss: 9.2044\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5840 - val_loss: 9.5051\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5268 - val_loss: 9.5444\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4266 - val_loss: 9.4858\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5441 - val_loss: 9.3231\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4708 - val_loss: 9.3149\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6294 - val_loss: 9.2280\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5311 - val_loss: 9.1242\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5751 - val_loss: 9.2635\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5661 - val_loss: 9.0992\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5460 - val_loss: 9.2484\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5117 - val_loss: 8.9694\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6195 - val_loss: 9.4479\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4472 - val_loss: 8.7772\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4056 - val_loss: 8.8811\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6254 - val_loss: 9.1345\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6260 - val_loss: 9.3425\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7522 - val_loss: 8.9738\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6184 - val_loss: 8.8666\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5022 - val_loss: 9.0911\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5784 - val_loss: 9.1730\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5122 - val_loss: 9.0204\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 93us/step - loss: 6.3659 - val_loss: 8.9101\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5563 - val_loss: 8.7463\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5256 - val_loss: 8.8634\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5610 - val_loss: 8.8648\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0061 - val_loss: 9.3301\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8980 - val_loss: 8.7381\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6834 - val_loss: 8.8971\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7540 - val_loss: 8.8019\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4842 - val_loss: 8.7743\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4046 - val_loss: 8.6707\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3674 - val_loss: 8.7347\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4414 - val_loss: 8.7227\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4207 - val_loss: 8.6108\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3384 - val_loss: 8.6735\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3658 - val_loss: 8.7059\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4422 - val_loss: 8.7446\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6610 - val_loss: 8.1759\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6045 - val_loss: 8.5426\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4196 - val_loss: 8.4841\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3991 - val_loss: 8.4573\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5064 - val_loss: 8.5386\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2183 - val_loss: 8.5482\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3435 - val_loss: 8.1019\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5261 - val_loss: 8.3096\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3152 - val_loss: 8.5559\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4852 - val_loss: 8.6393\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1963 - val_loss: 8.3044\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3867 - val_loss: 8.5397\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2286 - val_loss: 8.3693\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2205 - val_loss: 8.0549\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3577 - val_loss: 8.3658\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5479 - val_loss: 8.2783\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3857 - val_loss: 8.4119\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3970 - val_loss: 8.0462\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4717 - val_loss: 8.2212\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4488 - val_loss: 8.1301\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2147 - val_loss: 8.4157\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2494 - val_loss: 8.3154\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1950 - val_loss: 7.8204\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3728 - val_loss: 7.9721\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1878 - val_loss: 8.1638\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.2187 - val_loss: 8.2108\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2874 - val_loss: 8.3361\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3048 - val_loss: 8.0686\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4451 - val_loss: 8.0995\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2899 - val_loss: 8.0283\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3286 - val_loss: 8.3451\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4898 - val_loss: 7.8267\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6365 - val_loss: 7.8705\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3184 - val_loss: 8.1710\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1893 - val_loss: 8.1806\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2415 - val_loss: 8.1068\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5397 - val_loss: 7.9205\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3559 - val_loss: 8.1028\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3742 - val_loss: 8.0406\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4703 - val_loss: 8.6211\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2212 - val_loss: 7.9429\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0947 - val_loss: 7.8656\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2107 - val_loss: 7.7832\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3225 - val_loss: 7.8169\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4026 - val_loss: 8.0750\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2317 - val_loss: 8.0420\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2233 - val_loss: 7.9917\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3167 - val_loss: 7.7743\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1376 - val_loss: 8.0870\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2604 - val_loss: 7.9827\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2545 - val_loss: 7.8249\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2595 - val_loss: 8.1577\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3310 - val_loss: 7.7382\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1415 - val_loss: 7.7613\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1172 - val_loss: 7.8278\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1818 - val_loss: 7.9356\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1875 - val_loss: 8.1189\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2379 - val_loss: 7.9947\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1318 - val_loss: 8.0178\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2191 - val_loss: 8.0342\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5568 - val_loss: 7.6536\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4086 - val_loss: 7.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2072 - val_loss: 7.8744\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1048 - val_loss: 8.0763\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2796 - val_loss: 8.0055\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0807 - val_loss: 7.8353\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1834 - val_loss: 7.9578\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3802 - val_loss: 8.3451\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0860 - val_loss: 7.8121\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1100 - val_loss: 8.0623\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2325 - val_loss: 7.7795\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2576 - val_loss: 7.8988\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0954 - val_loss: 7.9544\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0354 - val_loss: 7.7417\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1664 - val_loss: 7.8996\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9805 - val_loss: 7.7023\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1249 - val_loss: 7.7413\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3056 - val_loss: 7.9834\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0087 - val_loss: 7.9371\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0492 - val_loss: 7.9468\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1337 - val_loss: 7.8287\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1393 - val_loss: 7.8117\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1328 - val_loss: 8.0201\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0270 - val_loss: 7.8392\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9842 - val_loss: 7.7106\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2075 - val_loss: 7.8285\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1130 - val_loss: 8.1140\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1809 - val_loss: 7.7892\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0824 - val_loss: 7.9137\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1057 - val_loss: 7.8703\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0396 - val_loss: 7.9310\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0194 - val_loss: 7.6838\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1403 - val_loss: 8.1222\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1385 - val_loss: 7.7921\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9482 - val_loss: 7.8010\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0405 - val_loss: 7.8223\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1964 - val_loss: 7.8724\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2196 - val_loss: 7.7173\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0327 - val_loss: 7.7263\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9125 - val_loss: 7.7294\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8879 - val_loss: 7.9857\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0673 - val_loss: 7.9391\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1196 - val_loss: 8.0249\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3595 - val_loss: 7.6448\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1507 - val_loss: 8.0953\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1821 - val_loss: 7.9816\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8751 - val_loss: 7.6162\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8869 - val_loss: 7.5708\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4165 - val_loss: 8.2437\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0390 - val_loss: 7.8544\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8713 - val_loss: 8.0961\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0243 - val_loss: 7.9288\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9208 - val_loss: 8.0626\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0484 - val_loss: 7.7091\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8820 - val_loss: 7.9781\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8905 - val_loss: 7.7234\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8726 - val_loss: 7.9117\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8679 - val_loss: 8.0443\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1105 - val_loss: 7.7952\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3071 - val_loss: 7.6141\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2739 - val_loss: 8.4993\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2443 - val_loss: 7.9945\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8928 - val_loss: 7.8215\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8218 - val_loss: 7.7068\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8573 - val_loss: 7.9712\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8261 - val_loss: 8.0739\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8113 - val_loss: 7.9442\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9273 - val_loss: 7.8207\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9164 - val_loss: 7.7163\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8584 - val_loss: 7.7816\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7656 - val_loss: 7.8555\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8406 - val_loss: 7.7526\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8509 - val_loss: 7.9877\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7740 - val_loss: 8.0982\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8371 - val_loss: 7.9847\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9670 - val_loss: 7.9430\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1908 - val_loss: 7.9935\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0806 - val_loss: 7.6211\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9090 - val_loss: 8.0991\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 6.1168 - val_loss: 8.2193\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0787 - val_loss: 8.3154\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8342 - val_loss: 8.2222\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9213 - val_loss: 7.9646\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8907 - val_loss: 7.8828\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9021 - val_loss: 7.8356\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8501 - val_loss: 8.0634\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8761 - val_loss: 8.0175\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7228 - val_loss: 8.1889\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7906 - val_loss: 7.9107\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7776 - val_loss: 8.0025\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8936 - val_loss: 8.1534\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8521 - val_loss: 7.8662\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0092 - val_loss: 8.2138\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8355 - val_loss: 8.0914\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1651 - val_loss: 8.2088\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3664 - val_loss: 8.0977\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9185 - val_loss: 8.3222\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9510 - val_loss: 8.0738\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3247 - val_loss: 8.7105\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9717 - val_loss: 7.9247\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9945 - val_loss: 7.9351\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8659 - val_loss: 7.9648\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8875 - val_loss: 8.2346\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8019 - val_loss: 8.1706\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9025 - val_loss: 7.7292\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7322 - val_loss: 7.9366\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7294 - val_loss: 7.9686\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7685 - val_loss: 7.8453\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7265 - val_loss: 8.0326\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8288 - val_loss: 8.0558\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7023 - val_loss: 8.3746\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7017 - val_loss: 7.9061\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6851 - val_loss: 7.9721\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8152 - val_loss: 8.1074\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0538 - val_loss: 8.2446\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0861 - val_loss: 8.9558\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0026 - val_loss: 8.1964\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8705 - val_loss: 8.1448\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0447 - val_loss: 8.0022\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8786 - val_loss: 8.2852\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8330 - val_loss: 8.0417\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2449 - val_loss: 8.7164\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8186 - val_loss: 8.3315\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9034 - val_loss: 8.3650\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7304 - val_loss: 7.8304\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7622 - val_loss: 8.2353\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6835 - val_loss: 8.3361\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6440 - val_loss: 8.1777\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6978 - val_loss: 8.0300\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6165 - val_loss: 8.1679\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9627 - val_loss: 7.8711\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8868 - val_loss: 8.5847\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9811 - val_loss: 8.2417\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9761 - val_loss: 8.5112\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8526 - val_loss: 8.3360\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6962 - val_loss: 8.4420\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7030 - val_loss: 8.0823\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8098 - val_loss: 8.2607\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9413 - val_loss: 8.4163\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7984 - val_loss: 8.2351\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6519 - val_loss: 8.1055\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6836 - val_loss: 8.0897\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7611 - val_loss: 7.9068\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8283 - val_loss: 8.1228\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8058 - val_loss: 8.5016\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8042 - val_loss: 8.5200\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6608 - val_loss: 8.0586\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0409 - val_loss: 8.6209\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1166 - val_loss: 8.1034\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9571 - val_loss: 8.6100\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9124 - val_loss: 8.1415\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7272 - val_loss: 7.9129\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6737 - val_loss: 8.1168\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8293 - val_loss: 8.2457\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8100 - val_loss: 8.1637\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8564 - val_loss: 8.0726\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7238 - val_loss: 7.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6670 - val_loss: 8.3516\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7408 - val_loss: 8.3666\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6436 - val_loss: 8.2123\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7623 - val_loss: 7.9094\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7924 - val_loss: 8.0997\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7041 - val_loss: 8.2502\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6208 - val_loss: 7.9987\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5887 - val_loss: 8.0540\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6565 - val_loss: 8.3469\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5730 - val_loss: 8.3592\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6373 - val_loss: 8.0930\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7143 - val_loss: 8.1757\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7576 - val_loss: 8.4097\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7046 - val_loss: 8.3590\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6371 - val_loss: 8.5607\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6428 - val_loss: 8.0005\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6950 - val_loss: 8.2409\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8203 - val_loss: 8.3847\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6365 - val_loss: 8.4057\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6615 - val_loss: 8.2043\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7635 - val_loss: 8.3612\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9756 - val_loss: 8.3139\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6862 - val_loss: 8.7527\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8043 - val_loss: 8.0768\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6527 - val_loss: 8.2991\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6047 - val_loss: 8.1243\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6366 - val_loss: 7.9768\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6579 - val_loss: 8.1808\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6187 - val_loss: 8.1784\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6986 - val_loss: 8.4123\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6941 - val_loss: 8.4317\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6075 - val_loss: 8.2210\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5909 - val_loss: 8.2755\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6506 - val_loss: 8.3574\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7437 - val_loss: 8.3928\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7354 - val_loss: 8.1148\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7339 - val_loss: 8.2443\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6165 - val_loss: 8.3465\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7199 - val_loss: 8.7402\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9936 - val_loss: 8.2296\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6454 - val_loss: 8.1468\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6954 - val_loss: 8.4926\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8262 - val_loss: 8.2993\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5837 - val_loss: 8.2760\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6777 - val_loss: 8.6021\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7028 - val_loss: 8.1633\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7617 - val_loss: 7.9694\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6191 - val_loss: 8.4943\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6510 - val_loss: 8.1694\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8277 - val_loss: 8.7204\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0460 - val_loss: 8.5624\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6827 - val_loss: 8.6460\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9780 - val_loss: 8.1174\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6362 - val_loss: 8.6555\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9201 - val_loss: 8.1977\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6248 - val_loss: 8.5137\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7876 - val_loss: 8.2947\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9156 - val_loss: 8.6828\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7928 - val_loss: 8.2966\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6641 - val_loss: 8.4032\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5110 - val_loss: 8.3505\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5283 - val_loss: 8.3010\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6418 - val_loss: 8.2199\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6241 - val_loss: 8.3752\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7602 - val_loss: 8.4495\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5777 - val_loss: 8.2404\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5120 - val_loss: 8.1091\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5819 - val_loss: 8.3341\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4965 - val_loss: 8.2548\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6812 - val_loss: 8.6766\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5306 - val_loss: 8.2182\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7246 - val_loss: 8.4793\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2888 - val_loss: 8.3590\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9367 - val_loss: 9.1996\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9442 - val_loss: 8.5714\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6967 - val_loss: 8.2360\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6220 - val_loss: 8.3349\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.5705 - val_loss: 8.2380\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5761 - val_loss: 8.0074\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6238 - val_loss: 8.4022\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5123 - val_loss: 8.4083\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6858 - val_loss: 8.4764\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5600 - val_loss: 8.2915\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5982 - val_loss: 8.2425\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4872 - val_loss: 8.1379\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6000 - val_loss: 8.5975\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5673 - val_loss: 8.4817\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5340 - val_loss: 8.3452\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4589 - val_loss: 8.4302\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4906 - val_loss: 8.3302\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5481 - val_loss: 8.5499\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4849 - val_loss: 8.4569\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7004 - val_loss: 8.5955\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9660 - val_loss: 8.4719\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7096 - val_loss: 8.5767\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5396 - val_loss: 8.4121\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5998 - val_loss: 8.7622\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5191 - val_loss: 8.3946\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5565 - val_loss: 8.3022\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4756 - val_loss: 8.5611\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4623 - val_loss: 8.4236\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5184 - val_loss: 8.4542\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6106 - val_loss: 8.3708\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4768 - val_loss: 8.6542\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4434 - val_loss: 8.3360\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5483 - val_loss: 8.5082\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6033 - val_loss: 8.5356\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4508 - val_loss: 8.3570\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4569 - val_loss: 8.4932\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5562 - val_loss: 8.5667\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4557 - val_loss: 8.6355\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4479 - val_loss: 8.4443\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4876 - val_loss: 8.4030\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6710 - val_loss: 8.5703\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4328 - val_loss: 8.5638\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5312 - val_loss: 8.4635\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5266 - val_loss: 8.5966\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6510 - val_loss: 8.2310\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5399 - val_loss: 8.4877\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5795 - val_loss: 8.4726\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4669 - val_loss: 8.5339\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4344 - val_loss: 8.4678\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6024 - val_loss: 8.4573\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5589 - val_loss: 8.4133\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7785 - val_loss: 8.6290\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4718 - val_loss: 8.6009\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4327 - val_loss: 8.7204\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5232 - val_loss: 8.4728\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5388 - val_loss: 8.5703\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4463 - val_loss: 8.6631\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4594 - val_loss: 8.7324\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6115 - val_loss: 8.6617\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6278 - val_loss: 8.3145\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5556 - val_loss: 8.6272\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4408 - val_loss: 8.6491\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4548 - val_loss: 8.6798\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4265 - val_loss: 8.7498\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4740 - val_loss: 8.7187\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6709 - val_loss: 8.8493\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4322 - val_loss: 9.0965\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4286 - val_loss: 8.6956\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4374 - val_loss: 8.5190\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4344 - val_loss: 8.6639\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4571 - val_loss: 8.6473\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5115 - val_loss: 8.6072\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5614 - val_loss: 8.9153\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4806 - val_loss: 8.7516\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3621 - val_loss: 9.0165\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6397 - val_loss: 8.5529\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6998 - val_loss: 8.8726\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3618 - val_loss: 8.7665\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4363 - val_loss: 8.8237\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5059 - val_loss: 8.8983\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4576 - val_loss: 8.6802\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5345 - val_loss: 8.7548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5278 - val_loss: 8.9486\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5575 - val_loss: 9.1493\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6378 - val_loss: 8.7909\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4819 - val_loss: 8.8550\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8877 - val_loss: 8.5885\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3036 - val_loss: 9.0119\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5920 - val_loss: 8.7106\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4253 - val_loss: 8.8611\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3879 - val_loss: 8.9749\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3112 - val_loss: 8.7310\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3288 - val_loss: 8.7448\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4563 - val_loss: 8.6474\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4887 - val_loss: 8.9838\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2821 - val_loss: 8.9337\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4832 - val_loss: 8.8321\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5767 - val_loss: 8.7193\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7154 - val_loss: 8.6154\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4713 - val_loss: 8.8601\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3018 - val_loss: 8.9857\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3736 - val_loss: 8.9433\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3861 - val_loss: 8.5843\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3282 - val_loss: 8.7649\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5352 - val_loss: 8.6175\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3672 - val_loss: 9.0174\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3595 - val_loss: 8.9857\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4653 - val_loss: 9.0491\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4915 - val_loss: 8.9549\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5320 - val_loss: 9.1315\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4593 - val_loss: 8.9301\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3930 - val_loss: 9.1118\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3981 - val_loss: 8.7535\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7158 - val_loss: 9.1963\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7764 - val_loss: 8.7582\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4418 - val_loss: 9.0532\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3938 - val_loss: 8.8518\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4331 - val_loss: 9.0072\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4056 - val_loss: 9.1744\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4822 - val_loss: 8.6695\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3409 - val_loss: 8.7761\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3247 - val_loss: 9.3559\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3052 - val_loss: 8.9390\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5076 - val_loss: 9.0260\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4334 - val_loss: 9.0154\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.5118 - val_loss: 8.9230\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 5.5398 - val_loss: 9.0387\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4252 - val_loss: 8.9968\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3451 - val_loss: 9.0874\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2978 - val_loss: 9.1552\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3884 - val_loss: 8.9138\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3611 - val_loss: 8.9858\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2870 - val_loss: 8.7225\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3046 - val_loss: 8.9291\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2942 - val_loss: 9.2199\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3099 - val_loss: 9.1491\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3377 - val_loss: 8.9458\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4324 - val_loss: 9.1125\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5849 - val_loss: 8.9049\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4738 - val_loss: 9.1465\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5290 - val_loss: 8.9967\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7671 - val_loss: 9.2508\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8364 - val_loss: 9.1221\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7493 - val_loss: 9.5738\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5843 - val_loss: 8.9152\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4386 - val_loss: 8.9269\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4382 - val_loss: 9.2981\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4444 - val_loss: 9.1572\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3120 - val_loss: 8.9924\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2379 - val_loss: 9.1414\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3220 - val_loss: 9.1390\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3058 - val_loss: 8.9772\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3641 - val_loss: 8.9480\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3079 - val_loss: 9.2243\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2969 - val_loss: 9.3725\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3222 - val_loss: 9.0307\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3079 - val_loss: 9.1792\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2632 - val_loss: 9.0263\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3282 - val_loss: 9.3343\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.3284 - val_loss: 9.5046\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3727 - val_loss: 9.0895\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2902 - val_loss: 8.9537\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2881 - val_loss: 9.3233\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2401 - val_loss: 9.4030\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4045 - val_loss: 9.1006\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3033 - val_loss: 8.9323\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3095 - val_loss: 8.9390\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3336 - val_loss: 9.1711\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2409 - val_loss: 9.7528\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2834 - val_loss: 9.1664\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2446 - val_loss: 9.1925\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3613 - val_loss: 9.0002\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2844 - val_loss: 9.2402\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2839 - val_loss: 9.1299\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2536 - val_loss: 9.0923\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2086 - val_loss: 9.0705\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2179 - val_loss: 9.2249\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2180 - val_loss: 9.1254\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1910 - val_loss: 9.1572\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2566 - val_loss: 9.1087\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2112 - val_loss: 9.2376\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2558 - val_loss: 9.3599\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3386 - val_loss: 9.3921\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2981 - val_loss: 9.1332\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2966 - val_loss: 9.1634\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1469 - val_loss: 9.5517\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2972 - val_loss: 9.1613\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2697 - val_loss: 8.9792\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3548 - val_loss: 9.7011\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5928 - val_loss: 9.5416\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3911 - val_loss: 9.3616\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3434 - val_loss: 9.7491\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1975 - val_loss: 9.4067\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3051 - val_loss: 9.3947\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2496 - val_loss: 9.1433\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3148 - val_loss: 9.4003\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3821 - val_loss: 9.6076\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5012 - val_loss: 9.5012\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3457 - val_loss: 9.4499\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4542 - val_loss: 9.5503\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4464 - val_loss: 9.5130\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0973 - val_loss: 9.1298\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2985 - val_loss: 9.5122\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3861 - val_loss: 9.2622\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3777 - val_loss: 9.7371\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2347 - val_loss: 9.5784\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2692 - val_loss: 9.4665\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2730 - val_loss: 9.4991\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3189 - val_loss: 9.5473\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2527 - val_loss: 9.1191\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2710 - val_loss: 9.2058\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4250 - val_loss: 9.0075\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2496 - val_loss: 9.3081\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1934 - val_loss: 9.3502\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2555 - val_loss: 9.3149\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2495 - val_loss: 9.5910\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2291 - val_loss: 9.3030\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4566 - val_loss: 9.5865\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6532 - val_loss: 9.3244\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4584 - val_loss: 9.5599\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3887 - val_loss: 9.8214\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4937 - val_loss: 9.7866\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3276 - val_loss: 9.2103\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3620 - val_loss: 9.6274\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.2784 - val_loss: 9.5208\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 134us/step - loss: 5.2858 - val_loss: 9.4848\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3206 - val_loss: 9.2381\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3350 - val_loss: 9.6845\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2023 - val_loss: 9.4320\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3857 - val_loss: 10.1382\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4477 - val_loss: 9.3337\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3727 - val_loss: 9.9309\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2542 - val_loss: 9.1531\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3136 - val_loss: 9.6894\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4428 - val_loss: 9.3233\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3141 - val_loss: 9.5448\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2728 - val_loss: 9.8347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3275 - val_loss: 9.3015\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3195 - val_loss: 9.1878\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2662 - val_loss: 9.5126\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2031 - val_loss: 9.6267\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2043 - val_loss: 9.3937\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1557 - val_loss: 9.6063\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2253 - val_loss: 9.5117\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3595 - val_loss: 9.6661\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2755 - val_loss: 9.4968\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2249 - val_loss: 9.4654\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3044 - val_loss: 9.4244\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3435 - val_loss: 9.8107\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2225 - val_loss: 9.5673\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3490 - val_loss: 9.4030\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2129 - val_loss: 10.0155\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4132 - val_loss: 9.7133\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5783 - val_loss: 9.9162\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3781 - val_loss: 9.5489\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2314 - val_loss: 9.9825\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2634 - val_loss: 9.4789\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1598 - val_loss: 9.7935\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3607 - val_loss: 9.8238\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6704 - val_loss: 9.9518\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6699 - val_loss: 9.7653\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5452 - val_loss: 9.7398\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4991 - val_loss: 9.4468\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2367 - val_loss: 9.2621\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1812 - val_loss: 9.6629\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2567 - val_loss: 9.9613\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2047 - val_loss: 9.5646\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3753 - val_loss: 9.6898\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2775 - val_loss: 9.4602\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6676 - val_loss: 9.9307\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2764 - val_loss: 9.7263\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2678 - val_loss: 9.6453\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2321 - val_loss: 9.2851\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4926 - val_loss: 9.7046\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3454 - val_loss: 9.6525\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1366 - val_loss: 9.5670\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1668 - val_loss: 9.3738\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2101 - val_loss: 9.6876\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3788 - val_loss: 9.3461\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3312 - val_loss: 9.4574\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2398 - val_loss: 9.9236\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1648 - val_loss: 9.4730\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2019 - val_loss: 9.5506\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2414 - val_loss: 9.8369\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1782 - val_loss: 10.0885\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2071 - val_loss: 9.5953\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0877 - val_loss: 9.6415\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1486 - val_loss: 9.6097\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2203 - val_loss: 9.8362\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1295 - val_loss: 9.8857\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2285 - val_loss: 9.6356\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2895 - val_loss: 9.5450\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2762 - val_loss: 9.8856\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5922 - val_loss: 9.9635\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4617 - val_loss: 9.9188\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5141 - val_loss: 9.6365\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3870 - val_loss: 9.8068\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.1923 - val_loss: 9.7918\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1655 - val_loss: 9.6086\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2524 - val_loss: 9.4064\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1944 - val_loss: 9.6274\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1374 - val_loss: 9.9913\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2225 - val_loss: 9.6562\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1356 - val_loss: 9.7944\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2853 - val_loss: 9.9415\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2092 - val_loss: 9.6776\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1040 - val_loss: 9.4317\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2760 - val_loss: 9.7347\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2996 - val_loss: 9.5717\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4000 - val_loss: 10.0652\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3387 - val_loss: 9.9125\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2337 - val_loss: 9.6243\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2258 - val_loss: 9.8302\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2368 - val_loss: 9.8490\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2855 - val_loss: 9.9603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4265 - val_loss: 9.5495\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1100 - val_loss: 9.9151\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4694 - val_loss: 9.9184\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2155 - val_loss: 10.0334\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2865 - val_loss: 9.5874\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2525 - val_loss: 10.0206\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2908 - val_loss: 9.7787\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2796 - val_loss: 9.3888\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0993 - val_loss: 9.8683\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9742 - val_loss: 10.0793\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9590 - val_loss: 10.0507\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3379 - val_loss: 9.7353\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1410 - val_loss: 9.7126\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1304 - val_loss: 9.7121\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1191 - val_loss: 9.7872\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1362 - val_loss: 9.8831\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1587 - val_loss: 9.8300\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2035 - val_loss: 10.0530\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1639 - val_loss: 9.6421\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4327 - val_loss: 9.5961\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3366 - val_loss: 9.6588\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6653 - val_loss: 10.0740\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3319 - val_loss: 10.1434\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2741 - val_loss: 9.7184\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4129 - val_loss: 9.9829\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1985 - val_loss: 9.8478\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2064 - val_loss: 9.7332\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1796 - val_loss: 9.6670\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1270 - val_loss: 9.7106\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2115 - val_loss: 9.8600\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0712 - val_loss: 9.6588\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1763 - val_loss: 9.9542\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2767 - val_loss: 9.6574\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2063 - val_loss: 9.7450\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3147 - val_loss: 9.8495\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3343 - val_loss: 10.1418\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5255 - val_loss: 9.7759\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1967 - val_loss: 9.8711\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1711 - val_loss: 10.0541\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2203 - val_loss: 10.2378\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4427 - val_loss: 9.6526\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1458 - val_loss: 10.0624\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1583 - val_loss: 10.0839\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2158 - val_loss: 9.7555\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1811 - val_loss: 10.0202\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1691 - val_loss: 9.8794\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4102 - val_loss: 9.8777\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4150 - val_loss: 9.6618\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2911 - val_loss: 9.9263\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2899 - val_loss: 9.9941\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3608 - val_loss: 10.0429\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6061 - val_loss: 10.1603\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4031 - val_loss: 10.0530\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2325 - val_loss: 9.6931\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1764 - val_loss: 9.5932\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3839 - val_loss: 9.7808\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1274 - val_loss: 10.1347\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2721 - val_loss: 9.9057\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1866 - val_loss: 9.6994\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2740 - val_loss: 9.6114\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1917 - val_loss: 9.8729\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1157 - val_loss: 9.8391\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2025 - val_loss: 9.6803\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1089 - val_loss: 9.8148\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2183 - val_loss: 9.7165\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1416 - val_loss: 9.6947\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2915 - val_loss: 9.7652\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2640 - val_loss: 9.9994\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1406 - val_loss: 9.6098\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2707 - val_loss: 9.7162\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3563 - val_loss: 9.7931\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1912 - val_loss: 9.7867\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2341 - val_loss: 9.5619\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0662 - val_loss: 9.8781\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1187 - val_loss: 9.6500\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0756 - val_loss: 9.8166\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1627 - val_loss: 10.2224\n",
      "Epoch 920/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.1467 - val_loss: 9.9451\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2085 - val_loss: 9.8813\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1522 - val_loss: 10.0259\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2232 - val_loss: 9.7123\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1684 - val_loss: 9.9124\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2442 - val_loss: 10.0356\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1019 - val_loss: 9.8395\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1978 - val_loss: 10.0681\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2487 - val_loss: 9.8328\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2017 - val_loss: 9.9637\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3371 - val_loss: 9.7599\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1057 - val_loss: 10.3563\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1380 - val_loss: 9.9482\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4205 - val_loss: 9.9322\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2145 - val_loss: 9.9527\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1525 - val_loss: 9.7393\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0828 - val_loss: 9.9062\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1556 - val_loss: 9.9806\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1052 - val_loss: 10.2794\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0815 - val_loss: 9.8282\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1499 - val_loss: 9.6003\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1510 - val_loss: 9.9863\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4490 - val_loss: 10.2280\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3037 - val_loss: 9.5291\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3680 - val_loss: 9.8402\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4596 - val_loss: 10.4759\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3237 - val_loss: 10.2155\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6213 - val_loss: 9.8658\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1616 - val_loss: 9.9738\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6188 - val_loss: 9.9558\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5599 - val_loss: 10.0933\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7762 - val_loss: 10.0922\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5399 - val_loss: 9.6129\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3012 - val_loss: 10.1219\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1633 - val_loss: 10.2547\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.3334 - val_loss: 9.9339\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.2483 - val_loss: 10.1956\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2325 - val_loss: 9.9504\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1684 - val_loss: 9.9698\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1119 - val_loss: 9.7123\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1290 - val_loss: 9.9191\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1641 - val_loss: 10.0615\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2307 - val_loss: 9.9690\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1698 - val_loss: 9.8838\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2415 - val_loss: 10.1832\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3021 - val_loss: 9.9842\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2328 - val_loss: 10.1631\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1920 - val_loss: 9.8472\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1744 - val_loss: 10.0137\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1978 - val_loss: 9.9875\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1414 - val_loss: 10.3316\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1763 - val_loss: 9.9045\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.0914 - val_loss: 9.7988\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1163 - val_loss: 9.8126\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1374 - val_loss: 9.9854\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2659 - val_loss: 10.2615\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2770 - val_loss: 10.0877\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3873 - val_loss: 10.0814\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2768 - val_loss: 9.9180\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3808 - val_loss: 10.6486\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0560 - val_loss: 10.3491\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4909 - val_loss: 10.1542\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6436 - val_loss: 9.9028\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3571 - val_loss: 10.8421\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5562 - val_loss: 10.1296\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2850 - val_loss: 9.9077\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5817 - val_loss: 9.7881\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2593 - val_loss: 10.1659\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2501 - val_loss: 9.8752\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2340 - val_loss: 10.0808\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2042 - val_loss: 10.2203\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0648 - val_loss: 9.9868\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.1183 - val_loss: 9.7235\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1538 - val_loss: 9.9521\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1012 - val_loss: 10.0821\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4163 - val_loss: 9.9670\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1846 - val_loss: 9.9935\n",
      "Epoch 997/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 5.1418 - val_loss: 9.9105\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1294 - val_loss: 9.9781\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1873 - val_loss: 10.3142\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3992 - val_loss: 10.0916\n",
      "10.884357492802506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.7288758 , -0.06541843,  0.58632547, -1.3629136 ,  0.46422407],\n",
       "        [ 2.3081396 ,  0.7881358 , -0.62912446, -1.2251635 ,  0.19705184],\n",
       "        [-0.501008  , -0.4680923 , -0.9469238 ,  0.3474041 , -0.12078792],\n",
       "        [-2.3030055 , -1.2931288 ,  0.1704122 ,  1.382648  ,  0.05134116],\n",
       "        [ 0.12318213,  0.22270057,  0.3667293 , -0.13824373,  0.64969444],\n",
       "        [-2.633094  ,  0.81835854,  0.06489894,  2.4211962 ,  0.61502564],\n",
       "        [-0.82157815,  0.2703321 , -2.1007023 ,  1.9908931 , -2.7727017 ]],\n",
       "       dtype=float32),\n",
       " array([-1.3600553 , -1.4318937 , -0.59196126,  2.2808192 , -1.9100335 ],\n",
       "       dtype=float32),\n",
       " array([[-0.353239  ,  0.58053946, -0.7805671 , -0.58372176,  0.28919235,\n",
       "          0.21245453, -0.07810632, -0.36836976,  0.7225775 , -0.20783734,\n",
       "          0.25532198,  0.14420606,  0.7811201 , -0.7235585 , -0.18971212],\n",
       "        [-0.2553936 ,  0.92786413, -0.40111747, -0.9749811 , -0.6000833 ,\n",
       "          0.2306046 , -0.3255578 , -0.36380255,  0.45587474,  0.5368976 ,\n",
       "          0.7599177 , -0.8302978 ,  0.66948336, -0.4158258 , -0.57370424],\n",
       "        [-0.2835931 , -0.15060855, -0.15433389, -0.15128627, -0.16361375,\n",
       "          0.6865891 , -0.48795542,  0.2470644 ,  0.53268194,  0.0965841 ,\n",
       "         -0.04025728, -0.28887686,  0.39407736, -0.25765526, -0.69601464],\n",
       "        [-0.43406036,  0.14998972, -0.8619269 , -0.6654006 ,  0.10511695,\n",
       "          0.65835416, -0.13459523, -0.4402481 ,  0.52659476,  0.7139352 ,\n",
       "          0.6193119 ,  0.04634136,  0.92296255, -0.4259656 , -0.86296666],\n",
       "        [ 0.15469883, -0.20886509,  0.46004623,  0.427731  ,  0.54424447,\n",
       "         -0.65088004,  0.11305516,  0.28128773, -0.20055918, -0.06023018,\n",
       "         -0.73357636,  0.51515204, -0.05606276,  0.5229809 ,  0.42753214]],\n",
       "       dtype=float32),\n",
       " array([-1.5028005,  1.3389317, -1.5312612, -1.5650913, -1.5059997,\n",
       "         1.5109783, -1.4929973, -1.5051312,  1.5143471,  1.549428 ,\n",
       "         1.557635 , -1.5309218,  1.5509982, -1.4644856, -1.5305965],\n",
       "       dtype=float32),\n",
       " array([[-1.0179863 ],\n",
       "        [ 0.51664335],\n",
       "        [-1.1524128 ],\n",
       "        [-1.0806129 ],\n",
       "        [-0.9799474 ],\n",
       "        [ 1.1031556 ],\n",
       "        [-0.8836304 ],\n",
       "        [-0.84131813],\n",
       "        [ 0.9892655 ],\n",
       "        [ 1.2902608 ],\n",
       "        [ 1.1802372 ],\n",
       "        [-1.0288284 ],\n",
       "        [ 1.28132   ],\n",
       "        [-0.6997631 ],\n",
       "        [-1.1366143 ]], dtype=float32),\n",
       " array([1.5761083], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_3(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure3_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 976us/step - loss: 487.5792 - val_loss: 269.0505\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 130.3600 - val_loss: 108.8329\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 64.0872 - val_loss: 40.1041\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 29.7220 - val_loss: 21.9029\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 17.5885 - val_loss: 21.0870\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 16.4608 - val_loss: 20.4587\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 13.4995 - val_loss: 17.7018\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 11.4539 - val_loss: 16.6077\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 10.6430 - val_loss: 15.1764\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.0561 - val_loss: 14.3627\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.8370 - val_loss: 13.8949\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.4125 - val_loss: 13.2160\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.6234 - val_loss: 12.8431\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.1815 - val_loss: 12.6181\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.7007 - val_loss: 12.6131\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.4971 - val_loss: 12.1255\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 8.3909 - val_loss: 11.9263\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 8.2251 - val_loss: 11.7468\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1519 - val_loss: 11.5239\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.8938 - val_loss: 11.3989\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8191 - val_loss: 11.2498\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7820 - val_loss: 11.2603\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.7105 - val_loss: 11.2102\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4986 - val_loss: 10.9725\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5015 - val_loss: 10.8406\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3508 - val_loss: 10.6666\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4743 - val_loss: 10.6933\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2442 - val_loss: 10.5854\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2078 - val_loss: 10.5412\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 7.1893 - val_loss: 10.6154\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.3111 - val_loss: 10.6298\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1532 - val_loss: 10.2959\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0985 - val_loss: 10.3956\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0051 - val_loss: 10.3123\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8871 - val_loss: 10.1114\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9266 - val_loss: 10.0766\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0517 - val_loss: 10.0632\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9794 - val_loss: 10.3019\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9114 - val_loss: 10.2831\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8122 - val_loss: 10.2127\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8259 - val_loss: 10.1964\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8095 - val_loss: 9.9014\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8970 - val_loss: 10.0394\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.7030 - val_loss: 10.1513\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7022 - val_loss: 10.0676\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.6953 - val_loss: 9.9701\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7247 - val_loss: 10.1301\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.8795 - val_loss: 10.1986\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6275 - val_loss: 10.0475\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5675 - val_loss: 9.9863\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5490 - val_loss: 9.7673\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5638 - val_loss: 9.8785\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5482 - val_loss: 9.8167\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5388 - val_loss: 10.0358\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4646 - val_loss: 9.8662\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5543 - val_loss: 9.7349\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4308 - val_loss: 9.8976\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4223 - val_loss: 9.6622\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4929 - val_loss: 9.8769\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6097 - val_loss: 9.7707\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7240 - val_loss: 10.0750\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5608 - val_loss: 9.6828\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3804 - val_loss: 9.4441\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3816 - val_loss: 9.6871\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3225 - val_loss: 9.9843\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2895 - val_loss: 9.7179\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.2691 - val_loss: 10.0026\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.3066 - val_loss: 9.5577\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3241 - val_loss: 9.5614\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.2047 - val_loss: 9.7732\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.1666 - val_loss: 9.7533\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3051 - val_loss: 9.5290\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2375 - val_loss: 9.6345\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3248 - val_loss: 9.6517\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3773 - val_loss: 9.5608\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1532 - val_loss: 9.6632\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1967 - val_loss: 9.5425\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0779 - val_loss: 9.8585\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1056 - val_loss: 9.3153\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0236 - val_loss: 9.5387\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1706 - val_loss: 9.5310\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2224 - val_loss: 9.7124\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0841 - val_loss: 9.4605\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0355 - val_loss: 9.1715\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0931 - val_loss: 9.5331\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3121 - val_loss: 9.7725\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0870 - val_loss: 9.3904\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0333 - val_loss: 9.2509\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0592 - val_loss: 9.5131\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9656 - val_loss: 9.7097\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9520 - val_loss: 9.3330\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0748 - val_loss: 9.7751\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0339 - val_loss: 9.2471\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9632 - val_loss: 9.3421\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1374 - val_loss: 9.4132\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0059 - val_loss: 9.3198\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9498 - val_loss: 9.1082\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9893 - val_loss: 9.5823\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9240 - val_loss: 9.2634\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8962 - val_loss: 9.4510\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9395 - val_loss: 9.2319\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8385 - val_loss: 9.3812\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7792 - val_loss: 9.2665\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.8397 - val_loss: 9.3864\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8398 - val_loss: 9.5219\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7281 - val_loss: 9.1667\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7891 - val_loss: 9.5248\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8452 - val_loss: 9.0023\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8303 - val_loss: 9.1257\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9601 - val_loss: 9.1915\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7121 - val_loss: 9.3386\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7808 - val_loss: 9.4363\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8665 - val_loss: 9.5819\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8333 - val_loss: 9.3693\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8515 - val_loss: 9.4067\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.7181 - val_loss: 9.0181\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7004 - val_loss: 9.0691\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7013 - val_loss: 9.0997\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6438 - val_loss: 9.1540\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6124 - val_loss: 9.5775\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7400 - val_loss: 9.3647\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1545 - val_loss: 9.4343\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9674 - val_loss: 10.5382\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0959 - val_loss: 9.0453\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7615 - val_loss: 9.4696\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8243 - val_loss: 9.0585\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6811 - val_loss: 9.0998\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7840 - val_loss: 9.2187\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7027 - val_loss: 9.3097\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6471 - val_loss: 9.1038\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5933 - val_loss: 9.0396\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6560 - val_loss: 9.2832\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6197 - val_loss: 9.0619\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6528 - val_loss: 8.9202\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6024 - val_loss: 8.8499\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5449 - val_loss: 9.4617\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6244 - val_loss: 9.1637\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7328 - val_loss: 8.8113\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7924 - val_loss: 8.8379\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6490 - val_loss: 8.9248\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5504 - val_loss: 8.9555\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4983 - val_loss: 8.7998\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4600 - val_loss: 9.0778\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5596 - val_loss: 9.1327\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5692 - val_loss: 9.5710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7645 - val_loss: 9.1362\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5174 - val_loss: 9.0472\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6037 - val_loss: 8.9477\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5002 - val_loss: 8.9693\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4589 - val_loss: 9.0145\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4829 - val_loss: 9.1011\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4194 - val_loss: 8.9208\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4746 - val_loss: 8.6929\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3967 - val_loss: 8.7569\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4684 - val_loss: 8.9580\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.5511 - val_loss: 9.3166\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5300 - val_loss: 9.0112\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4764 - val_loss: 8.5949\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4885 - val_loss: 9.0487\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6879 - val_loss: 9.3754\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.2859 - val_loss: 9.7171\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6934 - val_loss: 9.0309\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4587 - val_loss: 9.4861\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4914 - val_loss: 8.7842\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4060 - val_loss: 8.9704\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4990 - val_loss: 9.1648\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5740 - val_loss: 8.7649\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6597 - val_loss: 9.4834\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5246 - val_loss: 9.0307\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3490 - val_loss: 9.0757\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2945 - val_loss: 9.0410\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4773 - val_loss: 9.3006\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4323 - val_loss: 9.5605\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6896 - val_loss: 9.0346\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8313 - val_loss: 9.2566\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7600 - val_loss: 9.0913\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7265 - val_loss: 9.1556\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3572 - val_loss: 9.0555\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.5647 - val_loss: 9.4656\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5706 - val_loss: 9.1668\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3061 - val_loss: 8.8919\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2975 - val_loss: 8.5211\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4399 - val_loss: 8.8464\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3733 - val_loss: 9.1413\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4751 - val_loss: 8.7471\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3465 - val_loss: 8.9755\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3119 - val_loss: 8.8445\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3239 - val_loss: 9.0511\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2834 - val_loss: 8.7468\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2078 - val_loss: 8.9598\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2978 - val_loss: 9.0130\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2838 - val_loss: 9.0229\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2809 - val_loss: 9.1318\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2634 - val_loss: 8.6236\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2481 - val_loss: 8.6655\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2693 - val_loss: 8.8611\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2442 - val_loss: 9.3029\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3465 - val_loss: 8.8292\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2310 - val_loss: 8.9023\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2059 - val_loss: 8.8100\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2487 - val_loss: 8.9319\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7149 - val_loss: 8.7732\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2311 - val_loss: 10.0980\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5648 - val_loss: 8.4156\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6260 - val_loss: 9.7249\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6866 - val_loss: 9.0430\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4737 - val_loss: 9.4500\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5253 - val_loss: 8.8618\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.1473 - val_loss: 9.2756\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3722 - val_loss: 9.4080\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5171 - val_loss: 9.1901\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2368 - val_loss: 9.0392\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1830 - val_loss: 8.6735\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2068 - val_loss: 8.7925\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2433 - val_loss: 8.7186\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2364 - val_loss: 9.1970\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6510 - val_loss: 9.1532\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2798 - val_loss: 8.6272\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3883 - val_loss: 8.9551\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1754 - val_loss: 8.8206\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2933 - val_loss: 9.3726\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2904 - val_loss: 9.0278\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.5197 - val_loss: 8.9674\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3732 - val_loss: 8.7299\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1179 - val_loss: 8.8994\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1038 - val_loss: 8.6563\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1480 - val_loss: 8.4371\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2229 - val_loss: 8.7720\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1745 - val_loss: 8.9798\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1273 - val_loss: 8.9683\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1338 - val_loss: 8.9089\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2571 - val_loss: 9.0817\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2135 - val_loss: 9.1280\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2629 - val_loss: 9.1422\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1430 - val_loss: 8.5730\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2163 - val_loss: 8.7217\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2903 - val_loss: 8.8823\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2070 - val_loss: 8.9082\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3321 - val_loss: 8.9047\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4308 - val_loss: 8.9314\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7884 - val_loss: 9.2669\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2534 - val_loss: 8.7537\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0928 - val_loss: 9.0144\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2373 - val_loss: 9.0018\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1690 - val_loss: 8.8013\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2658 - val_loss: 9.5097\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2596 - val_loss: 8.7164\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0869 - val_loss: 9.0295\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1742 - val_loss: 8.5973\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0532 - val_loss: 8.8934\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0309 - val_loss: 9.0819\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0322 - val_loss: 8.8870\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0990 - val_loss: 8.5133\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2411 - val_loss: 9.0236\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.0597 - val_loss: 8.6061\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0304 - val_loss: 8.8725\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9671 - val_loss: 8.8023\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9621 - val_loss: 8.7579\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9843 - val_loss: 8.9664\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3786 - val_loss: 8.9236\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7815 - val_loss: 9.8881\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3309 - val_loss: 9.3835\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4643 - val_loss: 9.2961\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1088 - val_loss: 8.5792\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1178 - val_loss: 8.7188\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1330 - val_loss: 8.8637\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0671 - val_loss: 8.8565\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9649 - val_loss: 8.9798\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4484 - val_loss: 9.7362\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2408 - val_loss: 9.3949\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1616 - val_loss: 9.5604\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0410 - val_loss: 8.4943\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0069 - val_loss: 8.8726\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0449 - val_loss: 8.9153\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1615 - val_loss: 9.6540\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9855 - val_loss: 8.7944\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0429 - val_loss: 9.4149\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9007 - val_loss: 8.4592\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9172 - val_loss: 8.8656\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9133 - val_loss: 9.2353\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0283 - val_loss: 9.6733\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1084 - val_loss: 9.0797\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9022 - val_loss: 8.7526\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9109 - val_loss: 9.1423\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9218 - val_loss: 8.9535\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8734 - val_loss: 9.4015\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2467 - val_loss: 8.9461\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2162 - val_loss: 8.9562\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1297 - val_loss: 9.6829\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0760 - val_loss: 9.1588\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9496 - val_loss: 9.7673\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7460 - val_loss: 8.8389\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4088 - val_loss: 9.1506\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0320 - val_loss: 8.9319\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1648 - val_loss: 9.3061\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8036 - val_loss: 9.3786\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0430 - val_loss: 9.4387\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0082 - val_loss: 9.4922\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9088 - val_loss: 8.8157\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 100us/step - loss: 4.9262 - val_loss: 8.9350\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9267 - val_loss: 9.0072\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9683 - val_loss: 8.8173\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0436 - val_loss: 9.3240\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0148 - val_loss: 9.2214\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1040 - val_loss: 9.1447\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8886 - val_loss: 8.9561\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0117 - val_loss: 8.7861\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8013 - val_loss: 8.7728\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9384 - val_loss: 8.7857\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0016 - val_loss: 9.6547\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3067 - val_loss: 9.4768\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1659 - val_loss: 9.5530\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9779 - val_loss: 8.4460\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8766 - val_loss: 8.7793\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8232 - val_loss: 8.4122\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7921 - val_loss: 8.5885\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7817 - val_loss: 9.0693\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9057 - val_loss: 8.8740\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8723 - val_loss: 9.2453\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9205 - val_loss: 8.8990\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.7860 - val_loss: 8.8436\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8472 - val_loss: 8.3407\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7742 - val_loss: 9.0585\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8009 - val_loss: 8.8394\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7797 - val_loss: 9.0108\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7445 - val_loss: 8.8877\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9147 - val_loss: 9.0045\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7838 - val_loss: 8.7197\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9021 - val_loss: 9.1239\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9545 - val_loss: 9.0727\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0986 - val_loss: 9.2481\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3148 - val_loss: 9.9839\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7828 - val_loss: 9.0690\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8525 - val_loss: 9.9313\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9985 - val_loss: 8.7598\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8562 - val_loss: 8.9703\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9143 - val_loss: 8.8160\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8699 - val_loss: 8.5849\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8105 - val_loss: 8.8780\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8188 - val_loss: 9.0965\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0268 - val_loss: 9.3441\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9726 - val_loss: 9.0081\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1352 - val_loss: 9.4896\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5832 - val_loss: 9.2576\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6806 - val_loss: 10.0945\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6443 - val_loss: 9.4033\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9946 - val_loss: 9.0289\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7913 - val_loss: 9.0603\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7271 - val_loss: 8.7744\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7994 - val_loss: 8.6957\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7868 - val_loss: 8.7991\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8634 - val_loss: 9.1638\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7163 - val_loss: 9.0946\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.7694 - val_loss: 9.1112\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1017 - val_loss: 9.0185\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2117 - val_loss: 9.2013\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6395 - val_loss: 8.8641\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7871 - val_loss: 9.0530\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7760 - val_loss: 8.9976\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.0152 - val_loss: 9.4060\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0368 - val_loss: 9.5436\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6739 - val_loss: 8.8569\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.8042 - val_loss: 8.7828\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7297 - val_loss: 8.9024\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6812 - val_loss: 9.1489\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7207 - val_loss: 8.8731\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7023 - val_loss: 9.3825\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7794 - val_loss: 8.9377\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7510 - val_loss: 8.8397\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7864 - val_loss: 8.9509\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7199 - val_loss: 8.7053\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6620 - val_loss: 8.8323\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6910 - val_loss: 9.0897\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 4.6437 - val_loss: 9.2581\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5620 - val_loss: 8.9180\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6666 - val_loss: 8.8458\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.5974 - val_loss: 8.9739\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5428 - val_loss: 9.2560\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6227 - val_loss: 8.9561\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6195 - val_loss: 9.0406\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6663 - val_loss: 9.0186\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7080 - val_loss: 9.3993\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0353 - val_loss: 9.2741\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8904 - val_loss: 9.1765\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5945 - val_loss: 8.6589\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7455 - val_loss: 9.1864\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6628 - val_loss: 9.2088\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5047 - val_loss: 9.1932\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5667 - val_loss: 8.7425\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5599 - val_loss: 8.5652\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6846 - val_loss: 9.2507\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8868 - val_loss: 8.7730\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6436 - val_loss: 9.0649\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9479 - val_loss: 9.2041\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6426 - val_loss: 8.7439\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7206 - val_loss: 9.1702\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.5112 - val_loss: 8.6230\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4898 - val_loss: 9.0028\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.4961 - val_loss: 8.9146\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5114 - val_loss: 9.1423\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5450 - val_loss: 8.8041\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6284 - val_loss: 9.2160\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7215 - val_loss: 8.9827\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6035 - val_loss: 9.1460\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5996 - val_loss: 8.9185\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6380 - val_loss: 8.4465\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5348 - val_loss: 8.5753\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5277 - val_loss: 9.1141\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5654 - val_loss: 8.7290\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6309 - val_loss: 8.8682\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5911 - val_loss: 8.9679\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8412 - val_loss: 8.6318\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5211 - val_loss: 9.0161\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4887 - val_loss: 8.7714\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4625 - val_loss: 8.7890\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5314 - val_loss: 8.7622\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4102 - val_loss: 8.7643\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4823 - val_loss: 8.9627\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5002 - val_loss: 9.0895\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.6122 - val_loss: 8.3566\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7529 - val_loss: 9.2953\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4228 - val_loss: 8.9269\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4270 - val_loss: 9.3435\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5646 - val_loss: 8.3040\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3929 - val_loss: 8.9037\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3635 - val_loss: 8.7754\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.3407 - val_loss: 8.7938\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4387 - val_loss: 8.6985\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4403 - val_loss: 8.8059\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5241 - val_loss: 9.2895\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7302 - val_loss: 8.5276\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7447 - val_loss: 8.6142\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5568 - val_loss: 8.5448\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.4499 - val_loss: 8.5375\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5213 - val_loss: 8.6254\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4575 - val_loss: 9.4027\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8566 - val_loss: 8.7267\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5872 - val_loss: 9.4218\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3569 - val_loss: 8.6759\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5402 - val_loss: 9.5050\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6921 - val_loss: 8.5547\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5781 - val_loss: 8.5087\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5679 - val_loss: 8.9067\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5003 - val_loss: 8.4724\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3287 - val_loss: 8.8646\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4031 - val_loss: 8.8725\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4218 - val_loss: 8.5979\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6538 - val_loss: 8.4080\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5419 - val_loss: 8.7566\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3216 - val_loss: 8.4568\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2354 - val_loss: 8.5458\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5977 - val_loss: 8.6776\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6004 - val_loss: 8.9226\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.2952 - val_loss: 8.5367\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4575 - val_loss: 8.3635\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3405 - val_loss: 8.1991\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3643 - val_loss: 8.7891\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4301 - val_loss: 8.8048\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4696 - val_loss: 9.1344\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5717 - val_loss: 8.4968\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4001 - val_loss: 8.4679\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2338 - val_loss: 7.9979\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 171us/step - loss: 4.2338 - val_loss: 8.4453\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 164us/step - loss: 4.2673 - val_loss: 8.6194\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.1930 - val_loss: 8.2988\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 4.2322 - val_loss: 8.2566\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4464 - val_loss: 8.7961\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3473 - val_loss: 8.4167\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1946 - val_loss: 8.2790\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.4427 - val_loss: 8.0025\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3577 - val_loss: 8.4166\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3101 - val_loss: 8.0158\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4283 - val_loss: 8.6215\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5593 - val_loss: 8.3303\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6278 - val_loss: 8.8043\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3780 - val_loss: 8.5210\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5922 - val_loss: 8.6077\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3506 - val_loss: 8.4777\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2958 - val_loss: 8.4967\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1938 - val_loss: 7.9800\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4614 - val_loss: 7.7014\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6561 - val_loss: 9.0816\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3112 - val_loss: 8.3751\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3334 - val_loss: 8.3925\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0593 - val_loss: 8.0881\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1969 - val_loss: 8.9396\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5437 - val_loss: 8.1642\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2035 - val_loss: 8.1659\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1157 - val_loss: 8.2210\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1010 - val_loss: 8.5838\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1794 - val_loss: 8.3502\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1613 - val_loss: 8.6966\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2659 - val_loss: 8.0269\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3495 - val_loss: 9.3192\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4510 - val_loss: 8.1871\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2349 - val_loss: 7.7907\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1488 - val_loss: 8.0996\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1063 - val_loss: 8.1552\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3171 - val_loss: 8.6344\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1603 - val_loss: 8.2608\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2981 - val_loss: 8.8616\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5284 - val_loss: 8.2745\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5773 - val_loss: 9.0143\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2953 - val_loss: 7.9586\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1288 - val_loss: 8.4239\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1702 - val_loss: 8.0302\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0050 - val_loss: 7.9739\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0602 - val_loss: 8.1555\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3400 - val_loss: 8.2144\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2994 - val_loss: 7.8098\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0898 - val_loss: 8.0675\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2929 - val_loss: 8.0576\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0667 - val_loss: 8.0513\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0336 - val_loss: 7.9526\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0836 - val_loss: 7.8239\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0404 - val_loss: 8.0544\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1212 - val_loss: 7.7532\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1061 - val_loss: 7.9856\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1323 - val_loss: 8.0334\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2036 - val_loss: 8.3101\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0390 - val_loss: 7.8436\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0105 - val_loss: 8.0945\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0041 - val_loss: 7.8707\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0543 - val_loss: 7.9129\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1157 - val_loss: 7.6923\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1956 - val_loss: 8.6019\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1986 - val_loss: 7.9907\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1016 - val_loss: 8.0787\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1771 - val_loss: 8.2682\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3206 - val_loss: 8.4422\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6035 - val_loss: 9.6945\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.8571 - val_loss: 7.9597\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1584 - val_loss: 7.9479\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1905 - val_loss: 8.0375\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1316 - val_loss: 8.1829\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1821 - val_loss: 8.9372\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3833 - val_loss: 7.9787\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0450 - val_loss: 8.0093\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3003 - val_loss: 8.1084\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9728 - val_loss: 7.8010\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9590 - val_loss: 7.9487\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0801 - val_loss: 7.8699\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1853 - val_loss: 8.7133\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2847 - val_loss: 8.0482\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9877 - val_loss: 7.8491\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1145 - val_loss: 7.5155\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4175 - val_loss: 7.7756\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0205 - val_loss: 8.1237\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9793 - val_loss: 7.9173\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9821 - val_loss: 8.1351\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0975 - val_loss: 7.8819\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1594 - val_loss: 7.7204\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.3439 - val_loss: 7.7474\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.9661 - val_loss: 8.1316\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0978 - val_loss: 7.9324\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1225 - val_loss: 8.2848\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9260 - val_loss: 7.8167\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9542 - val_loss: 7.8776\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9339 - val_loss: 7.7801\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9993 - val_loss: 7.8837\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9869 - val_loss: 7.9306\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9820 - val_loss: 7.7131\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0241 - val_loss: 8.0464\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0618 - val_loss: 7.9720\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0202 - val_loss: 8.5131\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2519 - val_loss: 7.9769\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4036 - val_loss: 9.3216\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1150 - val_loss: 7.9356\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0361 - val_loss: 9.2078\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3005 - val_loss: 7.6451\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8402 - val_loss: 8.3125\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0326 - val_loss: 7.4513\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0012 - val_loss: 7.6162\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9427 - val_loss: 7.7283\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3134 - val_loss: 7.7356\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1440 - val_loss: 8.2827\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2525 - val_loss: 7.9418\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2866 - val_loss: 8.0534\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1898 - val_loss: 8.7300\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3844 - val_loss: 8.1614\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1484 - val_loss: 8.6569\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8785 - val_loss: 7.9294\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9929 - val_loss: 8.8413\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2084 - val_loss: 7.8742\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9986 - val_loss: 8.0205\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0182 - val_loss: 8.0004\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3055 - val_loss: 8.0362\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5837 - val_loss: 8.9905\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4462 - val_loss: 8.0358\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1031 - val_loss: 8.8061\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1785 - val_loss: 7.7135\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0927 - val_loss: 7.9689\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8204 - val_loss: 7.6713\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9614 - val_loss: 7.7982\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8726 - val_loss: 7.7086\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0651 - val_loss: 8.3055\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1269 - val_loss: 7.6020\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9812 - val_loss: 8.0113\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1865 - val_loss: 7.5713\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9550 - val_loss: 7.8287\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0094 - val_loss: 7.7881\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2755 - val_loss: 7.9468\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9210 - val_loss: 7.7201\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1393 - val_loss: 7.4700\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0698 - val_loss: 8.1258\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9781 - val_loss: 7.6754\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9689 - val_loss: 8.0741\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0406 - val_loss: 7.7772\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9868 - val_loss: 7.6446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8959 - val_loss: 7.4547\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8873 - val_loss: 7.8051\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8642 - val_loss: 7.9737\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8701 - val_loss: 7.8599\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9055 - val_loss: 7.5740\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8807 - val_loss: 8.0808\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9662 - val_loss: 7.8691\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8892 - val_loss: 7.7543\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9615 - val_loss: 7.6839\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9404 - val_loss: 8.1978\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7829 - val_loss: 7.5256\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9042 - val_loss: 8.1937\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9838 - val_loss: 7.7349\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8740 - val_loss: 7.8988\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8389 - val_loss: 7.6995\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0869 - val_loss: 8.7188\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2158 - val_loss: 7.8339\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0010 - val_loss: 8.0442\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9813 - val_loss: 7.7234\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0037 - val_loss: 7.6236\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2320 - val_loss: 8.7712\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4726 - val_loss: 7.7766\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1037 - val_loss: 8.2421\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8721 - val_loss: 7.8065\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8852 - val_loss: 8.3435\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9733 - val_loss: 7.5828\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0664 - val_loss: 8.0025\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9067 - val_loss: 7.5057\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4797 - val_loss: 9.5914\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5081 - val_loss: 7.7201\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1990 - val_loss: 8.2598\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2156 - val_loss: 7.7155\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8406 - val_loss: 8.3279\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9477 - val_loss: 7.9331\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9421 - val_loss: 8.2092\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0248 - val_loss: 7.7881\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0378 - val_loss: 8.0704\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8923 - val_loss: 7.6014\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8492 - val_loss: 7.8786\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8208 - val_loss: 7.7378\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9353 - val_loss: 7.6662\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1923 - val_loss: 8.1803\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9389 - val_loss: 7.9458\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8169 - val_loss: 8.1525\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8240 - val_loss: 7.9092\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8062 - val_loss: 7.6515\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8081 - val_loss: 7.5050\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8449 - val_loss: 7.4532\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9301 - val_loss: 7.8184\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9607 - val_loss: 8.0372\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9041 - val_loss: 7.7516\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8781 - val_loss: 7.8248\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1578 - val_loss: 7.6971\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8596 - val_loss: 7.6503\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8839 - val_loss: 7.7360\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7817 - val_loss: 7.8111\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9581 - val_loss: 7.6176\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8232 - val_loss: 8.1047\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7684 - val_loss: 7.6823\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8338 - val_loss: 7.7234\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8001 - val_loss: 7.7122\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8606 - val_loss: 7.6540\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0582 - val_loss: 7.7733\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8378 - val_loss: 8.0147\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8820 - val_loss: 7.6275\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7628 - val_loss: 7.9537\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8507 - val_loss: 7.5038\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8884 - val_loss: 7.5099\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7431 - val_loss: 8.0065\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8103 - val_loss: 7.7288\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8306 - val_loss: 8.1081\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8933 - val_loss: 7.6006\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8665 - val_loss: 8.4155\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2993 - val_loss: 8.3384\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5212 - val_loss: 8.2491\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8787 - val_loss: 7.6449\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7617 - val_loss: 7.7951\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 3.8726 - val_loss: 7.6899\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8851 - val_loss: 7.7099\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9677 - val_loss: 8.1103\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8627 - val_loss: 7.8505\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8775 - val_loss: 7.9492\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7492 - val_loss: 7.6393\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8738 - val_loss: 7.7174\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8191 - val_loss: 7.7108\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8348 - val_loss: 7.6444\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9859 - val_loss: 8.1072\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8606 - val_loss: 7.8909\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9801 - val_loss: 7.5122\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9360 - val_loss: 7.6291\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7779 - val_loss: 7.9739\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9808 - val_loss: 8.2463\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8793 - val_loss: 7.7747\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1007 - val_loss: 7.9046\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7010 - val_loss: 8.8068\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9537 - val_loss: 7.6669\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9074 - val_loss: 7.9932\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0569 - val_loss: 8.2839\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9184 - val_loss: 7.8278\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9768 - val_loss: 8.1181\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.0604 - val_loss: 7.5117\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8994 - val_loss: 7.5700\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9919 - val_loss: 8.0423\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8248 - val_loss: 7.9356\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9928 - val_loss: 7.8106\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1138 - val_loss: 8.2700\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7385 - val_loss: 7.7352\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0592 - val_loss: 7.7240\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8573 - val_loss: 8.2165\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 3.7812 - val_loss: 7.7546\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7335 - val_loss: 8.2618\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0537 - val_loss: 7.9212\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8207 - val_loss: 8.2003\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8441 - val_loss: 7.5080\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0145 - val_loss: 8.0258\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6995 - val_loss: 8.0994\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8623 - val_loss: 7.7236\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7930 - val_loss: 8.2767\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8387 - val_loss: 8.0235\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7061 - val_loss: 7.8744\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7690 - val_loss: 7.7442\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8117 - val_loss: 8.4029\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7894 - val_loss: 7.7260\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8874 - val_loss: 7.7217\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8384 - val_loss: 8.5444\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9770 - val_loss: 7.5110\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7651 - val_loss: 7.8148\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8019 - val_loss: 7.6775\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8614 - val_loss: 7.8431\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9760 - val_loss: 7.8534\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7599 - val_loss: 7.9267\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7384 - val_loss: 7.6876\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7891 - val_loss: 8.4863\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1298 - val_loss: 7.9558\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8261 - val_loss: 8.0459\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8585 - val_loss: 7.6775\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7112 - val_loss: 8.6199\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8557 - val_loss: 8.0292\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9588 - val_loss: 8.4539\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7456 - val_loss: 7.7448\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8960 - val_loss: 7.8223\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7804 - val_loss: 8.0853\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7487 - val_loss: 7.8498\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7431 - val_loss: 8.0492\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7326 - val_loss: 7.7400\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7702 - val_loss: 8.1180\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0224 - val_loss: 7.8682\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7795 - val_loss: 8.9199\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8708 - val_loss: 7.8392\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6806 - val_loss: 7.9601\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8541 - val_loss: 8.5122\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6972 - val_loss: 7.7472\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8215 - val_loss: 8.2831\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6892 - val_loss: 7.5920\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 3.7634 - val_loss: 9.2704\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9218 - val_loss: 7.9985\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9476 - val_loss: 8.9532\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9368 - val_loss: 7.8677\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2048 - val_loss: 7.9644\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7288 - val_loss: 7.8416\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8496 - val_loss: 7.7621\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.7575 - val_loss: 7.6249\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7294 - val_loss: 7.6702\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6820 - val_loss: 7.7968\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6932 - val_loss: 7.8377\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6636 - val_loss: 7.4049\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.6993 - val_loss: 7.9428\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6956 - val_loss: 7.7542\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8616 - val_loss: 8.1690\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8383 - val_loss: 7.9328\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7970 - val_loss: 8.0241\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9769 - val_loss: 7.6626\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6933 - val_loss: 7.7651\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7127 - val_loss: 7.9839\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7035 - val_loss: 7.7439\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8669 - val_loss: 7.6184\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0021 - val_loss: 8.7293\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9069 - val_loss: 7.8077\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6275 - val_loss: 8.2462\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7745 - val_loss: 7.7007\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6439 - val_loss: 7.6978\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8671 - val_loss: 8.2259\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8446 - val_loss: 7.5632\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8197 - val_loss: 8.0361\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.7565 - val_loss: 8.0651\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6704 - val_loss: 7.7617\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8175 - val_loss: 7.6385\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0547 - val_loss: 9.4480\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9104 - val_loss: 7.7276\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7632 - val_loss: 8.4299\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8835 - val_loss: 7.8523\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8468 - val_loss: 8.4728\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7633 - val_loss: 7.5729\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6132 - val_loss: 8.0518\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7178 - val_loss: 7.7676\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7022 - val_loss: 7.7730\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6621 - val_loss: 7.9366\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.8648 - val_loss: 8.9289\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.8569 - val_loss: 7.7959\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9436 - val_loss: 9.4550\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9161 - val_loss: 8.0286\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8671 - val_loss: 8.3888\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6965 - val_loss: 7.6247\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7354 - val_loss: 8.3565\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9986 - val_loss: 7.6734\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8265 - val_loss: 8.2044\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6909 - val_loss: 7.8553\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7305 - val_loss: 7.8753\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6082 - val_loss: 7.6964\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6577 - val_loss: 7.9672\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6431 - val_loss: 7.9295\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7729 - val_loss: 8.0494\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6205 - val_loss: 8.0246\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7548 - val_loss: 8.0682\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7474 - val_loss: 7.5195\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7743 - val_loss: 7.9544\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6494 - val_loss: 7.9205\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6646 - val_loss: 7.7408\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7211 - val_loss: 7.5807\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0441 - val_loss: 9.2612\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8542 - val_loss: 7.7585\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7414 - val_loss: 8.4353\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9169 - val_loss: 7.9169\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9512 - val_loss: 8.2764\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6000 - val_loss: 7.7007\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8408 - val_loss: 9.0239\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1641 - val_loss: 7.7577\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6711 - val_loss: 8.0235\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6221 - val_loss: 8.1567\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9233 - val_loss: 8.1206\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4136 - val_loss: 8.9109\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7962 - val_loss: 8.0444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7980 - val_loss: 8.9372\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7411 - val_loss: 7.8922\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6795 - val_loss: 7.7710\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7554 - val_loss: 8.3610\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8062 - val_loss: 7.6537\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7222 - val_loss: 7.8854\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6229 - val_loss: 8.1056\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5946 - val_loss: 8.1154\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7046 - val_loss: 8.0058\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.7245 - val_loss: 7.8801\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7678 - val_loss: 8.1972\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6693 - val_loss: 7.8794\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5926 - val_loss: 8.1236\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.7862 - val_loss: 7.5892\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6297 - val_loss: 8.1346\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9023 - val_loss: 8.2557\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9087 - val_loss: 7.6387\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7616 - val_loss: 8.6884\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.7709 - val_loss: 7.9303\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9001 - val_loss: 7.8224\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9306 - val_loss: 8.4581\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6958 - val_loss: 7.6274\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7505 - val_loss: 8.5073\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8271 - val_loss: 8.0193\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6205 - val_loss: 7.8697\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7126 - val_loss: 8.1390\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6794 - val_loss: 7.7483\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7973 - val_loss: 8.2873\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6893 - val_loss: 7.6882\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7584 - val_loss: 8.7216\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9305 - val_loss: 8.1630\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8439 - val_loss: 7.7962\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5479 - val_loss: 8.1641\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.6633 - val_loss: 7.9752\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5858 - val_loss: 8.6193\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9402 - val_loss: 7.9284\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.0232 - val_loss: 8.5189\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7436 - val_loss: 8.5030\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7699 - val_loss: 7.7863\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6899 - val_loss: 7.8136\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6420 - val_loss: 8.1926\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5839 - val_loss: 7.8683\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.5635 - val_loss: 8.3344\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6282 - val_loss: 7.9453\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6105 - val_loss: 8.3052\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.6718 - val_loss: 7.9218\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6725 - val_loss: 7.8868\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6376 - val_loss: 8.2716\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6345 - val_loss: 8.3763\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6587 - val_loss: 7.7409\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5794 - val_loss: 8.1088\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.5808 - val_loss: 8.2902\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6704 - val_loss: 8.2155\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.6873 - val_loss: 7.7624\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6027 - val_loss: 8.3063\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6212 - val_loss: 8.1219\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5580 - val_loss: 8.3404\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5845 - val_loss: 8.3718\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7031 - val_loss: 8.4185\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6516 - val_loss: 7.8125\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9699 - val_loss: 9.2223\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7595 - val_loss: 7.8370\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 3.5850 - val_loss: 8.5134\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7169 - val_loss: 8.1149\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6477 - val_loss: 7.9423\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7353 - val_loss: 7.9477\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9935 - val_loss: 8.5759\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7312 - val_loss: 8.1797\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.6066 - val_loss: 8.0283\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7264 - val_loss: 8.4663\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6493 - val_loss: 8.1337\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7327 - val_loss: 8.6739\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8603 - val_loss: 8.0625\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8792 - val_loss: 8.9058\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6903 - val_loss: 8.1151\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.4943 - val_loss: 9.0616\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6790 - val_loss: 7.9075\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9473 - val_loss: 7.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7986 - val_loss: 8.9511\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5439 - val_loss: 8.2173\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6646 - val_loss: 8.1742\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.6738 - val_loss: 8.2624\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7038 - val_loss: 8.1359\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.6261 - val_loss: 8.5989\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6339 - val_loss: 8.2093\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6564 - val_loss: 8.2387\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7492 - val_loss: 8.5649\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7932 - val_loss: 8.3867\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5775 - val_loss: 8.3008\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.6059 - val_loss: 8.0050\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5791 - val_loss: 8.2672\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.6163 - val_loss: 8.5943\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6202 - val_loss: 8.3461\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6668 - val_loss: 7.9286\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1714 - val_loss: 8.6729\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6037 - val_loss: 7.9552\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.6053 - val_loss: 8.4927\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5956 - val_loss: 8.3488\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.7157 - val_loss: 8.0142\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8302 - val_loss: 8.8764\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7517 - val_loss: 8.5260\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7941 - val_loss: 8.5064\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9779 - val_loss: 8.7322\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7984 - val_loss: 8.0992\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6423 - val_loss: 8.6594\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5231 - val_loss: 8.1568\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5967 - val_loss: 8.6444\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7099 - val_loss: 8.7688\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7520 - val_loss: 8.1370\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.5684 - val_loss: 8.2669\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.5806 - val_loss: 8.5414\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.5949 - val_loss: 8.3904\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6064 - val_loss: 8.5225\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1640 - val_loss: 8.2157\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9803 - val_loss: 9.2338\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8075 - val_loss: 7.9693\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5904 - val_loss: 8.7273\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5685 - val_loss: 8.2099\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5965 - val_loss: 8.4145\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.6113 - val_loss: 8.2262\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6585 - val_loss: 8.3184\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6341 - val_loss: 8.2815\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5629 - val_loss: 8.2096\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5782 - val_loss: 8.5308\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7193 - val_loss: 7.9912\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8010 - val_loss: 8.9785\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8915 - val_loss: 8.4494\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8778 - val_loss: 8.0290\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7228 - val_loss: 8.4726\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7491 - val_loss: 8.9384\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7268 - val_loss: 8.1912\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.246 - 0s 98us/step - loss: 3.7006 - val_loss: 8.2071\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1930 - val_loss: 10.2861\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1471 - val_loss: 7.9570\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5245 - val_loss: 9.9036\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0551 - val_loss: 8.2046\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5740 - val_loss: 9.1647\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.6388 - val_loss: 8.3230\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5289 - val_loss: 8.5944\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7299 - val_loss: 8.0967\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6486 - val_loss: 8.6985\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6367 - val_loss: 8.0820\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.5156 - val_loss: 8.8040\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6301 - val_loss: 8.0879\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.6331 - val_loss: 8.9161\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6122 - val_loss: 8.2938\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6153 - val_loss: 8.8453\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7575 - val_loss: 8.1952\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7983 - val_loss: 8.9662\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5658 - val_loss: 8.0808\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.5715 - val_loss: 8.7637\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5451 - val_loss: 8.4263\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7899 - val_loss: 9.4716\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9197 - val_loss: 8.2277\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7516 - val_loss: 9.0487\n",
      "Epoch 997/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 3.6346 - val_loss: 8.0744\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6963 - val_loss: 8.7638\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.5383 - val_loss: 8.2997\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.5244 - val_loss: 8.4996\n",
      "7.216272038928533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.16243517,  1.122077  ,  2.8560452 ,  2.2493777 ,  3.5669627 ,\n",
       "         -0.9180955 ,  1.944857  ,  6.6755676 ,  0.27070794, -2.0343685 ],\n",
       "        [ 0.96825826, -0.6077919 , -1.507651  ,  1.7450968 ,  0.04354353,\n",
       "          0.38012785,  1.1624945 , -4.379269  , -0.4663922 ,  0.3645556 ],\n",
       "        [ 0.8729432 ,  0.40877116, -1.3155353 ,  1.4644109 , -0.06413081,\n",
       "         -0.5828039 , -0.769657  ,  1.1289961 , -0.9244863 , -0.21816698],\n",
       "        [-0.67934567, -0.7120239 ,  1.6429641 , -0.1205655 , -2.005322  ,\n",
       "          0.32881853, -0.2139117 ,  1.8799223 ,  1.635175  , -0.39642552],\n",
       "        [ 1.6915435 ,  0.07351439, -1.5879179 , -0.12003101,  0.93923396,\n",
       "         -0.2546069 , -0.06680035, -0.35054806, -1.2160046 ,  0.50890523],\n",
       "        [ 0.11358173,  0.22145705, -0.8307466 ,  1.364433  , -1.108322  ,\n",
       "         -1.1261615 ,  1.205211  , -1.2765306 ,  0.73458976,  0.083188  ],\n",
       "        [-3.311329  , -0.26861703, -0.59079087,  0.938843  , -1.0738344 ,\n",
       "         -0.7473333 ,  0.06557725, -1.49075   ,  1.7296891 , -0.5810198 ]],\n",
       "       dtype=float32),\n",
       " array([-2.1044388,  1.4038042, -2.2241254,  1.8129059,  0.6692138,\n",
       "         1.5224273,  1.7089173,  1.6012883,  2.543453 , -1.0349115],\n",
       "       dtype=float32),\n",
       " array([[-0.9255589 , -0.2431469 ,  0.49831182,  0.03053086, -0.24485518],\n",
       "        [ 0.9336042 ,  1.090753  , -1.0524412 ,  0.656973  , -1.1011573 ],\n",
       "        [-0.72759265, -1.1399082 ,  0.8203068 , -1.0118142 ,  0.10762481],\n",
       "        [-0.6920218 , -1.139611  ,  1.2817444 , -0.20707466,  0.9115377 ],\n",
       "        [ 0.9904856 ,  0.60025877, -1.3033862 ,  0.84406215, -1.2267139 ],\n",
       "        [-0.16941424, -1.0557238 ,  0.9012627 , -0.41569042,  0.82968026],\n",
       "        [ 0.90534556,  1.1506869 , -1.436962  ,  0.9723983 , -0.60275126],\n",
       "        [-1.2934464 , -2.030737  ,  1.4077991 , -1.0736825 ,  1.1039231 ],\n",
       "        [ 0.06635128,  0.9514645 , -0.6789098 ,  0.77124244, -0.5592817 ],\n",
       "        [-0.02874008, -1.0299324 ,  0.7361948 , -1.1264344 ,  0.85766596]],\n",
       "       dtype=float32),\n",
       " array([ 1.4062937,  1.4756765, -1.4628018,  1.3314439, -1.3662347],\n",
       "       dtype=float32),\n",
       " array([[ 1.2814164 ],\n",
       "        [ 1.6824073 ],\n",
       "        [-1.5238882 ],\n",
       "        [ 0.85082436],\n",
       "        [-1.0465862 ]], dtype=float32),\n",
       " array([1.5416625], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_4(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure4_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 454.8135 - val_loss: 207.6744\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 114.2854 - val_loss: 80.6046\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 39.8448 - val_loss: 36.0790\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 23.2090 - val_loss: 23.9938\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.7682 - val_loss: 19.3026\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.2204 - val_loss: 19.2789\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.8241 - val_loss: 18.9905\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.3870 - val_loss: 19.1023\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 14.2835 - val_loss: 17.1461\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 12.7868 - val_loss: 16.5954\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.7416 - val_loss: 15.3752\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.9693 - val_loss: 15.1553\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.4139 - val_loss: 14.5158\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.3656 - val_loss: 13.5638\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 9.7995 - val_loss: 13.0410\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 10.0439 - val_loss: 12.7188\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 9.4053 - val_loss: 12.1357\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.5486 - val_loss: 11.6342\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2355 - val_loss: 11.4947\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.9653 - val_loss: 11.2417\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8088 - val_loss: 11.0154\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.8231 - val_loss: 10.7953\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7921 - val_loss: 10.6187\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7946 - val_loss: 10.8179\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.8815 - val_loss: 10.5341\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4690 - val_loss: 10.1525\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.4016 - val_loss: 9.7379\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.7870 - val_loss: 10.3301\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0177 - val_loss: 10.2368\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5774 - val_loss: 9.8709\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2680 - val_loss: 9.8629\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2709 - val_loss: 9.8305\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3365 - val_loss: 9.8824\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1674 - val_loss: 9.7827\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0808 - val_loss: 9.8047\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1823 - val_loss: 9.5166\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2408 - val_loss: 9.5472\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.2853 - val_loss: 9.8021\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 7.0635 - val_loss: 9.8097\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.1058 - val_loss: 9.7287\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0622 - val_loss: 9.5096\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.3787 - val_loss: 9.8620\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1060 - val_loss: 9.5999\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.3187 - val_loss: 9.6039\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0481 - val_loss: 9.3778\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0326 - val_loss: 9.4636\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9801 - val_loss: 9.4431\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9995 - val_loss: 9.5624\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0161 - val_loss: 9.2713\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0217 - val_loss: 9.5456\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2076 - val_loss: 9.4946\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9258 - val_loss: 9.6845\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8817 - val_loss: 9.3626\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0503 - val_loss: 9.2302\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9169 - val_loss: 9.3825\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8476 - val_loss: 9.2198\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9787 - val_loss: 8.9432\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9094 - val_loss: 9.1746\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1461 - val_loss: 9.0073\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8171 - val_loss: 9.3977\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7544 - val_loss: 9.2711\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8234 - val_loss: 9.4456\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0307 - val_loss: 9.3411\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6648 - val_loss: 9.3222\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7835 - val_loss: 9.4437\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7585 - val_loss: 9.5217\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7275 - val_loss: 8.9433\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6314 - val_loss: 8.7983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7261 - val_loss: 9.3775\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6706 - val_loss: 9.0821\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6105 - val_loss: 9.0744\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.7518 - val_loss: 9.3980\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7966 - val_loss: 9.1649\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5614 - val_loss: 8.9878\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6941 - val_loss: 8.9845\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6667 - val_loss: 8.8530\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4499 - val_loss: 8.7536\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0466 - val_loss: 8.8487\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4526 - val_loss: 9.4250\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.3533 - val_loss: 9.2403\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3457 - val_loss: 9.0733\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6581 - val_loss: 9.6497\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8033 - val_loss: 9.4154\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5409 - val_loss: 9.0512\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2191 - val_loss: 9.0503\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2518 - val_loss: 8.8255\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5593 - val_loss: 8.7101\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4163 - val_loss: 9.3217\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9885 - val_loss: 8.7437\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2973 - val_loss: 9.1229\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3218 - val_loss: 9.2342\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4315 - val_loss: 8.7429\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1826 - val_loss: 8.7749\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3595 - val_loss: 9.3978\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1907 - val_loss: 9.6068\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9295 - val_loss: 8.9357\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3861 - val_loss: 8.5577\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0619 - val_loss: 8.7260\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1501 - val_loss: 9.1676\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2326 - val_loss: 9.0890\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3432 - val_loss: 8.7444\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9243 - val_loss: 8.6036\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8814 - val_loss: 8.5086\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0977 - val_loss: 8.7952\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3195 - val_loss: 8.9834\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0851 - val_loss: 8.7527\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1707 - val_loss: 8.3568\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8906 - val_loss: 8.2919\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9233 - val_loss: 8.7434\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4432 - val_loss: 9.7498\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3776 - val_loss: 8.6355\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8861 - val_loss: 9.2716\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0829 - val_loss: 8.6531\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8755 - val_loss: 8.3432\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6736 - val_loss: 8.1475\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0087 - val_loss: 8.3576\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1800 - val_loss: 9.1106\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8899 - val_loss: 8.6727\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8042 - val_loss: 8.6856\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7241 - val_loss: 8.4671\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9776 - val_loss: 8.7503\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0521 - val_loss: 8.8336\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9410 - val_loss: 8.4949\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4991 - val_loss: 8.8729\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6119 - val_loss: 9.7348\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1855 - val_loss: 10.7854\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.4540 - val_loss: 9.5430\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9073 - val_loss: 8.3402\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6114 - val_loss: 8.7664\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4762 - val_loss: 8.7614\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6251 - val_loss: 8.7571\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7449 - val_loss: 8.3490\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4960 - val_loss: 8.5922\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6256 - val_loss: 8.6187\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5679 - val_loss: 8.2895\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4958 - val_loss: 8.5716\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3831 - val_loss: 8.5538\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2885 - val_loss: 8.3413\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3887 - val_loss: 8.4645\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6112 - val_loss: 8.3123\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3551 - val_loss: 8.4390\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3769 - val_loss: 8.2163\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5182 - val_loss: 8.5572\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8194 - val_loss: 8.9374\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3805 - val_loss: 8.4816\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2925 - val_loss: 8.2272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3785 - val_loss: 8.1387\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4601 - val_loss: 8.2010\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4149 - val_loss: 8.4140\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3480 - val_loss: 8.5003\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3900 - val_loss: 8.2270\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5123 - val_loss: 9.0630\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8789 - val_loss: 8.6660\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2660 - val_loss: 8.6250\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3506 - val_loss: 9.0132\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0683 - val_loss: 8.3263\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1287 - val_loss: 8.4209\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6754 - val_loss: 9.1891\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4120 - val_loss: 8.5546\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6258 - val_loss: 8.6916\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3948 - val_loss: 8.2863\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8293 - val_loss: 8.6242\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5230 - val_loss: 8.1819\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2273 - val_loss: 8.0347\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2850 - val_loss: 8.2726\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2561 - val_loss: 8.4791\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3490 - val_loss: 8.6038\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9750 - val_loss: 8.5136\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1908 - val_loss: 8.1436\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0600 - val_loss: 8.2941\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0831 - val_loss: 8.1909\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9920 - val_loss: 8.4727\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.1137 - val_loss: 8.2858\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2840 - val_loss: 8.2561\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1392 - val_loss: 7.9484\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0813 - val_loss: 8.3077\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0134 - val_loss: 8.1685\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1367 - val_loss: 8.4522\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1386 - val_loss: 8.7384\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3535 - val_loss: 9.3649\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8855 - val_loss: 8.8064\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4084 - val_loss: 8.3157\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8755 - val_loss: 8.3070\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9369 - val_loss: 8.4247\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0248 - val_loss: 8.2304\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9507 - val_loss: 7.9981\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0352 - val_loss: 8.5685\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9693 - val_loss: 8.1984\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3474 - val_loss: 8.7531\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3416 - val_loss: 8.0205\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9369 - val_loss: 8.4137\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8771 - val_loss: 8.2709\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8785 - val_loss: 8.1324\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9808 - val_loss: 7.9845\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9967 - val_loss: 8.4366\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3253 - val_loss: 8.6094\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0605 - val_loss: 8.4012\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9260 - val_loss: 8.1625\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9527 - val_loss: 8.2678\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9484 - val_loss: 8.4816\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.7978 - val_loss: 8.7421\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8576 - val_loss: 8.4992\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9834 - val_loss: 8.1480\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9611 - val_loss: 8.2324\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8880 - val_loss: 8.7900\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9969 - val_loss: 8.3531\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9769 - val_loss: 7.9872\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0172 - val_loss: 8.9351\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0464 - val_loss: 8.9736\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1545 - val_loss: 7.9160\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8024 - val_loss: 8.0084\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7208 - val_loss: 8.2246\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0122 - val_loss: 8.9330\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1510 - val_loss: 8.3447\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9766 - val_loss: 8.2956\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8096 - val_loss: 8.2834\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7545 - val_loss: 8.0893\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.154 - 0s 95us/step - loss: 4.7783 - val_loss: 8.1318\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7469 - val_loss: 7.9990\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8071 - val_loss: 8.2163\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9474 - val_loss: 8.2284\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8240 - val_loss: 8.8237\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.9468 - val_loss: 9.9693\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.3994 - val_loss: 8.8123\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0164 - val_loss: 8.1881\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1583 - val_loss: 8.9111\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1448 - val_loss: 8.5475\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7347 - val_loss: 8.2130\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7107 - val_loss: 8.1165\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0241 - val_loss: 8.4559\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9504 - val_loss: 8.5212\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7705 - val_loss: 8.0930\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0241 - val_loss: 8.5015\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3643 - val_loss: 8.4235\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.9778 - val_loss: 9.2093\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9820 - val_loss: 9.3289\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.9490 - val_loss: 8.2970\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7324 - val_loss: 8.6898\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.7514 - val_loss: 8.2947\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8297 - val_loss: 8.4087\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7377 - val_loss: 8.2797\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.7446 - val_loss: 9.0933\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0256 - val_loss: 9.6543\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5137 - val_loss: 9.4483\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.8266 - val_loss: 8.4408\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8751 - val_loss: 8.1748\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6918 - val_loss: 8.5459\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6431 - val_loss: 8.4775\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6998 - val_loss: 8.1636\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6538 - val_loss: 8.7259\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8732 - val_loss: 8.6596\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8452 - val_loss: 8.3405\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6440 - val_loss: 8.3896\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7535 - val_loss: 8.6132\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6526 - val_loss: 8.3409\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7076 - val_loss: 8.6898\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7137 - val_loss: 8.7391\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7051 - val_loss: 8.5118\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1098 - val_loss: 8.4513\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7085 - val_loss: 8.2377\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6986 - val_loss: 8.4021\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5787 - val_loss: 8.8901\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6851 - val_loss: 8.6623\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6782 - val_loss: 8.3579\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6707 - val_loss: 8.6917\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7058 - val_loss: 8.7586\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6383 - val_loss: 8.6118\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0811 - val_loss: 8.3605\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7560 - val_loss: 8.5654\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6010 - val_loss: 8.7642\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.6340 - val_loss: 8.3694\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9835 - val_loss: 8.7288\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 4.6198 - val_loss: 8.7490\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6930 - val_loss: 9.1501\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0449 - val_loss: 8.6729\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6508 - val_loss: 8.8015\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7860 - val_loss: 8.6041\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6118 - val_loss: 8.6751\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8390 - val_loss: 8.2944\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5810 - val_loss: 8.5249\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6976 - val_loss: 8.4725\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8889 - val_loss: 9.0452\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8096 - val_loss: 8.7567\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7060 - val_loss: 8.6963\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7366 - val_loss: 8.7170\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5439 - val_loss: 8.4795\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5333 - val_loss: 8.6033\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5982 - val_loss: 8.4853\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5315 - val_loss: 8.4709\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6630 - val_loss: 8.6115\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9850 - val_loss: 8.9229\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6325 - val_loss: 8.3840\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6836 - val_loss: 8.4511\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6248 - val_loss: 8.6413\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6786 - val_loss: 8.6198\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6165 - val_loss: 9.1447\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0798 - val_loss: 8.8847\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.4767 - val_loss: 8.6673\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6835 - val_loss: 8.6757\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6849 - val_loss: 8.9728\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.6948 - val_loss: 8.9102\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6788 - val_loss: 8.9206\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7244 - val_loss: 8.5637\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5673 - val_loss: 8.8271\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5649 - val_loss: 8.8732\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5912 - val_loss: 8.6641\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7403 - val_loss: 8.8573\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6959 - val_loss: 8.3546\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.7697 - val_loss: 8.7031\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5861 - val_loss: 8.6925\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9320 - val_loss: 9.6755\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7967 - val_loss: 8.6549\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5302 - val_loss: 8.4641\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6022 - val_loss: 8.3049\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5896 - val_loss: 8.8487\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7648 - val_loss: 9.0126\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8222 - val_loss: 8.4145\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7203 - val_loss: 8.4453\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5656 - val_loss: 8.6695\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6348 - val_loss: 8.6721\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9289 - val_loss: 8.5017\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7404 - val_loss: 9.4219\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7503 - val_loss: 8.5609\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8999 - val_loss: 8.5076\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8790 - val_loss: 8.8624\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6124 - val_loss: 8.7649\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6089 - val_loss: 8.5456\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5864 - val_loss: 8.8976\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6175 - val_loss: 8.4383\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4202 - val_loss: 8.3705\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.4215 - val_loss: 8.3833\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5683 - val_loss: 9.0393\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4732 - val_loss: 9.0268\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.8395 - val_loss: 8.9709\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9766 - val_loss: 8.6891\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6277 - val_loss: 8.4497\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5436 - val_loss: 8.2585\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.5227 - val_loss: 8.5769\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5355 - val_loss: 8.5800\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6809 - val_loss: 8.7332\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4745 - val_loss: 9.3548\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1575 - val_loss: 8.9021\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5360 - val_loss: 9.2289\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7647 - val_loss: 8.9914\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4788 - val_loss: 8.7382\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5619 - val_loss: 8.3868\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.5366 - val_loss: 8.3751\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4593 - val_loss: 8.6167\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 549us/step - loss: 4.4869 - val_loss: 9.0150\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6437 - val_loss: 9.1099\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5146 - val_loss: 8.6316\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.4476 - val_loss: 8.8322\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5012 - val_loss: 8.7015\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.4945 - val_loss: 8.5895\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 125us/step - loss: 4.7346 - val_loss: 8.6208\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.5642 - val_loss: 8.8228\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4992 - val_loss: 8.5909\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6260 - val_loss: 8.6744\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4603 - val_loss: 8.8334\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6212 - val_loss: 8.4340\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4726 - val_loss: 8.7591\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6184 - val_loss: 8.6940\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5764 - val_loss: 8.2488\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4534 - val_loss: 8.8784\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4121 - val_loss: 8.5492\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6124 - val_loss: 8.4453\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5427 - val_loss: 8.4694\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5277 - val_loss: 8.6166\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4032 - val_loss: 8.8711\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3562 - val_loss: 8.5186\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4547 - val_loss: 8.8018\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5169 - val_loss: 8.6763\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.4566 - val_loss: 8.6646\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6895 - val_loss: 8.8694\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3565 - val_loss: 8.9956\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4483 - val_loss: 8.7477\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5321 - val_loss: 8.7654\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.7643 - val_loss: 8.9641\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9347 - val_loss: 9.4696\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9122 - val_loss: 9.2400\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9637 - val_loss: 8.6265\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5240 - val_loss: 9.1053\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6663 - val_loss: 8.7535\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5291 - val_loss: 8.3866\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6868 - val_loss: 8.9554\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0281 - val_loss: 9.2989\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9652 - val_loss: 8.6102\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7644 - val_loss: 8.7768\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6748 - val_loss: 9.1304\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7875 - val_loss: 9.7653\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.5577 - val_loss: 8.7677\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4042 - val_loss: 8.9059\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5879 - val_loss: 8.6305\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4654 - val_loss: 8.5048\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.4408 - val_loss: 8.5322\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4393 - val_loss: 8.6532\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5198 - val_loss: 8.7460\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6298 - val_loss: 9.1690\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0844 - val_loss: 9.2524\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5585 - val_loss: 9.1105\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4621 - val_loss: 8.6963\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4459 - val_loss: 8.9197\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6777 - val_loss: 8.5538\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5559 - val_loss: 8.6896\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.4456 - val_loss: 9.1107\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6340 - val_loss: 8.6235\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5757 - val_loss: 9.0064\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9012 - val_loss: 8.8409\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6094 - val_loss: 8.9233\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4746 - val_loss: 8.7711\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2816 - val_loss: 8.7707\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7574 - val_loss: 8.0493\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2951 - val_loss: 8.8208\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4115 - val_loss: 8.5116\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.3071 - val_loss: 7.7600\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3325 - val_loss: 8.7528\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6823 - val_loss: 10.3034\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8352 - val_loss: 10.7534\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.8452 - val_loss: 8.7914\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.0180 - val_loss: 8.5477\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3229 - val_loss: 8.3154\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3000 - val_loss: 8.8769\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3722 - val_loss: 8.6849\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7652 - val_loss: 8.9146\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.5925 - val_loss: 8.1706\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3072 - val_loss: 8.7908\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3681 - val_loss: 8.4413\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6457 - val_loss: 8.4829\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8093 - val_loss: 9.1215\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7596 - val_loss: 8.5520\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3756 - val_loss: 8.8986\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3282 - val_loss: 8.4928\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3890 - val_loss: 8.3245\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3689 - val_loss: 8.5692\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3028 - val_loss: 8.5733\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4250 - val_loss: 8.9087\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4838 - val_loss: 8.4760\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4448 - val_loss: 8.5375\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5792 - val_loss: 8.9406\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4629 - val_loss: 8.9422\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.4531 - val_loss: 8.9589\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5307 - val_loss: 8.6264\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5819 - val_loss: 8.5286\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3419 - val_loss: 8.7161\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8194 - val_loss: 9.3928\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6931 - val_loss: 8.3884\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3646 - val_loss: 8.4461\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3918 - val_loss: 8.4686\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2523 - val_loss: 8.1712\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3046 - val_loss: 8.6329\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4116 - val_loss: 8.2116\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5420 - val_loss: 8.4610\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5403 - val_loss: 9.2718\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.3032 - val_loss: 8.9008\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.4975 - val_loss: 8.7458\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4424 - val_loss: 8.0068\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3922 - val_loss: 9.0782\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5536 - val_loss: 8.7040\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5581 - val_loss: 8.1656\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2530 - val_loss: 8.6704\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3345 - val_loss: 8.5904\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2284 - val_loss: 8.0473\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3712 - val_loss: 8.4000\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3387 - val_loss: 8.2357\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2943 - val_loss: 8.4877\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6219 - val_loss: 8.6768\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2756 - val_loss: 9.3304\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4546 - val_loss: 8.7300\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4690 - val_loss: 8.6379\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4714 - val_loss: 8.4906\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.4356 - val_loss: 8.5944\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4339 - val_loss: 8.4661\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6345 - val_loss: 8.8329\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7503 - val_loss: 8.4545\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2230 - val_loss: 9.4102\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3965 - val_loss: 8.5190\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4300 - val_loss: 9.0078\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3019 - val_loss: 8.7109\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4318 - val_loss: 8.4499\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2457 - val_loss: 7.8950\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3737 - val_loss: 8.4629\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5903 - val_loss: 8.8066\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7270 - val_loss: 8.6352\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2178 - val_loss: 8.4781\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4895 - val_loss: 8.7718\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3822 - val_loss: 8.6259\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3136 - val_loss: 8.4603\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7181 - val_loss: 8.9649\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9662 - val_loss: 9.0032\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6835 - val_loss: 7.9438\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3162 - val_loss: 8.5493\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2734 - val_loss: 8.6537\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3768 - val_loss: 8.3480\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2616 - val_loss: 8.3236\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4017 - val_loss: 8.8730\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9766 - val_loss: 9.3695\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7842 - val_loss: 9.0555\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1920 - val_loss: 8.5297\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6594 - val_loss: 8.4275\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4930 - val_loss: 8.6036\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3810 - val_loss: 8.2956\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4429 - val_loss: 8.2880\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2923 - val_loss: 8.0840\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2294 - val_loss: 8.1626\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4076 - val_loss: 8.7645\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6896 - val_loss: 8.5372\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3941 - val_loss: 8.5344\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2289 - val_loss: 7.8210\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1898 - val_loss: 8.5740\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1950 - val_loss: 8.4241\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2719 - val_loss: 8.3181\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5368 - val_loss: 8.1263\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2167 - val_loss: 8.4927\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2375 - val_loss: 8.4683\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2499 - val_loss: 8.4200\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1419 - val_loss: 8.0368\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5339 - val_loss: 9.3246\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8302 - val_loss: 8.8013\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3154 - val_loss: 8.8769\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2668 - val_loss: 8.2542\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4170 - val_loss: 8.4871\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.8316 - val_loss: 9.1923\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0303 - val_loss: 9.0725\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 4.0742 - val_loss: 9.0330\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.2146 - val_loss: 8.7919\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6199 - val_loss: 8.1755\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6398 - val_loss: 8.6492\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4514 - val_loss: 7.9154\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2198 - val_loss: 8.2759\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2728 - val_loss: 8.0857\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2798 - val_loss: 8.2054\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 99us/step - loss: 4.2679 - val_loss: 8.2559\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3283 - val_loss: 9.1122\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6092 - val_loss: 8.1816\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4545 - val_loss: 8.3916\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.3022 - val_loss: 8.6291\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4316 - val_loss: 8.3044\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2411 - val_loss: 8.4606\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.3488 - val_loss: 8.1091\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3628 - val_loss: 8.6424\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6724 - val_loss: 10.3055\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0707 - val_loss: 9.3353\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.3219 - val_loss: 8.7979\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5667 - val_loss: 8.3119\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5638 - val_loss: 8.3303\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5271 - val_loss: 8.6617\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2470 - val_loss: 8.2758\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3109 - val_loss: 8.1837\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4263 - val_loss: 8.6226\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3917 - val_loss: 8.8940\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1791 - val_loss: 8.2893\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4856 - val_loss: 8.4880\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1113 - val_loss: 8.1931\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3088 - val_loss: 8.4967\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1772 - val_loss: 8.2160\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2178 - val_loss: 8.3334\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2155 - val_loss: 8.1495\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1383 - val_loss: 8.2159\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1671 - val_loss: 8.1121\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4726 - val_loss: 8.2410\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3737 - val_loss: 8.2786\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4018 - val_loss: 8.1843\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1411 - val_loss: 8.5881\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.2542 - val_loss: 8.1437\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1561 - val_loss: 9.6322\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6132 - val_loss: 9.2803\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5699 - val_loss: 8.8959\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3837 - val_loss: 8.2679\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4080 - val_loss: 8.3997\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4661 - val_loss: 8.9344\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2135 - val_loss: 8.1639\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3417 - val_loss: 8.6486\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5575 - val_loss: 9.1401\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7678 - val_loss: 9.0734\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6402 - val_loss: 8.7373\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7791 - val_loss: 8.6154\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4044 - val_loss: 8.3363\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8110 - val_loss: 9.8293\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3755 - val_loss: 9.3079\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5712 - val_loss: 8.9330\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4813 - val_loss: 8.2270\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4333 - val_loss: 8.1769\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2094 - val_loss: 8.3967\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2163 - val_loss: 8.1108\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2525 - val_loss: 8.3684\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4324 - val_loss: 8.1495\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8307 - val_loss: 10.1545\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1863 - val_loss: 9.2811\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5167 - val_loss: 9.3179\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3034 - val_loss: 8.6755\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1835 - val_loss: 7.9623\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2431 - val_loss: 8.0029\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1189 - val_loss: 8.1849\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2433 - val_loss: 8.1760\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1431 - val_loss: 8.0834\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2103 - val_loss: 8.1413\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1410 - val_loss: 8.1855\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2805 - val_loss: 8.3741\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2918 - val_loss: 8.6846\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3406 - val_loss: 8.5826\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2430 - val_loss: 8.6697\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2407 - val_loss: 7.9624\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3384 - val_loss: 8.2086\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1796 - val_loss: 9.0785\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3347 - val_loss: 8.2987\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1995 - val_loss: 8.6365\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3724 - val_loss: 8.3370\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3799 - val_loss: 8.4249\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.3622 - val_loss: 8.6863\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1372 - val_loss: 8.0100\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2091 - val_loss: 8.3160\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1305 - val_loss: 8.2774\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1087 - val_loss: 8.4364\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1313 - val_loss: 8.4666\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1787 - val_loss: 8.2605\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2364 - val_loss: 8.2488\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4203 - val_loss: 8.2920\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0453 - val_loss: 8.4482\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1574 - val_loss: 8.4490\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2257 - val_loss: 8.5200\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2962 - val_loss: 8.2609\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3911 - val_loss: 8.3847\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1175 - val_loss: 8.6110\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1556 - val_loss: 8.5261\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0906 - val_loss: 8.4822\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1919 - val_loss: 8.4738\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1536 - val_loss: 8.3585\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1697 - val_loss: 8.0569\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2079 - val_loss: 8.4130\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.1566 - val_loss: 8.2040\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1880 - val_loss: 8.3644\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1156 - val_loss: 8.2285\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3346 - val_loss: 8.1934\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0659 - val_loss: 8.4779\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0752 - val_loss: 8.3526\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0868 - val_loss: 8.2708\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3481 - val_loss: 8.6180\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3630 - val_loss: 8.6494\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8243 - val_loss: 8.7953\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.3104 - val_loss: 8.3165\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.1599 - val_loss: 8.6266\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1679 - val_loss: 8.5235\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1242 - val_loss: 8.5085\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3239 - val_loss: 9.2570\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5568 - val_loss: 9.8740\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.3940 - val_loss: 8.4498\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2684 - val_loss: 8.0267\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2834 - val_loss: 7.9839\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0819 - val_loss: 8.7057\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1883 - val_loss: 8.5852\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.3666 - val_loss: 8.5019\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.5664 - val_loss: 8.7838\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8169 - val_loss: 8.8665\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5863 - val_loss: 8.2603\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4174 - val_loss: 8.3832\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2451 - val_loss: 8.6346\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3512 - val_loss: 8.1548\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1740 - val_loss: 8.2672\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0928 - val_loss: 8.3003\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.0879 - val_loss: 8.9022\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1377 - val_loss: 8.0787\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1253 - val_loss: 8.2119\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1431 - val_loss: 8.3918\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1152 - val_loss: 8.3132\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.2164 - val_loss: 8.4168\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.2562 - val_loss: 7.7829\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2111 - val_loss: 8.1325\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3358 - val_loss: 8.7100\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3776 - val_loss: 8.8380\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4535 - val_loss: 8.0344\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8338 - val_loss: 8.4340\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1790 - val_loss: 9.2297\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.4684 - val_loss: 8.2691\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1312 - val_loss: 9.2757\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6889 - val_loss: 8.5575\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2023 - val_loss: 8.6802\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0916 - val_loss: 8.0852\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0885 - val_loss: 8.5970\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1091 - val_loss: 8.1442\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0711 - val_loss: 8.3881\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0656 - val_loss: 7.9956\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.1019 - val_loss: 8.3274\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1163 - val_loss: 8.5601\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1187 - val_loss: 8.1257\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0868 - val_loss: 8.4390\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1243 - val_loss: 8.1486\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.0722 - val_loss: 8.4576\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1677 - val_loss: 8.1060\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0210 - val_loss: 8.1385\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0356 - val_loss: 8.3737\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1082 - val_loss: 8.3112\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.3712 - val_loss: 8.7874\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3022 - val_loss: 10.0815\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6969 - val_loss: 8.9716\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1497 - val_loss: 10.1437\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4514 - val_loss: 8.3873\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2759 - val_loss: 8.6274\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1570 - val_loss: 8.0678\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0896 - val_loss: 8.5248\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1174 - val_loss: 8.2650\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1239 - val_loss: 8.8719\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0869 - val_loss: 8.4669\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1122 - val_loss: 8.2532\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2982 - val_loss: 8.2600\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1202 - val_loss: 8.5505\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0555 - val_loss: 7.9769\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0833 - val_loss: 8.4874\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3382 - val_loss: 8.2536\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3755 - val_loss: 8.7693\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3477 - val_loss: 8.1036\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1566 - val_loss: 8.4699\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1096 - val_loss: 8.0560\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1525 - val_loss: 8.2238\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4327 - val_loss: 9.5751\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4392 - val_loss: 9.0485\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7638 - val_loss: 9.7841\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.5469 - val_loss: 8.0127\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1285 - val_loss: 8.0593\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4055 - val_loss: 8.5614\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2970 - val_loss: 8.6391\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5262 - val_loss: 10.1355\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8599 - val_loss: 8.3351\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4748 - val_loss: 8.6599\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4268 - val_loss: 8.6488\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1581 - val_loss: 8.6528\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1166 - val_loss: 7.9708\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1440 - val_loss: 8.7102\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.4581 - val_loss: 8.6163\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8788 - val_loss: 8.6692\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2067 - val_loss: 8.5503\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0418 - val_loss: 8.5011\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0550 - val_loss: 8.5805\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3998 - val_loss: 9.2968\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3546 - val_loss: 8.7182\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2396 - val_loss: 8.3170\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1686 - val_loss: 8.2422\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1343 - val_loss: 8.3562\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1086 - val_loss: 8.1497\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9684 - val_loss: 8.1599\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9545 - val_loss: 8.0966\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0447 - val_loss: 8.3419\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9870 - val_loss: 8.1981\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9630 - val_loss: 8.3835\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0622 - val_loss: 8.1609\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.1946 - val_loss: 8.5546\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 3.8632 - val_loss: 8.3949\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0241 - val_loss: 8.6781\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0899 - val_loss: 8.2878\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2077 - val_loss: 8.3113\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2187 - val_loss: 8.4067\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2520 - val_loss: 8.7369\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3408 - val_loss: 8.0289\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4257 - val_loss: 8.0764\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0982 - val_loss: 8.4084\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2167 - val_loss: 8.3905\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3702 - val_loss: 8.5912\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0550 - val_loss: 7.9563\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0593 - val_loss: 8.0757\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1050 - val_loss: 8.2570\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0344 - val_loss: 8.1760\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3283 - val_loss: 8.9742\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3782 - val_loss: 8.2186\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0562 - val_loss: 8.0235\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0901 - val_loss: 8.6182\n",
      "Epoch 765/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 4.1372 - val_loss: 8.0419\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0940 - val_loss: 8.6536\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1801 - val_loss: 8.5226\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0457 - val_loss: 8.1184\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1447 - val_loss: 8.3406\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9983 - val_loss: 8.3507\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1477 - val_loss: 7.9985\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1212 - val_loss: 8.5596\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0699 - val_loss: 8.1252\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0970 - val_loss: 8.5157\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0301 - val_loss: 8.0601\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0181 - val_loss: 8.1516\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2721 - val_loss: 8.9024\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1499 - val_loss: 8.0968\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.1587 - val_loss: 8.3663\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3521 - val_loss: 8.3272\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0384 - val_loss: 8.0121\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0588 - val_loss: 8.3370\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1229 - val_loss: 8.2291\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1751 - val_loss: 8.1345\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0410 - val_loss: 8.3850\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1763 - val_loss: 8.1779\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4884 - val_loss: 8.8823\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4595 - val_loss: 8.8579\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1572 - val_loss: 8.4424\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1055 - val_loss: 8.4671\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3330 - val_loss: 7.7923\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9961 - val_loss: 8.8985\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2931 - val_loss: 8.4921\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0333 - val_loss: 8.2189\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9962 - val_loss: 8.5643\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2054 - val_loss: 8.2007\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1974 - val_loss: 8.7990\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1044 - val_loss: 7.9089\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0135 - val_loss: 8.4724\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0445 - val_loss: 8.6353\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 3.9791 - val_loss: 8.2297\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1268 - val_loss: 8.3656\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0268 - val_loss: 8.2720\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0992 - val_loss: 8.4942\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1022 - val_loss: 8.5148\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0957 - val_loss: 8.1385\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1397 - val_loss: 8.1887\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0171 - val_loss: 8.3857\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2696 - val_loss: 8.4315\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7145 - val_loss: 9.8182\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8287 - val_loss: 8.3425\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0670 - val_loss: 9.0625\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1716 - val_loss: 8.2946\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1872 - val_loss: 8.4043\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4360 - val_loss: 8.8398\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2089 - val_loss: 8.3385\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2962 - val_loss: 8.3357\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0351 - val_loss: 8.4304\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.0133 - val_loss: 8.5650\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3219 - val_loss: 8.1626\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 3.9160 - val_loss: 8.7123\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9679 - val_loss: 8.4844\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6426 - val_loss: 8.1581\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.6401 - val_loss: 9.1538\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 4.2226 - val_loss: 8.5428\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3677 - val_loss: 9.2481\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1541 - val_loss: 8.1894\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9832 - val_loss: 8.2406\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9459 - val_loss: 8.3739\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9687 - val_loss: 8.8125\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0650 - val_loss: 8.1328\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3908 - val_loss: 9.3429\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0651 - val_loss: 8.8859\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4417 - val_loss: 9.2883\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4840 - val_loss: 8.3723\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3801 - val_loss: 8.6126\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1837 - val_loss: 8.4180\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9864 - val_loss: 8.5062\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2106 - val_loss: 9.0180\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4855 - val_loss: 8.0899\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8112 - val_loss: 9.0674\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0657 - val_loss: 8.2170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0020 - val_loss: 8.5264\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0110 - val_loss: 8.4901\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0723 - val_loss: 8.5220\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3416 - val_loss: 8.5804\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2707 - val_loss: 8.3353\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1021 - val_loss: 9.0567\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.4242 - val_loss: 8.8382\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1694 - val_loss: 9.1622\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.5532 - val_loss: 8.1965\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9576 - val_loss: 8.0616\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0381 - val_loss: 8.2062\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0726 - val_loss: 8.3926\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0882 - val_loss: 8.1517\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9856 - val_loss: 8.4174\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9958 - val_loss: 8.0395\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9868 - val_loss: 8.2545\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2793 - val_loss: 8.4998\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0356 - val_loss: 8.3010\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0808 - val_loss: 8.3365\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9098 - val_loss: 8.3495\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1768 - val_loss: 8.9496\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1483 - val_loss: 8.3223\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0247 - val_loss: 8.4030\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9811 - val_loss: 8.4419\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0911 - val_loss: 8.7522\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9962 - val_loss: 8.2133\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9408 - val_loss: 8.5187\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9723 - val_loss: 8.0863\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9138 - val_loss: 8.3498\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9101 - val_loss: 8.2767\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0839 - val_loss: 8.3362\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0419 - val_loss: 8.2751\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0748 - val_loss: 8.1104\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0432 - val_loss: 8.3865\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1427 - val_loss: 8.0444\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0181 - val_loss: 8.5149\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9947 - val_loss: 8.6001\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0342 - val_loss: 8.8772\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9990 - val_loss: 8.1130\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2526 - val_loss: 8.2804\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3036 - val_loss: 8.2491\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9542 - val_loss: 8.0839\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1186 - val_loss: 8.7568\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4386 - val_loss: 8.1197\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.2856 - val_loss: 8.6497\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1803 - val_loss: 8.2033\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9187 - val_loss: 8.6136\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9665 - val_loss: 8.3878\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0922 - val_loss: 8.1585\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2979 - val_loss: 8.3740\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0262 - val_loss: 8.1423\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0699 - val_loss: 8.2831\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0249 - val_loss: 8.2907\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0556 - val_loss: 7.9549\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1266 - val_loss: 8.1467\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1023 - val_loss: 8.9620\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2636 - val_loss: 8.7792\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8765 - val_loss: 8.7880\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.3226 - val_loss: 8.5626\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4457 - val_loss: 8.3928\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.0282 - val_loss: 9.2513\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4599 - val_loss: 8.0966\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2091 - val_loss: 7.9788\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0374 - val_loss: 8.4009\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0399 - val_loss: 8.4618\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.9061 - val_loss: 8.2235\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 3.9153 - val_loss: 8.0784\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8956 - val_loss: 8.1099\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.0420 - val_loss: 8.1054\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2822 - val_loss: 8.9226\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0524 - val_loss: 8.3959\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8872 - val_loss: 8.6609\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3038 - val_loss: 8.1115\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1359 - val_loss: 8.2280\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0535 - val_loss: 8.4412\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9622 - val_loss: 8.1192\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9706 - val_loss: 9.1465\n",
      "Epoch 920/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.2673 - val_loss: 7.9803\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.9404 - val_loss: 8.1637\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2731 - val_loss: 9.1257\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2851 - val_loss: 8.6010\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9183 - val_loss: 8.6013\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9575 - val_loss: 7.9371\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8723 - val_loss: 8.1852\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9501 - val_loss: 8.1283\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9159 - val_loss: 8.6616\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0803 - val_loss: 8.1020\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9509 - val_loss: 8.2248\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8994 - val_loss: 8.2666\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0020 - val_loss: 7.8631\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0091 - val_loss: 8.4775\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8684 - val_loss: 8.5621\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0503 - val_loss: 8.1104\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9825 - val_loss: 8.1514\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.889 - 0s 116us/step - loss: 3.9420 - val_loss: 8.2250\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 3.9809 - val_loss: 8.2881\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9679 - val_loss: 8.4770\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2679 - val_loss: 8.0517\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8940 - val_loss: 8.2886\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0518 - val_loss: 8.5645\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9882 - val_loss: 8.2512\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9725 - val_loss: 8.3065\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0658 - val_loss: 8.1263\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9266 - val_loss: 8.7639\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0026 - val_loss: 8.4839\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3588 - val_loss: 9.1893\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0329 - val_loss: 8.6732\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3937 - val_loss: 8.2939\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9341 - val_loss: 8.0156\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8932 - val_loss: 8.0027\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9390 - val_loss: 8.4214\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9239 - val_loss: 8.3038\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0230 - val_loss: 8.6122\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0652 - val_loss: 8.2003\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0600 - val_loss: 8.3627\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1989 - val_loss: 8.8898\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0704 - val_loss: 8.1313\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9586 - val_loss: 8.2810\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.9441 - val_loss: 8.2888\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1428 - val_loss: 8.1086\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0854 - val_loss: 8.3678\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8829 - val_loss: 8.7527\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9392 - val_loss: 8.5370\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0494 - val_loss: 8.2703\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2711 - val_loss: 8.4480\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0097 - val_loss: 8.4335\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7827 - val_loss: 8.8016\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.6039 - val_loss: 8.7177\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4510 - val_loss: 9.6224\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4928 - val_loss: 8.1199\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4123 - val_loss: 8.7936\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2080 - val_loss: 8.6056\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.1048 - val_loss: 7.8758\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0466 - val_loss: 8.0905\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8079 - val_loss: 8.1883\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0209 - val_loss: 8.3733\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9168 - val_loss: 8.3645\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9247 - val_loss: 8.2375\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8810 - val_loss: 8.4031\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8517 - val_loss: 8.1971\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0884 - val_loss: 9.0565\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9006 - val_loss: 8.3135\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1928 - val_loss: 9.2571\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1228 - val_loss: 8.7616\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7898 - val_loss: 10.4235\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1737 - val_loss: 8.6609\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3682 - val_loss: 8.8134\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1535 - val_loss: 8.1695\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9687 - val_loss: 8.6985\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0771 - val_loss: 8.3625\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9275 - val_loss: 8.1893\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9091 - val_loss: 8.1570\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2742 - val_loss: 8.6827\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2708 - val_loss: 8.9043\n",
      "Epoch 997/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 3.9187 - val_loss: 8.5390\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1245 - val_loss: 8.4916\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9757 - val_loss: 8.0658\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8720 - val_loss: 8.2767\n",
      "7.058238966990325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 5.39351046e-01,  2.52797574e-01, -2.91687250e-01,\n",
       "          3.10475469e+00, -1.72136676e+00,  7.69018590e-01,\n",
       "          4.07023478e+00, -1.13834202e+00, -2.09590507e+00,\n",
       "          2.30160117e+00],\n",
       "        [ 3.92183781e-01, -2.30618167e+00,  1.96762800e+00,\n",
       "          5.75860977e-01,  7.63407528e-01,  1.36196065e+00,\n",
       "         -2.31887794e+00,  1.99672186e+00, -6.12289727e-01,\n",
       "          5.58820292e-02],\n",
       "        [-6.54923737e-01,  5.40605299e-02,  6.69640124e-01,\n",
       "         -1.34657049e+00,  7.50180930e-02, -2.54732847e-01,\n",
       "          4.66212668e-02, -7.82372296e-01, -5.17966413e+00,\n",
       "         -6.72307730e-01],\n",
       "        [ 3.13650757e-01,  9.98466074e-01,  1.78901744e+00,\n",
       "          8.60540792e-02,  2.94427752e-01, -8.86224806e-01,\n",
       "          2.59038520e+00, -1.97178200e-01,  9.90088582e-01,\n",
       "         -1.30355406e+00],\n",
       "        [-2.90753692e-02, -8.51105809e-01,  2.22427726e-01,\n",
       "         -2.09354952e-01,  1.27487222e-03, -7.97286332e-02,\n",
       "         -4.42562878e-01,  9.56673846e-02, -1.48826385e+00,\n",
       "         -9.74260092e-01],\n",
       "        [ 3.55737865e-01, -9.57165539e-01, -2.06709099e+00,\n",
       "          1.58970797e+00,  2.72354662e-01, -2.27554369e+00,\n",
       "         -8.44194233e-01,  6.87782541e-02,  4.41743713e-03,\n",
       "          1.09223478e-01],\n",
       "        [ 3.31063360e-01, -1.97690058e+00,  2.77563721e-01,\n",
       "         -1.75644636e-01,  4.65791374e-01, -1.84195173e+00,\n",
       "         -1.17887974e-01,  7.07728326e-01, -2.36399817e+00,\n",
       "          2.39037633e+00]], dtype=float32),\n",
       " array([-1.2514707 ,  1.8114437 ,  0.68506795,  1.9221203 , -1.0307177 ,\n",
       "        -2.2290194 ,  1.2936896 , -1.5113373 ,  1.1584626 ,  1.8056483 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.39774087, -0.2505833 ,  0.28708246,  0.6835585 , -0.39833963,\n",
       "         -0.09420919,  0.02422995, -0.45150974, -0.02627984,  0.16820368],\n",
       "        [ 1.1409177 , -1.2206494 , -0.43261185,  0.48653457,  0.99339527,\n",
       "          0.7325218 , -0.97459793, -0.9192813 , -0.901987  , -1.1077591 ],\n",
       "        [-0.4202312 ,  0.49588913,  0.16771603,  0.0681956 , -0.22822742,\n",
       "         -0.36769506,  0.11403758, -0.05445462,  0.9392138 ,  0.2591575 ],\n",
       "        [-0.37753883,  0.6699133 ,  0.14091296, -1.0314617 , -0.1071806 ,\n",
       "         -0.6209522 ,  0.6106669 ,  1.0413067 ,  0.21993296,  0.19620232],\n",
       "        [ 1.1459867 , -0.75790375, -0.94986916,  1.2092731 ,  0.7185718 ,\n",
       "          0.68861365, -0.9028994 , -1.1327062 , -0.37343588, -0.06521418],\n",
       "        [ 0.68291354, -0.3606518 , -0.1946951 ,  0.6342974 ,  0.2292606 ,\n",
       "         -0.32510743,  0.38073236, -0.559733  ,  0.17000002, -0.404111  ],\n",
       "        [ 1.502585  , -0.9504772 , -1.389208  ,  1.4620197 ,  1.071435  ,\n",
       "          1.4687771 , -0.6509967 , -0.6364622 , -1.0778089 , -0.23238362],\n",
       "        [ 0.7316466 , -0.9363856 , -0.90947753,  0.69515204,  0.5024882 ,\n",
       "          1.3177574 , -0.40499005, -1.1439732 , -0.28814065, -0.26083317],\n",
       "        [-0.42073107,  0.17954187, -0.14833894, -0.6979837 , -0.48629054,\n",
       "         -0.5980679 ,  0.5091761 ,  0.63027364, -0.10735536, -0.39627886],\n",
       "        [-0.7871072 , -0.2757855 , -0.12573706, -0.74622524,  0.12030364,\n",
       "         -0.15273763,  0.21779075,  0.7512153 ,  0.03219263,  0.45211837]],\n",
       "       dtype=float32),\n",
       " array([-1.4489776,  1.3354415,  1.2936059, -1.4454014, -1.2889422,\n",
       "        -1.4292747,  1.2528248,  1.4156854,  1.1425269,  1.104558 ],\n",
       "       dtype=float32),\n",
       " array([[-1.2832875 ],\n",
       "        [ 0.70630157],\n",
       "        [ 0.6014944 ],\n",
       "        [-1.3320185 ],\n",
       "        [-0.48484176],\n",
       "        [-1.1605818 ],\n",
       "        [ 0.44597095],\n",
       "        [ 1.0649775 ],\n",
       "        [ 0.25626874],\n",
       "        [ 0.2409861 ]], dtype=float32),\n",
       " array([1.5454656], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_5(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure5_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 448.6657 - val_loss: 207.0813\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 108.1012 - val_loss: 81.2527\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 40.8973 - val_loss: 40.3845\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 21.7130 - val_loss: 25.7712\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 17.6837 - val_loss: 18.3987\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 13.4999 - val_loss: 15.5884\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 11.2799 - val_loss: 15.0613\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 11.1189 - val_loss: 13.5257\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.6489 - val_loss: 12.8267\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.1365 - val_loss: 12.3037\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.6690 - val_loss: 10.9556\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0806 - val_loss: 12.3495\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0912 - val_loss: 11.2003\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.7043 - val_loss: 11.2785\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4260 - val_loss: 10.9464\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3221 - val_loss: 10.8506\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2518 - val_loss: 11.6304\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.2440 - val_loss: 11.2216\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2067 - val_loss: 11.3869\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1945 - val_loss: 11.4290\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9930 - val_loss: 10.9158\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.6269 - val_loss: 11.2157\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1718 - val_loss: 11.2057\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0267 - val_loss: 10.8285\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9132 - val_loss: 11.4516\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8490 - val_loss: 10.9361\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7434 - val_loss: 11.4778\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6832 - val_loss: 11.3678\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6126 - val_loss: 11.5865\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6842 - val_loss: 11.3489\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5261 - val_loss: 11.4676\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6805 - val_loss: 10.8390\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7063 - val_loss: 10.6356\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7529 - val_loss: 11.1971\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.6373 - val_loss: 11.0727\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5960 - val_loss: 10.9030\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4865 - val_loss: 10.7436\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3949 - val_loss: 10.8726\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4269 - val_loss: 10.9752\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3279 - val_loss: 11.2655\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6363 - val_loss: 10.8534\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6016 - val_loss: 11.1606\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8098 - val_loss: 10.6669\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3879 - val_loss: 11.7922\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1017 - val_loss: 10.6226\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1496 - val_loss: 12.7941\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1387 - val_loss: 10.6392\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3929 - val_loss: 10.5570\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2978 - val_loss: 11.0954\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4515 - val_loss: 10.6288\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4588 - val_loss: 10.6639\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0711 - val_loss: 10.6016\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1308 - val_loss: 10.1891\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0992 - val_loss: 10.0579\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0505 - val_loss: 10.4533\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2723 - val_loss: 10.1718\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.3472 - val_loss: 10.5590\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2508 - val_loss: 10.5022\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3879 - val_loss: 10.1098\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0490 - val_loss: 9.9518\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1033 - val_loss: 10.0031\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0958 - val_loss: 10.0328\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0375 - val_loss: 10.2837\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4990 - val_loss: 10.6680\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2837 - val_loss: 10.8943\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9534 - val_loss: 10.2952\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7390 - val_loss: 10.4572\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 117us/step - loss: 6.0614 - val_loss: 10.0177\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0055 - val_loss: 10.0504\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9849 - val_loss: 9.8993\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1066 - val_loss: 10.1476\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9857 - val_loss: 9.5616\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9612 - val_loss: 9.9004\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2359 - val_loss: 10.4981\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3187 - val_loss: 9.8857\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0451 - val_loss: 9.8106\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8957 - val_loss: 9.7166\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9316 - val_loss: 9.6095\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1994 - val_loss: 9.5666\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0899 - val_loss: 9.7602\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0697 - val_loss: 9.9396\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2224 - val_loss: 9.6338\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0572 - val_loss: 9.7100\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0819 - val_loss: 9.7498\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9556 - val_loss: 9.5443\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8496 - val_loss: 9.4466\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9490 - val_loss: 9.8526\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2933 - val_loss: 9.7543\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1193 - val_loss: 9.8033\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9245 - val_loss: 9.8213\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9065 - val_loss: 10.0775\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0875 - val_loss: 9.6286\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4201 - val_loss: 9.9734\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8713 - val_loss: 9.6846\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2406 - val_loss: 9.8901\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1979 - val_loss: 9.5952\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9257 - val_loss: 9.5461\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8194 - val_loss: 9.8680\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8603 - val_loss: 9.3789\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9117 - val_loss: 9.4398\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9035 - val_loss: 9.5094\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9418 - val_loss: 9.6269\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7890 - val_loss: 9.9767\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1209 - val_loss: 9.9285\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4200 - val_loss: 10.4043\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2526 - val_loss: 9.3606\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3234 - val_loss: 9.4539\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5064 - val_loss: 10.5888\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0350 - val_loss: 9.9544\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8998 - val_loss: 9.7773\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9349 - val_loss: 9.3125\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8871 - val_loss: 9.4833\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0362 - val_loss: 10.4802\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9578 - val_loss: 9.5698\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9833 - val_loss: 9.8906\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8532 - val_loss: 9.6378\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8212 - val_loss: 9.6600\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7756 - val_loss: 9.3236\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7797 - val_loss: 9.5521\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8202 - val_loss: 9.4753\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7333 - val_loss: 9.6836\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7092 - val_loss: 9.8691\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9060 - val_loss: 9.1700\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6913 - val_loss: 9.6780\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8217 - val_loss: 9.5847\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7253 - val_loss: 9.4018\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9812 - val_loss: 9.3183\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2302 - val_loss: 9.5022\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9441 - val_loss: 9.4308\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6641 - val_loss: 9.3710\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6986 - val_loss: 9.5672\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6700 - val_loss: 9.3399\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6474 - val_loss: 9.5613\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7485 - val_loss: 9.5258\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7137 - val_loss: 9.7467\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7674 - val_loss: 9.8200\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8012 - val_loss: 9.5905\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8321 - val_loss: 9.9017\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8042 - val_loss: 8.8976\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8755 - val_loss: 9.4124\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8411 - val_loss: 11.1895\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0578 - val_loss: 9.8672\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3865 - val_loss: 11.1970\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3498 - val_loss: 9.4701\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3644 - val_loss: 9.0961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7270 - val_loss: 9.9374\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0053 - val_loss: 9.3762\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0162 - val_loss: 9.3331\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8221 - val_loss: 9.6563\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7050 - val_loss: 9.2745\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.7007 - val_loss: 10.3419\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8426 - val_loss: 9.2636\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7712 - val_loss: 10.5358\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8837 - val_loss: 9.4324\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6859 - val_loss: 10.6690\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7816 - val_loss: 9.2403\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0802 - val_loss: 9.1527\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8268 - val_loss: 9.5633\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7054 - val_loss: 9.2073\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5788 - val_loss: 9.8504\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6062 - val_loss: 9.2970\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9110 - val_loss: 11.1982\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2899 - val_loss: 9.3883\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0894 - val_loss: 9.5531\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7916 - val_loss: 9.6085\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7205 - val_loss: 8.9821\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7908 - val_loss: 9.6344\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6765 - val_loss: 9.2530\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8524 - val_loss: 9.1943\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6122 - val_loss: 9.6119\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7999 - val_loss: 9.3837\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6496 - val_loss: 9.5520\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5315 - val_loss: 9.3787\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5956 - val_loss: 9.4172\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6162 - val_loss: 9.0776\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6814 - val_loss: 9.3691\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7850 - val_loss: 9.8364\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6970 - val_loss: 9.1099\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7321 - val_loss: 9.6317\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6954 - val_loss: 9.9419\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7269 - val_loss: 9.1787\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7605 - val_loss: 9.3654\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5401 - val_loss: 9.4146\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6635 - val_loss: 8.9472\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5910 - val_loss: 9.4097\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4848 - val_loss: 9.3112\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6037 - val_loss: 9.7690\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7494 - val_loss: 8.9455\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8173 - val_loss: 9.1788\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5656 - val_loss: 10.2748\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6628 - val_loss: 9.1617\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5331 - val_loss: 9.5145\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4335 - val_loss: 9.1868\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4095 - val_loss: 9.5477\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5363 - val_loss: 9.3234\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4695 - val_loss: 9.1126\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4427 - val_loss: 9.4174\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5133 - val_loss: 9.0126\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4066 - val_loss: 9.2146\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4338 - val_loss: 9.3656\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4954 - val_loss: 9.2063\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4884 - val_loss: 9.3343\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4423 - val_loss: 9.4435\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3448 - val_loss: 9.2325\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4658 - val_loss: 9.3017\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4929 - val_loss: 9.1926\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7478 - val_loss: 10.9624\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7839 - val_loss: 9.5475\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7889 - val_loss: 9.3368\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4266 - val_loss: 9.3319\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4803 - val_loss: 9.4963\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4714 - val_loss: 9.2480\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3362 - val_loss: 9.6083\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3789 - val_loss: 9.5974\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7979 - val_loss: 9.6121\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9813 - val_loss: 11.1265\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7714 - val_loss: 9.5288\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6585 - val_loss: 9.5133\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5816 - val_loss: 9.5978\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0753 - val_loss: 10.2829\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5623 - val_loss: 10.8707\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0297 - val_loss: 9.7829\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.4236 - val_loss: 9.5647\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3441 - val_loss: 9.7945\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4392 - val_loss: 9.7096\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4102 - val_loss: 9.4880\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6271 - val_loss: 9.3974\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5378 - val_loss: 9.6647\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3846 - val_loss: 9.2341\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4057 - val_loss: 9.2605\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3046 - val_loss: 9.3541\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2806 - val_loss: 9.4128\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2904 - val_loss: 9.8290\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5286 - val_loss: 9.8241\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5341 - val_loss: 10.4381\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4274 - val_loss: 9.3978\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4485 - val_loss: 9.7619\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3629 - val_loss: 9.5413\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2943 - val_loss: 9.6215\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3518 - val_loss: 9.3977\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4753 - val_loss: 9.5049\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3214 - val_loss: 9.6016\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3931 - val_loss: 9.8282\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4668 - val_loss: 9.4691\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2968 - val_loss: 9.7709\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5251 - val_loss: 10.2752\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3467 - val_loss: 9.8330\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2797 - val_loss: 9.5058\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3444 - val_loss: 9.5062\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3945 - val_loss: 9.8009\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2968 - val_loss: 9.6805\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2910 - val_loss: 9.7773\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2431 - val_loss: 9.3135\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3740 - val_loss: 10.2358\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5636 - val_loss: 9.7544\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4882 - val_loss: 10.6843\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4932 - val_loss: 9.5535\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4810 - val_loss: 10.3130\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2858 - val_loss: 9.6380\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1632 - val_loss: 9.6360\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2566 - val_loss: 9.5304\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3286 - val_loss: 9.5550\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6275 - val_loss: 10.6771\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6835 - val_loss: 9.5725\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4212 - val_loss: 9.7070\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9421 - val_loss: 11.0374\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8073 - val_loss: 9.7294\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4640 - val_loss: 9.6018\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1737 - val_loss: 9.6928\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3690 - val_loss: 9.3700\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3704 - val_loss: 10.3684\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4294 - val_loss: 9.9317\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1841 - val_loss: 9.5960\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1833 - val_loss: 9.5940\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4268 - val_loss: 10.8991\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6402 - val_loss: 9.3174\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2361 - val_loss: 9.9701\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2452 - val_loss: 9.4579\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2538 - val_loss: 11.7192\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9018 - val_loss: 9.5885\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4451 - val_loss: 9.8109\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4778 - val_loss: 9.8561\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1684 - val_loss: 9.6539\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4026 - val_loss: 9.6446\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2876 - val_loss: 10.9704\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4708 - val_loss: 9.4278\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2227 - val_loss: 9.8083\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3526 - val_loss: 9.8011\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2526 - val_loss: 11.4811\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3808 - val_loss: 10.4538\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3835 - val_loss: 10.4475\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2219 - val_loss: 9.6763\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1947 - val_loss: 9.7165\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2762 - val_loss: 9.8218\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3652 - val_loss: 9.9084\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2563 - val_loss: 10.1576\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3421 - val_loss: 9.7981\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4024 - val_loss: 9.6369\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3645 - val_loss: 9.6639\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 5.4240 - val_loss: 11.2457\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5873 - val_loss: 10.0238\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2687 - val_loss: 10.1603\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2246 - val_loss: 10.2935\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1661 - val_loss: 10.3696\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.3598 - val_loss: 9.4998\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3125 - val_loss: 10.4662\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2331 - val_loss: 10.3752\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2912 - val_loss: 9.8928\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3791 - val_loss: 9.7259\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0926 - val_loss: 10.1080\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2061 - val_loss: 9.9922\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3303 - val_loss: 10.2536\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2744 - val_loss: 9.9836\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6836 - val_loss: 12.6275\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9860 - val_loss: 10.0243\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0773 - val_loss: 10.6886\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2053 - val_loss: 9.9351\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.1761 - val_loss: 10.7017\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0252 - val_loss: 9.8329\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3025 - val_loss: 9.9494\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0399 - val_loss: 10.0287\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0986 - val_loss: 10.3096\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0427 - val_loss: 10.3563\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1218 - val_loss: 10.0377\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1570 - val_loss: 10.2182\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1273 - val_loss: 9.9079\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2234 - val_loss: 10.2922\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0677 - val_loss: 10.0065\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1059 - val_loss: 10.4346\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0341 - val_loss: 10.4992\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0453 - val_loss: 10.3839\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1746 - val_loss: 10.0422\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1527 - val_loss: 10.1890\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0455 - val_loss: 10.0945\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0789 - val_loss: 10.7325\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2597 - val_loss: 10.4085\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1447 - val_loss: 10.1035\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0057 - val_loss: 10.0518\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1594 - val_loss: 9.9443\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2183 - val_loss: 10.2881\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5689 - val_loss: 11.1691\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3748 - val_loss: 10.6591\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1164 - val_loss: 10.2416\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4313 - val_loss: 11.3675\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4555 - val_loss: 10.1981\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4516 - val_loss: 10.1119\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2682 - val_loss: 10.9048\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1730 - val_loss: 10.2258\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0329 - val_loss: 10.6611\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3538 - val_loss: 10.1879\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3011 - val_loss: 10.0743\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2864 - val_loss: 11.1201\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6273 - val_loss: 10.0420\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2108 - val_loss: 10.2927\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9963 - val_loss: 10.1957\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0336 - val_loss: 10.3216\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1150 - val_loss: 10.6620\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9505 - val_loss: 10.2260\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1102 - val_loss: 10.3104\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6144 - val_loss: 10.3031\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4254 - val_loss: 11.8560\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2970 - val_loss: 9.7776\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1748 - val_loss: 10.3573\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3489 - val_loss: 10.6524\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5939 - val_loss: 11.0784\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3357 - val_loss: 10.8630\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1217 - val_loss: 10.2505\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1308 - val_loss: 10.1932\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9509 - val_loss: 10.1816\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0469 - val_loss: 10.5172\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0247 - val_loss: 10.7276\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9575 - val_loss: 10.3860\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9222 - val_loss: 10.4562\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8703 - val_loss: 9.9859\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1739 - val_loss: 10.9419\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0030 - val_loss: 10.4816\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.0653 - val_loss: 10.2361\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0088 - val_loss: 10.6576\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8936 - val_loss: 10.3133\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0060 - val_loss: 11.3104\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2861 - val_loss: 10.4788\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9822 - val_loss: 10.5827\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0312 - val_loss: 10.1666\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0249 - val_loss: 10.1770\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3017 - val_loss: 11.4004\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4329 - val_loss: 10.5516\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1741 - val_loss: 10.1781\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1809 - val_loss: 10.6584\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2095 - val_loss: 9.9702\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9767 - val_loss: 10.1846\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2357 - val_loss: 11.6629\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3967 - val_loss: 10.4797\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1650 - val_loss: 11.0212\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9255 - val_loss: 10.2932\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2321 - val_loss: 10.1688\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2535 - val_loss: 11.6402\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2834 - val_loss: 10.7884\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4286 - val_loss: 10.8284\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2620 - val_loss: 10.4200\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9731 - val_loss: 10.0993\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.8761 - val_loss: 10.5995\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8496 - val_loss: 10.5475\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9930 - val_loss: 10.6074\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9242 - val_loss: 10.2982\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8839 - val_loss: 10.3213\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9764 - val_loss: 10.9658\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0005 - val_loss: 10.4253\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9744 - val_loss: 10.3361\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8526 - val_loss: 10.6487\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1863 - val_loss: 10.3753\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9639 - val_loss: 10.7175\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8178 - val_loss: 10.4468\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7906 - val_loss: 10.7040\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9067 - val_loss: 10.3026\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0231 - val_loss: 11.3063\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0911 - val_loss: 10.2184\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9412 - val_loss: 10.7082\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8436 - val_loss: 10.7987\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.8313 - val_loss: 10.6680\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9507 - val_loss: 10.2501\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5003 - val_loss: 12.3482\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6052 - val_loss: 10.4570\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0307 - val_loss: 11.0758\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9092 - val_loss: 10.2767\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1550 - val_loss: 10.9525\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8472 - val_loss: 10.3963\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8994 - val_loss: 10.3221\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9539 - val_loss: 10.9088\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8246 - val_loss: 10.4839\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0911 - val_loss: 10.9053\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8569 - val_loss: 10.6884\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8386 - val_loss: 10.4573\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9392 - val_loss: 11.1817\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9916 - val_loss: 10.5371\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8867 - val_loss: 10.8726\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8397 - val_loss: 10.4558\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8929 - val_loss: 10.3092\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0250 - val_loss: 11.0343\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8800 - val_loss: 10.4430\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0553 - val_loss: 11.2872\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9774 - val_loss: 10.6118\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9081 - val_loss: 11.1648\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0667 - val_loss: 10.5225\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1937 - val_loss: 10.5990\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1439 - val_loss: 11.9270\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8956 - val_loss: 10.6711\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1224 - val_loss: 12.4494\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0042 - val_loss: 10.3821\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0236 - val_loss: 10.3672\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0679 - val_loss: 11.5988\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1736 - val_loss: 11.4920\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3248 - val_loss: 12.9156\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9631 - val_loss: 10.8783\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 90us/step - loss: 5.3820 - val_loss: 10.9428\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0778 - val_loss: 10.9966\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7964 - val_loss: 10.6986\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7953 - val_loss: 11.0792\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.8138 - val_loss: 10.9713\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8107 - val_loss: 10.6363\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7991 - val_loss: 10.5471\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8063 - val_loss: 10.3636\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1459 - val_loss: 11.0433\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7736 - val_loss: 10.8597\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9727 - val_loss: 11.9941\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5527 - val_loss: 10.5665\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9461 - val_loss: 11.1664\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8381 - val_loss: 11.0502\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9865 - val_loss: 10.4010\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8577 - val_loss: 10.5982\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7558 - val_loss: 10.5848\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7643 - val_loss: 11.5263\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7680 - val_loss: 10.6349\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1389 - val_loss: 11.5695\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7011 - val_loss: 10.6999\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1496 - val_loss: 11.0532\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7774 - val_loss: 11.0834\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7978 - val_loss: 10.8191\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6980 - val_loss: 12.4478\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9961 - val_loss: 10.8190\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0075 - val_loss: 10.8356\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8332 - val_loss: 11.0277\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8634 - val_loss: 11.1850\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7338 - val_loss: 11.7413\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9142 - val_loss: 11.1454\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8953 - val_loss: 11.1809\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8303 - val_loss: 10.8061\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8698 - val_loss: 11.7298\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8806 - val_loss: 10.4099\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9876 - val_loss: 11.1789\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8019 - val_loss: 11.0527\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8473 - val_loss: 11.1366\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7369 - val_loss: 11.2678\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8503 - val_loss: 11.3960\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6819 - val_loss: 10.9657\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7855 - val_loss: 11.4200\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7218 - val_loss: 10.8354\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9096 - val_loss: 10.9023\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9089 - val_loss: 11.1397\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.8905 - val_loss: 11.2797\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6937 - val_loss: 10.9821\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7034 - val_loss: 11.4261\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5496 - val_loss: 10.7415\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7352 - val_loss: 11.6143\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7042 - val_loss: 10.9107\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0829 - val_loss: 10.7017\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1837 - val_loss: 11.1552\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7194 - val_loss: 11.4358\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6187 - val_loss: 10.9332\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7375 - val_loss: 12.0692\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8442 - val_loss: 10.8290\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8203 - val_loss: 10.8118\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6635 - val_loss: 11.3971\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5984 - val_loss: 11.4472\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5674 - val_loss: 11.3512\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5641 - val_loss: 11.5198\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7772 - val_loss: 10.8270\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5556 - val_loss: 10.6429\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8418 - val_loss: 11.4056\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5091 - val_loss: 11.2551\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5343 - val_loss: 11.1339\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5477 - val_loss: 10.8649\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5800 - val_loss: 11.1516\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6174 - val_loss: 11.2394\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5233 - val_loss: 11.1034\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5319 - val_loss: 11.5529\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5558 - val_loss: 10.9874\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6839 - val_loss: 10.8801\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6701 - val_loss: 12.3173\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0861 - val_loss: 11.0749\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1881 - val_loss: 11.3803\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 103us/step - loss: 4.8391 - val_loss: 13.2505\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2049 - val_loss: 10.8371\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7611 - val_loss: 10.8985\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7991 - val_loss: 11.4146\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6835 - val_loss: 11.4868\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4725 - val_loss: 11.1581\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4744 - val_loss: 11.5966\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4679 - val_loss: 10.9616\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4658 - val_loss: 11.3574\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6539 - val_loss: 10.8258\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6600 - val_loss: 11.2346\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5053 - val_loss: 11.4357\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5896 - val_loss: 10.9961\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7221 - val_loss: 11.2792\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1007 - val_loss: 12.1523\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9183 - val_loss: 10.7670\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6458 - val_loss: 11.1161\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5481 - val_loss: 11.4961\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4215 - val_loss: 11.0441\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6215 - val_loss: 10.9833\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5493 - val_loss: 11.8049\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3653 - val_loss: 11.3495\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5094 - val_loss: 11.3494\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4626 - val_loss: 11.4078\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4086 - val_loss: 10.8268\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4683 - val_loss: 12.1244\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4745 - val_loss: 11.3664\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9106 - val_loss: 12.2130\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5864 - val_loss: 10.7456\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6399 - val_loss: 10.7518\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4948 - val_loss: 11.5164\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5797 - val_loss: 11.1844\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7962 - val_loss: 12.4529\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8688 - val_loss: 11.5680\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5455 - val_loss: 11.4455\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5632 - val_loss: 11.5699\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3787 - val_loss: 11.3894\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4136 - val_loss: 11.7540\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4508 - val_loss: 11.1265\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4565 - val_loss: 12.0942\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6496 - val_loss: 10.8728\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5354 - val_loss: 11.4270\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3879 - val_loss: 11.9520\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3788 - val_loss: 11.3891\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3923 - val_loss: 11.8960\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7116 - val_loss: 10.8479\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7991 - val_loss: 11.0500\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6124 - val_loss: 11.6465\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4828 - val_loss: 11.3863\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5047 - val_loss: 12.1962\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6474 - val_loss: 11.7238\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7359 - val_loss: 11.0303\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8566 - val_loss: 11.1277\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3960 - val_loss: 11.2007\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4385 - val_loss: 11.7119\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3739 - val_loss: 11.1305\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4372 - val_loss: 11.9335\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5062 - val_loss: 11.4891\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3798 - val_loss: 12.0019\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3566 - val_loss: 11.1606\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4779 - val_loss: 11.4709\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4720 - val_loss: 11.2212\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5669 - val_loss: 10.8790\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4999 - val_loss: 11.5013\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6661 - val_loss: 11.5033\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3792 - val_loss: 12.3631\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4857 - val_loss: 11.2524\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5492 - val_loss: 11.9718\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3190 - val_loss: 11.2680\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5255 - val_loss: 13.0707\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9310 - val_loss: 11.2938\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5843 - val_loss: 11.1426\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4337 - val_loss: 11.4382\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5565 - val_loss: 11.1538\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6214 - val_loss: 11.2286\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6646 - val_loss: 12.1264\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4190 - val_loss: 11.3552\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 96us/step - loss: 4.4402 - val_loss: 12.2839\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.5124 - val_loss: 11.0071\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5426 - val_loss: 11.9369\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4060 - val_loss: 11.3493\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3851 - val_loss: 11.0978\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3301 - val_loss: 11.3531\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3783 - val_loss: 11.5307\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3857 - val_loss: 11.4538\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3406 - val_loss: 11.0918\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4510 - val_loss: 11.9922\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9918 - val_loss: 11.5719\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8278 - val_loss: 12.3317\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5549 - val_loss: 11.4471\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4414 - val_loss: 12.4112\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5128 - val_loss: 11.1320\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2993 - val_loss: 11.8901\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4889 - val_loss: 11.0648\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4037 - val_loss: 11.3517\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4538 - val_loss: 11.5584\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3260 - val_loss: 11.4694\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3399 - val_loss: 11.9022\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3013 - val_loss: 11.3521\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1788 - val_loss: 13.0224\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5923 - val_loss: 11.3415\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3917 - val_loss: 11.8608\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2522 - val_loss: 11.5868\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2741 - val_loss: 11.5859\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4600 - val_loss: 11.2704\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3781 - val_loss: 12.1514\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5716 - val_loss: 11.5833\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4001 - val_loss: 11.4462\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4969 - val_loss: 11.3547\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4592 - val_loss: 11.1843\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4401 - val_loss: 12.1795\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4068 - val_loss: 11.3764\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3601 - val_loss: 11.4027\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3451 - val_loss: 11.8917\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2825 - val_loss: 11.6684\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2721 - val_loss: 11.6201\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3659 - val_loss: 11.3836\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3068 - val_loss: 11.6321\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3146 - val_loss: 11.5333\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2997 - val_loss: 11.7097\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3345 - val_loss: 11.6707\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3124 - val_loss: 11.5953\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2971 - val_loss: 12.1352\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2943 - val_loss: 11.8411\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4505 - val_loss: 11.2903\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3331 - val_loss: 11.7452\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3484 - val_loss: 11.7679\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4495 - val_loss: 11.8711\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2949 - val_loss: 11.4797\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4109 - val_loss: 11.7047\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4664 - val_loss: 11.4002\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1669 - val_loss: 11.4618\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3572 - val_loss: 11.5373\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3151 - val_loss: 11.2942\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3033 - val_loss: 11.6574\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1905 - val_loss: 11.8132\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5553 - val_loss: 11.5347\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1194 - val_loss: 14.7775\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2666 - val_loss: 11.6580\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3893 - val_loss: 12.6549\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3546 - val_loss: 11.4199\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8208 - val_loss: 11.8058\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4392 - val_loss: 12.3600\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3607 - val_loss: 11.1565\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2994 - val_loss: 12.3982\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8416 - val_loss: 12.4226\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7182 - val_loss: 11.4511\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6098 - val_loss: 12.3934\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5627 - val_loss: 11.4296\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2573 - val_loss: 11.7095\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4664 - val_loss: 12.1661\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4680 - val_loss: 11.4263\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4126 - val_loss: 11.2973\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3086 - val_loss: 12.0407\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 94us/step - loss: 4.2861 - val_loss: 11.4321\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4029 - val_loss: 12.1772\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2294 - val_loss: 11.3390\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1871 - val_loss: 12.4201\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5948 - val_loss: 11.2549\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3884 - val_loss: 11.2429\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6261 - val_loss: 12.9780\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5992 - val_loss: 11.5573\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1201 - val_loss: 13.0168\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5243 - val_loss: 11.5131\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3989 - val_loss: 12.0715\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4425 - val_loss: 11.5881\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2555 - val_loss: 11.6634\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3426 - val_loss: 11.7406\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1329 - val_loss: 11.2725\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.1661 - val_loss: 11.8313\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1602 - val_loss: 11.5295\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1272 - val_loss: 11.6356\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2016 - val_loss: 11.7163\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.1767 - val_loss: 11.5318\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2002 - val_loss: 11.7910\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1707 - val_loss: 11.7072\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3586 - val_loss: 11.3707\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2769 - val_loss: 11.4290\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2329 - val_loss: 12.3786\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3904 - val_loss: 11.4774\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3415 - val_loss: 11.6477\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3239 - val_loss: 12.3020\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5970 - val_loss: 12.0731\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6872 - val_loss: 11.7515\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7296 - val_loss: 12.3276\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2900 - val_loss: 11.0034\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3118 - val_loss: 11.4712\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2905 - val_loss: 11.5245\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1893 - val_loss: 11.5744\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2506 - val_loss: 11.4793\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1687 - val_loss: 12.2026\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4759 - val_loss: 11.6686\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5891 - val_loss: 12.5661\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4206 - val_loss: 11.6744\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5896 - val_loss: 11.6072\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1899 - val_loss: 11.6935\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2201 - val_loss: 11.7999\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2285 - val_loss: 12.1862\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3904 - val_loss: 11.5837\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3997 - val_loss: 11.3594\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3952 - val_loss: 13.0726\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6266 - val_loss: 11.5303\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3006 - val_loss: 11.7965\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2708 - val_loss: 12.0731\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.1654 - val_loss: 11.4036\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4440 - val_loss: 11.7321\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2672 - val_loss: 13.1655\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5389 - val_loss: 11.4938\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0727 - val_loss: 12.9311\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2669 - val_loss: 11.7728\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4761 - val_loss: 11.8609\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7907 - val_loss: 13.9939\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6089 - val_loss: 11.5381\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4199 - val_loss: 12.2938\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3051 - val_loss: 11.5118\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5867 - val_loss: 11.6609\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6792 - val_loss: 13.4504\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2551 - val_loss: 11.9172\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2817 - val_loss: 13.4066\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6030 - val_loss: 11.8593\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5487 - val_loss: 11.5351\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2693 - val_loss: 12.2400\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2209 - val_loss: 11.4202\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8092 - val_loss: 12.8262\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2231 - val_loss: 11.7137\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3462 - val_loss: 11.5670\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1436 - val_loss: 11.8264\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2400 - val_loss: 11.6196\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1653 - val_loss: 11.8473\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2245 - val_loss: 12.3022\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1664 - val_loss: 11.7419\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 4.1379 - val_loss: 11.4827\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3054 - val_loss: 12.7259\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1753 - val_loss: 11.8622\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2006 - val_loss: 12.1380\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2076 - val_loss: 11.8281\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2430 - val_loss: 11.5081\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2690 - val_loss: 11.7008\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.1264 - val_loss: 12.0053\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1912 - val_loss: 11.7505\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.3414 - val_loss: 11.5676\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2330 - val_loss: 12.4322\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3036 - val_loss: 11.9370\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3944 - val_loss: 11.4130\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4016 - val_loss: 12.0722\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2706 - val_loss: 11.9901\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1473 - val_loss: 11.5997\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2254 - val_loss: 12.7080\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.2722 - val_loss: 11.7520\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6023 - val_loss: 11.7269\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1217 - val_loss: 11.8983\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1230 - val_loss: 11.7422\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1856 - val_loss: 11.3558\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1619 - val_loss: 12.2157\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1237 - val_loss: 11.8008\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2346 - val_loss: 12.3376\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2945 - val_loss: 11.8679\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4751 - val_loss: 12.2917\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1488 - val_loss: 11.4508\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4240 - val_loss: 12.0495\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.3129 - val_loss: 11.5752\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1587 - val_loss: 12.0096\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1733 - val_loss: 11.5298\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1462 - val_loss: 12.5986\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1987 - val_loss: 11.7911\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1647 - val_loss: 11.4779\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1476 - val_loss: 11.7656\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0760 - val_loss: 11.2100\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1725 - val_loss: 12.5078\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1864 - val_loss: 11.8233\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1780 - val_loss: 11.8021\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2218 - val_loss: 11.6230\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0336 - val_loss: 11.4197\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1799 - val_loss: 12.4657\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0569 - val_loss: 11.6267\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 4.3411 - val_loss: 13.6405\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.3843 - val_loss: 11.2892\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2582 - val_loss: 11.4004\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4635 - val_loss: 13.2241\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6115 - val_loss: 11.4367\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2617 - val_loss: 11.9909\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1690 - val_loss: 12.4849\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1859 - val_loss: 11.5477\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0997 - val_loss: 12.0564\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2162 - val_loss: 11.5168\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4995 - val_loss: 13.1719\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2416 - val_loss: 11.4572\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0123 - val_loss: 12.3179\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 4.2513 - val_loss: 11.5226\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1710 - val_loss: 11.8798\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0751 - val_loss: 11.5141\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4318 - val_loss: 12.3940\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2578 - val_loss: 11.5995\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0955 - val_loss: 11.9808\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1317 - val_loss: 11.7640\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1434 - val_loss: 12.3805\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3340 - val_loss: 11.3925\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3064 - val_loss: 14.5590\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7934 - val_loss: 11.2752\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2456 - val_loss: 11.5429\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0417 - val_loss: 11.9619\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3254 - val_loss: 11.7727\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6635 - val_loss: 13.6297\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4367 - val_loss: 11.5134\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2915 - val_loss: 12.0822\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2220 - val_loss: 11.6643\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1522 - val_loss: 11.8094\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1953 - val_loss: 11.8498\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.1109 - val_loss: 11.7831\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2002 - val_loss: 11.5837\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0970 - val_loss: 11.5190\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4047 - val_loss: 13.0955\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.2813 - val_loss: 11.6730\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1817 - val_loss: 11.9881\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6520 - val_loss: 13.2185\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3525 - val_loss: 11.5369\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5100 - val_loss: 11.7346\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2090 - val_loss: 12.5335\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3096 - val_loss: 11.8915\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2092 - val_loss: 13.0740\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3214 - val_loss: 11.4161\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1442 - val_loss: 11.5168\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0771 - val_loss: 12.3651\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2047 - val_loss: 11.5411\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4515 - val_loss: 11.4253\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5654 - val_loss: 14.5534\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.7092 - val_loss: 11.2738\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.5013 - val_loss: 12.3627\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3238 - val_loss: 12.0344\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1632 - val_loss: 11.7514\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2026 - val_loss: 12.2674\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1512 - val_loss: 11.3645\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0678 - val_loss: 12.2251\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2972 - val_loss: 11.7207\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9916 - val_loss: 12.1889\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1312 - val_loss: 11.7072\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1960 - val_loss: 11.6396\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2190 - val_loss: 12.1072\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1259 - val_loss: 11.4490\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1420 - val_loss: 11.8920\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1380 - val_loss: 12.5797\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2210 - val_loss: 11.3536\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2024 - val_loss: 11.9727\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1222 - val_loss: 11.4613\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2213 - val_loss: 11.9597\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1456 - val_loss: 13.5105\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.2574 - val_loss: 11.3960\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3610 - val_loss: 11.5549\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4382 - val_loss: 13.4361\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2960 - val_loss: 11.8448\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9595 - val_loss: 11.8037\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9739 - val_loss: 12.0413\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0478 - val_loss: 11.7764\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0201 - val_loss: 11.6843\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0552 - val_loss: 11.7835\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0995 - val_loss: 11.5504\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0655 - val_loss: 11.9777\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0334 - val_loss: 11.3131\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2649 - val_loss: 11.7189\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1597 - val_loss: 12.4849\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1773 - val_loss: 11.6936\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1586 - val_loss: 12.6693\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1367 - val_loss: 11.0310\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0874 - val_loss: 12.7564\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1536 - val_loss: 11.7076\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0059 - val_loss: 12.0803\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3254 - val_loss: 11.7735\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3437 - val_loss: 11.6313\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2100 - val_loss: 12.5804\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1655 - val_loss: 11.8504\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9922 - val_loss: 12.0149\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2117 - val_loss: 11.3290\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1430 - val_loss: 11.5350\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9821 - val_loss: 12.3703\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.3938 - val_loss: 11.7921\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0654 - val_loss: 12.0541\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9859 - val_loss: 11.6800\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0351 - val_loss: 11.9656\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9740 - val_loss: 11.4863\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0264 - val_loss: 11.6935\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 3.9267 - val_loss: 11.5900\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0813 - val_loss: 12.0308\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.0975 - val_loss: 12.1676\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0646 - val_loss: 11.3563\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6130 - val_loss: 13.3548\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 4.1791 - val_loss: 11.4413\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0698 - val_loss: 11.8726\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9965 - val_loss: 11.6507\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9069 - val_loss: 11.7773\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0943 - val_loss: 11.4035\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9727 - val_loss: 12.2578\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1656 - val_loss: 11.5200\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1133 - val_loss: 11.7195\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1127 - val_loss: 11.7376\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8846 - val_loss: 11.4877\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9836 - val_loss: 11.1720\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1522 - val_loss: 12.9204\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2789 - val_loss: 11.7020\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1293 - val_loss: 11.7519\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2778 - val_loss: 12.4766\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0433 - val_loss: 11.2045\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.2442 - val_loss: 13.1373\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0188 - val_loss: 11.8039\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1569 - val_loss: 12.7952\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0948 - val_loss: 11.4348\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9107 - val_loss: 12.2122\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9056 - val_loss: 11.3996\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0371 - val_loss: 12.5109\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 4.0296 - val_loss: 11.7212\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9912 - val_loss: 11.5555\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0334 - val_loss: 12.0099\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3353 - val_loss: 12.2285\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1404 - val_loss: 11.4036\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2458 - val_loss: 11.5902\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.1674 - val_loss: 12.2930\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0387 - val_loss: 11.7260\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1145 - val_loss: 11.3184\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0043 - val_loss: 11.7009\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0206 - val_loss: 11.5283\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9257 - val_loss: 11.7982\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9482 - val_loss: 11.8628\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0249 - val_loss: 12.4452\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1585 - val_loss: 11.2394\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0620 - val_loss: 12.3092\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0412 - val_loss: 11.7938\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0403 - val_loss: 11.6527\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9690 - val_loss: 11.4699\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9823 - val_loss: 11.4630\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9805 - val_loss: 12.1736\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9618 - val_loss: 11.4754\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8799 - val_loss: 11.5187\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9789 - val_loss: 11.8517\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0410 - val_loss: 11.5819\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8543 - val_loss: 11.7702\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0019 - val_loss: 11.5493\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0930 - val_loss: 13.0270\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3815 - val_loss: 11.2187\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9273 - val_loss: 12.2727\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1959 - val_loss: 12.4912\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3304 - val_loss: 11.0688\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3134 - val_loss: 13.0071\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2283 - val_loss: 11.9892\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0094 - val_loss: 11.4090\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2626 - val_loss: 13.5266\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4238 - val_loss: 11.3662\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0412 - val_loss: 12.2167\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9204 - val_loss: 11.4297\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8611 - val_loss: 11.5298\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9325 - val_loss: 12.1022\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9382 - val_loss: 11.5672\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9303 - val_loss: 11.4443\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8807 - val_loss: 11.3634\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1738 - val_loss: 13.4604\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3200 - val_loss: 11.1437\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8596 - val_loss: 11.9691\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0774 - val_loss: 11.8059\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8595 - val_loss: 11.5914\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9448 - val_loss: 12.2453\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9426 - val_loss: 11.3647\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9178 - val_loss: 11.4017\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0487 - val_loss: 12.6240\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1413 - val_loss: 11.2353\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 3.9590 - val_loss: 11.3241\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0375 - val_loss: 11.9289\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8992 - val_loss: 11.7488\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9134 - val_loss: 12.0342\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8932 - val_loss: 11.2928\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9679 - val_loss: 11.3641\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0147 - val_loss: 11.5107\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9446 - val_loss: 11.5352\n",
      "7.679749149387166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.0727436 ,  0.56470597, -2.813895  ,  1.1301001 ,  0.75247073,\n",
       "          2.5609727 , -1.1813607 , -1.4873018 ,  0.27920425,  1.8011307 ],\n",
       "        [-0.09418276, -0.8559169 ,  2.0949564 ,  0.93121403,  0.46039432,\n",
       "         -0.8900191 ,  1.0637549 , -1.1108001 ,  0.3112595 , -0.21977438],\n",
       "        [ 0.0231803 , -2.0874476 ,  0.4391476 ,  2.8372698 , -0.32009083,\n",
       "          0.129061  ,  0.28859258,  0.05034657,  0.6787449 , -0.32913455],\n",
       "        [-0.44810745, -0.42586723, -2.250143  , -0.8543707 ,  0.51707757,\n",
       "          0.00759366, -1.270443  ,  1.7206628 , -0.53953373, -0.77434003],\n",
       "        [-0.67430294, -0.26849124,  1.354062  ,  0.9010869 , -0.01822092,\n",
       "         -0.26219097,  0.27647364, -0.24194579,  0.90190095, -0.24712461],\n",
       "        [-0.6872266 , -0.8108298 ,  1.5044708 ,  0.64178187, -1.4786613 ,\n",
       "         -0.6757957 ,  1.7345508 ,  2.5526524 , -0.15979283,  0.3661914 ],\n",
       "        [ 2.8715522 , -1.5260693 , -0.5081732 , -1.2227898 ,  0.36869976,\n",
       "          1.0694298 , -0.06478675,  2.1256483 , -1.1177151 , -0.29902104]],\n",
       "       dtype=float32),\n",
       " array([ 2.2062936 ,  0.82890815,  1.6514025 ,  1.318026  ,  2.626862  ,\n",
       "         0.05749415, -2.2663043 ,  2.5734298 ,  0.47868678,  1.7504271 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.30020726, -0.15245992,  0.00666225,  0.46032926,  0.07789857,\n",
       "          0.4593385 , -0.08070341,  0.13447641, -0.5267443 , -0.2380952 ,\n",
       "         -0.03391288, -0.00380038, -0.6444437 ,  0.04516678, -0.43612018],\n",
       "        [ 0.24947982, -0.32475924,  0.03996024,  0.6441179 , -0.4767732 ,\n",
       "          0.0051407 ,  0.63348174,  0.08821657, -0.4589975 , -0.32004872,\n",
       "         -0.01291061, -0.52289164, -0.37804428,  0.35238525, -0.05183439],\n",
       "        [ 0.94780505,  0.0902067 ,  0.5045938 ,  0.60353017,  0.05871021,\n",
       "          0.23648247,  0.5370135 ,  0.05597705, -0.8291051 , -0.40468517,\n",
       "          0.27467284,  0.15831949, -0.85571754,  0.37862435,  0.1727198 ],\n",
       "        [-0.6064461 , -0.13647187, -0.6408736 , -0.6427047 , -0.40513358,\n",
       "         -0.7287164 ,  0.26720932, -0.2880361 ,  0.7521829 ,  0.9518503 ,\n",
       "          0.3474099 ,  0.24252069,  0.34189287, -0.45809582,  0.35297534],\n",
       "        [ 0.96715176,  0.0042502 ,  0.3310242 ,  0.82495767,  0.49252924,\n",
       "          0.30921635, -0.228433  ,  0.06108953, -0.6236774 , -0.65235096,\n",
       "         -0.16699001, -0.37386963, -0.8606453 ,  0.20253   , -0.09830476],\n",
       "        [ 0.8230697 ,  0.20204769,  0.5691245 ,  0.3282211 ,  0.8874248 ,\n",
       "          0.5236944 , -0.09981755,  0.58107275, -0.7911939 , -0.5468397 ,\n",
       "         -0.5205713 ,  0.3034876 , -0.3980301 ,  0.6435222 , -0.2780739 ],\n",
       "        [ 1.4053768 ,  1.1198024 ,  0.98829657,  1.2569047 ,  0.74402696,\n",
       "          1.3772739 , -0.8679769 ,  1.226283  , -1.1487573 , -1.0078773 ,\n",
       "         -0.9271809 ,  0.96759355, -1.3698281 ,  0.74258494, -1.3270642 ],\n",
       "        [ 0.88798875, -0.0713784 , -0.05582946,  0.06845622,  0.18150553,\n",
       "         -0.10462491, -0.17871143,  0.4007957 , -0.7015812 , -0.7235196 ,\n",
       "         -0.02599509, -0.23548672, -0.49775225,  0.07921739, -0.60882825],\n",
       "        [ 0.7648836 ,  0.63448584,  0.36535028,  0.24365734,  0.17227845,\n",
       "          0.48825487, -0.26282796,  0.6757162 , -0.8685607 , -0.3091652 ,\n",
       "          0.09594175,  0.13079594, -0.70309246,  0.6312846 , -0.66685355],\n",
       "        [ 0.8553116 ,  0.13407071,  0.0108826 ,  0.6035578 ,  0.65766305,\n",
       "          0.8864817 ,  0.02384226,  0.4319344 , -0.52531683, -1.1510093 ,\n",
       "         -0.56449556, -0.03875222, -1.0721396 ,  0.64175034, -0.24547662]],\n",
       "       dtype=float32),\n",
       " array([ 1.6664127,  1.0350124,  1.4776559,  1.6110568,  1.4139543,\n",
       "         1.620891 , -1.1254925,  1.4772518, -1.6354268, -1.6435511,\n",
       "        -1.2115318,  1.1594015, -1.6421449,  1.5323194, -1.4717405],\n",
       "       dtype=float32),\n",
       " array([[ 1.2438077 ],\n",
       "        [ 0.13440122],\n",
       "        [ 0.41879192],\n",
       "        [ 0.9034657 ],\n",
       "        [ 0.42974228],\n",
       "        [ 0.70275503],\n",
       "        [-0.0796684 ],\n",
       "        [ 0.4605232 ],\n",
       "        [-0.8647938 ],\n",
       "        [-1.016935  ],\n",
       "        [-0.23472372],\n",
       "        [ 0.0306067 ],\n",
       "        [-1.0694014 ],\n",
       "        [ 0.64319766],\n",
       "        [-0.39926058]], dtype=float32),\n",
       " array([1.6899054], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_6(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure6_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.0780\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0656 - val_loss: 0.0275\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0635 - val_loss: 0.0365\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0514 - val_loss: 0.0348\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0326 - val_loss: 0.0139\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0226 - val_loss: 0.0130\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0198 - val_loss: 0.0089\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0175 - val_loss: 0.0084\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0134 - val_loss: 0.0078\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0138 - val_loss: 0.0076\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0124 - val_loss: 0.0061\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0110 - val_loss: 0.0079\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0105 - val_loss: 0.0058\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0092 - val_loss: 0.0057\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0101 - val_loss: 0.0050\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 116us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.007 - 0s 133us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0068 - val_loss: 0.0036\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0069\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0065\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0078\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 164us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0064\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0068\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 202us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "0.010574804618954659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.42605963, -0.07777546,  0.01991159, -0.25458196, -0.20944428],\n",
       "        [ 0.01476798,  0.27787945,  0.6385119 , -0.30709037,  0.40728468],\n",
       "        [ 0.6436845 , -0.10575218, -0.24513009,  0.43868735,  0.36013085],\n",
       "        [-0.7721344 , -0.91658956, -0.07400794,  1.1030083 , -0.6017021 ],\n",
       "        [ 0.11562541,  0.5563142 ,  1.07536   , -0.07066115,  0.6955638 ],\n",
       "        [ 0.54512054,  0.8538673 ,  0.48709026, -1.3089812 ,  0.7320952 ],\n",
       "        [ 0.962849  , -0.04362402, -0.2506559 ,  0.23799028,  0.52421737],\n",
       "        [ 0.30450827, -0.46097523,  0.13852961, -0.16888665, -0.20524688],\n",
       "        [ 0.8619594 , -0.305783  ,  0.03242037, -0.3511745 ,  0.72221786],\n",
       "        [-2.0347128 , -0.33124498,  0.2243542 ,  0.39747217, -0.80346715],\n",
       "        [ 0.7102007 , -0.34486458, -0.42145637, -0.2874849 ,  0.48127884],\n",
       "        [-0.81777394,  0.39722285, -0.95864487,  0.4399041 , -0.91013914],\n",
       "        [-0.24695365,  0.7478601 ,  0.00490227, -0.6609163 , -0.96770114],\n",
       "        [-1.0467479 , -1.0241798 , -0.54121006, -1.8529525 , -0.21166761],\n",
       "        [-0.13126135,  1.0241446 , -0.04662781,  0.5474105 ,  0.43599048],\n",
       "        [-0.40779862, -0.47193116,  0.23337427, -0.09396785, -0.411977  ],\n",
       "        [-0.7015976 ,  0.17683053,  0.19155349,  0.99045914, -0.44900686],\n",
       "        [-0.9677817 , -0.13208453,  0.04157878, -0.11938401,  0.44745678],\n",
       "        [ 0.46137097,  0.2399946 , -0.27517456,  0.11309992,  0.90693915],\n",
       "        [-0.6221708 ,  1.0261769 , -0.73608667,  0.71725386,  0.19904943],\n",
       "        [ 0.09998357, -0.77262294,  0.13410261,  2.1663303 , -0.30169642],\n",
       "        [-0.34337422, -0.8579347 , -0.07062864,  0.75845164, -0.1356278 ]],\n",
       "       dtype=float32),\n",
       " array([-0.00768357, -0.1736997 ,  0.05291174,  0.5538037 , -0.03981334],\n",
       "       dtype=float32),\n",
       " array([[ 0.8420951 ,  0.6015991 , -0.24290012, -0.19421199,  0.08776131],\n",
       "        [ 0.43609884,  0.06249835, -0.25968173,  0.40848002, -0.48816955],\n",
       "        [ 0.06627186,  0.3498035 , -0.05360738,  0.48249775,  0.23760946],\n",
       "        [ 0.5834734 ,  0.991281  , -0.27661377, -0.21883269,  0.7319214 ],\n",
       "        [-0.71220785, -0.5920973 ,  0.293205  ,  0.05874055,  0.03727054]],\n",
       "       dtype=float32),\n",
       " array([-0.03215174, -0.18332183,  0.03437136, -0.10773303, -0.25945935],\n",
       "       dtype=float32),\n",
       " array([[-0.34562573],\n",
       "        [-0.23003545],\n",
       "        [ 0.03709192],\n",
       "        [-0.09676383],\n",
       "        [-0.08315697]], dtype=float32),\n",
       " array([0.16531226], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_1(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure1_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.1497\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1427 - val_loss: 0.1603\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0981 - val_loss: 0.0413\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0519 - val_loss: 0.0275\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0419 - val_loss: 0.0265\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0303 - val_loss: 0.0155\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0148\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0303 - val_loss: 0.0246\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0293 - val_loss: 0.0125\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0252 - val_loss: 0.0122\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0232 - val_loss: 0.0133\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0207 - val_loss: 0.0090\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0199 - val_loss: 0.0083\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0186 - val_loss: 0.0089\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0172 - val_loss: 0.0067\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0156 - val_loss: 0.0060\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0141 - val_loss: 0.0055\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0127 - val_loss: 0.0051\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0117 - val_loss: 0.0046\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0107 - val_loss: 0.0044\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0101 - val_loss: 0.0043\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0041\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0042\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0043\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0077 - val_loss: 0.0047\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 123us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 116us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0073\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0072\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0069\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0067\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0076\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0083\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "0.015278239734470844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.01248734e-01, -3.90587375e-02,  4.54134762e-01,\n",
       "         -3.48079592e-01,  8.65140617e-01],\n",
       "        [-2.88793981e-01, -4.50984865e-01, -9.66663137e-02,\n",
       "         -7.36611784e-01, -2.06296936e-01],\n",
       "        [ 9.03432891e-02,  1.50342092e-01, -5.56128323e-01,\n",
       "         -3.42928916e-01, -8.30271006e-01],\n",
       "        [-8.82532597e-01,  1.31845906e-01,  4.36266780e-01,\n",
       "         -6.63835704e-01, -3.46058130e-01],\n",
       "        [-1.23831853e-01,  1.83544278e-01,  1.67308394e-02,\n",
       "         -3.51047546e-01, -5.09675264e-01],\n",
       "        [-3.57962638e-01,  2.95447975e-01,  3.86118084e-01,\n",
       "         -1.11707095e-02,  7.00566649e-01],\n",
       "        [-3.08032006e-01,  2.08132327e-01,  2.97880560e-01,\n",
       "         -2.94365995e-02, -3.27254891e-01],\n",
       "        [ 2.77151644e-01, -4.41821367e-01, -1.91900060e-02,\n",
       "          1.07123882e-01,  3.82201165e-01],\n",
       "        [ 7.87151873e-01, -3.59174401e-01, -6.70557082e-01,\n",
       "         -2.30177402e-01,  1.27651647e-01],\n",
       "        [-5.31766057e-01, -2.65929312e-01,  2.35073850e-01,\n",
       "          9.83673707e-02,  1.64237648e-01],\n",
       "        [ 1.11850671e-01,  4.20652442e-02, -5.83600819e-01,\n",
       "          8.62189680e-02, -6.05681419e-01],\n",
       "        [-7.99171850e-02, -2.67699093e-01, -1.72281176e-01,\n",
       "          2.48755410e-01,  2.46268138e-03],\n",
       "        [ 4.35381979e-01, -1.77850008e-01, -2.58936673e-01,\n",
       "         -4.47460413e-01, -1.82137385e-01],\n",
       "        [ 2.76219798e-03,  3.56493592e-01, -1.08143198e+00,\n",
       "         -4.13582414e-01,  2.24912000e+00],\n",
       "        [-1.05393551e-01, -3.97492759e-02,  3.47225182e-02,\n",
       "         -3.00396949e-01,  3.65866758e-02],\n",
       "        [ 1.65148646e-01, -2.50798196e-01,  5.24828508e-02,\n",
       "          2.63114363e-01,  6.66578189e-02],\n",
       "        [-2.68950254e-01, -3.53772402e-01,  5.88742137e-01,\n",
       "         -1.04441965e+00, -1.67854324e-01],\n",
       "        [-2.84054667e-01, -4.75412220e-01, -6.06401622e-01,\n",
       "         -5.48096061e-01,  3.73477906e-01],\n",
       "        [ 7.81833529e-01,  2.01874048e-01, -1.72860062e+00,\n",
       "         -4.66651529e-01, -9.76826310e-01],\n",
       "        [ 5.62961161e-01,  4.91029806e-02, -3.90524238e-01,\n",
       "         -6.57809675e-01,  9.75693643e-01],\n",
       "        [-8.20816234e-02, -2.52240837e-01,  5.51816225e-01,\n",
       "         -1.23940162e-01, -3.09584069e+00],\n",
       "        [-5.15639186e-01,  2.53309280e-01, -5.93307257e-01,\n",
       "         -9.15242592e-04, -1.24017745e-01]], dtype=float32),\n",
       " array([ 0.07995366,  0.09022209,  0.04568386, -0.27458608, -0.9749035 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.8207362e-01,  2.6423132e-01,  2.0889793e-01, -1.3381918e-01,\n",
       "          4.1770145e-01, -3.5249277e-03,  5.4700263e-02, -1.6409394e-01,\n",
       "          1.8051204e-01,  2.2179812e-01],\n",
       "        [-2.8673163e-01, -1.5667979e-01,  1.5180763e-02, -2.3395440e-01,\n",
       "         -3.1440264e-01, -4.2986012e-01,  4.9213114e-01, -2.8228912e-01,\n",
       "          4.3637428e-01,  3.3424550e-01],\n",
       "        [-1.7312650e-01,  7.1871108e-01,  7.6672447e-01,  7.5501591e-02,\n",
       "          3.9689547e-01,  2.4331275e-02,  3.4504578e-01, -4.6562526e-01,\n",
       "          1.4954442e-01,  6.2802148e-01],\n",
       "        [ 3.6216546e-02, -8.4570512e-02, -2.7165374e-01,  8.0636449e-02,\n",
       "          6.1176866e-01,  3.1812027e-01, -1.4070369e-02, -2.7313161e-01,\n",
       "         -5.8629012e-01, -1.2840571e-01],\n",
       "        [ 2.4281210e-01, -3.0998370e-01, -3.3045948e-01, -7.2250009e-04,\n",
       "         -1.0184427e+00, -6.8394445e-02, -4.7611743e-01,  4.9487630e-01,\n",
       "          3.3869794e-01, -6.9415861e-01]], dtype=float32),\n",
       " array([ 0.02339823,  0.06368183, -0.0398352 , -0.01394779, -0.17615487,\n",
       "         0.07074098,  0.03968789, -0.29957235,  0.03961592, -0.1170972 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.05803621],\n",
       "        [-0.03086175],\n",
       "        [-0.07072955],\n",
       "        [-0.00755625],\n",
       "        [-0.46648595],\n",
       "        [-0.00709337],\n",
       "        [-0.157364  ],\n",
       "        [ 0.07002266],\n",
       "        [ 0.01075669],\n",
       "        [-0.15372479]], dtype=float32),\n",
       " array([0.17032197], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_2(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure2_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1916 - val_loss: 0.0284\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.1080 - val_loss: 0.1249\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0829 - val_loss: 0.0502\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0403 - val_loss: 0.0113\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0260 - val_loss: 0.0103\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0233 - val_loss: 0.0090\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0208 - val_loss: 0.0098\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0169 - val_loss: 0.0106\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0172 - val_loss: 0.0081\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0152 - val_loss: 0.0053\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0138 - val_loss: 0.0050\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0124 - val_loss: 0.0051\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0129 - val_loss: 0.0047\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0104 - val_loss: 0.0052\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0107 - val_loss: 0.0044\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0063\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0084 - val_loss: 0.0057\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0084\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0050 - val_loss: 0.0093\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0069 - val_loss: 0.0038\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0069\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0067\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0077\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 0.0076\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0079\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0072\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0070\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 111us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "0.010149426758289337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.5104556 , -1.3649668 ,  0.16585827,  0.20282786,  0.49746516],\n",
       "        [ 0.6764522 , -0.14558627,  0.7936166 ,  0.7196441 ,  0.71913815],\n",
       "        [ 0.27733368,  0.4032202 ,  0.81099224, -0.45604977, -0.27115762],\n",
       "        [-0.08518778, -1.9339663 ,  1.5164855 ,  0.17174101,  0.4490696 ],\n",
       "        [ 0.29391977,  0.31291568,  0.06588762,  0.24900812,  0.259849  ],\n",
       "        [ 0.44609088, -0.3561649 , -1.3681657 ,  0.23819059,  0.82344115],\n",
       "        [-0.07799527, -0.03031418,  0.6238308 , -0.29837093, -0.22517957],\n",
       "        [ 0.2755493 , -0.17813592,  0.10340314, -0.01708427,  0.0929043 ],\n",
       "        [ 0.21225977,  0.09164099, -0.40890488,  0.5774647 ,  0.4049441 ],\n",
       "        [-0.7614256 , -0.8268645 ,  0.1616915 , -0.45591894, -0.7940281 ],\n",
       "        [ 0.04979641,  1.4386493 , -0.5712316 ,  0.87113386, -0.21665843],\n",
       "        [-0.34429568, -0.19074517, -0.07778696, -0.6864819 , -1.0254422 ],\n",
       "        [-0.3641495 ,  0.25448275, -0.2415153 , -0.12336337, -0.789139  ],\n",
       "        [-0.30248472,  0.13750961, -1.9427685 ,  1.2489722 , -0.8421561 ],\n",
       "        [-0.42492616,  0.20542948,  0.13218509,  0.07942171, -0.11954376],\n",
       "        [-0.52691644, -0.68690586, -0.3033789 ,  0.05742169,  0.35334116],\n",
       "        [ 0.1551061 , -1.4463054 ,  0.7242646 , -0.56906277,  0.50415635],\n",
       "        [ 0.19062014,  1.6829239 , -0.72309   , -0.19532047, -0.35205886],\n",
       "        [-0.09485277,  1.2406318 , -0.18382658,  0.6164345 , -0.08503483],\n",
       "        [-1.2351041 ,  0.52800506,  0.51707125,  0.57037693, -0.53190356],\n",
       "        [ 0.33201823, -0.62174004,  1.9022782 , -0.52088886,  0.43379316],\n",
       "        [ 0.23777248, -1.3059038 ,  0.646822  , -0.18597972, -0.94801337]],\n",
       "       dtype=float32),\n",
       " array([-0.18678947,  0.25723773,  0.7432889 , -0.3355185 , -0.01106483],\n",
       "       dtype=float32),\n",
       " array([[-0.32201508, -0.35366166, -0.15919262,  0.22030257, -0.20549247,\n",
       "         -0.38936976, -0.11798636, -0.3818779 ,  0.20504814, -0.15864807,\n",
       "         -0.35387683, -0.00849017,  0.5528088 ,  0.17077313,  0.46659303],\n",
       "        [ 0.44628522,  0.65617555, -0.09468698, -0.22820127, -0.17016517,\n",
       "          0.46277127,  0.30363935,  0.18337795, -0.05370223,  0.3445283 ,\n",
       "          0.19273111, -0.10251462, -0.6945693 ,  0.39543813, -0.34516326],\n",
       "        [ 0.02896429,  0.549719  , -0.61908054, -0.17749996, -0.34966436,\n",
       "         -0.06460667, -0.10113768, -0.01356925, -0.02586384,  0.3197867 ,\n",
       "         -0.01874084, -0.42027342, -0.21219268,  0.4551751 , -0.32435906],\n",
       "        [-0.2526664 , -0.08202852,  0.7544082 , -0.03768339, -0.00117953,\n",
       "         -0.1308995 , -0.1765641 , -0.1969107 ,  0.00792987, -0.03874873,\n",
       "         -0.3849261 , -0.1209532 ,  0.37615824, -0.09170265,  0.5215551 ],\n",
       "        [-0.14317694,  0.26284927, -0.5814613 ,  0.13479541, -0.23877728,\n",
       "         -0.2788896 , -0.04687491,  0.27208066,  0.0358373 ,  0.06859824,\n",
       "         -0.02758098, -0.04906409, -0.2704522 ,  0.02779432, -0.46723092]],\n",
       "       dtype=float32),\n",
       " array([-0.03284944, -0.14822996,  0.20145334,  0.17923716, -0.09350923,\n",
       "        -0.00709138,  0.19037767, -0.10218575,  0.15942766, -0.10404915,\n",
       "        -0.2317399 ,  0.2324143 ,  0.0736511 , -0.00579801,  0.3579389 ],\n",
       "       dtype=float32),\n",
       " array([[-0.02307248],\n",
       "        [-0.19490911],\n",
       "        [ 0.2915101 ],\n",
       "        [ 0.00339747],\n",
       "        [ 0.00447601],\n",
       "        [-0.02462582],\n",
       "        [-0.02442888],\n",
       "        [-0.0308436 ],\n",
       "        [ 0.00127194],\n",
       "        [-0.00619064],\n",
       "        [-0.05272104],\n",
       "        [ 0.00498386],\n",
       "        [ 0.25864547],\n",
       "        [-0.08770332],\n",
       "        [ 0.07011835]], dtype=float32),\n",
       " array([0.20068596], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_3(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure3_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 291\n",
      "Trainable params: 291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2983 - val_loss: 0.1942\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.1297 - val_loss: 0.0217\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0553 - val_loss: 0.0104\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0394 - val_loss: 0.0074\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0276 - val_loss: 0.0076\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0131 - val_loss: 0.0085\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0131 - val_loss: 0.0056\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0110 - val_loss: 0.0051\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0100 - val_loss: 0.0046\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0097 - val_loss: 0.0049\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0107 - val_loss: 0.0045\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0083 - val_loss: 0.0044\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0042\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0042\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 113us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 114us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 118us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 143us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 126us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0065\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0073\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0105\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0066\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 133us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0068\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0071\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0069\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 126us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0063\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0022 - val_loss: 0.0077\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0063\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0068\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0070\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 258us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0062\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0075\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0060\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0059\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0062\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0076\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 126us/step - loss: 0.0014 - val_loss: 0.0085\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0014 - val_loss: 0.0076\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0062\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0071\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0074\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0060\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0083\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0059\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0082\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0063\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0060\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0074\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0067\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0068\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0080\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0070\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0062\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0064\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0065\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0013 - val_loss: 0.0067\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0010 - val_loss: 0.0067\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0065\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0065\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0072\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0065\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0064\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0071\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0068\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0069\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0066\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0010 - val_loss: 0.0068\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0010 - val_loss: 0.0067\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 9.8026e-04 - val_loss: 0.0069\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0068\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0071\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0069\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.8522e-04 - val_loss: 0.0066\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0072\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0077\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0069\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0066\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0070\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9526e-04 - val_loss: 0.0068\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9759e-04 - val_loss: 0.0067\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.7435e-04 - val_loss: 0.0067\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.7031e-04 - val_loss: 0.0067\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.8669e-04 - val_loss: 0.0070\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0074\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0010 - val_loss: 0.0073\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0068\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.6326e-04 - val_loss: 0.0068\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0070\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.7298e-04 - val_loss: 0.0073\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0070\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0068\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0068\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0070\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.4174e-04 - val_loss: 0.0070\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.6111e-04 - val_loss: 0.0070\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6823e-04 - val_loss: 0.0076\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.9839e-04 - val_loss: 0.0072\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0084\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0069\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0065\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9282e-04 - val_loss: 0.0072\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0066\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0068\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.5747e-04 - val_loss: 0.0075\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0077\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0074\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0066\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9437e-04 - val_loss: 0.0065\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.9014e-04 - val_loss: 0.0069\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.3048e-04 - val_loss: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0072\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.8413e-04 - val_loss: 0.0070\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.3137e-04 - val_loss: 0.0074\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.8988e-04 - val_loss: 0.0071\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0074\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0077\n",
      "0.01167001947760582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.66158277,  0.4425873 , -1.1086903 ,  0.10679191, -0.10305981,\n",
       "          0.18635064, -0.03261758, -0.42856145,  0.293184  , -0.52332664],\n",
       "        [-0.546337  , -0.13943301,  0.20290516, -1.3790962 ,  0.37715313,\n",
       "          0.58803797, -0.0724607 , -0.09307076, -0.16117214,  0.25323528],\n",
       "        [ 0.5214689 , -0.10949008,  0.8612542 , -0.19324389,  0.21184772,\n",
       "         -0.20438097, -0.5215213 ,  0.15538877, -0.27269676, -0.30890936],\n",
       "        [ 0.60288984,  0.24934107,  1.4024686 ,  0.92994565,  0.08463224,\n",
       "         -0.23654194, -0.6247185 , -0.00417121, -0.1580552 , -1.6997945 ],\n",
       "        [ 0.32997617, -0.22422571, -0.4207746 , -0.11020105, -0.21649693,\n",
       "         -0.01926761, -0.6244146 ,  0.24130294, -0.21946259,  0.45718363],\n",
       "        [-1.3655093 ,  0.6933503 , -0.13095807, -0.2212351 ,  0.66821015,\n",
       "          0.24088503, -0.04546517, -0.4768003 ,  0.00571786,  0.5434827 ],\n",
       "        [-0.1426752 ,  0.09581514,  0.5837343 ,  0.10552273,  0.6665544 ,\n",
       "          0.15189697, -0.6956318 , -0.20303597,  0.16902773,  0.7088606 ],\n",
       "        [ 0.8235618 , -0.18682235,  0.04583272,  0.21026957,  0.23955712,\n",
       "          0.45302927, -0.74370164, -0.2529108 , -0.06389027, -0.26050463],\n",
       "        [-0.09260981, -0.25271976, -0.7563116 ,  1.6852447 ,  0.04845533,\n",
       "          0.5239535 , -0.54240584, -0.5879617 ,  0.3222035 ,  1.4896638 ],\n",
       "        [ 0.34769958, -0.07757469,  0.33902746, -0.55534923,  0.01115472,\n",
       "          0.14676037, -0.58487356, -0.26469603, -0.06239533, -1.9148556 ],\n",
       "        [ 0.2153761 , -0.84213316, -0.4447332 ,  0.05728438,  0.0612692 ,\n",
       "          0.18222621,  0.03007551, -0.6766394 ,  0.41213802, -0.22976357],\n",
       "        [ 0.17629083, -0.03365535,  1.0666397 , -0.16267481, -0.5006583 ,\n",
       "          0.2679826 , -0.46465194, -0.20783666,  0.10550895, -1.604659  ],\n",
       "        [-0.9263237 , -0.51239544,  0.47304633, -0.84908307, -0.3757006 ,\n",
       "         -0.01343239, -0.61874664, -0.54144895,  0.2990729 , -0.59959507],\n",
       "        [-0.99597174, -0.8338943 , -1.3722106 ,  0.8849956 , -0.39350978,\n",
       "          0.6002265 , -0.70932794,  0.02140347,  0.34745786, -1.1260417 ],\n",
       "        [-0.26642916, -0.5219686 ,  0.1787455 , -0.36922988, -0.1472184 ,\n",
       "          0.13696511, -0.7498572 , -0.16440637, -0.28116542,  0.85428077],\n",
       "        [ 0.54735273,  0.37377873, -0.62259233, -0.17914423,  0.35181826,\n",
       "          0.55797213,  0.02513321,  0.10621493, -0.35869753, -0.1020715 ],\n",
       "        [ 0.33811113,  0.42211208,  0.15164283, -0.20356646, -0.25610587,\n",
       "          0.11299864, -0.02935996, -0.08753373, -0.26510373, -0.21962473],\n",
       "        [ 0.25450778, -0.24494505,  0.05117889, -0.1803652 , -0.16781797,\n",
       "          0.4424661 , -0.36208084, -0.5399316 ,  0.21907966,  0.15607889],\n",
       "        [-0.35366493, -0.8558983 , -1.0576023 , -0.40085918, -0.86385214,\n",
       "         -0.07925777, -0.32935297, -0.30060065,  0.05404089,  1.6803243 ],\n",
       "        [ 1.3047067 , -0.9484772 , -0.52549404,  0.10020138, -0.01910966,\n",
       "          0.25785455, -0.6876495 , -0.10712784,  0.35258248, -0.8330424 ],\n",
       "        [ 0.16294096, -0.02061201,  1.9946458 , -1.0005972 ,  0.01760778,\n",
       "         -0.10276031, -0.11908578,  0.04723075, -0.21974099,  0.12371118],\n",
       "        [-0.376196  , -0.6492175 ,  0.67305076, -0.76065785,  0.19580458,\n",
       "         -0.24985656, -0.5805598 , -0.44887713,  0.03793352, -0.24628817]],\n",
       "       dtype=float32),\n",
       " array([ 0.46219438, -0.06804523,  0.36015442, -0.42787653, -0.04525953,\n",
       "         0.17797042, -0.4206973 , -0.14043862,  0.06087298, -0.22236186],\n",
       "       dtype=float32),\n",
       " array([[ 0.25168735,  0.53392404, -0.21658376,  0.28873903,  0.26813042],\n",
       "        [ 0.6271681 ,  0.50538874, -0.5820791 , -0.2198129 ,  0.24275167],\n",
       "        [ 0.76192266,  0.37094235,  0.5302144 ,  0.36724573,  0.04992414],\n",
       "        [-0.46805334, -0.3075559 ,  0.0748    , -0.03401778,  0.5113742 ],\n",
       "        [-0.5577735 , -0.07369612,  0.29143408,  0.337117  ,  0.0943718 ],\n",
       "        [ 0.24405019,  0.02353029, -0.23302333, -0.5252375 , -0.46536607],\n",
       "        [-0.0607358 ,  0.04353749, -0.30929166,  0.60386074,  0.23153812],\n",
       "        [ 0.23691955, -0.09347023,  0.43061477, -0.4023703 , -0.33157322],\n",
       "        [-0.05254011,  0.0727445 , -0.02636533, -0.39832553, -0.61850023],\n",
       "        [ 0.1604972 ,  0.7417092 ,  0.23701307,  0.18672468, -0.5924326 ]],\n",
       "       dtype=float32),\n",
       " array([-0.2604413 , -0.1420537 , -0.15308219,  0.05299079,  0.17900535],\n",
       "       dtype=float32),\n",
       " array([[-0.2213127 ],\n",
       "        [-0.5691309 ],\n",
       "        [ 0.00543804],\n",
       "        [-0.00812415],\n",
       "        [ 0.00692408]], dtype=float32),\n",
       " array([0.17116952], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_4(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure4_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 351\n",
      "Trainable params: 351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3431 - val_loss: 0.1033\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.1320 - val_loss: 0.0290\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0661 - val_loss: 0.0218\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0492 - val_loss: 0.0137\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0256 - val_loss: 0.0163\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0218 - val_loss: 0.0111\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 0.0215 - val_loss: 0.0057\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0192 - val_loss: 0.0052\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0176 - val_loss: 0.0081\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0144 - val_loss: 0.0067\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0144 - val_loss: 0.0060\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0132 - val_loss: 0.0062\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0117 - val_loss: 0.0050\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0112 - val_loss: 0.0058\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0106 - val_loss: 0.0050\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0107 - val_loss: 0.0048\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0114 - val_loss: 0.0050\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0096 - val_loss: 0.0044\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0095 - val_loss: 0.0042\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0092 - val_loss: 0.0041\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0039\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0038\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0040\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0045\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0039\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0036\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0037\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0077 - val_loss: 0.0043\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0080 - val_loss: 0.0042\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0041\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0038\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0072 - val_loss: 0.0041\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0039\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0036\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 113us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0040\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0040\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 133us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0066\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0073\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0033\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0031\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.7676e-04 - val_loss: 0.0022\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.7779e-04 - val_loss: 0.0020\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.4358e-04 - val_loss: 0.0026\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 144us/step - loss: 9.6022e-04 - val_loss: 0.0026\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.8133e-04 - val_loss: 0.0022\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.4643e-04 - val_loss: 0.0021\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.2496e-04 - val_loss: 0.0021\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9368e-04 - val_loss: 0.0026\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "0.007543719373643398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.8610001 , -0.69259506, -0.04879162,  0.49990648,  0.12087695,\n",
       "         -0.3130062 , -0.2902251 ,  0.13304886,  0.10281271,  0.34344184],\n",
       "        [-1.0500197 , -0.75020295,  0.0891478 , -0.1620969 ,  0.28636977,\n",
       "         -0.03386784,  0.29471952,  0.44975516,  0.40577102,  0.40337408],\n",
       "        [-0.8181066 , -0.3465711 , -0.04623673, -0.3937001 , -0.4681498 ,\n",
       "          0.20688802, -0.1088808 , -0.15312329, -0.11984669,  0.1848564 ],\n",
       "        [-0.8765797 , -0.7483909 ,  1.0353211 ,  0.13621739,  0.3792853 ,\n",
       "          0.23240094, -0.36602482,  0.5326473 ,  1.639029  , -0.4720744 ],\n",
       "        [-0.34530672, -0.33807015, -0.14380863,  0.12248819, -0.31446236,\n",
       "          0.2176863 , -0.29968452,  0.6476523 , -0.3387815 ,  0.35390815],\n",
       "        [ 0.96023905, -0.45538405, -0.3042542 , -0.13684462, -0.3438831 ,\n",
       "         -0.7934102 , -0.14345106,  0.40933284, -0.07168973, -0.19313207],\n",
       "        [-0.16871041, -0.18558829,  0.61611503,  0.17277129,  0.01124904,\n",
       "         -0.2866169 ,  0.5564643 ,  0.255947  , -0.6308447 , -0.02819077],\n",
       "        [ 0.37892848, -0.59891   ,  0.22959577,  0.38005257, -0.05456138,\n",
       "         -0.39200047,  0.43631425,  0.42100507, -0.17596054,  0.13396662],\n",
       "        [ 0.43115136,  0.16871928,  0.3903348 ,  0.07967362,  0.20155844,\n",
       "         -0.06553167, -0.45974684, -0.03828773, -0.7352232 ,  0.42459172],\n",
       "        [-0.5627788 , -0.78050536,  0.08282033,  0.39554533,  0.46049613,\n",
       "          0.4403969 ,  1.5062801 ,  0.13853383,  0.17855741, -0.6870212 ],\n",
       "        [ 0.01816121,  0.7924317 ,  0.08653035, -0.6812272 , -0.1897927 ,\n",
       "          0.99194163,  0.32078376,  0.39768478, -0.9078714 ,  0.0744862 ],\n",
       "        [-0.42003545,  0.59610236, -0.5622042 ,  0.522399  ,  0.02014218,\n",
       "          1.4151936 , -0.10736804, -0.06045735,  2.1032133 ,  0.0450928 ],\n",
       "        [ 0.19355659,  0.35767913,  0.05156858,  0.32075578,  0.5221802 ,\n",
       "          0.57269657,  0.35291362,  0.7481572 ,  0.8672682 , -0.41057813],\n",
       "        [ 1.0857325 ,  0.8736627 ,  0.95213795, -0.6497073 , -0.39182732,\n",
       "          0.2863179 ,  0.11730704,  0.32775646,  0.84185517,  1.0726838 ],\n",
       "        [-0.35648263,  0.1646797 , -0.13450713, -0.47135955,  0.12813683,\n",
       "          0.02435317,  0.00248986,  0.40012112, -0.3702768 , -0.12889951],\n",
       "        [ 0.14746857,  0.06062706, -0.21723421,  0.2386766 ,  0.0401875 ,\n",
       "          0.17220502,  0.02407788,  0.3640924 ,  0.4325534 , -0.32218152],\n",
       "        [-0.555843  , -0.60712254,  0.24787019, -0.10146818,  0.36995098,\n",
       "         -1.0016336 , -0.7513339 ,  0.2640193 ,  1.1720002 , -0.55915695],\n",
       "        [ 0.694602  , -0.0400816 ,  0.88679075,  0.24733779, -0.21329771,\n",
       "          0.47001693,  0.41943526,  0.22080861,  0.11862718,  0.17386462],\n",
       "        [ 0.42345712,  1.2356534 , -0.50130194, -1.0409795 , -0.547898  ,\n",
       "          0.27413562, -0.7772208 , -0.15555634, -0.8062694 ,  0.06361241],\n",
       "        [ 0.5964339 ,  0.1730316 , -1.6558836 , -0.4645025 , -0.15665284,\n",
       "          0.13703474,  0.14369075,  0.22801448,  0.32687125,  0.36251873],\n",
       "        [-2.1970034 , -0.4637606 , -0.6843343 ,  0.02560357, -0.19666949,\n",
       "          0.13448714, -0.00695568, -0.12475915,  0.23142147, -0.19221121],\n",
       "        [-0.67048436,  0.11592941, -0.4042248 , -0.14212991, -0.10129547,\n",
       "          0.27220178, -0.07690399,  0.72015584,  0.53542197,  0.9614362 ]],\n",
       "       dtype=float32),\n",
       " array([-0.4577568 , -0.14087334, -0.04625501, -0.10622949, -0.06469228,\n",
       "         0.17580754, -0.02149651,  0.31630576,  0.19402213,  0.09491361],\n",
       "       dtype=float32),\n",
       " array([[-0.38071334,  0.01034755, -0.56693774,  0.17706175, -0.29952946,\n",
       "          0.40125656,  0.22402045, -0.0545666 , -0.970381  , -0.38314497],\n",
       "        [ 0.08790754, -0.09394558,  0.40769926,  0.1445468 ,  0.43853045,\n",
       "          0.11230648,  0.09750581, -0.582529  ,  0.7975488 ,  0.2047785 ],\n",
       "        [ 0.06068541, -0.07752174,  0.2668463 , -0.08634959,  0.07770556,\n",
       "         -0.3236899 , -0.09670718,  0.09974144, -0.5835583 ,  0.4929706 ],\n",
       "        [ 0.5629299 ,  0.04084234, -0.09977936, -0.1535219 ,  0.24847935,\n",
       "          0.37113905, -0.0779117 ,  0.04102311,  0.5111539 , -0.3131086 ],\n",
       "        [ 0.12549578,  0.22752397, -0.80696493, -0.04211681, -0.16332841,\n",
       "          0.43028134,  0.49241978, -0.30824405,  0.23693672,  0.07764688],\n",
       "        [ 0.38382316, -0.6368048 , -0.4387408 ,  0.15625347, -0.06059819,\n",
       "          0.0428153 , -0.4247607 , -0.23581843, -0.6717818 , -0.10392806],\n",
       "        [ 0.06727803,  0.07394533,  0.05812488,  0.29223287,  0.16734594,\n",
       "          0.3481628 ,  0.2960121 ,  0.08731437, -0.43659532,  0.03939222],\n",
       "        [-0.07764399,  0.01860606,  0.09864655,  0.2245126 ,  0.4710068 ,\n",
       "         -0.05492577,  0.10970808, -0.12276682,  0.3972949 ,  0.30445555],\n",
       "        [-0.40776688,  0.28977388,  0.24105488, -0.0732986 , -0.5551012 ,\n",
       "          0.28622267,  0.13073298, -0.13282879, -0.45787406, -0.3752201 ],\n",
       "        [-0.81086624,  0.09473016, -0.20201394, -0.15929861,  0.07684928,\n",
       "          0.34669766,  0.3995577 ,  0.04652597, -0.1765124 ,  0.5330895 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.16316453,  0.04906862, -0.19362842, -0.07673691,  0.18320899,\n",
       "         0.07171491,  0.17132252, -0.20134947,  0.09000069, -0.07964904],\n",
       "       dtype=float32),\n",
       " array([[-1.5622361e-01],\n",
       "        [-4.7717756e-03],\n",
       "        [ 2.3437187e-04],\n",
       "        [-1.9507413e-04],\n",
       "        [-3.3847287e-02],\n",
       "        [ 1.4212597e-02],\n",
       "        [-4.7861916e-04],\n",
       "        [-3.0367519e-03],\n",
       "        [-4.0115249e-01],\n",
       "        [-8.6015956e-03]], dtype=float32),\n",
       " array([0.03296249], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_5(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure5_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.5754 - val_loss: 0.4512\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.2162 - val_loss: 0.1839\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.1128 - val_loss: 0.0173\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0425 - val_loss: 0.0314\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0466 - val_loss: 0.0489\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0355 - val_loss: 0.0151\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0226 - val_loss: 0.0184\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0222 - val_loss: 0.0101\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0193 - val_loss: 0.0103\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0189 - val_loss: 0.0080\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0198 - val_loss: 0.0092\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0193 - val_loss: 0.0079\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0165 - val_loss: 0.0079\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0169 - val_loss: 0.0087\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0157 - val_loss: 0.0084\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0146 - val_loss: 0.0078\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0142 - val_loss: 0.0079\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0153 - val_loss: 0.0064\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0127 - val_loss: 0.0074\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0128 - val_loss: 0.0063\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0124 - val_loss: 0.0074\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0123 - val_loss: 0.0069\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0120 - val_loss: 0.0067\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0124 - val_loss: 0.0062\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0115 - val_loss: 0.0070\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0116 - val_loss: 0.0062\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0118 - val_loss: 0.0069\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0065\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0107 - val_loss: 0.0062\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 349us/step - loss: 0.0091 - val_loss: 0.0065\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 209us/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0095 - val_loss: 0.0065\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0108\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0099 - val_loss: 0.0069\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0096\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0077 - val_loss: 0.0086\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0088\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0084\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0061 - val_loss: 0.0094\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0072\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0109\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0073 - val_loss: 0.0094\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0068\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0085\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0052 - val_loss: 0.0078\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0052 - val_loss: 0.0077\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0083\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 138us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0052 - val_loss: 0.0089\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0093\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0069\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0075\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0067\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0090\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0117\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0047 - val_loss: 0.0081\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0074\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0045 - val_loss: 0.0068\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0072\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0040 - val_loss: 0.0076\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0073\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0076\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0085\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0073\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0082\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0091\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0040 - val_loss: 0.0094\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0077\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0073\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0076\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0081\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0093\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0093\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0072\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0071\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0073\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0078\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0067\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0084\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0060\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0086\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0070\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0067\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0076\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0075\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0081\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0084\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0077\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0075\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0071\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0067\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0031 - val_loss: 0.0066\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0091\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0033 - val_loss: 0.0070\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0063\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0029 - val_loss: 0.0087\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 149us/step - loss: 0.0033 - val_loss: 0.0101\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0066\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0031 - val_loss: 0.0068\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0066\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0072\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0066\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0029 - val_loss: 0.0087\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0107\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0062\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0076\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0067\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0078\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0074\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0063\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0071\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0063\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0073\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0068\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0074\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0072\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0081\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0040 - val_loss: 0.0121\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0093\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0066\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0100\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0068\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0068\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0073\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0074\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0088\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0084\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0105\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0068\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0093\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0100\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0076\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0070\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0067\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0101\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0065\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0067\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0070\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0075\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0068\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0079\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0067\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0081\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0085\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0072\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0068\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0069\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0074\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0086\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0082\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0079\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0032 - val_loss: 0.0074\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0023 - val_loss: 0.0070\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0069\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0091\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0073\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0103\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0092\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0073\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 0.0069\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0028 - val_loss: 0.0098\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 0.0080\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0070\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0070\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0070\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0071\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0077\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0105\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0082\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 133us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0018 - val_loss: 0.0073\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0077\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0063\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0018 - val_loss: 0.0086\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0071\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0074\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0073\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0022 - val_loss: 0.0081\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0078\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0079\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0071\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0069\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0063\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0078\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0091\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0080\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0072\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0073\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0083\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0077\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0084\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0100\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0070\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0074\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0073\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0078\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0091\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0024 - val_loss: 0.0071\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0080\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0067\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0105\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0075\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0082\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0096\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0100\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0070\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0072\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0075\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0069\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0072\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0071\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0088\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0069\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0064\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0092\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0077\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0063\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0072\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0077\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0070\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0083\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0072\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0074\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0068\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0090\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0017 - val_loss: 0.0070\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0084\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0079\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0082\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0015 - val_loss: 0.0073\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0032 - val_loss: 0.0071\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0073\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0076\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0082\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0081\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0078\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0079\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0085\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0092\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0090\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0076\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0066\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0085\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 114us/step - loss: 0.0022 - val_loss: 0.0078\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0064\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0073\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0087\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0072\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0066\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0085\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0071\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0072\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0079\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0066\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0090\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0098\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0080\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0069\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0152\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0086\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0085\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0072\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0081\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0076\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0081\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0068\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0071\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0087\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0074\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0074\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0075\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0082\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0083\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0069\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0080\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0082\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0084\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0081\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0067\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0087\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0080\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0093\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0072\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0070\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0091\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0074\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0074\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0082\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0073\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0085\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0083\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0072\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0087\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0074\n",
      "0.005262305494397879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 6.52661920e-01, -3.57384346e-02,  1.63505271e-01,\n",
       "         -8.23379338e-01, -9.21211317e-02,  6.90834224e-01,\n",
       "         -3.70481938e-01,  7.61913419e-01,  5.49882174e-01,\n",
       "         -2.37085834e-01],\n",
       "        [-2.14445651e-01, -5.85439622e-01,  5.29419601e-01,\n",
       "          2.80065089e-01,  5.94026625e-01,  4.15281832e-01,\n",
       "         -3.56058687e-01, -9.22980487e-01, -2.32882574e-01,\n",
       "          3.86679381e-01],\n",
       "        [-1.48893637e-03, -2.51165461e-02,  4.74239774e-02,\n",
       "          2.45677143e-01,  4.59122807e-01, -3.36362958e-01,\n",
       "         -3.29041988e-01,  1.38766274e-01,  2.73531586e-01,\n",
       "         -2.65145749e-01],\n",
       "        [ 5.02472520e-01, -1.52574599e-01,  4.05685455e-01,\n",
       "          1.57966897e-01,  6.63309574e-01,  9.51064050e-01,\n",
       "         -7.93316543e-01, -7.98670292e-01,  6.82790101e-01,\n",
       "         -3.70312572e-01],\n",
       "        [ 2.41264567e-01,  4.01149035e-01, -7.93255642e-02,\n",
       "         -4.23042148e-01, -1.02782790e-02,  3.50716472e-01,\n",
       "          6.28901303e-01, -6.63010299e-01,  5.06783605e-01,\n",
       "         -2.93409228e-01],\n",
       "        [ 1.14565432e-01, -7.68960491e-02,  6.58342600e-01,\n",
       "          5.18604577e-01, -1.33938551e+00,  3.62256706e-01,\n",
       "          4.35815424e-01, -4.91228849e-01, -2.42629379e-01,\n",
       "          1.51625976e-01],\n",
       "        [ 4.80882972e-01, -3.07014674e-01,  6.75754786e-01,\n",
       "          1.55430855e-02,  4.23022360e-01, -1.53617442e-01,\n",
       "          4.11542296e-01,  5.07233031e-02, -2.69117564e-01,\n",
       "          3.18917900e-01],\n",
       "        [ 2.06006080e-01, -5.13538957e-01, -5.11343814e-02,\n",
       "          3.84489745e-02,  2.02649385e-02,  2.93646127e-01,\n",
       "         -7.26227043e-03,  6.14447176e-01,  5.41093424e-02,\n",
       "         -4.30201858e-01],\n",
       "        [-5.78869879e-03,  2.81804092e-02,  1.69055611e-01,\n",
       "         -8.79348218e-01, -3.10143530e-01,  3.01426817e-02,\n",
       "          5.11510491e-01, -7.54991651e-01,  2.54977588e-03,\n",
       "         -1.52231127e-01],\n",
       "        [ 8.48460615e-01,  8.99019092e-02,  4.04449731e-01,\n",
       "          2.45957285e-01,  4.14395809e-01, -2.50223845e-01,\n",
       "         -1.31034887e+00,  8.39897692e-01, -1.99006855e-01,\n",
       "          1.79797053e-01],\n",
       "        [-4.06896532e-01, -3.22953761e-02,  4.66626436e-01,\n",
       "         -4.73366350e-01, -2.23796979e-01, -5.45424044e-01,\n",
       "          2.21810099e-02, -2.66084701e-01, -2.62979865e-01,\n",
       "          2.50222385e-01],\n",
       "        [-7.54162343e-03,  7.65045226e-01,  3.62272978e-01,\n",
       "          6.00639343e-01,  1.63610339e-01,  1.89320609e-01,\n",
       "         -1.03970420e+00,  3.01525950e-01, -1.89131692e-01,\n",
       "         -2.39531957e-02],\n",
       "        [-1.33262813e-01, -6.68030560e-01, -1.28867239e-01,\n",
       "          5.12130320e-01, -2.49882668e-01, -7.74823010e-01,\n",
       "         -7.24663734e-01,  7.13481188e-01,  3.68505716e-01,\n",
       "         -2.92999059e-01],\n",
       "        [-4.36920017e-01,  5.63203156e-01,  1.44391760e-01,\n",
       "         -6.73287928e-01, -2.00626540e+00, -3.39588135e-01,\n",
       "         -2.98222154e-01, -3.57214719e-01,  8.24859813e-02,\n",
       "          2.28627294e-01],\n",
       "        [ 1.34602889e-01, -5.73974967e-01,  2.62097716e-01,\n",
       "         -1.99176773e-01,  3.88495654e-01, -2.80104190e-01,\n",
       "          4.97832835e-01,  9.56721753e-02, -1.94177225e-01,\n",
       "         -4.13250625e-01],\n",
       "        [ 8.14295709e-02, -3.27344000e-01,  2.29008704e-01,\n",
       "          2.53653020e-01,  3.97305518e-01, -3.56069535e-01,\n",
       "         -6.51564598e-01,  1.67641923e-01,  3.03731889e-01,\n",
       "          2.00027451e-01],\n",
       "        [-2.26395354e-01, -1.79978460e-01,  2.01909140e-01,\n",
       "          2.20430747e-01,  3.83537531e-01,  3.42468649e-01,\n",
       "          2.80051976e-01,  3.14293019e-02,  7.10028231e-01,\n",
       "         -1.00386977e-01],\n",
       "        [-8.85600671e-02, -1.40142411e-01,  6.92231059e-02,\n",
       "          8.05399120e-01, -4.69485700e-01, -4.45715129e-01,\n",
       "         -2.02971980e-01,  1.81803450e-01,  4.26329732e-01,\n",
       "          5.18431999e-02],\n",
       "        [-9.90793169e-01, -1.46328881e-01,  5.48254311e-01,\n",
       "         -4.98710901e-01, -5.70469737e-01, -2.15112090e-01,\n",
       "          1.37512875e+00, -8.63856614e-01, -1.19948372e-01,\n",
       "          1.91116482e-01],\n",
       "        [ 2.08621435e-02,  2.84201741e-01, -4.53736037e-02,\n",
       "          1.78692099e-02,  1.01600289e+00, -3.57418150e-01,\n",
       "         -2.74555951e-01, -5.69719970e-01,  3.73445421e-01,\n",
       "         -4.72904652e-01],\n",
       "        [ 1.00720972e-01, -3.38290423e-01,  1.60534650e-01,\n",
       "          8.16480577e-01,  1.35284615e+00,  1.38075024e-01,\n",
       "         -6.52004406e-02,  5.14766388e-02,  2.69161582e-01,\n",
       "          1.76046759e-01],\n",
       "        [ 3.49004745e-01,  1.40846714e-01,  2.53443241e-01,\n",
       "          6.92842245e-01,  7.68972158e-01, -4.08490032e-01,\n",
       "         -2.54662246e-01, -3.16253126e-01,  5.92975497e-01,\n",
       "         -1.79971039e-01]], dtype=float32),\n",
       " array([ 0.1132528 , -0.13811131,  0.23533322,  0.13676384,  0.45465252,\n",
       "        -0.17988302, -0.29626113,  0.12199381,  0.18487597, -0.03282318],\n",
       "       dtype=float32),\n",
       " array([[ 0.2216449 ,  0.01980437,  0.45491377, -0.29928675, -0.14670916,\n",
       "         -0.14705227,  0.65409636, -0.05187334, -0.418597  , -0.28240764,\n",
       "          0.5655809 , -0.16299757,  0.19222432, -0.16133475,  0.3504875 ],\n",
       "        [-0.21608475,  0.10726434, -0.17981339,  0.27832425,  0.0145478 ,\n",
       "         -0.15317951, -0.39169207,  0.08951481, -0.27746516, -0.15624122,\n",
       "          0.22403024,  0.30228472,  0.6520473 ,  0.38286492,  0.23484437],\n",
       "        [-0.38683936,  0.35237297,  0.05529744, -0.18505388,  0.39270985,\n",
       "         -0.18583977, -0.01876383, -0.0281855 ,  0.3525411 ,  0.26462367,\n",
       "         -0.02111139, -0.23714188,  0.28422582,  0.09421159, -0.10815483],\n",
       "        [ 0.11161277, -0.34422013,  0.06533343,  0.20441099, -0.22307187,\n",
       "         -0.27350658, -0.5187333 , -0.11510669,  0.24783891,  0.55463934,\n",
       "         -0.18893054, -0.19459915,  0.17225717,  0.1583022 ,  0.08379321],\n",
       "        [ 0.0925756 , -0.35718527,  0.0364622 ,  0.69784635,  0.16742635,\n",
       "          0.03645746, -0.15140684, -0.18527405,  0.38571262, -0.1461329 ,\n",
       "         -0.14063326, -0.07632131, -0.19849797,  0.22490679, -0.44346702],\n",
       "        [-0.1827945 , -0.33943495,  0.15912285,  0.51283365, -0.35729024,\n",
       "          0.14893696, -0.44280034,  0.21966974,  0.25218657,  0.49270785,\n",
       "          0.1428091 , -0.1621425 , -0.24617648, -0.23506555, -0.5826861 ],\n",
       "        [-0.20547478, -0.5840934 ,  0.53406966,  0.74864393,  0.27028775,\n",
       "         -0.35178995,  0.04124365, -0.0599892 ,  0.48560402,  0.5611573 ,\n",
       "         -0.27709273, -0.28746584, -0.06775604,  0.5699683 ,  0.09994497],\n",
       "        [-0.098619  ,  0.06380266,  0.3795675 ,  0.31010237,  0.08846933,\n",
       "         -0.20657374, -0.04599085,  0.28681898,  0.44693694,  0.08331094,\n",
       "          0.07719484, -0.19297774,  0.32075927, -0.04761503, -0.01139949],\n",
       "        [-0.40168852, -0.13245605,  0.18304943, -0.25229293,  0.13719334,\n",
       "          0.03523405,  0.02284048,  0.5903775 , -0.43684   , -0.03368608,\n",
       "          0.18337996,  0.0439349 , -0.18380168,  0.08534334,  0.27443177],\n",
       "        [ 0.3190301 , -0.05117091, -0.10833353, -0.01117711, -0.04230911,\n",
       "         -0.36023214,  0.3666196 , -0.0599401 ,  0.04405915, -0.01475833,\n",
       "          0.19008066, -0.17106274,  0.1673409 , -0.09968683, -0.2303141 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.22585985, -0.2941325 , -0.31406137,  0.24892417, -0.2893144 ,\n",
       "        -0.20447472, -0.22383015, -0.18813738,  0.2480574 ,  0.2591313 ,\n",
       "        -0.2511652 ,  0.30522397,  0.22909945,  0.27751976, -0.19373469],\n",
       "       dtype=float32),\n",
       " array([[-4.5746157e-05],\n",
       "        [ 1.2649939e-02],\n",
       "        [ 7.8509067e-04],\n",
       "        [-5.6255215e-01],\n",
       "        [ 2.7254908e-03],\n",
       "        [ 5.2183714e-02],\n",
       "        [ 5.3887203e-02],\n",
       "        [ 7.0775263e-02],\n",
       "        [-1.2632999e-01],\n",
       "        [-2.6091922e-02],\n",
       "        [ 5.9676310e-03],\n",
       "        [ 7.6764640e-03],\n",
       "        [-1.9338442e-02],\n",
       "        [-3.1742990e-02],\n",
       "        [ 2.7442828e-02]], dtype=float32),\n",
       " array([-0.18401065], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_6(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure6_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 35.6421 - val_loss: 30.9798\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.0855 - val_loss: 27.5400\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.8006 - val_loss: 23.3774\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.9071 - val_loss: 18.7746\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 21.6343 - val_loss: 14.1498\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.2651 - val_loss: 9.7631\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12.7428 - val_loss: 5.9019\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3581 - val_loss: 3.0570\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 4.8283 - val_loss: 1.5630\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6982 - val_loss: 1.4463\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9590 - val_loss: 2.3848\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1139 - val_loss: 3.6397\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6030 - val_loss: 4.4974\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.9561 - val_loss: 4.7713\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9741 - val_loss: 4.5828\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6938 - val_loss: 4.0297\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2104 - val_loss: 3.2823\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6648 - val_loss: 2.5340\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1939 - val_loss: 1.8982\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.8708 - val_loss: 1.4025\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7014 - val_loss: 1.0253\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6463 - val_loss: 0.7325\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6485 - val_loss: 0.5017\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.6589 - val_loss: 0.3286\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.6493 - val_loss: 0.2191\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6135 - val_loss: 0.1780\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5600 - val_loss: 0.1991\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5016 - val_loss: 0.2610\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4466 - val_loss: 0.3319\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3953 - val_loss: 0.3804\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3429 - val_loss: 0.3885\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2862 - val_loss: 0.3566\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2274 - val_loss: 0.2984\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1730 - val_loss: 0.2326\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1297 - val_loss: 0.1752\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1015 - val_loss: 0.1367\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0887 - val_loss: 0.1214\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0882 - val_loss: 0.1277\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0959 - val_loss: 0.1496\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1070 - val_loss: 0.1781\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1175 - val_loss: 0.2035\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1239 - val_loss: 0.2184\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1243 - val_loss: 0.2190\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1181 - val_loss: 0.2054\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1061 - val_loss: 0.1809\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0903 - val_loss: 0.1502\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0729 - val_loss: 0.1182\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0562 - val_loss: 0.0888\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0423 - val_loss: 0.0648\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0323 - val_loss: 0.0475\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0269 - val_loss: 0.0372\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0259 - val_loss: 0.0329\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0280 - val_loss: 0.0332\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0320 - val_loss: 0.0359\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0362 - val_loss: 0.0393\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0395 - val_loss: 0.0416\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0411 - val_loss: 0.0421\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0408 - val_loss: 0.0409\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0388 - val_loss: 0.0386\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0356 - val_loss: 0.0364\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 209us/step - loss: 0.0319 - val_loss: 0.0353\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0283 - val_loss: 0.0360\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0251 - val_loss: 0.0385\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0227 - val_loss: 0.0423\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0467\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0201 - val_loss: 0.0510\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0196 - val_loss: 0.0546\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0194 - val_loss: 0.0570\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.0580\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0195 - val_loss: 0.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0194 - val_loss: 0.0561\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0193 - val_loss: 0.0536\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0191 - val_loss: 0.0505\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0188 - val_loss: 0.0469\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0184 - val_loss: 0.0434\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0178 - val_loss: 0.0399\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0172 - val_loss: 0.0366\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0165 - val_loss: 0.0336\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0158 - val_loss: 0.0309\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0151 - val_loss: 0.0284\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0145 - val_loss: 0.0263\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0140 - val_loss: 0.0245\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0229\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0217\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0132 - val_loss: 0.0207\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0131 - val_loss: 0.0200\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0131 - val_loss: 0.0195\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0130 - val_loss: 0.0191\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0129 - val_loss: 0.0187\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0184\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0124 - val_loss: 0.0181\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0122 - val_loss: 0.0179\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0177\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0115 - val_loss: 0.0177\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0112 - val_loss: 0.0177\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0110 - val_loss: 0.0177\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0108 - val_loss: 0.0179\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0180\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0104 - val_loss: 0.0181\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0103 - val_loss: 0.0182\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0101 - val_loss: 0.0183\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0100 - val_loss: 0.0183\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0182\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0097 - val_loss: 0.0181\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0180\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0094 - val_loss: 0.0178\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0092 - val_loss: 0.0176\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0173\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0089 - val_loss: 0.0169\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0088 - val_loss: 0.0166\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0162\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0085 - val_loss: 0.0158\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0153\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0149\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0142\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0139\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0077 - val_loss: 0.0136\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0076 - val_loss: 0.0134\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0132\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0130\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0073 - val_loss: 0.0129\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0128\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0071 - val_loss: 0.0126\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0126\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0068 - val_loss: 0.0125\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0124\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0066 - val_loss: 0.0123\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0122\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0065 - val_loss: 0.0122\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0120\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0119\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0062 - val_loss: 0.0118\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0116\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0114\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0112\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0110\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0108\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0057 - val_loss: 0.0106\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0056 - val_loss: 0.0104\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0100\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0096\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0094\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0092\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 0.0091\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0089\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0050 - val_loss: 0.0088\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0049 - val_loss: 0.0087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0049 - val_loss: 0.0086\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0048 - val_loss: 0.0085\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0082\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0046 - val_loss: 0.0081\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0046 - val_loss: 0.0080\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0079\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0078\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0077\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0043 - val_loss: 0.0076\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0042 - val_loss: 0.0073\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0041 - val_loss: 0.0072\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0071\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0070\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0040 - val_loss: 0.0069\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0067\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0067\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0023 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 9.9733e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 9.8599e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.7476e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.6360e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.5256e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.4158e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 9.3074e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.1995e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 9.0929e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 0.0012 - val_loss: 8.9869e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.8819e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.7779e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 8.6749e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 8.5727e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.4713e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 8.3709e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.2714e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 8.1728e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.0750e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.9780e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 7.8819e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0011 - val_loss: 7.7868e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.6926e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.5990e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.5062e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 7.4145e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.3235e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.2332e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.1440e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 7.0554e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.9678e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 6.8808e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.7946e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.7093e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.6248e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.5410e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.4582e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 6.3759e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 6.2945e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 6.2140e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.1341e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.0549e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 5.9767e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 5.8991e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 5.8221e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 5.7461e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 5.6706e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.5961e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0010 - val_loss: 5.5222e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.4491e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 9.9900e-04 - val_loss: 5.3765e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9469e-04 - val_loss: 5.3047e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9042e-04 - val_loss: 5.2338e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8618e-04 - val_loss: 5.1634e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8196e-04 - val_loss: 5.0940e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.7777e-04 - val_loss: 5.0251e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7361e-04 - val_loss: 4.9568e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 9.6949e-04 - val_loss: 4.8893e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.6538e-04 - val_loss: 4.8224e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.6130e-04 - val_loss: 4.7564e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5727e-04 - val_loss: 4.6909e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5324e-04 - val_loss: 4.6262e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4924e-04 - val_loss: 4.5621e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4528e-04 - val_loss: 4.4987e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4134e-04 - val_loss: 4.4359e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3743e-04 - val_loss: 4.3738e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3354e-04 - val_loss: 4.3123e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.2968e-04 - val_loss: 4.2514e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2585e-04 - val_loss: 4.1913e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2205e-04 - val_loss: 4.1317e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1825e-04 - val_loss: 4.0729e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.1451e-04 - val_loss: 4.0147e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1078e-04 - val_loss: 3.9572e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0707e-04 - val_loss: 3.9002e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0339e-04 - val_loss: 3.8438e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9974e-04 - val_loss: 3.7881e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9612e-04 - val_loss: 3.7330e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9251e-04 - val_loss: 3.6785e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8893e-04 - val_loss: 3.6246e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8538e-04 - val_loss: 3.5713e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8184e-04 - val_loss: 3.5187e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7834e-04 - val_loss: 3.4666e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.7486e-04 - val_loss: 3.4152e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7140e-04 - val_loss: 3.3643e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.6797e-04 - val_loss: 3.3139e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.6457e-04 - val_loss: 3.2641e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6118e-04 - val_loss: 3.2150e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5782e-04 - val_loss: 3.1664e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.5448e-04 - val_loss: 3.1184e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 8.5116e-04 - val_loss: 3.0710e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4788e-04 - val_loss: 3.0241e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4461e-04 - val_loss: 2.9777e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4137e-04 - val_loss: 2.9319e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3814e-04 - val_loss: 2.8866e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3494e-04 - val_loss: 2.8419e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3177e-04 - val_loss: 2.7978e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 8.2861e-04 - val_loss: 2.7542e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2548e-04 - val_loss: 2.7111e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2236e-04 - val_loss: 2.6686e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1927e-04 - val_loss: 2.6267e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1622e-04 - val_loss: 2.5852e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1317e-04 - val_loss: 2.5442e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1015e-04 - val_loss: 2.5036e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0714e-04 - val_loss: 2.4637e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0417e-04 - val_loss: 2.4242e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0120e-04 - val_loss: 2.3852e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9826e-04 - val_loss: 2.3468e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9535e-04 - val_loss: 2.3089e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9244e-04 - val_loss: 2.2714e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8957e-04 - val_loss: 2.2345e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8671e-04 - val_loss: 2.1979e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8389e-04 - val_loss: 2.1618e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8106e-04 - val_loss: 2.1262e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7827e-04 - val_loss: 2.0912e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 7.7548e-04 - val_loss: 2.0566e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 7.7274e-04 - val_loss: 2.0224e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6999e-04 - val_loss: 1.9888e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6728e-04 - val_loss: 1.9555e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.6458e-04 - val_loss: 1.9226e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6190e-04 - val_loss: 1.8903e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7.5925e-04 - val_loss: 1.8584e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5661e-04 - val_loss: 1.8270e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5398e-04 - val_loss: 1.7961e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5138e-04 - val_loss: 1.7655e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4880e-04 - val_loss: 1.7352e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4623e-04 - val_loss: 1.7056e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4369e-04 - val_loss: 1.6763e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4116e-04 - val_loss: 1.6473e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3864e-04 - val_loss: 1.6188e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 7.3615e-04 - val_loss: 1.5907e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3368e-04 - val_loss: 1.5631e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3122e-04 - val_loss: 1.5357e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2878e-04 - val_loss: 1.5089e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 7.2636e-04 - val_loss: 1.4824e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 7.2396e-04 - val_loss: 1.4563e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2156e-04 - val_loss: 1.4306e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1920e-04 - val_loss: 1.4053e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1684e-04 - val_loss: 1.3803e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1450e-04 - val_loss: 1.3557e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1219e-04 - val_loss: 1.3315e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 7.0989e-04 - val_loss: 1.3076e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.0760e-04 - val_loss: 1.2842e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0532e-04 - val_loss: 1.2611e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 7.0307e-04 - val_loss: 1.2384e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0083e-04 - val_loss: 1.2159e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9862e-04 - val_loss: 1.1939e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.9640e-04 - val_loss: 1.1722e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9421e-04 - val_loss: 1.1508e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9204e-04 - val_loss: 1.1297e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8987e-04 - val_loss: 1.1090e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8773e-04 - val_loss: 1.0887e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8560e-04 - val_loss: 1.0686e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8349e-04 - val_loss: 1.0489e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8140e-04 - val_loss: 1.0296e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7931e-04 - val_loss: 1.0105e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7724e-04 - val_loss: 9.9166e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7518e-04 - val_loss: 9.7318e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7315e-04 - val_loss: 9.5501e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7112e-04 - val_loss: 9.3712e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6911e-04 - val_loss: 9.1961e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 6.6710e-04 - val_loss: 9.0237e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6512e-04 - val_loss: 8.8544e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6316e-04 - val_loss: 8.6879e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6120e-04 - val_loss: 8.5242e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5926e-04 - val_loss: 8.3621e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5733e-04 - val_loss: 8.2042e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5542e-04 - val_loss: 8.0487e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.5351e-04 - val_loss: 7.8959e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 6.5162e-04 - val_loss: 7.7458e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4974e-04 - val_loss: 7.5984e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4789e-04 - val_loss: 7.4543e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 6.4604e-04 - val_loss: 7.3117e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4420e-04 - val_loss: 7.1719e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4238e-04 - val_loss: 7.0347e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4057e-04 - val_loss: 6.8995e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3876e-04 - val_loss: 6.7676e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.3698e-04 - val_loss: 6.6377e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3520e-04 - val_loss: 6.5107e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3344e-04 - val_loss: 6.3854e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3170e-04 - val_loss: 6.2631e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2996e-04 - val_loss: 6.1424e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2823e-04 - val_loss: 6.0247e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2652e-04 - val_loss: 5.9083e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2482e-04 - val_loss: 5.7945e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2313e-04 - val_loss: 5.6838e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2145e-04 - val_loss: 5.5747e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1978e-04 - val_loss: 5.4675e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1812e-04 - val_loss: 5.3626e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1648e-04 - val_loss: 5.2592e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.1485e-04 - val_loss: 5.1583e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1321e-04 - val_loss: 5.0595e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1160e-04 - val_loss: 4.9628e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1000e-04 - val_loss: 4.8679e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.0841e-04 - val_loss: 4.7750e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0683e-04 - val_loss: 4.6843e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0526e-04 - val_loss: 4.5947e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0371e-04 - val_loss: 4.5077e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0215e-04 - val_loss: 4.4219e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 6.0061e-04 - val_loss: 4.3383e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9908e-04 - val_loss: 4.2561e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9756e-04 - val_loss: 4.1761e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9605e-04 - val_loss: 4.0976e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9456e-04 - val_loss: 4.0210e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9306e-04 - val_loss: 3.9462e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9158e-04 - val_loss: 3.8725e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 5.9011e-04 - val_loss: 3.8009e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8866e-04 - val_loss: 3.7305e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8720e-04 - val_loss: 3.6619e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8576e-04 - val_loss: 3.5950e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8432e-04 - val_loss: 3.5294e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8290e-04 - val_loss: 3.4654e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8149e-04 - val_loss: 3.4027e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8008e-04 - val_loss: 3.3418e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7868e-04 - val_loss: 3.2815e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.7728e-04 - val_loss: 3.2234e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7591e-04 - val_loss: 3.1665e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.7454e-04 - val_loss: 3.1111e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7318e-04 - val_loss: 3.0566e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7182e-04 - val_loss: 3.0040e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7048e-04 - val_loss: 2.9524e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6914e-04 - val_loss: 2.9023e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6780e-04 - val_loss: 2.8531e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6648e-04 - val_loss: 2.8051e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 5.6517e-04 - val_loss: 2.7585e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6386e-04 - val_loss: 2.7132e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6257e-04 - val_loss: 2.6691e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6127e-04 - val_loss: 2.6260e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5999e-04 - val_loss: 2.5840e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5871e-04 - val_loss: 2.5431e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.5744e-04 - val_loss: 2.5035e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5619e-04 - val_loss: 2.4649e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5494e-04 - val_loss: 2.4274e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5369e-04 - val_loss: 2.3906e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5245e-04 - val_loss: 2.3551e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5122e-04 - val_loss: 2.3206e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5000e-04 - val_loss: 2.2867e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4878e-04 - val_loss: 2.2543e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4757e-04 - val_loss: 2.2228e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4637e-04 - val_loss: 2.1919e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4518e-04 - val_loss: 2.1623e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4399e-04 - val_loss: 2.1333e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4280e-04 - val_loss: 2.1053e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4163e-04 - val_loss: 2.0781e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4046e-04 - val_loss: 2.0517e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3930e-04 - val_loss: 2.0264e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3814e-04 - val_loss: 2.0017e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 5.3699e-04 - val_loss: 1.9779e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3585e-04 - val_loss: 1.9549e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3472e-04 - val_loss: 1.9326e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3358e-04 - val_loss: 1.9111e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3246e-04 - val_loss: 1.8902e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3134e-04 - val_loss: 1.8701e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3023e-04 - val_loss: 1.8508e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2912e-04 - val_loss: 1.8321e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2802e-04 - val_loss: 1.8143e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2693e-04 - val_loss: 1.7970e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 5.2584e-04 - val_loss: 1.7802e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2475e-04 - val_loss: 1.7644e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2368e-04 - val_loss: 1.7489e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2261e-04 - val_loss: 1.7339e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2154e-04 - val_loss: 1.7199e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2048e-04 - val_loss: 1.7062e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1942e-04 - val_loss: 1.6934e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1838e-04 - val_loss: 1.6810e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1733e-04 - val_loss: 1.6691e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1630e-04 - val_loss: 1.6578e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1526e-04 - val_loss: 1.6471e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1423e-04 - val_loss: 1.6366e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 5.1320e-04 - val_loss: 1.6267e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 5.1219e-04 - val_loss: 1.6178e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1118e-04 - val_loss: 1.6088e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1017e-04 - val_loss: 1.6005e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0917e-04 - val_loss: 1.5928e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0817e-04 - val_loss: 1.5855e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0717e-04 - val_loss: 1.5789e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0619e-04 - val_loss: 1.5721e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0520e-04 - val_loss: 1.5661e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0423e-04 - val_loss: 1.5605e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0325e-04 - val_loss: 1.5552e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0228e-04 - val_loss: 1.5504e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0132e-04 - val_loss: 1.5458e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0035e-04 - val_loss: 1.5416e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 4.9940e-04 - val_loss: 1.5378e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9845e-04 - val_loss: 1.5347e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9750e-04 - val_loss: 1.5315e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9655e-04 - val_loss: 1.5288e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9562e-04 - val_loss: 1.5264e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9468e-04 - val_loss: 1.5246e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9376e-04 - val_loss: 1.5227e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9283e-04 - val_loss: 1.5215e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9191e-04 - val_loss: 1.5205e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 4.9099e-04 - val_loss: 1.5196e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9008e-04 - val_loss: 1.5193e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8918e-04 - val_loss: 1.5189e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8827e-04 - val_loss: 1.5188e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8737e-04 - val_loss: 1.5191e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8646e-04 - val_loss: 1.5193e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 4.8557e-04 - val_loss: 1.5201e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8468e-04 - val_loss: 1.5211e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8380e-04 - val_loss: 1.5223e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8291e-04 - val_loss: 1.5237e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8204e-04 - val_loss: 1.5253e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8117e-04 - val_loss: 1.5273e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8029e-04 - val_loss: 1.5295e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.7942e-04 - val_loss: 1.5318e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7857e-04 - val_loss: 1.5346e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7770e-04 - val_loss: 1.5372e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7685e-04 - val_loss: 1.5400e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7599e-04 - val_loss: 1.5431e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7514e-04 - val_loss: 1.5464e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7431e-04 - val_loss: 1.5498e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7346e-04 - val_loss: 1.5535e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7262e-04 - val_loss: 1.5569e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7178e-04 - val_loss: 1.5605e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7095e-04 - val_loss: 1.5649e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7012e-04 - val_loss: 1.5689e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6930e-04 - val_loss: 1.5733e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6848e-04 - val_loss: 1.5776e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6766e-04 - val_loss: 1.5822e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6684e-04 - val_loss: 1.5870e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6603e-04 - val_loss: 1.5917e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6522e-04 - val_loss: 1.5966e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6440e-04 - val_loss: 1.6017e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6361e-04 - val_loss: 1.6068e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6281e-04 - val_loss: 1.6119e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6201e-04 - val_loss: 1.6173e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6121e-04 - val_loss: 1.6225e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6042e-04 - val_loss: 1.6281e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5964e-04 - val_loss: 1.6338e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 4.5885e-04 - val_loss: 1.6395e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5806e-04 - val_loss: 1.6451e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5729e-04 - val_loss: 1.6510e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.5651e-04 - val_loss: 1.6566e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5574e-04 - val_loss: 1.6628e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5497e-04 - val_loss: 1.6686e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5420e-04 - val_loss: 1.6748e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5343e-04 - val_loss: 1.6809e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5267e-04 - val_loss: 1.6871e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5191e-04 - val_loss: 1.6933e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5115e-04 - val_loss: 1.6997e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5039e-04 - val_loss: 1.7058e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4965e-04 - val_loss: 1.7122e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4889e-04 - val_loss: 1.7188e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.4815e-04 - val_loss: 1.7252e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4740e-04 - val_loss: 1.7318e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4666e-04 - val_loss: 1.7382e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 4.4592e-04 - val_loss: 1.7448e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4519e-04 - val_loss: 1.7513e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.4445e-04 - val_loss: 1.7580e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.4372e-04 - val_loss: 1.7646e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4299e-04 - val_loss: 1.7711e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4226e-04 - val_loss: 1.7777e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4154e-04 - val_loss: 1.7844e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4082e-04 - val_loss: 1.7910e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.4010e-04 - val_loss: 1.7976e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3938e-04 - val_loss: 1.8045e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.3867e-04 - val_loss: 1.8112e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3795e-04 - val_loss: 1.8177e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3725e-04 - val_loss: 1.8244e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3653e-04 - val_loss: 1.8312e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3583e-04 - val_loss: 1.8379e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3512e-04 - val_loss: 1.8447e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3442e-04 - val_loss: 1.8516e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3372e-04 - val_loss: 1.8583e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 4.3302e-04 - val_loss: 1.8649e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3233e-04 - val_loss: 1.8717e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3164e-04 - val_loss: 1.8785e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3094e-04 - val_loss: 1.8851e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3026e-04 - val_loss: 1.8918e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2957e-04 - val_loss: 1.8983e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.2889e-04 - val_loss: 1.9050e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2821e-04 - val_loss: 1.9115e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.2752e-04 - val_loss: 1.9179e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2685e-04 - val_loss: 1.9248e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2617e-04 - val_loss: 1.9311e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 4.2550e-04 - val_loss: 1.9377e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2483e-04 - val_loss: 1.9444e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2416e-04 - val_loss: 1.9508e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2349e-04 - val_loss: 1.9573e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2283e-04 - val_loss: 1.9636e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2216e-04 - val_loss: 1.9702e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2150e-04 - val_loss: 1.9764e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 4.2084e-04 - val_loss: 1.9827e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2018e-04 - val_loss: 1.9892e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1952e-04 - val_loss: 1.9953e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1887e-04 - val_loss: 2.0016e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1822e-04 - val_loss: 2.0079e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1756e-04 - val_loss: 2.0143e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1692e-04 - val_loss: 2.0204e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1628e-04 - val_loss: 2.0266e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 4.1562e-04 - val_loss: 2.0327e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1498e-04 - val_loss: 2.0387e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1434e-04 - val_loss: 2.0447e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1371e-04 - val_loss: 2.0506e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1306e-04 - val_loss: 2.0567e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1243e-04 - val_loss: 2.0629e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1179e-04 - val_loss: 2.0688e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1117e-04 - val_loss: 2.0745e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1053e-04 - val_loss: 2.0802e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0990e-04 - val_loss: 2.0861e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0928e-04 - val_loss: 2.0919e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0865e-04 - val_loss: 2.0976e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0803e-04 - val_loss: 2.1033e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0741e-04 - val_loss: 2.1087e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0678e-04 - val_loss: 2.1145e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0617e-04 - val_loss: 2.1197e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.0554e-04 - val_loss: 2.1256e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0493e-04 - val_loss: 2.1309e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0432e-04 - val_loss: 2.1364e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0371e-04 - val_loss: 2.1415e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.0309e-04 - val_loss: 2.1469e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0249e-04 - val_loss: 2.1523e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0188e-04 - val_loss: 2.1577e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0127e-04 - val_loss: 2.1628e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0067e-04 - val_loss: 2.1677e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0006e-04 - val_loss: 2.1729e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9947e-04 - val_loss: 2.1782e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9886e-04 - val_loss: 2.1831e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9827e-04 - val_loss: 2.1882e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.9767e-04 - val_loss: 2.1932e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9708e-04 - val_loss: 2.1980e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9649e-04 - val_loss: 2.2027e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 3.9589e-04 - val_loss: 2.2078e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.9530e-04 - val_loss: 2.2120e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9471e-04 - val_loss: 2.2169e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9413e-04 - val_loss: 2.2217e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9354e-04 - val_loss: 2.2264e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9296e-04 - val_loss: 2.2311e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9238e-04 - val_loss: 2.2354e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9179e-04 - val_loss: 2.2400e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9121e-04 - val_loss: 2.2444e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9063e-04 - val_loss: 2.2488e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9006e-04 - val_loss: 2.2532e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8948e-04 - val_loss: 2.2576e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8891e-04 - val_loss: 2.2613e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8834e-04 - val_loss: 2.2656e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8776e-04 - val_loss: 2.2702e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8719e-04 - val_loss: 2.2742e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 3.8662e-04 - val_loss: 2.2783e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 3.8605e-04 - val_loss: 2.2827e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8549e-04 - val_loss: 2.2863e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8492e-04 - val_loss: 2.2904e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8436e-04 - val_loss: 2.2942e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8380e-04 - val_loss: 2.2982e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8324e-04 - val_loss: 2.3019e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8268e-04 - val_loss: 2.3057e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8212e-04 - val_loss: 2.3095e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8157e-04 - val_loss: 2.3130e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8101e-04 - val_loss: 2.3165e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8045e-04 - val_loss: 2.3204e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7990e-04 - val_loss: 2.3239e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7935e-04 - val_loss: 2.3274e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7880e-04 - val_loss: 2.3309e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7825e-04 - val_loss: 2.3344e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 3.7770e-04 - val_loss: 2.3380e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7716e-04 - val_loss: 2.3413e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7661e-04 - val_loss: 2.3445e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7607e-04 - val_loss: 2.3478e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7553e-04 - val_loss: 2.3510e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7498e-04 - val_loss: 2.3543e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7444e-04 - val_loss: 2.3572e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.7391e-04 - val_loss: 2.3602e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7337e-04 - val_loss: 2.3635e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7283e-04 - val_loss: 2.3664e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7230e-04 - val_loss: 2.3695e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7176e-04 - val_loss: 2.3723e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7123e-04 - val_loss: 2.3751e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7070e-04 - val_loss: 2.3783e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7017e-04 - val_loss: 2.3812e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6964e-04 - val_loss: 2.3838e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6911e-04 - val_loss: 2.3866e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6859e-04 - val_loss: 2.3891e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6806e-04 - val_loss: 2.3917e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6754e-04 - val_loss: 2.3944e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6701e-04 - val_loss: 2.3972e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6649e-04 - val_loss: 2.3997e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6597e-04 - val_loss: 2.4022e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.6545e-04 - val_loss: 2.4048e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6493e-04 - val_loss: 2.4070e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6441e-04 - val_loss: 2.4094e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6390e-04 - val_loss: 2.4118e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6338e-04 - val_loss: 2.4144e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6287e-04 - val_loss: 2.4170e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6235e-04 - val_loss: 2.4190e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6184e-04 - val_loss: 2.4212e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6133e-04 - val_loss: 2.4233e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6082e-04 - val_loss: 2.4255e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6032e-04 - val_loss: 2.4274e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5980e-04 - val_loss: 2.4296e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5930e-04 - val_loss: 2.4318e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5879e-04 - val_loss: 2.4339e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5829e-04 - val_loss: 2.4360e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5779e-04 - val_loss: 2.4380e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.5728e-04 - val_loss: 2.4397e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5678e-04 - val_loss: 2.4414e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5628e-04 - val_loss: 2.4431e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5579e-04 - val_loss: 2.4450e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5529e-04 - val_loss: 2.4470e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5479e-04 - val_loss: 2.4487e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5430e-04 - val_loss: 2.4506e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5380e-04 - val_loss: 2.4521e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5331e-04 - val_loss: 2.4538e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5281e-04 - val_loss: 2.4554e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5232e-04 - val_loss: 2.4573e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5183e-04 - val_loss: 2.4588e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5134e-04 - val_loss: 2.4605e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5085e-04 - val_loss: 2.4622e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5037e-04 - val_loss: 2.4636e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4989e-04 - val_loss: 2.4650e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4940e-04 - val_loss: 2.4663e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4891e-04 - val_loss: 2.4674e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4843e-04 - val_loss: 2.4688e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 3.4795e-04 - val_loss: 2.4702e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 3.4746e-04 - val_loss: 2.4713e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4698e-04 - val_loss: 2.4730e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4651e-04 - val_loss: 2.4741e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4603e-04 - val_loss: 2.4751e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4555e-04 - val_loss: 2.4764e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4507e-04 - val_loss: 2.4781e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4460e-04 - val_loss: 2.4787e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4412e-04 - val_loss: 2.4799e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4365e-04 - val_loss: 2.4813e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4317e-04 - val_loss: 2.4824e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4270e-04 - val_loss: 2.4833e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4223e-04 - val_loss: 2.4846e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4176e-04 - val_loss: 2.4854e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4130e-04 - val_loss: 2.4861e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4082e-04 - val_loss: 2.4877e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4036e-04 - val_loss: 2.4883e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3989e-04 - val_loss: 2.4892e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3943e-04 - val_loss: 2.4901e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3897e-04 - val_loss: 2.4909e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3850e-04 - val_loss: 2.4920e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3804e-04 - val_loss: 2.4927e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3758e-04 - val_loss: 2.4935e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3712e-04 - val_loss: 2.4943e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3667e-04 - val_loss: 2.4946e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 3.3620e-04 - val_loss: 2.4955e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3574e-04 - val_loss: 2.4962e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3529e-04 - val_loss: 2.4970e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 3.3483e-04 - val_loss: 2.4974e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3438e-04 - val_loss: 2.4982e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3392e-04 - val_loss: 2.4987e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.3347e-04 - val_loss: 2.4992e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3301e-04 - val_loss: 2.5001e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3257e-04 - val_loss: 2.5006e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3211e-04 - val_loss: 2.5012e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3166e-04 - val_loss: 2.5020e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3122e-04 - val_loss: 2.5021e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3077e-04 - val_loss: 2.5028e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3032e-04 - val_loss: 2.5030e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2987e-04 - val_loss: 2.5034e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2943e-04 - val_loss: 2.5035e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2899e-04 - val_loss: 2.5040e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2854e-04 - val_loss: 2.5046e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2810e-04 - val_loss: 2.5052e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2766e-04 - val_loss: 2.5055e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2722e-04 - val_loss: 2.5058e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2678e-04 - val_loss: 2.5060e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2634e-04 - val_loss: 2.5063e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.2590e-04 - val_loss: 2.5067e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2547e-04 - val_loss: 2.5067e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2503e-04 - val_loss: 2.5070e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2459e-04 - val_loss: 2.5073e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2415e-04 - val_loss: 2.5076e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2372e-04 - val_loss: 2.5076e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2329e-04 - val_loss: 2.5076e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2285e-04 - val_loss: 2.5078e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2242e-04 - val_loss: 2.5081e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2199e-04 - val_loss: 2.5082e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2157e-04 - val_loss: 2.5084e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2114e-04 - val_loss: 2.5086e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2071e-04 - val_loss: 2.5087e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2028e-04 - val_loss: 2.5087e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1985e-04 - val_loss: 2.5085e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.1942e-04 - val_loss: 2.5083e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1900e-04 - val_loss: 2.5086e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1857e-04 - val_loss: 2.5083e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1816e-04 - val_loss: 2.5084e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1773e-04 - val_loss: 2.5084e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1731e-04 - val_loss: 2.5084e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1688e-04 - val_loss: 2.5085e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1647e-04 - val_loss: 2.5086e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1605e-04 - val_loss: 2.5086e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1563e-04 - val_loss: 2.5085e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1521e-04 - val_loss: 2.5083e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1479e-04 - val_loss: 2.5081e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1438e-04 - val_loss: 2.5080e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1396e-04 - val_loss: 2.5077e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1354e-04 - val_loss: 2.5077e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1313e-04 - val_loss: 2.5075e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1272e-04 - val_loss: 2.5074e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1230e-04 - val_loss: 2.5072e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1190e-04 - val_loss: 2.5068e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1149e-04 - val_loss: 2.5066e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1108e-04 - val_loss: 2.5064e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1066e-04 - val_loss: 2.5059e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1025e-04 - val_loss: 2.5061e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0985e-04 - val_loss: 2.5056e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 3.0944e-04 - val_loss: 2.5054e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0903e-04 - val_loss: 2.5052e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0863e-04 - val_loss: 2.5048e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 3.0822e-04 - val_loss: 2.5047e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0782e-04 - val_loss: 2.5042e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0742e-04 - val_loss: 2.5039e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0701e-04 - val_loss: 2.5038e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0660e-04 - val_loss: 2.5032e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0621e-04 - val_loss: 2.5032e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0580e-04 - val_loss: 2.5023e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0541e-04 - val_loss: 2.5018e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 3.0501e-04 - val_loss: 2.5016e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0461e-04 - val_loss: 2.5010e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.0421e-04 - val_loss: 2.5008e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0382e-04 - val_loss: 2.5006e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0342e-04 - val_loss: 2.5003e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0302e-04 - val_loss: 2.4997e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0263e-04 - val_loss: 2.4993e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 3.0223e-04 - val_loss: 2.4987e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0184e-04 - val_loss: 2.4983e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0145e-04 - val_loss: 2.4978e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0106e-04 - val_loss: 2.4971e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0066e-04 - val_loss: 2.4969e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0027e-04 - val_loss: 2.4963e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9989e-04 - val_loss: 2.4956e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9949e-04 - val_loss: 2.4954e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9910e-04 - val_loss: 2.4948e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9872e-04 - val_loss: 2.4946e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9833e-04 - val_loss: 2.4938e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9795e-04 - val_loss: 2.4935e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9756e-04 - val_loss: 2.4928e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9717e-04 - val_loss: 2.4923e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9679e-04 - val_loss: 2.4915e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9640e-04 - val_loss: 2.4913e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9602e-04 - val_loss: 2.4902e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9564e-04 - val_loss: 2.4898e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9526e-04 - val_loss: 2.4892e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9487e-04 - val_loss: 2.4886e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9450e-04 - val_loss: 2.4878e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9411e-04 - val_loss: 2.4873e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9373e-04 - val_loss: 2.4869e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9336e-04 - val_loss: 2.4862e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9298e-04 - val_loss: 2.4857e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9260e-04 - val_loss: 2.4851e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9222e-04 - val_loss: 2.4845e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9185e-04 - val_loss: 2.4838e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.9148e-04 - val_loss: 2.4831e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9110e-04 - val_loss: 2.4826e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9073e-04 - val_loss: 2.4819e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9035e-04 - val_loss: 2.4811e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8998e-04 - val_loss: 2.4804e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8961e-04 - val_loss: 2.4796e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8924e-04 - val_loss: 2.4789e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8887e-04 - val_loss: 2.4782e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8850e-04 - val_loss: 2.4778e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8813e-04 - val_loss: 2.4766e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8776e-04 - val_loss: 2.4760e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8739e-04 - val_loss: 2.4757e-05\n",
      "3.1918141758069396e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.4972712 ,  1.1983103 ,  0.55198175,  0.49735886, -0.9871544 ],\n",
       "        [-0.516381  , -0.7493354 ,  0.09029235, -0.53057796,  0.60803044],\n",
       "        [-0.7899559 ,  1.4216826 ,  1.5982524 ,  1.0730485 , -1.0867842 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.8497863 , -0.7726063 ,  0.61374   , -0.9131135 ,  0.43090382],\n",
       "       dtype=float32),\n",
       " array([[-3.48383784e-01,  8.10980618e-01, -1.10070489e-01,\n",
       "          4.41076368e-01, -1.31641611e-01],\n",
       "        [-9.51579452e-01,  3.21457475e-01,  2.55592197e-01,\n",
       "         -2.05613095e-02,  7.18704017e-04],\n",
       "        [-5.17058253e-01,  9.68577713e-02, -1.64514184e-01,\n",
       "          3.34117442e-01,  3.56699467e-01],\n",
       "        [ 5.80054581e-01,  1.13027126e-01, -4.32037890e-01,\n",
       "         -5.12755573e-01,  4.35394682e-02],\n",
       "        [-1.07791328e+00,  6.31578267e-02,  2.09732100e-01,\n",
       "          1.06566995e-01,  6.93198502e-01]], dtype=float32),\n",
       " array([-0.90925735,  0.87682956, -0.8281077 ,  0.87066793,  0.9061792 ],\n",
       "       dtype=float32),\n",
       " array([[-1.0660119],\n",
       "        [ 0.9198661],\n",
       "        [-0.4935676],\n",
       "        [ 0.7303439],\n",
       "        [ 1.0426514]], dtype=float32),\n",
       " array([0.91958433], dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_1(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure1_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.5576 - val_loss: 31.0804\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.6136 - val_loss: 27.8516\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 30.0765 - val_loss: 23.2496\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.7221 - val_loss: 17.5611\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 20.4360 - val_loss: 11.5488\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 14.5965 - val_loss: 6.3167\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7238 - val_loss: 3.4962\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 3.9675 - val_loss: 3.9594\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2391 - val_loss: 5.2471\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4015 - val_loss: 4.3616\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2680 - val_loss: 2.5731\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7701 - val_loss: 1.6821\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7493 - val_loss: 1.7602\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.8146 - val_loss: 2.3135\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2455 - val_loss: 3.0246\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1119 - val_loss: 3.6858\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2896 - val_loss: 4.1326\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5703 - val_loss: 4.2584\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.7729 - val_loss: 4.0328\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7980 - val_loss: 3.5028\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6333 - val_loss: 2.7759\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3308 - val_loss: 1.9879\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.9730 - val_loss: 1.2662\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6389 - val_loss: 0.7006\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3812 - val_loss: 0.3290\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2197 - val_loss: 0.1408\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.1471 - val_loss: 0.0929\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1414 - val_loss: 0.1297\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1768 - val_loss: 0.2001\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2293 - val_loss: 0.2663\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2788 - val_loss: 0.3068\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3104 - val_loss: 0.3146\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3154 - val_loss: 0.2931\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2927 - val_loss: 0.2519\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2484 - val_loss: 0.2029\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1935 - val_loss: 0.1576\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.1409 - val_loss: 0.1242\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1015 - val_loss: 0.1070\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0820 - val_loss: 0.1048\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0824 - val_loss: 0.1126\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0970 - val_loss: 0.1230\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1164 - val_loss: 0.1294\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1316 - val_loss: 0.1273\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1365 - val_loss: 0.1164\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1297 - val_loss: 0.0990\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.1139 - val_loss: 0.0788\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0938 - val_loss: 0.0595\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0738 - val_loss: 0.0435\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0571 - val_loss: 0.0320\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0450 - val_loss: 0.0250\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0219\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0334 - val_loss: 0.0221\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.0247\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0329 - val_loss: 0.0289\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0346 - val_loss: 0.0336\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 0.0367 - val_loss: 0.0378\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0383 - val_loss: 0.0407\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0387 - val_loss: 0.0417\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0374 - val_loss: 0.0410\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0346 - val_loss: 0.0392\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0307 - val_loss: 0.0370\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0265 - val_loss: 0.0352\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0231 - val_loss: 0.0345\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0208 - val_loss: 0.0349\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0362\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0378\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0209 - val_loss: 0.0393\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0218 - val_loss: 0.0402\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0223 - val_loss: 0.0404\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0224 - val_loss: 0.0398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0387\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0371\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0201 - val_loss: 0.0351\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0190 - val_loss: 0.0331\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0180 - val_loss: 0.0309\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0170 - val_loss: 0.0288\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0161 - val_loss: 0.0268\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0154 - val_loss: 0.0250\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0149 - val_loss: 0.0234\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0146 - val_loss: 0.0222\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0144 - val_loss: 0.0213\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.0206\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0142 - val_loss: 0.0201\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0140 - val_loss: 0.0195\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0138 - val_loss: 0.0191\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0134 - val_loss: 0.0186\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0130 - val_loss: 0.0181\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0125 - val_loss: 0.0177\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0121 - val_loss: 0.0173\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0117 - val_loss: 0.0169\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0112 - val_loss: 0.0162\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0111 - val_loss: 0.0159\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0109 - val_loss: 0.0155\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0151\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0146\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0090 - val_loss: 0.0115\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0088 - val_loss: 0.0113\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0112\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0105\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0105\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0104\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0104\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0101\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0098\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0066 - val_loss: 0.0097\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0065 - val_loss: 0.0097\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0064 - val_loss: 0.0096\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0064 - val_loss: 0.0095\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0094\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0093\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0092\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 0.0092\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0091\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0090\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0058 - val_loss: 0.0088\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0086\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0056 - val_loss: 0.0085\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 136us/step - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0054 - val_loss: 0.0083\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0054 - val_loss: 0.0082\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0081\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0081\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0052 - val_loss: 0.0080\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0079\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0051 - val_loss: 0.0078\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0078\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0077\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0050 - val_loss: 0.0075\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0071\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0069\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 374us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9627e-04 - val_loss: 0.0019\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9225e-04 - val_loss: 0.0019\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8826e-04 - val_loss: 0.0019\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8426e-04 - val_loss: 0.0019\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8031e-04 - val_loss: 0.0019\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7638e-04 - val_loss: 0.0019\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7246e-04 - val_loss: 0.0018\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6859e-04 - val_loss: 0.0018\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6472e-04 - val_loss: 0.0018\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6087e-04 - val_loss: 0.0018\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5705e-04 - val_loss: 0.0018\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5325e-04 - val_loss: 0.0018\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4948e-04 - val_loss: 0.0018\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4573e-04 - val_loss: 0.0018\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4200e-04 - val_loss: 0.0018\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3828e-04 - val_loss: 0.0018\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3459e-04 - val_loss: 0.0018\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3093e-04 - val_loss: 0.0018\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2728e-04 - val_loss: 0.0018\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2365e-04 - val_loss: 0.0018\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2005e-04 - val_loss: 0.0018\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1646e-04 - val_loss: 0.0018\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1289e-04 - val_loss: 0.0017\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.0935e-04 - val_loss: 0.0017\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0582e-04 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0232e-04 - val_loss: 0.0017\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9883e-04 - val_loss: 0.0017\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9537e-04 - val_loss: 0.0017\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9191e-04 - val_loss: 0.0017\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8849e-04 - val_loss: 0.0017\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.8508e-04 - val_loss: 0.0017\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8169e-04 - val_loss: 0.0017\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7831e-04 - val_loss: 0.0017\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7496e-04 - val_loss: 0.0017\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.7163e-04 - val_loss: 0.0017\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6831e-04 - val_loss: 0.0017\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6500e-04 - val_loss: 0.0017\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6173e-04 - val_loss: 0.0017\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5846e-04 - val_loss: 0.0017\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5523e-04 - val_loss: 0.0016\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5200e-04 - val_loss: 0.0016\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4879e-04 - val_loss: 0.0016\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4560e-04 - val_loss: 0.0016\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4243e-04 - val_loss: 0.0016\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3927e-04 - val_loss: 0.0016\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3613e-04 - val_loss: 0.0016\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3301e-04 - val_loss: 0.0016\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2990e-04 - val_loss: 0.0016\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2681e-04 - val_loss: 0.0016\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.2375e-04 - val_loss: 0.0016\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2069e-04 - val_loss: 0.0016\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1765e-04 - val_loss: 0.0016\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 8.1463e-04 - val_loss: 0.0016\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1162e-04 - val_loss: 0.0016\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0863e-04 - val_loss: 0.0016\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0567e-04 - val_loss: 0.0016\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0269e-04 - val_loss: 0.0016\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9974e-04 - val_loss: 0.0016\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9682e-04 - val_loss: 0.0015\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9391e-04 - val_loss: 0.0015\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9101e-04 - val_loss: 0.0015\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 7.8813e-04 - val_loss: 0.0015\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8527e-04 - val_loss: 0.0015\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8242e-04 - val_loss: 0.0015\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7958e-04 - val_loss: 0.0015\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7675e-04 - val_loss: 0.0015\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7395e-04 - val_loss: 0.0015\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7116e-04 - val_loss: 0.0015\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6839e-04 - val_loss: 0.0015\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6562e-04 - val_loss: 0.0015\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6287e-04 - val_loss: 0.0015\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6014e-04 - val_loss: 0.0015\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5742e-04 - val_loss: 0.0015\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5472e-04 - val_loss: 0.0015\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5202e-04 - val_loss: 0.0015\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4934e-04 - val_loss: 0.0015\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4668e-04 - val_loss: 0.0015\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4403e-04 - val_loss: 0.0015\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4139e-04 - val_loss: 0.0014\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3877e-04 - val_loss: 0.0014\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3615e-04 - val_loss: 0.0014\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3356e-04 - val_loss: 0.0014\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3098e-04 - val_loss: 0.0014\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2841e-04 - val_loss: 0.0014\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.2585e-04 - val_loss: 0.0014\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2330e-04 - val_loss: 0.0014\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2077e-04 - val_loss: 0.0014\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1825e-04 - val_loss: 0.0014\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1575e-04 - val_loss: 0.0014\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1325e-04 - val_loss: 0.0014\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1077e-04 - val_loss: 0.0014\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0831e-04 - val_loss: 0.0014\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0585e-04 - val_loss: 0.0014\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0341e-04 - val_loss: 0.0014\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0097e-04 - val_loss: 0.0014\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9855e-04 - val_loss: 0.0014\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9615e-04 - val_loss: 0.0014\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9375e-04 - val_loss: 0.0014\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9137e-04 - val_loss: 0.0014\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8899e-04 - val_loss: 0.0014\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8663e-04 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8429e-04 - val_loss: 0.0013\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8195e-04 - val_loss: 0.0013\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7962e-04 - val_loss: 0.0013\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7731e-04 - val_loss: 0.0013\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7501e-04 - val_loss: 0.0013\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7272e-04 - val_loss: 0.0013\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7044e-04 - val_loss: 0.0013\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6817e-04 - val_loss: 0.0013\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6591e-04 - val_loss: 0.0013\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6366e-04 - val_loss: 0.0013\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6143e-04 - val_loss: 0.0013\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5920e-04 - val_loss: 0.0013\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5699e-04 - val_loss: 0.0013\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5478e-04 - val_loss: 0.0013\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5259e-04 - val_loss: 0.0013\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5041e-04 - val_loss: 0.0013\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4824e-04 - val_loss: 0.0013\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4608e-04 - val_loss: 0.0013\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4393e-04 - val_loss: 0.0013\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4178e-04 - val_loss: 0.0013\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3965e-04 - val_loss: 0.0013\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3753e-04 - val_loss: 0.0013\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3542e-04 - val_loss: 0.0013\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3332e-04 - val_loss: 0.0013\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3123e-04 - val_loss: 0.0013\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2915e-04 - val_loss: 0.0012\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2708e-04 - val_loss: 0.0012\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2502e-04 - val_loss: 0.0012\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2297e-04 - val_loss: 0.0012\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 6.2093e-04 - val_loss: 0.0012\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1889e-04 - val_loss: 0.0012\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1687e-04 - val_loss: 0.0012\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1487e-04 - val_loss: 0.0012\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1286e-04 - val_loss: 0.0012\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1086e-04 - val_loss: 0.0012\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0888e-04 - val_loss: 0.0012\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0690e-04 - val_loss: 0.0012\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0495e-04 - val_loss: 0.0012\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0299e-04 - val_loss: 0.0012\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0103e-04 - val_loss: 0.0012\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9910e-04 - val_loss: 0.0012\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9717e-04 - val_loss: 0.0012\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9525e-04 - val_loss: 0.0012\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9334e-04 - val_loss: 0.0012\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9144e-04 - val_loss: 0.0012\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8954e-04 - val_loss: 0.0012\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8765e-04 - val_loss: 0.0012\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8578e-04 - val_loss: 0.0012\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8391e-04 - val_loss: 0.0012\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8205e-04 - val_loss: 0.0012\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8020e-04 - val_loss: 0.0012\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7835e-04 - val_loss: 0.0012\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7652e-04 - val_loss: 0.0012\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7470e-04 - val_loss: 0.0012\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7288e-04 - val_loss: 0.0011\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7107e-04 - val_loss: 0.0011\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6926e-04 - val_loss: 0.0011\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6747e-04 - val_loss: 0.0011\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6569e-04 - val_loss: 0.0011\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6392e-04 - val_loss: 0.0011\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6214e-04 - val_loss: 0.0011\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6038e-04 - val_loss: 0.0011\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5862e-04 - val_loss: 0.0011\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5688e-04 - val_loss: 0.0011\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.5514e-04 - val_loss: 0.0011\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5341e-04 - val_loss: 0.0011\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5170e-04 - val_loss: 0.0011\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4998e-04 - val_loss: 0.0011\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4827e-04 - val_loss: 0.0011\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4657e-04 - val_loss: 0.0011\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4488e-04 - val_loss: 0.0011\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4320e-04 - val_loss: 0.0011\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4152e-04 - val_loss: 0.0011\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.3985e-04 - val_loss: 0.0011\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3818e-04 - val_loss: 0.0011\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3653e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3489e-04 - val_loss: 0.0011\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3324e-04 - val_loss: 0.0011\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3162e-04 - val_loss: 0.0011\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2999e-04 - val_loss: 0.0011\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2837e-04 - val_loss: 0.0011\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2676e-04 - val_loss: 0.0011\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2516e-04 - val_loss: 0.0011\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2356e-04 - val_loss: 0.0011\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2197e-04 - val_loss: 0.0011\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2038e-04 - val_loss: 0.0011\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1881e-04 - val_loss: 0.0010\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1723e-04 - val_loss: 0.0010\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1568e-04 - val_loss: 0.0010\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1412e-04 - val_loss: 0.0010\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1257e-04 - val_loss: 0.0010\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1102e-04 - val_loss: 0.0010\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.0949e-04 - val_loss: 0.0010\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0796e-04 - val_loss: 0.0010\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.0643e-04 - val_loss: 0.0010\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0492e-04 - val_loss: 0.0010\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0341e-04 - val_loss: 0.0010\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0190e-04 - val_loss: 0.0010\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0041e-04 - val_loss: 0.0010\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9891e-04 - val_loss: 0.0010\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9743e-04 - val_loss: 0.0010\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9595e-04 - val_loss: 0.0010\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9448e-04 - val_loss: 0.0010\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9301e-04 - val_loss: 0.0010\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9156e-04 - val_loss: 9.9808e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9010e-04 - val_loss: 9.9541e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8865e-04 - val_loss: 9.9271e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8722e-04 - val_loss: 9.9005e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8578e-04 - val_loss: 9.8737e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8435e-04 - val_loss: 9.8468e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8292e-04 - val_loss: 9.8207e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8151e-04 - val_loss: 9.7944e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8010e-04 - val_loss: 9.7679e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7869e-04 - val_loss: 9.7418e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7729e-04 - val_loss: 9.7159e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7590e-04 - val_loss: 9.6900e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7451e-04 - val_loss: 9.6639e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7312e-04 - val_loss: 9.6383e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7175e-04 - val_loss: 9.6125e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7038e-04 - val_loss: 9.5871e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6901e-04 - val_loss: 9.5616e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6765e-04 - val_loss: 9.5365e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6630e-04 - val_loss: 9.5110e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6495e-04 - val_loss: 9.4858e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6360e-04 - val_loss: 9.4609e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6227e-04 - val_loss: 9.4358e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6094e-04 - val_loss: 9.4108e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5961e-04 - val_loss: 9.3860e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5829e-04 - val_loss: 9.3615e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5698e-04 - val_loss: 9.3367e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5567e-04 - val_loss: 9.3122e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5436e-04 - val_loss: 9.2879e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5306e-04 - val_loss: 9.2635e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5177e-04 - val_loss: 9.2394e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5048e-04 - val_loss: 9.2149e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4919e-04 - val_loss: 9.1909e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4791e-04 - val_loss: 9.1668e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4664e-04 - val_loss: 9.1433e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.4538e-04 - val_loss: 9.1195e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.4412e-04 - val_loss: 9.0958e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4285e-04 - val_loss: 9.0720e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4160e-04 - val_loss: 9.0487e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4035e-04 - val_loss: 9.0250e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3911e-04 - val_loss: 9.0017e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3786e-04 - val_loss: 8.9784e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3663e-04 - val_loss: 8.9554e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3541e-04 - val_loss: 8.9322e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3419e-04 - val_loss: 8.9093e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3297e-04 - val_loss: 8.8862e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3175e-04 - val_loss: 8.8633e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3054e-04 - val_loss: 8.8405e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2934e-04 - val_loss: 8.8179e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2813e-04 - val_loss: 8.7953e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.2694e-04 - val_loss: 8.7729e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2576e-04 - val_loss: 8.7503e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2457e-04 - val_loss: 8.7280e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.2339e-04 - val_loss: 8.7059e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2222e-04 - val_loss: 8.6834e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2104e-04 - val_loss: 8.6616e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1987e-04 - val_loss: 8.6393e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1871e-04 - val_loss: 8.6174e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1755e-04 - val_loss: 8.5956e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1640e-04 - val_loss: 8.5740e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1526e-04 - val_loss: 8.5520e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1411e-04 - val_loss: 8.5303e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1297e-04 - val_loss: 8.5087e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1183e-04 - val_loss: 8.4874e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1070e-04 - val_loss: 8.4661e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0958e-04 - val_loss: 8.4447e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0846e-04 - val_loss: 8.4235e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0734e-04 - val_loss: 8.4021e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0622e-04 - val_loss: 8.3810e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0511e-04 - val_loss: 8.3601e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0401e-04 - val_loss: 8.3393e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0291e-04 - val_loss: 8.3181e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0181e-04 - val_loss: 8.2974e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0072e-04 - val_loss: 8.2768e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9963e-04 - val_loss: 8.2561e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9855e-04 - val_loss: 8.2354e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9747e-04 - val_loss: 8.2150e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9639e-04 - val_loss: 8.1944e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9532e-04 - val_loss: 8.1743e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.9426e-04 - val_loss: 8.1539e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9319e-04 - val_loss: 8.1337e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9213e-04 - val_loss: 8.1138e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9108e-04 - val_loss: 8.0934e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9003e-04 - val_loss: 8.0735e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8898e-04 - val_loss: 8.0535e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8793e-04 - val_loss: 8.0335e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8689e-04 - val_loss: 8.0138e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8586e-04 - val_loss: 7.9940e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8482e-04 - val_loss: 7.9744e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8380e-04 - val_loss: 7.9549e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8277e-04 - val_loss: 7.9351e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8175e-04 - val_loss: 7.9158e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8074e-04 - val_loss: 7.8963e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7972e-04 - val_loss: 7.8769e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7871e-04 - val_loss: 7.8579e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7772e-04 - val_loss: 7.8386e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7671e-04 - val_loss: 7.8194e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7570e-04 - val_loss: 7.8005e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7472e-04 - val_loss: 7.7814e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7373e-04 - val_loss: 7.7624e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7274e-04 - val_loss: 7.7436e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7176e-04 - val_loss: 7.7247e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7078e-04 - val_loss: 7.7060e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6981e-04 - val_loss: 7.6874e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6883e-04 - val_loss: 7.6688e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6786e-04 - val_loss: 7.6502e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6690e-04 - val_loss: 7.6317e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6593e-04 - val_loss: 7.6132e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6498e-04 - val_loss: 7.5951e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6403e-04 - val_loss: 7.5766e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6308e-04 - val_loss: 7.5583e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6212e-04 - val_loss: 7.5402e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6118e-04 - val_loss: 7.5220e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6025e-04 - val_loss: 7.5041e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5930e-04 - val_loss: 7.4859e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5837e-04 - val_loss: 7.4681e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5744e-04 - val_loss: 7.4501e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5651e-04 - val_loss: 7.4324e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5559e-04 - val_loss: 7.4148e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5467e-04 - val_loss: 7.3968e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5375e-04 - val_loss: 7.3793e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5284e-04 - val_loss: 7.3617e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5192e-04 - val_loss: 7.3442e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5102e-04 - val_loss: 7.3269e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5012e-04 - val_loss: 7.3095e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4922e-04 - val_loss: 7.2921e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4832e-04 - val_loss: 7.2748e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4743e-04 - val_loss: 7.2575e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4653e-04 - val_loss: 7.2404e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4564e-04 - val_loss: 7.2233e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4476e-04 - val_loss: 7.2062e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4388e-04 - val_loss: 7.1890e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4300e-04 - val_loss: 7.1722e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.4213e-04 - val_loss: 7.1552e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4126e-04 - val_loss: 7.1385e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4039e-04 - val_loss: 7.1216e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3952e-04 - val_loss: 7.1049e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3866e-04 - val_loss: 7.0883e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3780e-04 - val_loss: 7.0717e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3694e-04 - val_loss: 7.0552e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3609e-04 - val_loss: 7.0386e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3524e-04 - val_loss: 7.0221e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3439e-04 - val_loss: 7.0057e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3354e-04 - val_loss: 6.9895e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3270e-04 - val_loss: 6.9731e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3186e-04 - val_loss: 6.9570e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3103e-04 - val_loss: 6.9406e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.3020e-04 - val_loss: 6.9244e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2936e-04 - val_loss: 6.9084e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2854e-04 - val_loss: 6.8924e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2771e-04 - val_loss: 6.8763e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2689e-04 - val_loss: 6.8603e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2607e-04 - val_loss: 6.8446e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2526e-04 - val_loss: 6.8287e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2444e-04 - val_loss: 6.8130e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2363e-04 - val_loss: 6.7972e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2282e-04 - val_loss: 6.7815e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2202e-04 - val_loss: 6.7660e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2122e-04 - val_loss: 6.7503e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2042e-04 - val_loss: 6.7349e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1962e-04 - val_loss: 6.7194e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1883e-04 - val_loss: 6.7039e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1804e-04 - val_loss: 6.6885e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1725e-04 - val_loss: 6.6732e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1647e-04 - val_loss: 6.6578e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1568e-04 - val_loss: 6.6425e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1490e-04 - val_loss: 6.6275e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1413e-04 - val_loss: 6.6123e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1335e-04 - val_loss: 6.5974e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.1258e-04 - val_loss: 6.5822e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1181e-04 - val_loss: 6.5674e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1105e-04 - val_loss: 6.5523e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1027e-04 - val_loss: 6.5375e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0952e-04 - val_loss: 6.5226e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.0875e-04 - val_loss: 6.5078e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0800e-04 - val_loss: 6.4930e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0725e-04 - val_loss: 6.4784e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0649e-04 - val_loss: 6.4635e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0575e-04 - val_loss: 6.4490e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0500e-04 - val_loss: 6.4344e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0425e-04 - val_loss: 6.4200e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0352e-04 - val_loss: 6.4053e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0277e-04 - val_loss: 6.3908e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0204e-04 - val_loss: 6.3766e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0131e-04 - val_loss: 6.3621e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0057e-04 - val_loss: 6.3479e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9985e-04 - val_loss: 6.3337e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9912e-04 - val_loss: 6.3194e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.9839e-04 - val_loss: 6.3052e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9767e-04 - val_loss: 6.2910e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9695e-04 - val_loss: 6.2770e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9623e-04 - val_loss: 6.2628e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9552e-04 - val_loss: 6.2490e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9481e-04 - val_loss: 6.2349e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9409e-04 - val_loss: 6.2212e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9339e-04 - val_loss: 6.2071e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9268e-04 - val_loss: 6.1933e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9198e-04 - val_loss: 6.1796e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9128e-04 - val_loss: 6.1659e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9058e-04 - val_loss: 6.1522e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8989e-04 - val_loss: 6.1383e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8919e-04 - val_loss: 6.1248e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8850e-04 - val_loss: 6.1111e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8781e-04 - val_loss: 6.0977e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8712e-04 - val_loss: 6.0840e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8643e-04 - val_loss: 6.0707e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8576e-04 - val_loss: 6.0573e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8507e-04 - val_loss: 6.0439e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8440e-04 - val_loss: 6.0306e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8372e-04 - val_loss: 6.0173e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8305e-04 - val_loss: 6.0039e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.8237e-04 - val_loss: 5.9909e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8170e-04 - val_loss: 5.9775e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8104e-04 - val_loss: 5.9646e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8037e-04 - val_loss: 5.9514e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7971e-04 - val_loss: 5.9382e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7905e-04 - val_loss: 5.9253e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7839e-04 - val_loss: 5.9123e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7774e-04 - val_loss: 5.8994e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7708e-04 - val_loss: 5.8866e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7643e-04 - val_loss: 5.8736e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7578e-04 - val_loss: 5.8607e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7513e-04 - val_loss: 5.8480e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7448e-04 - val_loss: 5.8353e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7384e-04 - val_loss: 5.8227e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7320e-04 - val_loss: 5.8098e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7256e-04 - val_loss: 5.7971e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7192e-04 - val_loss: 5.7847e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7128e-04 - val_loss: 5.7720e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7065e-04 - val_loss: 5.7595e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7002e-04 - val_loss: 5.7470e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6939e-04 - val_loss: 5.7347e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6876e-04 - val_loss: 5.7220e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6813e-04 - val_loss: 5.7097e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6751e-04 - val_loss: 5.6974e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6688e-04 - val_loss: 5.6850e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6627e-04 - val_loss: 5.6728e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6565e-04 - val_loss: 5.6605e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6503e-04 - val_loss: 5.6484e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6442e-04 - val_loss: 5.6363e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6381e-04 - val_loss: 5.6242e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6320e-04 - val_loss: 5.6121e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6259e-04 - val_loss: 5.6000e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6198e-04 - val_loss: 5.5880e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6138e-04 - val_loss: 5.5760e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6078e-04 - val_loss: 5.5640e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.6017e-04 - val_loss: 5.5522e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5958e-04 - val_loss: 5.5401e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5898e-04 - val_loss: 5.5284e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5838e-04 - val_loss: 5.5164e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5778e-04 - val_loss: 5.5048e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5720e-04 - val_loss: 5.4928e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5661e-04 - val_loss: 5.4813e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5602e-04 - val_loss: 5.4696e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5543e-04 - val_loss: 5.4578e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5485e-04 - val_loss: 5.4463e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5427e-04 - val_loss: 5.4348e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5368e-04 - val_loss: 5.4233e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5311e-04 - val_loss: 5.4117e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5253e-04 - val_loss: 5.4002e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5195e-04 - val_loss: 5.3889e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5138e-04 - val_loss: 5.3774e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5081e-04 - val_loss: 5.3659e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5024e-04 - val_loss: 5.3546e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4967e-04 - val_loss: 5.3433e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4910e-04 - val_loss: 5.3321e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4854e-04 - val_loss: 5.3208e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4798e-04 - val_loss: 5.3097e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4741e-04 - val_loss: 5.2982e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4685e-04 - val_loss: 5.2871e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4630e-04 - val_loss: 5.2762e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4574e-04 - val_loss: 5.2650e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4518e-04 - val_loss: 5.2539e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4463e-04 - val_loss: 5.2429e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4408e-04 - val_loss: 5.2318e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4353e-04 - val_loss: 5.2209e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.4298e-04 - val_loss: 5.2101e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4244e-04 - val_loss: 5.1990e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4189e-04 - val_loss: 5.1883e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4135e-04 - val_loss: 5.1772e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.4080e-04 - val_loss: 5.1666e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4027e-04 - val_loss: 5.1556e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3972e-04 - val_loss: 5.1449e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3920e-04 - val_loss: 5.1341e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3866e-04 - val_loss: 5.1235e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.3812e-04 - val_loss: 5.1128e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3759e-04 - val_loss: 5.1023e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3706e-04 - val_loss: 5.0914e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3653e-04 - val_loss: 5.0811e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3601e-04 - val_loss: 5.0704e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3548e-04 - val_loss: 5.0599e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3495e-04 - val_loss: 5.0493e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3443e-04 - val_loss: 5.0389e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3391e-04 - val_loss: 5.0285e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3339e-04 - val_loss: 5.0181e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3287e-04 - val_loss: 5.0076e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3236e-04 - val_loss: 4.9973e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3184e-04 - val_loss: 4.9872e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3134e-04 - val_loss: 4.9768e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3082e-04 - val_loss: 4.9665e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3031e-04 - val_loss: 4.9563e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2980e-04 - val_loss: 4.9460e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2929e-04 - val_loss: 4.9359e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2879e-04 - val_loss: 4.9258e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2829e-04 - val_loss: 4.9156e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2778e-04 - val_loss: 4.9056e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2728e-04 - val_loss: 4.8954e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2678e-04 - val_loss: 4.8855e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2628e-04 - val_loss: 4.8755e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2579e-04 - val_loss: 4.8653e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2529e-04 - val_loss: 4.8555e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2479e-04 - val_loss: 4.8455e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2430e-04 - val_loss: 4.8356e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2381e-04 - val_loss: 4.8256e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2332e-04 - val_loss: 4.8160e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2283e-04 - val_loss: 4.8060e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2235e-04 - val_loss: 4.7962e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2186e-04 - val_loss: 4.7863e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2137e-04 - val_loss: 4.7767e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2089e-04 - val_loss: 4.7670e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2041e-04 - val_loss: 4.7573e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1993e-04 - val_loss: 4.7476e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1945e-04 - val_loss: 4.7379e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1898e-04 - val_loss: 4.7284e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1850e-04 - val_loss: 4.7187e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1802e-04 - val_loss: 4.7091e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1755e-04 - val_loss: 4.6997e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1708e-04 - val_loss: 4.6901e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1661e-04 - val_loss: 4.6806e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1614e-04 - val_loss: 4.6711e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1567e-04 - val_loss: 4.6616e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1521e-04 - val_loss: 4.6521e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1474e-04 - val_loss: 4.6429e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.1428e-04 - val_loss: 4.6334e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1382e-04 - val_loss: 4.6243e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1336e-04 - val_loss: 4.6148e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1290e-04 - val_loss: 4.6056e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1244e-04 - val_loss: 4.5963e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1198e-04 - val_loss: 4.5871e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1153e-04 - val_loss: 4.5779e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1107e-04 - val_loss: 4.5685e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1061e-04 - val_loss: 4.5595e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1017e-04 - val_loss: 4.5504e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0971e-04 - val_loss: 4.5412e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0926e-04 - val_loss: 4.5321e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0881e-04 - val_loss: 4.5230e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0837e-04 - val_loss: 4.5140e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0792e-04 - val_loss: 4.5049e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0748e-04 - val_loss: 4.4960e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0703e-04 - val_loss: 4.4869e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0659e-04 - val_loss: 4.4781e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.0615e-04 - val_loss: 4.4689e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0571e-04 - val_loss: 4.4601e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0527e-04 - val_loss: 4.4512e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0484e-04 - val_loss: 4.4423e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0440e-04 - val_loss: 4.4335e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0397e-04 - val_loss: 4.4247e-04\n",
      "0.0002721378696151078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03889734,  0.5113609 , -0.6847888 ,  0.5183343 , -0.75870466],\n",
       "        [-0.8815038 ,  0.291253  , -0.1051743 ,  1.1593301 , -0.62455904],\n",
       "        [ 0.81181574,  0.9476168 ,  0.36905318,  0.24579082, -0.64575255]],\n",
       "       dtype=float32),\n",
       " array([-0.6093154 ,  0.35221583, -0.6423176 , -0.48661128,  0.42522877],\n",
       "       dtype=float32),\n",
       " array([[-0.18379413,  0.43037397, -0.4279939 , -0.06893022, -0.3152057 ,\n",
       "          0.30165404, -0.36938602, -0.00873825, -0.4966687 , -0.26341173],\n",
       "        [-0.43110305, -0.49818295, -0.5748151 , -0.38305098, -0.20579858,\n",
       "         -0.6117527 ,  0.21773547,  0.21822439,  0.38463446, -0.5446202 ],\n",
       "        [-0.13812755, -0.34262168,  0.3010797 , -0.2698826 , -0.4322621 ,\n",
       "         -0.29632366, -0.79574126,  0.6050327 , -0.27839202, -0.06004401],\n",
       "        [ 0.35037553,  0.49517697,  0.20357603, -0.50358856,  0.28758958,\n",
       "          0.35600626,  0.03560254,  0.09661929,  0.634248  ,  0.0106471 ],\n",
       "        [-0.0188462 ,  0.45207652, -0.32104805, -0.04188174, -0.38038415,\n",
       "          0.15350695,  0.28804556, -0.5913686 ,  0.24856614,  0.5343197 ]],\n",
       "       dtype=float32),\n",
       " array([-0.8153349, -0.8615969, -0.8387581,  0.8480871,  0.8259359,\n",
       "         0.7891975, -0.7827736,  0.7459979,  0.8663104,  0.8523542],\n",
       "       dtype=float32),\n",
       " array([[-0.48438877],\n",
       "        [-0.73246175],\n",
       "        [-0.8176821 ],\n",
       "        [ 0.6888793 ],\n",
       "        [ 0.3680465 ],\n",
       "        [ 0.49802694],\n",
       "        [-0.46438488],\n",
       "        [ 0.2340345 ],\n",
       "        [ 0.84420896],\n",
       "        [ 0.59301674]], dtype=float32),\n",
       " array([0.8732379], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_2(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure2_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 36.1561 - val_loss: 32.3501\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.8470 - val_loss: 28.5805\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3275 - val_loss: 23.6861\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 25.2551 - val_loss: 17.3202\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 18.7940 - val_loss: 10.3379\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 11.6930 - val_loss: 4.3749\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2151 - val_loss: 0.9507\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0516 - val_loss: 2.1433\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6417 - val_loss: 4.8524\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4241 - val_loss: 5.2236\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0050 - val_loss: 3.5573\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5296 - val_loss: 1.6512\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0594 - val_loss: 0.7009\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2781 - val_loss: 0.7528\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5978 - val_loss: 1.2790\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6756 - val_loss: 1.8206\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0773 - val_loss: 2.1527\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4905 - val_loss: 2.2059\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7236 - val_loss: 1.9975\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6962 - val_loss: 1.6055\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4311 - val_loss: 1.1508\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0317 - val_loss: 0.7682\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6429 - val_loss: 0.5581\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3943 - val_loss: 0.5331\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.3404 - val_loss: 0.6036\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4332 - val_loss: 0.6459\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5565 - val_loss: 0.5993\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6037 - val_loss: 0.4908\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5377 - val_loss: 0.3804\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3930 - val_loss: 0.3093\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2395 - val_loss: 0.2899\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1394 - val_loss: 0.3132\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1174 - val_loss: 0.3563\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1574 - val_loss: 0.3926\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2208 - val_loss: 0.4009\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2697 - val_loss: 0.3715\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2811 - val_loss: 0.3075\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2511 - val_loss: 0.2227\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1918 - val_loss: 0.1374\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1244 - val_loss: 0.0721\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0712 - val_loss: 0.0403\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0476 - val_loss: 0.0434\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0557 - val_loss: 0.0689\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0841 - val_loss: 0.0964\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1129 - val_loss: 0.1082\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1253 - val_loss: 0.0982\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1154 - val_loss: 0.0732\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0899 - val_loss: 0.0459\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0614 - val_loss: 0.0276\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0408 - val_loss: 0.0227\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0327 - val_loss: 0.0298\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0352 - val_loss: 0.0433\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0430 - val_loss: 0.0571\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0500 - val_loss: 0.0669\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0522 - val_loss: 0.0707\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0487 - val_loss: 0.0690\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0413 - val_loss: 0.0638\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0331 - val_loss: 0.0573\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0272 - val_loss: 0.0507\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0249 - val_loss: 0.0448\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0254 - val_loss: 0.0393\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0268 - val_loss: 0.0342\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0273 - val_loss: 0.0297\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0260 - val_loss: 0.0263\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0234 - val_loss: 0.0242\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0205 - val_loss: 0.0233\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0185 - val_loss: 0.0234\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0178 - val_loss: 0.0242\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0183 - val_loss: 0.0253\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0191 - val_loss: 0.0264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0196 - val_loss: 0.0273\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0191 - val_loss: 0.0279\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0177 - val_loss: 0.0283\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.0286\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.0290\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0134 - val_loss: 0.0295\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0134 - val_loss: 0.0299\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0139 - val_loss: 0.0300\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0145 - val_loss: 0.0296\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0148 - val_loss: 0.0287\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0145 - val_loss: 0.0274\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0138 - val_loss: 0.0259\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0245\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.0234\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0117 - val_loss: 0.0225\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0116 - val_loss: 0.0220\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0117 - val_loss: 0.0215\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0209\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0201\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0118 - val_loss: 0.0193\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0115 - val_loss: 0.0185\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0179\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0108 - val_loss: 0.0174\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0172\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0105 - val_loss: 0.0172\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0173\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0104 - val_loss: 0.0174\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0103 - val_loss: 0.0176\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0177\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0101 - val_loss: 0.0178\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0099 - val_loss: 0.0177\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.0176\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0174\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0096 - val_loss: 0.0170\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0165\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0159\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0153\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0093 - val_loss: 0.0146\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0092 - val_loss: 0.0141\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0135\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0131\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0128\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0124\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0124\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0124\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0086 - val_loss: 0.0125\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0126\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0083 - val_loss: 0.0125\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0082 - val_loss: 0.0121\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0081 - val_loss: 0.0119\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0081 - val_loss: 0.0116\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0080 - val_loss: 0.0113\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0080 - val_loss: 0.0111\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0108\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 374us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0073 - val_loss: 0.0097\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0096\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0092\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0091\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0070 - val_loss: 0.0090\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0070 - val_loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0088\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0068 - val_loss: 0.0087\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0068 - val_loss: 0.0085\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0026 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.9887e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.9638e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.9388e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.9138e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.8886e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.8639e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 9.8393e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.8146e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 9.7901e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.7657e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.7413e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.7170e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.6929e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.6687e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 9.6447e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.6207e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 9.5969e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 9.5731e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.5495e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.5261e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.5027e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.4790e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 9.4557e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.4328e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.4095e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9953e-04 - val_loss: 9.3867e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9688e-04 - val_loss: 9.3635e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9426e-04 - val_loss: 9.3407e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9163e-04 - val_loss: 9.3180e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8901e-04 - val_loss: 9.2952e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8640e-04 - val_loss: 9.2728e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8381e-04 - val_loss: 9.2501e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8121e-04 - val_loss: 9.2278e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7863e-04 - val_loss: 9.2053e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7606e-04 - val_loss: 9.1831e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7349e-04 - val_loss: 9.1607e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7093e-04 - val_loss: 9.1388e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6839e-04 - val_loss: 9.1165e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6584e-04 - val_loss: 9.0945e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6330e-04 - val_loss: 9.0727e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6079e-04 - val_loss: 9.0510e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 9.5827e-04 - val_loss: 9.0294e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5577e-04 - val_loss: 9.0077e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5327e-04 - val_loss: 8.9862e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5078e-04 - val_loss: 8.9646e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4830e-04 - val_loss: 8.9433e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4583e-04 - val_loss: 8.9219e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4337e-04 - val_loss: 8.9006e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4091e-04 - val_loss: 8.8795e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3847e-04 - val_loss: 8.8583e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3603e-04 - val_loss: 8.8374e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3359e-04 - val_loss: 8.8165e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3116e-04 - val_loss: 8.7953e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.2874e-04 - val_loss: 8.7746e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2635e-04 - val_loss: 8.7541e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2395e-04 - val_loss: 8.7333e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2156e-04 - val_loss: 8.7125e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1916e-04 - val_loss: 8.6922e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1679e-04 - val_loss: 8.6718e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1442e-04 - val_loss: 8.6514e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1207e-04 - val_loss: 8.6312e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0971e-04 - val_loss: 8.6109e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0737e-04 - val_loss: 8.5907e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0503e-04 - val_loss: 8.5708e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0271e-04 - val_loss: 8.5505e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0039e-04 - val_loss: 8.5306e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9807e-04 - val_loss: 8.5109e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9577e-04 - val_loss: 8.4912e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9346e-04 - val_loss: 8.4712e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9117e-04 - val_loss: 8.4516e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8888e-04 - val_loss: 8.4321e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 8.8661e-04 - val_loss: 8.4124e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8435e-04 - val_loss: 8.3932e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8208e-04 - val_loss: 8.3739e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7983e-04 - val_loss: 8.3545e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7758e-04 - val_loss: 8.3353e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7534e-04 - val_loss: 8.3160e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7311e-04 - val_loss: 8.2968e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7088e-04 - val_loss: 8.2778e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6867e-04 - val_loss: 8.2587e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6644e-04 - val_loss: 8.2398e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6425e-04 - val_loss: 8.2210e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6205e-04 - val_loss: 8.2024e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5987e-04 - val_loss: 8.1835e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5768e-04 - val_loss: 8.1648e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5551e-04 - val_loss: 8.1461e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5334e-04 - val_loss: 8.1276e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5117e-04 - val_loss: 8.1090e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4902e-04 - val_loss: 8.0908e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4687e-04 - val_loss: 8.0725e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4473e-04 - val_loss: 8.0542e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4261e-04 - val_loss: 8.0361e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4048e-04 - val_loss: 8.0178e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3836e-04 - val_loss: 7.9997e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3625e-04 - val_loss: 7.9816e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3414e-04 - val_loss: 7.9635e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3205e-04 - val_loss: 7.9456e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2995e-04 - val_loss: 7.9278e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2787e-04 - val_loss: 7.9099e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2578e-04 - val_loss: 7.8923e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2372e-04 - val_loss: 7.8745e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2164e-04 - val_loss: 7.8571e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1959e-04 - val_loss: 7.8392e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1753e-04 - val_loss: 7.8220e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1549e-04 - val_loss: 7.8044e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1345e-04 - val_loss: 7.7871e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1141e-04 - val_loss: 7.7697e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.0939e-04 - val_loss: 7.7524e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0736e-04 - val_loss: 7.7353e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0536e-04 - val_loss: 7.7182e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0336e-04 - val_loss: 7.7010e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0135e-04 - val_loss: 7.6838e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.9935e-04 - val_loss: 7.6669e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9737e-04 - val_loss: 7.6499e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9539e-04 - val_loss: 7.6331e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9341e-04 - val_loss: 7.6165e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9144e-04 - val_loss: 7.5995e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8947e-04 - val_loss: 7.5829e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8752e-04 - val_loss: 7.5666e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8557e-04 - val_loss: 7.5498e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8363e-04 - val_loss: 7.5331e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8168e-04 - val_loss: 7.5167e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7975e-04 - val_loss: 7.5003e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7783e-04 - val_loss: 7.4837e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7590e-04 - val_loss: 7.4675e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7399e-04 - val_loss: 7.4511e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7208e-04 - val_loss: 7.4350e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7017e-04 - val_loss: 7.4189e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6829e-04 - val_loss: 7.4026e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6640e-04 - val_loss: 7.3867e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6452e-04 - val_loss: 7.3704e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6264e-04 - val_loss: 7.3545e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6077e-04 - val_loss: 7.3387e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5890e-04 - val_loss: 7.3230e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5704e-04 - val_loss: 7.3072e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5518e-04 - val_loss: 7.2914e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5333e-04 - val_loss: 7.2755e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5148e-04 - val_loss: 7.2598e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4965e-04 - val_loss: 7.2441e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4781e-04 - val_loss: 7.2285e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4598e-04 - val_loss: 7.2131e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4416e-04 - val_loss: 7.1976e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4234e-04 - val_loss: 7.1822e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4055e-04 - val_loss: 7.1669e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.3873e-04 - val_loss: 7.1516e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3694e-04 - val_loss: 7.1362e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3515e-04 - val_loss: 7.1211e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3335e-04 - val_loss: 7.1059e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3157e-04 - val_loss: 7.0908e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2980e-04 - val_loss: 7.0756e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2803e-04 - val_loss: 7.0608e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2626e-04 - val_loss: 7.0455e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2450e-04 - val_loss: 7.0307e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2275e-04 - val_loss: 7.0157e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2100e-04 - val_loss: 7.0008e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1925e-04 - val_loss: 6.9861e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1752e-04 - val_loss: 6.9713e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1579e-04 - val_loss: 6.9567e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1406e-04 - val_loss: 6.9422e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1233e-04 - val_loss: 6.9274e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1062e-04 - val_loss: 6.9128e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0890e-04 - val_loss: 6.8984e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0721e-04 - val_loss: 6.8840e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0550e-04 - val_loss: 6.8693e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0380e-04 - val_loss: 6.8549e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0211e-04 - val_loss: 6.8405e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.0042e-04 - val_loss: 6.8262e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9874e-04 - val_loss: 6.8119e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.9706e-04 - val_loss: 6.7978e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9540e-04 - val_loss: 6.7837e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9374e-04 - val_loss: 6.7693e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9207e-04 - val_loss: 6.7555e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9041e-04 - val_loss: 6.7413e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8876e-04 - val_loss: 6.7274e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8712e-04 - val_loss: 6.7134e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8549e-04 - val_loss: 6.6994e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8385e-04 - val_loss: 6.6853e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8222e-04 - val_loss: 6.6716e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8059e-04 - val_loss: 6.6580e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7897e-04 - val_loss: 6.6439e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7736e-04 - val_loss: 6.6304e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7574e-04 - val_loss: 6.6167e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7414e-04 - val_loss: 6.6031e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7253e-04 - val_loss: 6.5895e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7093e-04 - val_loss: 6.5758e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6934e-04 - val_loss: 6.5622e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6776e-04 - val_loss: 6.5488e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6618e-04 - val_loss: 6.5353e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6460e-04 - val_loss: 6.5220e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6303e-04 - val_loss: 6.5088e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.6146e-04 - val_loss: 6.4955e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5989e-04 - val_loss: 6.4822e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5834e-04 - val_loss: 6.4689e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5679e-04 - val_loss: 6.4556e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5523e-04 - val_loss: 6.4423e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5369e-04 - val_loss: 6.4293e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5215e-04 - val_loss: 6.4162e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5060e-04 - val_loss: 6.4031e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4908e-04 - val_loss: 6.3901e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.4756e-04 - val_loss: 6.3771e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4603e-04 - val_loss: 6.3642e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4451e-04 - val_loss: 6.3513e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4300e-04 - val_loss: 6.3384e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4149e-04 - val_loss: 6.3256e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3999e-04 - val_loss: 6.3128e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3849e-04 - val_loss: 6.3003e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3699e-04 - val_loss: 6.2876e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3550e-04 - val_loss: 6.2747e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3402e-04 - val_loss: 6.2622e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3253e-04 - val_loss: 6.2495e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3106e-04 - val_loss: 6.2371e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2959e-04 - val_loss: 6.2245e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2812e-04 - val_loss: 6.2118e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2665e-04 - val_loss: 6.1991e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2519e-04 - val_loss: 6.1868e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2374e-04 - val_loss: 6.1745e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.2228e-04 - val_loss: 6.1623e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2084e-04 - val_loss: 6.1499e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1939e-04 - val_loss: 6.1377e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1797e-04 - val_loss: 6.1254e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1653e-04 - val_loss: 6.1132e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1510e-04 - val_loss: 6.1011e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1367e-04 - val_loss: 6.0888e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.1225e-04 - val_loss: 6.0766e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1083e-04 - val_loss: 6.0646e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0942e-04 - val_loss: 6.0525e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0800e-04 - val_loss: 6.0405e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0659e-04 - val_loss: 6.0286e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0520e-04 - val_loss: 6.0168e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0379e-04 - val_loss: 6.0048e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0241e-04 - val_loss: 5.9929e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 6.0102e-04 - val_loss: 5.9809e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9963e-04 - val_loss: 5.9690e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9825e-04 - val_loss: 5.9574e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9688e-04 - val_loss: 5.9456e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9550e-04 - val_loss: 5.9339e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9413e-04 - val_loss: 5.9222e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9276e-04 - val_loss: 5.9106e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.9140e-04 - val_loss: 5.8990e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9005e-04 - val_loss: 5.8873e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8869e-04 - val_loss: 5.8756e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8735e-04 - val_loss: 5.8643e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8599e-04 - val_loss: 5.8528e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8466e-04 - val_loss: 5.8412e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8331e-04 - val_loss: 5.8298e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8198e-04 - val_loss: 5.8185e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.8065e-04 - val_loss: 5.8071e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7933e-04 - val_loss: 5.7956e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7800e-04 - val_loss: 5.7846e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7668e-04 - val_loss: 5.7732e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7537e-04 - val_loss: 5.7618e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7406e-04 - val_loss: 5.7505e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7275e-04 - val_loss: 5.7393e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7145e-04 - val_loss: 5.7284e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7015e-04 - val_loss: 5.7170e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6884e-04 - val_loss: 5.7062e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6756e-04 - val_loss: 5.6950e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6627e-04 - val_loss: 5.6839e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6498e-04 - val_loss: 5.6729e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6370e-04 - val_loss: 5.6620e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6243e-04 - val_loss: 5.6510e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6114e-04 - val_loss: 5.6401e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5988e-04 - val_loss: 5.6292e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5861e-04 - val_loss: 5.6182e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5734e-04 - val_loss: 5.6074e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5609e-04 - val_loss: 5.5966e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5483e-04 - val_loss: 5.5858e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5358e-04 - val_loss: 5.5749e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5233e-04 - val_loss: 5.5643e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5109e-04 - val_loss: 5.5535e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4983e-04 - val_loss: 5.5430e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4859e-04 - val_loss: 5.5324e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4736e-04 - val_loss: 5.5219e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4613e-04 - val_loss: 5.5113e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.4491e-04 - val_loss: 5.5006e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4368e-04 - val_loss: 5.4899e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4246e-04 - val_loss: 5.4795e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 5.4124e-04 - val_loss: 5.4690e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4002e-04 - val_loss: 5.4585e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3882e-04 - val_loss: 5.4482e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3761e-04 - val_loss: 5.4379e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3641e-04 - val_loss: 5.4275e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3520e-04 - val_loss: 5.4171e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3400e-04 - val_loss: 5.4067e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3281e-04 - val_loss: 5.3964e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3163e-04 - val_loss: 5.3862e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3043e-04 - val_loss: 5.3758e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2925e-04 - val_loss: 5.3658e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2807e-04 - val_loss: 5.3555e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2689e-04 - val_loss: 5.3454e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2571e-04 - val_loss: 5.3353e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2454e-04 - val_loss: 5.3251e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2337e-04 - val_loss: 5.3150e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2220e-04 - val_loss: 5.3048e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2105e-04 - val_loss: 5.2949e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1989e-04 - val_loss: 5.2849e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1873e-04 - val_loss: 5.2750e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1758e-04 - val_loss: 5.2649e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1643e-04 - val_loss: 5.2549e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1528e-04 - val_loss: 5.2452e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.1414e-04 - val_loss: 5.2354e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1301e-04 - val_loss: 5.2254e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1187e-04 - val_loss: 5.2154e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.1074e-04 - val_loss: 5.2058e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0961e-04 - val_loss: 5.1959e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0849e-04 - val_loss: 5.1861e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0736e-04 - val_loss: 5.1763e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0623e-04 - val_loss: 5.1666e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0512e-04 - val_loss: 5.1569e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0401e-04 - val_loss: 5.1473e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0289e-04 - val_loss: 5.1377e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0179e-04 - val_loss: 5.1280e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0068e-04 - val_loss: 5.1184e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9957e-04 - val_loss: 5.1089e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9848e-04 - val_loss: 5.0993e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9738e-04 - val_loss: 5.0898e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9629e-04 - val_loss: 5.0805e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9521e-04 - val_loss: 5.0708e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9411e-04 - val_loss: 5.0613e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9303e-04 - val_loss: 5.0518e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9195e-04 - val_loss: 5.0425e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9087e-04 - val_loss: 5.0332e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8979e-04 - val_loss: 5.0236e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8872e-04 - val_loss: 5.0144e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8765e-04 - val_loss: 5.0050e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8658e-04 - val_loss: 4.9957e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.8552e-04 - val_loss: 4.9865e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8446e-04 - val_loss: 4.9773e-04\n",
      "0.0002449593448545784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.7244419 , -0.18053065, -0.52981913, -0.43697247,  0.53630316],\n",
       "        [-0.94422174, -0.00260216,  0.33968464,  0.60096806, -0.44988677],\n",
       "        [ 0.8580506 ,  1.584395  ,  0.8190745 ,  0.52542037,  0.65288067]],\n",
       "       dtype=float32),\n",
       " array([-0.5093216 ,  0.37297165, -0.65194654, -0.36437142, -0.6290139 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.0578681 ,  0.2785509 , -0.4462231 , -0.40439898, -0.5536354 ,\n",
       "         -0.22892714, -0.18569808,  0.1688244 , -0.15997669,  0.23754506,\n",
       "         -0.08420013, -0.15355483, -0.37878224, -0.1059102 , -0.0822348 ],\n",
       "        [-0.0954055 , -0.15297212, -0.1094649 ,  0.00628059, -0.06464136,\n",
       "          0.5020361 ,  0.3382464 ,  0.22174034, -0.52526903, -0.5246862 ,\n",
       "          0.21151787, -0.2588147 , -0.10743792,  0.12558886,  0.35835662],\n",
       "        [ 0.05023582, -0.55573136,  0.03018558,  0.16093665, -0.01578087,\n",
       "         -0.0438478 ,  0.3578779 , -0.42825553, -0.50969064,  0.1254739 ,\n",
       "          0.331195  ,  0.20409352,  0.3858541 ,  0.28731725, -0.54692954],\n",
       "        [-0.1954887 ,  0.4802603 ,  0.07171959, -0.0313434 , -0.3040755 ,\n",
       "          0.0714956 ,  0.36108795, -0.07560654,  0.008303  , -0.0729896 ,\n",
       "         -0.20283355,  0.13123094,  0.07951839,  0.31293884, -0.13625787],\n",
       "        [-0.2538412 ,  0.45073563,  0.10152207, -0.04494459, -0.59335876,\n",
       "          0.16329853, -0.40585086, -0.5750757 , -0.13701706,  0.49161652,\n",
       "         -0.02069991, -0.35751307,  0.379549  ,  0.16547228, -0.58570826]],\n",
       "       dtype=float32),\n",
       " array([-0.14095262,  0.6340112 , -0.6542841 ,  0.48464894,  0.72205454,\n",
       "         0.71162623, -0.6010625 ,  0.60677636,  0.59395236, -0.7318    ,\n",
       "         0.7313231 , -0.70800054, -0.52575177,  0.7122615 ,  0.7077394 ],\n",
       "       dtype=float32),\n",
       " array([[-0.03963402],\n",
       "        [ 0.47715783],\n",
       "        [-0.40882322],\n",
       "        [ 0.19263232],\n",
       "        [ 0.5559553 ],\n",
       "        [ 0.5448757 ],\n",
       "        [-0.31785166],\n",
       "        [ 0.32313597],\n",
       "        [ 0.32773167],\n",
       "        [-0.6377092 ],\n",
       "        [ 0.65453225],\n",
       "        [-0.5547439 ],\n",
       "        [-0.25975436],\n",
       "        [ 0.5724046 ],\n",
       "        [ 0.5368243 ]], dtype=float32),\n",
       " array([0.80000955], dtype=float32)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_3(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure3_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 36.1100 - val_loss: 32.3294\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.8553 - val_loss: 27.7322\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 28.2076 - val_loss: 21.6494\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 22.2652 - val_loss: 14.4642\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 15.3166 - val_loss: 7.5180\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1756 - val_loss: 2.6316\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4942 - val_loss: 1.4667\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7702 - val_loss: 3.4896\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0869 - val_loss: 4.3828\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9874 - val_loss: 2.9030\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2442 - val_loss: 1.0907\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7590 - val_loss: 0.3294\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6139 - val_loss: 0.7575\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6777 - val_loss: 1.8542\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.8521 - val_loss: 2.9277\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5179 - val_loss: 3.5688\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1101 - val_loss: 3.7300\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4017 - val_loss: 3.5176\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3808 - val_loss: 3.0637\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1141 - val_loss: 2.4850\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6889 - val_loss: 1.8784\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1991 - val_loss: 1.3229\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7414 - val_loss: 0.8770\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4039 - val_loss: 0.5695\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2425 - val_loss: 0.3953\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2564 - val_loss: 0.3218\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3873 - val_loss: 0.3066\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5484 - val_loss: 0.3118\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6650 - val_loss: 0.3113\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6965 - val_loss: 0.2917\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6377 - val_loss: 0.2541\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5109 - val_loss: 0.2130\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3575 - val_loss: 0.1879\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2229 - val_loss: 0.1921\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1385 - val_loss: 0.2253\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1113 - val_loss: 0.2750\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1275 - val_loss: 0.3248\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1643 - val_loss: 0.3604\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2007 - val_loss: 0.3741\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2227 - val_loss: 0.3646\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2241 - val_loss: 0.3352\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2045 - val_loss: 0.2922\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1683 - val_loss: 0.2431\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1237 - val_loss: 0.1956\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0810 - val_loss: 0.1556\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0498 - val_loss: 0.1265\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0356 - val_loss: 0.1082\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0378 - val_loss: 0.0980\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0504 - val_loss: 0.0919\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0656 - val_loss: 0.0863\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0768 - val_loss: 0.0790\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0803 - val_loss: 0.0695\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0760 - val_loss: 0.0588\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0656 - val_loss: 0.0486\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0523 - val_loss: 0.0408\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0398 - val_loss: 0.0366\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0310 - val_loss: 0.0363\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0274 - val_loss: 0.0390\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0431\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0323 - val_loss: 0.0467\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0364 - val_loss: 0.0485\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0390 - val_loss: 0.0479\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0392 - val_loss: 0.0448\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0369 - val_loss: 0.0399\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0330 - val_loss: 0.0341\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0284 - val_loss: 0.0282\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0241 - val_loss: 0.0233\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0209 - val_loss: 0.0200\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0192 - val_loss: 0.0183\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0191 - val_loss: 0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0200 - val_loss: 0.0185\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0213 - val_loss: 0.0190\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0221 - val_loss: 0.0193\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.0191\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0213 - val_loss: 0.0187\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0199 - val_loss: 0.0185\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0184 - val_loss: 0.0186\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0171 - val_loss: 0.0191\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0200\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0158 - val_loss: 0.0210\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0157 - val_loss: 0.0218\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0224\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0225\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0222\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0214\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0158 - val_loss: 0.0203\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0152 - val_loss: 0.0192\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0146 - val_loss: 0.0182\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0140 - val_loss: 0.0173\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0167\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0163\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0131 - val_loss: 0.0160\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0130 - val_loss: 0.0155\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0146\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0116 - val_loss: 0.0146\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.0145\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0113 - val_loss: 0.0145\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0112 - val_loss: 0.0145\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0112 - val_loss: 0.0145\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0111 - val_loss: 0.0144\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0110 - val_loss: 0.0143\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0140\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0099 - val_loss: 0.0129\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0126\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0096 - val_loss: 0.0125\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0124\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0094 - val_loss: 0.0123\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0121\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0073 - val_loss: 0.0096\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0070 - val_loss: 0.0092\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0091\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0091\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0088\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0088\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0087\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0064 - val_loss: 0.0085\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0079\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0069\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0060\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9859e-04 - val_loss: 0.0015\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9458e-04 - val_loss: 0.0015\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9057e-04 - val_loss: 0.0014\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8660e-04 - val_loss: 0.0014\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.8265e-04 - val_loss: 0.0014\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7872e-04 - val_loss: 0.0014\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7480e-04 - val_loss: 0.0014\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.7093e-04 - val_loss: 0.0014\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6706e-04 - val_loss: 0.0014\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6321e-04 - val_loss: 0.0014\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5940e-04 - val_loss: 0.0014\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5560e-04 - val_loss: 0.0014\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5183e-04 - val_loss: 0.0014\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4807e-04 - val_loss: 0.0014\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4433e-04 - val_loss: 0.0014\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4062e-04 - val_loss: 0.0014\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3693e-04 - val_loss: 0.0014\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3326e-04 - val_loss: 0.0014\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2960e-04 - val_loss: 0.0014\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2598e-04 - val_loss: 0.0014\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.2235e-04 - val_loss: 0.0014\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1876e-04 - val_loss: 0.0013\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1520e-04 - val_loss: 0.0013\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1164e-04 - val_loss: 0.0013\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0812e-04 - val_loss: 0.0013\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.0461e-04 - val_loss: 0.0013\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0111e-04 - val_loss: 0.0013\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9764e-04 - val_loss: 0.0013\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 8.9419e-04 - val_loss: 0.0013\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9077e-04 - val_loss: 0.0013\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.8734e-04 - val_loss: 0.0013\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8394e-04 - val_loss: 0.0013\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8057e-04 - val_loss: 0.0013\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7722e-04 - val_loss: 0.0013\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7387e-04 - val_loss: 0.0013\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7055e-04 - val_loss: 0.0013\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6725e-04 - val_loss: 0.0013\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6397e-04 - val_loss: 0.0013\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6070e-04 - val_loss: 0.0013\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5744e-04 - val_loss: 0.0013\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5423e-04 - val_loss: 0.0013\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5101e-04 - val_loss: 0.0012\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4782e-04 - val_loss: 0.0012\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4464e-04 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4148e-04 - val_loss: 0.0012\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3834e-04 - val_loss: 0.0012\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3521e-04 - val_loss: 0.0012\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3211e-04 - val_loss: 0.0012\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2901e-04 - val_loss: 0.0012\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2593e-04 - val_loss: 0.0012\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2288e-04 - val_loss: 0.0012\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1984e-04 - val_loss: 0.0012\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1682e-04 - val_loss: 0.0012\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1381e-04 - val_loss: 0.0012\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1081e-04 - val_loss: 0.0012\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0785e-04 - val_loss: 0.0012\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0489e-04 - val_loss: 0.0012\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0194e-04 - val_loss: 0.0012\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9901e-04 - val_loss: 0.0012\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9611e-04 - val_loss: 0.0012\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9321e-04 - val_loss: 0.0012\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.9034e-04 - val_loss: 0.0012\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8746e-04 - val_loss: 0.0012\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8461e-04 - val_loss: 0.0012\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8179e-04 - val_loss: 0.0012\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7897e-04 - val_loss: 0.0011\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7617e-04 - val_loss: 0.0011\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7337e-04 - val_loss: 0.0011\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7060e-04 - val_loss: 0.0011\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6784e-04 - val_loss: 0.0011\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6510e-04 - val_loss: 0.0011\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6237e-04 - val_loss: 0.0011\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5965e-04 - val_loss: 0.0011\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5696e-04 - val_loss: 0.0011\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5427e-04 - val_loss: 0.0011\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5161e-04 - val_loss: 0.0011\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.4894e-04 - val_loss: 0.0011\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4630e-04 - val_loss: 0.0011\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4368e-04 - val_loss: 0.0011\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4106e-04 - val_loss: 0.0011\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3846e-04 - val_loss: 0.0011\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3588e-04 - val_loss: 0.0011\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3330e-04 - val_loss: 0.0011\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3074e-04 - val_loss: 0.0011\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2819e-04 - val_loss: 0.0011\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2567e-04 - val_loss: 0.0011\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2314e-04 - val_loss: 0.0011\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 7.2064e-04 - val_loss: 0.0011\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1815e-04 - val_loss: 0.0011\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1567e-04 - val_loss: 0.0011\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1320e-04 - val_loss: 0.0011\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1074e-04 - val_loss: 0.0010\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0830e-04 - val_loss: 0.0010\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0588e-04 - val_loss: 0.0010\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0346e-04 - val_loss: 0.0010\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0106e-04 - val_loss: 0.0010\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9867e-04 - val_loss: 0.0010\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9630e-04 - val_loss: 0.0010\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9394e-04 - val_loss: 0.0010\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9158e-04 - val_loss: 0.0010\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8923e-04 - val_loss: 0.0010\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8691e-04 - val_loss: 0.0010\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8460e-04 - val_loss: 0.0010\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8230e-04 - val_loss: 0.0010\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8000e-04 - val_loss: 0.0010\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7772e-04 - val_loss: 0.0010\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.7545e-04 - val_loss: 9.9720e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7319e-04 - val_loss: 9.9389e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7095e-04 - val_loss: 9.9062e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6872e-04 - val_loss: 9.8737e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6650e-04 - val_loss: 9.8411e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6429e-04 - val_loss: 9.8087e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6209e-04 - val_loss: 9.7764e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5990e-04 - val_loss: 9.7446e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5772e-04 - val_loss: 9.7128e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5556e-04 - val_loss: 9.6811e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5341e-04 - val_loss: 9.6492e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5126e-04 - val_loss: 9.6178e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4913e-04 - val_loss: 9.5865e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4701e-04 - val_loss: 9.5557e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4490e-04 - val_loss: 9.5246e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4280e-04 - val_loss: 9.4937e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.4071e-04 - val_loss: 9.4631e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3864e-04 - val_loss: 9.4326e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3657e-04 - val_loss: 9.4023e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3451e-04 - val_loss: 9.3718e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3247e-04 - val_loss: 9.3417e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3044e-04 - val_loss: 9.3119e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2841e-04 - val_loss: 9.2818e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2640e-04 - val_loss: 9.2521e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2439e-04 - val_loss: 9.2224e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2239e-04 - val_loss: 9.1929e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2041e-04 - val_loss: 9.1636e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.1844e-04 - val_loss: 9.1344e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1647e-04 - val_loss: 9.1055e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.1451e-04 - val_loss: 9.0765e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1257e-04 - val_loss: 9.0478e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1064e-04 - val_loss: 9.0189e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0871e-04 - val_loss: 8.9908e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.0680e-04 - val_loss: 8.9623e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0489e-04 - val_loss: 8.9341e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0299e-04 - val_loss: 8.9060e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.0111e-04 - val_loss: 8.8779e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9922e-04 - val_loss: 8.8501e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9736e-04 - val_loss: 8.8225e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9550e-04 - val_loss: 8.7945e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9365e-04 - val_loss: 8.7673e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9181e-04 - val_loss: 8.7397e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8998e-04 - val_loss: 8.7124e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8816e-04 - val_loss: 8.6852e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8634e-04 - val_loss: 8.6583e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8454e-04 - val_loss: 8.6316e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8275e-04 - val_loss: 8.6048e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8096e-04 - val_loss: 8.5782e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7918e-04 - val_loss: 8.5516e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7741e-04 - val_loss: 8.5251e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7565e-04 - val_loss: 8.4990e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7390e-04 - val_loss: 8.4727e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7217e-04 - val_loss: 8.4467e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7043e-04 - val_loss: 8.4207e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6870e-04 - val_loss: 8.3950e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6699e-04 - val_loss: 8.3694e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6528e-04 - val_loss: 8.3437e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6358e-04 - val_loss: 8.3180e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6188e-04 - val_loss: 8.2929e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6020e-04 - val_loss: 8.2676e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5852e-04 - val_loss: 8.2425e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5686e-04 - val_loss: 8.2173e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5520e-04 - val_loss: 8.1921e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5354e-04 - val_loss: 8.1677e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5191e-04 - val_loss: 8.1429e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 5.5027e-04 - val_loss: 8.1180e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4865e-04 - val_loss: 8.0938e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4703e-04 - val_loss: 8.0694e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4542e-04 - val_loss: 8.0452e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4382e-04 - val_loss: 8.0210e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4222e-04 - val_loss: 7.9971e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4063e-04 - val_loss: 7.9732e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3906e-04 - val_loss: 7.9492e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3748e-04 - val_loss: 7.9257e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3592e-04 - val_loss: 7.9016e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3436e-04 - val_loss: 7.8785e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3281e-04 - val_loss: 7.8551e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3127e-04 - val_loss: 7.8317e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2972e-04 - val_loss: 7.8085e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2820e-04 - val_loss: 7.7854e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2669e-04 - val_loss: 7.7625e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2517e-04 - val_loss: 7.7394e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2367e-04 - val_loss: 7.7166e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2217e-04 - val_loss: 7.6937e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2068e-04 - val_loss: 7.6709e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1919e-04 - val_loss: 7.6484e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1772e-04 - val_loss: 7.6261e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1625e-04 - val_loss: 7.6037e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1478e-04 - val_loss: 7.5817e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1333e-04 - val_loss: 7.5595e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1188e-04 - val_loss: 7.5373e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1044e-04 - val_loss: 7.5153e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0900e-04 - val_loss: 7.4933e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0757e-04 - val_loss: 7.4716e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.0615e-04 - val_loss: 7.4500e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0474e-04 - val_loss: 7.4285e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0333e-04 - val_loss: 7.4071e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0192e-04 - val_loss: 7.3855e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0053e-04 - val_loss: 7.3644e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9914e-04 - val_loss: 7.3431e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9776e-04 - val_loss: 7.3220e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9639e-04 - val_loss: 7.3011e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9501e-04 - val_loss: 7.2799e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9366e-04 - val_loss: 7.2591e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9230e-04 - val_loss: 7.2383e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9094e-04 - val_loss: 7.2176e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8961e-04 - val_loss: 7.1969e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8826e-04 - val_loss: 7.1765e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8694e-04 - val_loss: 7.1559e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8561e-04 - val_loss: 7.1355e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8429e-04 - val_loss: 7.1155e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8298e-04 - val_loss: 7.0953e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8168e-04 - val_loss: 7.0751e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8037e-04 - val_loss: 7.0551e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.7908e-04 - val_loss: 7.0351e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7779e-04 - val_loss: 7.0153e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.7650e-04 - val_loss: 6.9956e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7522e-04 - val_loss: 6.9761e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7396e-04 - val_loss: 6.9566e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7269e-04 - val_loss: 6.9371e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7143e-04 - val_loss: 6.9173e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7018e-04 - val_loss: 6.8982e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6893e-04 - val_loss: 6.8789e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6769e-04 - val_loss: 6.8597e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6645e-04 - val_loss: 6.8405e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6522e-04 - val_loss: 6.8216e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6400e-04 - val_loss: 6.8023e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6277e-04 - val_loss: 6.7836e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6157e-04 - val_loss: 6.7649e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6036e-04 - val_loss: 6.7460e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5916e-04 - val_loss: 6.7274e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5795e-04 - val_loss: 6.7088e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5676e-04 - val_loss: 6.6905e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5558e-04 - val_loss: 6.6722e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5439e-04 - val_loss: 6.6537e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5322e-04 - val_loss: 6.6355e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5205e-04 - val_loss: 6.6175e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5088e-04 - val_loss: 6.5993e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4972e-04 - val_loss: 6.5813e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4857e-04 - val_loss: 6.5632e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4742e-04 - val_loss: 6.5454e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4628e-04 - val_loss: 6.5276e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4514e-04 - val_loss: 6.5098e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4400e-04 - val_loss: 6.4922e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4288e-04 - val_loss: 6.4745e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.4175e-04 - val_loss: 6.4571e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4063e-04 - val_loss: 6.4396e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3952e-04 - val_loss: 6.4221e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.3841e-04 - val_loss: 6.4048e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3730e-04 - val_loss: 6.3875e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3620e-04 - val_loss: 6.3704e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3511e-04 - val_loss: 6.3532e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3402e-04 - val_loss: 6.3363e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3293e-04 - val_loss: 6.3192e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3185e-04 - val_loss: 6.3024e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3078e-04 - val_loss: 6.2857e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2972e-04 - val_loss: 6.2687e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2864e-04 - val_loss: 6.2520e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2759e-04 - val_loss: 6.2354e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2652e-04 - val_loss: 6.2189e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2548e-04 - val_loss: 6.2025e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2443e-04 - val_loss: 6.1859e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2338e-04 - val_loss: 6.1695e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2235e-04 - val_loss: 6.1531e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.2132e-04 - val_loss: 6.1370e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2028e-04 - val_loss: 6.1207e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1926e-04 - val_loss: 6.1046e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.1824e-04 - val_loss: 6.0886e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1723e-04 - val_loss: 6.0725e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1622e-04 - val_loss: 6.0566e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1521e-04 - val_loss: 6.0407e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1420e-04 - val_loss: 6.0249e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1321e-04 - val_loss: 6.0092e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1221e-04 - val_loss: 5.9935e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1122e-04 - val_loss: 5.9778e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1024e-04 - val_loss: 5.9621e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0925e-04 - val_loss: 5.9468e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0829e-04 - val_loss: 5.9316e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0732e-04 - val_loss: 5.9162e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0635e-04 - val_loss: 5.9007e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0538e-04 - val_loss: 5.8854e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0442e-04 - val_loss: 5.8703e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.0346e-04 - val_loss: 5.8551e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.0251e-04 - val_loss: 5.8402e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0156e-04 - val_loss: 5.8251e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0062e-04 - val_loss: 5.8102e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9968e-04 - val_loss: 5.7953e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9875e-04 - val_loss: 5.7805e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9782e-04 - val_loss: 5.7656e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9689e-04 - val_loss: 5.7510e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9596e-04 - val_loss: 5.7365e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9505e-04 - val_loss: 5.7215e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9412e-04 - val_loss: 5.7070e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9322e-04 - val_loss: 5.6922e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9230e-04 - val_loss: 5.6780e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9141e-04 - val_loss: 5.6636e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.9050e-04 - val_loss: 5.6493e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8960e-04 - val_loss: 5.6350e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8871e-04 - val_loss: 5.6206e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8782e-04 - val_loss: 5.6066e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8694e-04 - val_loss: 5.5926e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8606e-04 - val_loss: 5.5783e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8518e-04 - val_loss: 5.5643e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8430e-04 - val_loss: 5.5506e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8344e-04 - val_loss: 5.5366e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8257e-04 - val_loss: 5.5228e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8170e-04 - val_loss: 5.5089e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8084e-04 - val_loss: 5.4951e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7998e-04 - val_loss: 5.4816e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7913e-04 - val_loss: 5.4679e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7828e-04 - val_loss: 5.4543e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.7743e-04 - val_loss: 5.4407e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7659e-04 - val_loss: 5.4273e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7575e-04 - val_loss: 5.4138e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7492e-04 - val_loss: 5.4003e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7409e-04 - val_loss: 5.3869e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7326e-04 - val_loss: 5.3735e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7243e-04 - val_loss: 5.3605e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7161e-04 - val_loss: 5.3472e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7079e-04 - val_loss: 5.3341e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6998e-04 - val_loss: 5.3211e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6917e-04 - val_loss: 5.3083e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6836e-04 - val_loss: 5.2951e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6755e-04 - val_loss: 5.2822e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6675e-04 - val_loss: 5.2690e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6595e-04 - val_loss: 5.2563e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6516e-04 - val_loss: 5.2434e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6437e-04 - val_loss: 5.2306e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6358e-04 - val_loss: 5.2180e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6279e-04 - val_loss: 5.2052e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6200e-04 - val_loss: 5.1928e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6123e-04 - val_loss: 5.1802e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6045e-04 - val_loss: 5.1676e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5968e-04 - val_loss: 5.1551e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5891e-04 - val_loss: 5.1428e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5814e-04 - val_loss: 5.1305e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5737e-04 - val_loss: 5.1181e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5661e-04 - val_loss: 5.1058e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5586e-04 - val_loss: 5.0937e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5510e-04 - val_loss: 5.0814e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5436e-04 - val_loss: 5.0692e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5360e-04 - val_loss: 5.0571e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5286e-04 - val_loss: 5.0448e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5211e-04 - val_loss: 5.0328e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5138e-04 - val_loss: 5.0210e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5064e-04 - val_loss: 5.0091e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4991e-04 - val_loss: 4.9972e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4917e-04 - val_loss: 4.9853e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4844e-04 - val_loss: 4.9735e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4771e-04 - val_loss: 4.9617e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4700e-04 - val_loss: 4.9500e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4627e-04 - val_loss: 4.9383e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4556e-04 - val_loss: 4.9265e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4485e-04 - val_loss: 4.9150e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4413e-04 - val_loss: 4.9033e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4343e-04 - val_loss: 4.8919e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4272e-04 - val_loss: 4.8805e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4201e-04 - val_loss: 4.8691e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4132e-04 - val_loss: 4.8576e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4062e-04 - val_loss: 4.8465e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3993e-04 - val_loss: 4.8350e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3923e-04 - val_loss: 4.8240e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3854e-04 - val_loss: 4.8127e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3785e-04 - val_loss: 4.8015e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3718e-04 - val_loss: 4.7903e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.3649e-04 - val_loss: 4.7790e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.3581e-04 - val_loss: 4.7679e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3514e-04 - val_loss: 4.7569e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3446e-04 - val_loss: 4.7460e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3379e-04 - val_loss: 4.7351e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3312e-04 - val_loss: 4.7242e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3245e-04 - val_loss: 4.7136e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3180e-04 - val_loss: 4.7025e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3114e-04 - val_loss: 4.6918e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.3047e-04 - val_loss: 4.6809e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2982e-04 - val_loss: 4.6703e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2917e-04 - val_loss: 4.6594e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2851e-04 - val_loss: 4.6490e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2787e-04 - val_loss: 4.6381e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2722e-04 - val_loss: 4.6277e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2658e-04 - val_loss: 4.6171e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2594e-04 - val_loss: 4.6066e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2530e-04 - val_loss: 4.5962e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.2466e-04 - val_loss: 4.5859e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2403e-04 - val_loss: 4.5754e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2339e-04 - val_loss: 4.5649e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2276e-04 - val_loss: 4.5546e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2214e-04 - val_loss: 4.5444e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2152e-04 - val_loss: 4.5344e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2090e-04 - val_loss: 4.5243e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2028e-04 - val_loss: 4.5140e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1965e-04 - val_loss: 4.5039e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1904e-04 - val_loss: 4.4936e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1843e-04 - val_loss: 4.4836e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1782e-04 - val_loss: 4.4736e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.1721e-04 - val_loss: 4.4634e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1661e-04 - val_loss: 4.4535e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1600e-04 - val_loss: 4.4436e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.1540e-04 - val_loss: 4.4338e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.1480e-04 - val_loss: 4.4241e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.1421e-04 - val_loss: 4.4141e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1361e-04 - val_loss: 4.4043e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1302e-04 - val_loss: 4.3946e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1243e-04 - val_loss: 4.3849e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1184e-04 - val_loss: 4.3751e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1125e-04 - val_loss: 4.3654e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1066e-04 - val_loss: 4.3559e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1009e-04 - val_loss: 4.3463e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0951e-04 - val_loss: 4.3366e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0892e-04 - val_loss: 4.3273e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0835e-04 - val_loss: 4.3178e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0778e-04 - val_loss: 4.3084e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.0721e-04 - val_loss: 4.2988e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0664e-04 - val_loss: 4.2895e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0607e-04 - val_loss: 4.2802e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0551e-04 - val_loss: 4.2708e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0494e-04 - val_loss: 4.2616e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0438e-04 - val_loss: 4.2523e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0382e-04 - val_loss: 4.2431e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0327e-04 - val_loss: 4.2338e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0271e-04 - val_loss: 4.2246e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0215e-04 - val_loss: 4.2155e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0161e-04 - val_loss: 4.2064e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0106e-04 - val_loss: 4.1973e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0051e-04 - val_loss: 4.1882e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9997e-04 - val_loss: 4.1793e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9942e-04 - val_loss: 4.1702e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9887e-04 - val_loss: 4.1612e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9834e-04 - val_loss: 4.1523e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9780e-04 - val_loss: 4.1435e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9727e-04 - val_loss: 4.1346e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9673e-04 - val_loss: 4.1256e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9620e-04 - val_loss: 4.1169e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9567e-04 - val_loss: 4.1082e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9514e-04 - val_loss: 4.0993e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9461e-04 - val_loss: 4.0906e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9409e-04 - val_loss: 4.0819e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9357e-04 - val_loss: 4.0732e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9304e-04 - val_loss: 4.0646e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9253e-04 - val_loss: 4.0560e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9201e-04 - val_loss: 4.0475e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9149e-04 - val_loss: 4.0389e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9098e-04 - val_loss: 4.0304e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9047e-04 - val_loss: 4.0217e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8996e-04 - val_loss: 4.0133e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8945e-04 - val_loss: 4.0051e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8895e-04 - val_loss: 3.9967e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8844e-04 - val_loss: 3.9883e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8794e-04 - val_loss: 3.9801e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8744e-04 - val_loss: 3.9717e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8694e-04 - val_loss: 3.9634e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8644e-04 - val_loss: 3.9552e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8595e-04 - val_loss: 3.9467e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8545e-04 - val_loss: 3.9386e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8496e-04 - val_loss: 3.9301e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8447e-04 - val_loss: 3.9220e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8398e-04 - val_loss: 3.9139e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8349e-04 - val_loss: 3.9059e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8300e-04 - val_loss: 3.8978e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8251e-04 - val_loss: 3.8898e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8204e-04 - val_loss: 3.8817e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.8156e-04 - val_loss: 3.8735e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8108e-04 - val_loss: 3.8656e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8061e-04 - val_loss: 3.8577e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8012e-04 - val_loss: 3.8497e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.7965e-04 - val_loss: 3.8418e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.7917e-04 - val_loss: 3.8341e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7870e-04 - val_loss: 3.8261e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7823e-04 - val_loss: 3.8184e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7776e-04 - val_loss: 3.8106e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7730e-04 - val_loss: 3.8028e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.7683e-04 - val_loss: 3.7950e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.7638e-04 - val_loss: 3.7872e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7591e-04 - val_loss: 3.7795e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7545e-04 - val_loss: 3.7719e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7499e-04 - val_loss: 3.7642e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7453e-04 - val_loss: 3.7566e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7407e-04 - val_loss: 3.7493e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7362e-04 - val_loss: 3.7416e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7317e-04 - val_loss: 3.7341e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.7272e-04 - val_loss: 3.7264e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7227e-04 - val_loss: 3.7187e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7182e-04 - val_loss: 3.7113e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7137e-04 - val_loss: 3.7039e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7093e-04 - val_loss: 3.6965e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7048e-04 - val_loss: 3.6890e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7005e-04 - val_loss: 3.6815e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6960e-04 - val_loss: 3.6744e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6916e-04 - val_loss: 3.6669e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6872e-04 - val_loss: 3.6597e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6828e-04 - val_loss: 3.6522e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6785e-04 - val_loss: 3.6451e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6742e-04 - val_loss: 3.6378e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6699e-04 - val_loss: 3.6306e-04\n",
      "0.0006238146452233195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.23901601, -0.7780296 ,  0.06455855, -0.74722993, -0.6184778 ,\n",
       "          0.60119754,  0.7595726 , -0.06485737, -0.33488598,  1.0843974 ],\n",
       "        [-0.18823282,  0.24822621,  0.2831763 , -0.12071633, -0.50832045,\n",
       "         -0.6487418 , -0.46411273,  1.3642317 ,  0.8754057 , -0.72211814],\n",
       "        [-0.13148028, -1.0566496 ,  1.8635312 , -0.8834052 , -1.3848641 ,\n",
       "         -0.92668873, -0.7310501 , -0.5974123 , -0.25896022,  0.17282324]],\n",
       "       dtype=float32),\n",
       " array([ 0.54873466,  0.4324164 ,  0.47355974, -0.33128324, -0.7161277 ,\n",
       "         0.5859835 ,  0.420777  , -0.23802078,  0.49295434, -0.6019282 ],\n",
       "       dtype=float32),\n",
       " array([[-0.42225942,  0.26033983,  0.38283774, -0.51377064,  0.31146583],\n",
       "        [-0.72460186,  0.57049286, -0.25379714, -0.8270029 ,  0.01559149],\n",
       "        [ 0.23676133, -0.025828  ,  0.1314389 , -0.5800296 ,  0.20281239],\n",
       "        [ 0.2880134 , -0.07955879,  0.1326491 ,  0.13191925,  0.44558495],\n",
       "        [-0.11466061, -0.88041776, -0.86336607,  0.7871846 ,  0.57660156],\n",
       "        [-0.6322213 ,  0.3693458 ,  0.85107946, -0.6183131 , -0.01583315],\n",
       "        [-0.5524289 ,  0.23349695,  0.8400693 , -0.4286192 , -0.2460149 ],\n",
       "        [-0.3925892 , -0.28012073,  0.16714048,  0.01541838, -0.3084921 ],\n",
       "        [-0.2989792 ,  0.24695122,  0.39573035, -0.45286566,  0.3263991 ],\n",
       "        [ 0.11795747, -0.51361835, -0.45576805,  0.14364356, -0.5109812 ]],\n",
       "       dtype=float32),\n",
       " array([-0.5171407 ,  0.7359261 ,  0.64020175, -0.74506617, -0.5961771 ],\n",
       "       dtype=float32),\n",
       " array([[-0.25560948],\n",
       "        [ 0.9971658 ],\n",
       "        [ 0.43467057],\n",
       "        [-1.1185778 ],\n",
       "        [-0.28984246]], dtype=float32),\n",
       " array([0.7854826], dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_4(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure4_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.3000 - val_loss: 32.9612\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0248 - val_loss: 29.2189\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.5752 - val_loss: 22.1300\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 22.0220 - val_loss: 12.7094\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 13.6574 - val_loss: 4.4692\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5046 - val_loss: 1.6931\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0622 - val_loss: 5.3335\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.9438 - val_loss: 7.1417\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9697 - val_loss: 5.0381\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8677 - val_loss: 2.4464\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5876 - val_loss: 0.9200\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1940 - val_loss: 0.6292\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4361 - val_loss: 1.0893\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7994 - val_loss: 1.7413\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5572 - val_loss: 2.2130\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2029 - val_loss: 2.3563\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5012 - val_loss: 2.1786\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.4127 - val_loss: 1.7672\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0118 - val_loss: 1.2415\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4307 - val_loss: 0.7253\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.8252 - val_loss: 0.3326\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3536 - val_loss: 0.1507\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1451 - val_loss: 0.2029\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2464 - val_loss: 0.4067\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5592 - val_loss: 0.5942\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.8500 - val_loss: 0.6337\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.9192 - val_loss: 0.5195\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7527 - val_loss: 0.3343\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4795 - val_loss: 0.1685\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2434 - val_loss: 0.0722\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1222 - val_loss: 0.0511\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1189 - val_loss: 0.0835\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1913 - val_loss: 0.1374\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2850 - val_loss: 0.1837\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3548 - val_loss: 0.2029\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3750 - val_loss: 0.1891\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3413 - val_loss: 0.1486\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2677 - val_loss: 0.0964\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1790 - val_loss: 0.0501\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1023 - val_loss: 0.0235\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0581 - val_loss: 0.0220\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0533 - val_loss: 0.0403\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0796 - val_loss: 0.0660\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1174 - val_loss: 0.0846\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1451 - val_loss: 0.0873\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1491 - val_loss: 0.0736\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1284 - val_loss: 0.0506\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0936 - val_loss: 0.0285\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0594 - val_loss: 0.0152\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0374 - val_loss: 0.0137\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0315 - val_loss: 0.0214\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0386 - val_loss: 0.0327\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0515 - val_loss: 0.0418\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0623 - val_loss: 0.0447\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0659 - val_loss: 0.0409\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0612 - val_loss: 0.0321\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0502 - val_loss: 0.0218\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0371 - val_loss: 0.0134\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0262 - val_loss: 0.0089\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0203 - val_loss: 0.0085\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0200 - val_loss: 0.0107\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0235 - val_loss: 0.0132\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0281 - val_loss: 0.0144\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0309 - val_loss: 0.0134\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0306 - val_loss: 0.0107\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0272 - val_loss: 0.0073\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0222 - val_loss: 0.0047\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0173 - val_loss: 0.0036\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0042\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0128 - val_loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0082\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.0106\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0102\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0089\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0135 - val_loss: 0.0071\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0054\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0098 - val_loss: 0.0041\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0034\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0031\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0031\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0032\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0031\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0093 - val_loss: 0.0030\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0087 - val_loss: 0.0028\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.9939e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.9556e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.9176e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 9.8796e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.8420e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.8049e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.7678e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.7307e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.6941e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.6577e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.6216e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.5857e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.5497e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.5144e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.4790e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.4438e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.4087e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 9.3741e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.3396e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 9.3053e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 9.2715e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.2376e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 9.2035e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.1703e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.1371e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.1040e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.0711e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 9.0382e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.0061e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.9737e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.9415e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.9098e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.8779e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.8464e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.8148e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.7838e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0010 - val_loss: 8.7528e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.7220e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9884e-04 - val_loss: 8.6915e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9624e-04 - val_loss: 8.6607e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9368e-04 - val_loss: 8.6304e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9112e-04 - val_loss: 8.6004e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8855e-04 - val_loss: 8.5706e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8601e-04 - val_loss: 8.5408e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 9.8346e-04 - val_loss: 8.5111e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8093e-04 - val_loss: 8.4819e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7842e-04 - val_loss: 8.4526e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.7591e-04 - val_loss: 8.4234e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7341e-04 - val_loss: 8.3947e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7093e-04 - val_loss: 8.3656e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6843e-04 - val_loss: 8.3373e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6597e-04 - val_loss: 8.3089e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6349e-04 - val_loss: 8.2807e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6105e-04 - val_loss: 8.2526e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5861e-04 - val_loss: 8.2248e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.5616e-04 - val_loss: 8.1969e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5373e-04 - val_loss: 8.1695e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5133e-04 - val_loss: 8.1420e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4890e-04 - val_loss: 8.1144e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4649e-04 - val_loss: 8.0874e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4410e-04 - val_loss: 8.0606e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4173e-04 - val_loss: 8.0336e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3935e-04 - val_loss: 8.0073e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3698e-04 - val_loss: 7.9805e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3461e-04 - val_loss: 7.9543e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3226e-04 - val_loss: 7.9279e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2993e-04 - val_loss: 7.9019e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2758e-04 - val_loss: 7.8759e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2526e-04 - val_loss: 7.8502e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2295e-04 - val_loss: 7.8246e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2064e-04 - val_loss: 7.7989e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1834e-04 - val_loss: 7.7739e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1604e-04 - val_loss: 7.7486e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1375e-04 - val_loss: 7.7235e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1148e-04 - val_loss: 7.6987e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0922e-04 - val_loss: 7.6739e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0696e-04 - val_loss: 7.6490e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0469e-04 - val_loss: 7.6245e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0245e-04 - val_loss: 7.6000e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0021e-04 - val_loss: 7.5757e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9799e-04 - val_loss: 7.5518e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9577e-04 - val_loss: 7.5277e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9354e-04 - val_loss: 7.5040e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9135e-04 - val_loss: 7.4803e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8914e-04 - val_loss: 7.4569e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8696e-04 - val_loss: 7.4334e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8478e-04 - val_loss: 7.4099e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8259e-04 - val_loss: 7.3867e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8042e-04 - val_loss: 7.3637e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7826e-04 - val_loss: 7.3408e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7611e-04 - val_loss: 7.3180e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7396e-04 - val_loss: 7.2951e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7183e-04 - val_loss: 7.2726e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6969e-04 - val_loss: 7.2501e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6757e-04 - val_loss: 7.2278e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6546e-04 - val_loss: 7.2054e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6334e-04 - val_loss: 7.1836e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6125e-04 - val_loss: 7.1616e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5914e-04 - val_loss: 7.1400e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5705e-04 - val_loss: 7.1181e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5498e-04 - val_loss: 7.0965e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5291e-04 - val_loss: 7.0752e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5084e-04 - val_loss: 7.0537e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4878e-04 - val_loss: 7.0324e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.4672e-04 - val_loss: 7.0112e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4468e-04 - val_loss: 6.9903e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4264e-04 - val_loss: 6.9695e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4061e-04 - val_loss: 6.9486e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3859e-04 - val_loss: 6.9279e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3656e-04 - val_loss: 6.9071e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3456e-04 - val_loss: 6.8867e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3255e-04 - val_loss: 6.8662e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3055e-04 - val_loss: 6.8461e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2856e-04 - val_loss: 6.8256e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2658e-04 - val_loss: 6.8056e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2459e-04 - val_loss: 6.7858e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2263e-04 - val_loss: 6.7659e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2066e-04 - val_loss: 6.7462e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.1870e-04 - val_loss: 6.7266e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1674e-04 - val_loss: 6.7072e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1481e-04 - val_loss: 6.6877e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1286e-04 - val_loss: 6.6685e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.1093e-04 - val_loss: 6.6493e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0901e-04 - val_loss: 6.6300e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0709e-04 - val_loss: 6.6109e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0517e-04 - val_loss: 6.5922e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0327e-04 - val_loss: 6.5731e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0136e-04 - val_loss: 6.5543e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9947e-04 - val_loss: 6.5359e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9759e-04 - val_loss: 6.5174e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9571e-04 - val_loss: 6.4987e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.9383e-04 - val_loss: 6.4806e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9196e-04 - val_loss: 6.4623e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9010e-04 - val_loss: 6.4444e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8824e-04 - val_loss: 6.4261e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8639e-04 - val_loss: 6.4081e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8455e-04 - val_loss: 6.3903e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8270e-04 - val_loss: 6.3724e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8087e-04 - val_loss: 6.3548e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7904e-04 - val_loss: 6.3371e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7723e-04 - val_loss: 6.3196e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7541e-04 - val_loss: 6.3023e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7359e-04 - val_loss: 6.2850e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7179e-04 - val_loss: 6.2677e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7000e-04 - val_loss: 6.2503e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6820e-04 - val_loss: 6.2335e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 7.6642e-04 - val_loss: 6.2163e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 234us/step - loss: 7.6464e-04 - val_loss: 6.1994e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6286e-04 - val_loss: 6.1827e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6110e-04 - val_loss: 6.1656e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5933e-04 - val_loss: 6.1491e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5757e-04 - val_loss: 6.1325e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5583e-04 - val_loss: 6.1162e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5408e-04 - val_loss: 6.1000e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5234e-04 - val_loss: 6.0835e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5061e-04 - val_loss: 6.0672e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4887e-04 - val_loss: 6.0512e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4715e-04 - val_loss: 6.0349e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4543e-04 - val_loss: 6.0192e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4373e-04 - val_loss: 6.0033e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4202e-04 - val_loss: 5.9873e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4032e-04 - val_loss: 5.9714e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3862e-04 - val_loss: 5.9559e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3693e-04 - val_loss: 5.9403e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 7.3524e-04 - val_loss: 5.9247e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3356e-04 - val_loss: 5.9095e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.3189e-04 - val_loss: 5.8939e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3022e-04 - val_loss: 5.8786e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2856e-04 - val_loss: 5.8634e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2690e-04 - val_loss: 5.8481e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2524e-04 - val_loss: 5.8333e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.2359e-04 - val_loss: 5.8184e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2195e-04 - val_loss: 5.8033e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2032e-04 - val_loss: 5.7885e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1868e-04 - val_loss: 5.7736e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.1705e-04 - val_loss: 5.7588e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1543e-04 - val_loss: 5.7443e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1382e-04 - val_loss: 5.7295e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 7.1220e-04 - val_loss: 5.7151e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1059e-04 - val_loss: 5.7007e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0899e-04 - val_loss: 5.6864e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.0740e-04 - val_loss: 5.6722e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0581e-04 - val_loss: 5.6579e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0422e-04 - val_loss: 5.6438e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0264e-04 - val_loss: 5.6297e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0106e-04 - val_loss: 5.6157e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9948e-04 - val_loss: 5.6017e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9792e-04 - val_loss: 5.5878e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.9636e-04 - val_loss: 5.5740e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9480e-04 - val_loss: 5.5603e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.9325e-04 - val_loss: 5.5465e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9171e-04 - val_loss: 5.5332e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9016e-04 - val_loss: 5.5195e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8862e-04 - val_loss: 5.5059e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8708e-04 - val_loss: 5.4924e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8555e-04 - val_loss: 5.4790e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8403e-04 - val_loss: 5.4658e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8252e-04 - val_loss: 5.4525e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8101e-04 - val_loss: 5.4392e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7949e-04 - val_loss: 5.4262e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7799e-04 - val_loss: 5.4131e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7650e-04 - val_loss: 5.4001e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7500e-04 - val_loss: 5.3872e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.7351e-04 - val_loss: 5.3742e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7201e-04 - val_loss: 5.3616e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7054e-04 - val_loss: 5.3487e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6906e-04 - val_loss: 5.3360e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6759e-04 - val_loss: 5.3235e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6611e-04 - val_loss: 5.3109e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6465e-04 - val_loss: 5.2985e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6319e-04 - val_loss: 5.2860e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6173e-04 - val_loss: 5.2736e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6029e-04 - val_loss: 5.2613e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5884e-04 - val_loss: 5.2489e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5741e-04 - val_loss: 5.2367e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5597e-04 - val_loss: 5.2244e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5453e-04 - val_loss: 5.2123e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.5311e-04 - val_loss: 5.2002e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5168e-04 - val_loss: 5.1880e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5025e-04 - val_loss: 5.1762e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4885e-04 - val_loss: 5.1644e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4744e-04 - val_loss: 5.1525e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 195us/step - loss: 6.4603e-04 - val_loss: 5.1406e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4463e-04 - val_loss: 5.1291e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4323e-04 - val_loss: 5.1174e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4184e-04 - val_loss: 5.1058e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4044e-04 - val_loss: 5.0942e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3906e-04 - val_loss: 5.0826e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3768e-04 - val_loss: 5.0710e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.3631e-04 - val_loss: 5.0597e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3493e-04 - val_loss: 5.0483e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3357e-04 - val_loss: 5.0369e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3220e-04 - val_loss: 5.0258e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3084e-04 - val_loss: 5.0144e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2949e-04 - val_loss: 5.0031e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2814e-04 - val_loss: 4.9922e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2680e-04 - val_loss: 4.9810e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2544e-04 - val_loss: 4.9701e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2410e-04 - val_loss: 4.9590e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2277e-04 - val_loss: 4.9480e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2144e-04 - val_loss: 4.9373e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2012e-04 - val_loss: 4.9266e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1879e-04 - val_loss: 4.9157e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1747e-04 - val_loss: 4.9051e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1615e-04 - val_loss: 4.8942e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1484e-04 - val_loss: 4.8838e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1354e-04 - val_loss: 4.8730e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1223e-04 - val_loss: 4.8624e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1094e-04 - val_loss: 4.8518e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0963e-04 - val_loss: 4.8412e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0834e-04 - val_loss: 4.8309e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.0705e-04 - val_loss: 4.8205e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0577e-04 - val_loss: 4.8102e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0449e-04 - val_loss: 4.8000e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0321e-04 - val_loss: 4.7898e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0195e-04 - val_loss: 4.7796e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0067e-04 - val_loss: 4.7696e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9941e-04 - val_loss: 4.7595e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9815e-04 - val_loss: 4.7493e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9688e-04 - val_loss: 4.7391e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9562e-04 - val_loss: 4.7292e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9438e-04 - val_loss: 4.7192e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9313e-04 - val_loss: 4.7094e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.9190e-04 - val_loss: 4.6997e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9066e-04 - val_loss: 4.6899e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8942e-04 - val_loss: 4.6801e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8819e-04 - val_loss: 4.6703e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8696e-04 - val_loss: 4.6607e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8574e-04 - val_loss: 4.6511e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8452e-04 - val_loss: 4.6413e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8330e-04 - val_loss: 4.6319e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8209e-04 - val_loss: 4.6223e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8087e-04 - val_loss: 4.6127e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7967e-04 - val_loss: 4.6033e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7847e-04 - val_loss: 4.5939e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7726e-04 - val_loss: 4.5847e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.7607e-04 - val_loss: 4.5752e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.7487e-04 - val_loss: 4.5661e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7369e-04 - val_loss: 4.5569e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7251e-04 - val_loss: 4.5477e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7132e-04 - val_loss: 4.5385e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7014e-04 - val_loss: 4.5294e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6897e-04 - val_loss: 4.5203e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6779e-04 - val_loss: 4.5111e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.6663e-04 - val_loss: 4.5023e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.6546e-04 - val_loss: 4.4931e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6429e-04 - val_loss: 4.4842e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6314e-04 - val_loss: 4.4752e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.6199e-04 - val_loss: 4.4664e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6084e-04 - val_loss: 4.4575e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5970e-04 - val_loss: 4.4488e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5855e-04 - val_loss: 4.4400e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5741e-04 - val_loss: 4.4312e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5627e-04 - val_loss: 4.4226e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5514e-04 - val_loss: 4.4140e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5400e-04 - val_loss: 4.4052e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.5287e-04 - val_loss: 4.3966e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5175e-04 - val_loss: 4.3881e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5063e-04 - val_loss: 4.3796e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4951e-04 - val_loss: 4.3712e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4840e-04 - val_loss: 4.3628e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4728e-04 - val_loss: 4.3543e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4617e-04 - val_loss: 4.3459e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.4507e-04 - val_loss: 4.3375e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4397e-04 - val_loss: 4.3293e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4286e-04 - val_loss: 4.3210e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4178e-04 - val_loss: 4.3126e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4068e-04 - val_loss: 4.3044e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3959e-04 - val_loss: 4.2963e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3850e-04 - val_loss: 4.2882e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3742e-04 - val_loss: 4.2800e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3634e-04 - val_loss: 4.2719e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3527e-04 - val_loss: 4.2639e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3419e-04 - val_loss: 4.2558e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3312e-04 - val_loss: 4.2479e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3205e-04 - val_loss: 4.2398e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3099e-04 - val_loss: 4.2319e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2992e-04 - val_loss: 4.2241e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2887e-04 - val_loss: 4.2163e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2781e-04 - val_loss: 4.2084e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2676e-04 - val_loss: 4.2005e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2571e-04 - val_loss: 4.1926e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2466e-04 - val_loss: 4.1849e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2361e-04 - val_loss: 4.1774e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2258e-04 - val_loss: 4.1696e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2154e-04 - val_loss: 4.1618e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2050e-04 - val_loss: 4.1543e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1948e-04 - val_loss: 4.1466e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.1845e-04 - val_loss: 4.1390e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1742e-04 - val_loss: 4.1317e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1640e-04 - val_loss: 4.1240e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1538e-04 - val_loss: 4.1166e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.1436e-04 - val_loss: 4.1091e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1334e-04 - val_loss: 4.1017e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1233e-04 - val_loss: 4.0943e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1133e-04 - val_loss: 4.0869e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1032e-04 - val_loss: 4.0796e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0932e-04 - val_loss: 4.0721e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0832e-04 - val_loss: 4.0648e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0732e-04 - val_loss: 4.0574e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0633e-04 - val_loss: 4.0503e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0534e-04 - val_loss: 4.0431e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0435e-04 - val_loss: 4.0359e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.0336e-04 - val_loss: 4.0287e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 5.0237e-04 - val_loss: 4.0217e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.0139e-04 - val_loss: 4.0146e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0042e-04 - val_loss: 4.0075e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9945e-04 - val_loss: 4.0003e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9846e-04 - val_loss: 3.9935e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9750e-04 - val_loss: 3.9864e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9654e-04 - val_loss: 3.9792e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9557e-04 - val_loss: 3.9723e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9461e-04 - val_loss: 3.9656e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9366e-04 - val_loss: 3.9587e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9270e-04 - val_loss: 3.9517e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9174e-04 - val_loss: 3.9450e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9079e-04 - val_loss: 3.9381e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8985e-04 - val_loss: 3.9313e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8890e-04 - val_loss: 3.9244e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8796e-04 - val_loss: 3.9177e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8701e-04 - val_loss: 3.9111e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8608e-04 - val_loss: 3.9044e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8514e-04 - val_loss: 3.8977e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8421e-04 - val_loss: 3.8911e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8328e-04 - val_loss: 3.8844e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8236e-04 - val_loss: 3.8778e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8144e-04 - val_loss: 3.8713e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8051e-04 - val_loss: 3.8647e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7959e-04 - val_loss: 3.8581e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7868e-04 - val_loss: 3.8517e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7776e-04 - val_loss: 3.8451e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7684e-04 - val_loss: 3.8386e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7594e-04 - val_loss: 3.8323e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7503e-04 - val_loss: 3.8257e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7413e-04 - val_loss: 3.8193e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7322e-04 - val_loss: 3.8130e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7233e-04 - val_loss: 3.8067e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7144e-04 - val_loss: 3.8004e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7054e-04 - val_loss: 3.7941e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6965e-04 - val_loss: 3.7876e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6876e-04 - val_loss: 3.7814e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6787e-04 - val_loss: 3.7753e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6698e-04 - val_loss: 3.7690e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6611e-04 - val_loss: 3.7627e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6523e-04 - val_loss: 3.7567e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6434e-04 - val_loss: 3.7504e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6347e-04 - val_loss: 3.7444e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6260e-04 - val_loss: 3.7381e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6173e-04 - val_loss: 3.7321e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6087e-04 - val_loss: 3.7261e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6000e-04 - val_loss: 3.7200e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5914e-04 - val_loss: 3.7140e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.5828e-04 - val_loss: 3.7081e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5742e-04 - val_loss: 3.7021e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5657e-04 - val_loss: 3.6961e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5570e-04 - val_loss: 3.6900e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5485e-04 - val_loss: 3.6842e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5401e-04 - val_loss: 3.6783e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5317e-04 - val_loss: 3.6722e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5232e-04 - val_loss: 3.6665e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5148e-04 - val_loss: 3.6607e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5064e-04 - val_loss: 3.6548e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4980e-04 - val_loss: 3.6490e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4897e-04 - val_loss: 3.6432e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4813e-04 - val_loss: 3.6374e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4730e-04 - val_loss: 3.6316e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4647e-04 - val_loss: 3.6258e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4564e-04 - val_loss: 3.6202e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.4482e-04 - val_loss: 3.6145e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4400e-04 - val_loss: 3.6088e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4318e-04 - val_loss: 3.6033e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4236e-04 - val_loss: 3.5975e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4155e-04 - val_loss: 3.5920e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4074e-04 - val_loss: 3.5862e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3993e-04 - val_loss: 3.5805e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.3911e-04 - val_loss: 3.5749e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3831e-04 - val_loss: 3.5694e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3751e-04 - val_loss: 3.5640e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3671e-04 - val_loss: 3.5587e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3591e-04 - val_loss: 3.5531e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.3511e-04 - val_loss: 3.5477e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3432e-04 - val_loss: 3.5421e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3352e-04 - val_loss: 3.5366e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3273e-04 - val_loss: 3.5313e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3194e-04 - val_loss: 3.5258e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3116e-04 - val_loss: 3.5203e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3038e-04 - val_loss: 3.5151e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2959e-04 - val_loss: 3.5097e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2881e-04 - val_loss: 3.5044e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2803e-04 - val_loss: 3.4991e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2726e-04 - val_loss: 3.4938e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2649e-04 - val_loss: 3.4885e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2571e-04 - val_loss: 3.4834e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2494e-04 - val_loss: 3.4780e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2417e-04 - val_loss: 3.4728e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2340e-04 - val_loss: 3.4676e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2264e-04 - val_loss: 3.4623e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2188e-04 - val_loss: 3.4570e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2112e-04 - val_loss: 3.4518e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2036e-04 - val_loss: 3.4467e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1960e-04 - val_loss: 3.4415e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1885e-04 - val_loss: 3.4363e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1809e-04 - val_loss: 3.4313e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1734e-04 - val_loss: 3.4262e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1660e-04 - val_loss: 3.4211e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1585e-04 - val_loss: 3.4161e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1510e-04 - val_loss: 3.4110e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1436e-04 - val_loss: 3.4061e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1363e-04 - val_loss: 3.4010e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1289e-04 - val_loss: 3.3960e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1214e-04 - val_loss: 3.3910e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1141e-04 - val_loss: 3.3861e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1068e-04 - val_loss: 3.3812e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0995e-04 - val_loss: 3.3762e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0921e-04 - val_loss: 3.3712e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0850e-04 - val_loss: 3.3664e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0777e-04 - val_loss: 3.3613e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0704e-04 - val_loss: 3.3564e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0633e-04 - val_loss: 3.3515e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0561e-04 - val_loss: 3.3467e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0489e-04 - val_loss: 3.3420e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0418e-04 - val_loss: 3.3372e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0346e-04 - val_loss: 3.3324e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0274e-04 - val_loss: 3.3276e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0204e-04 - val_loss: 3.3228e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0134e-04 - val_loss: 3.3180e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0062e-04 - val_loss: 3.3132e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9992e-04 - val_loss: 3.3085e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9922e-04 - val_loss: 3.3038e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9852e-04 - val_loss: 3.2991e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9782e-04 - val_loss: 3.2943e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9712e-04 - val_loss: 3.2896e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9643e-04 - val_loss: 3.2850e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9573e-04 - val_loss: 3.2802e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9505e-04 - val_loss: 3.2756e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9435e-04 - val_loss: 3.2710e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9367e-04 - val_loss: 3.2665e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9298e-04 - val_loss: 3.2619e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9230e-04 - val_loss: 3.2573e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9161e-04 - val_loss: 3.2527e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9093e-04 - val_loss: 3.2481e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9025e-04 - val_loss: 3.2436e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8957e-04 - val_loss: 3.2390e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8890e-04 - val_loss: 3.2345e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8823e-04 - val_loss: 3.2300e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8755e-04 - val_loss: 3.2255e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8687e-04 - val_loss: 3.2211e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8622e-04 - val_loss: 3.2166e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8555e-04 - val_loss: 3.2120e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8488e-04 - val_loss: 3.2076e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8421e-04 - val_loss: 3.2031e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8355e-04 - val_loss: 3.1986e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8289e-04 - val_loss: 3.1944e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8224e-04 - val_loss: 3.1899e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8157e-04 - val_loss: 3.1856e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8092e-04 - val_loss: 3.1811e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8026e-04 - val_loss: 3.1768e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7961e-04 - val_loss: 3.1725e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7896e-04 - val_loss: 3.1682e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7832e-04 - val_loss: 3.1639e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7767e-04 - val_loss: 3.1596e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7702e-04 - val_loss: 3.1553e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7638e-04 - val_loss: 3.1508e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7573e-04 - val_loss: 3.1467e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7511e-04 - val_loss: 3.1423e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7446e-04 - val_loss: 3.1382e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7383e-04 - val_loss: 3.1339e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7319e-04 - val_loss: 3.1296e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7255e-04 - val_loss: 3.1254e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7192e-04 - val_loss: 3.1212e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7128e-04 - val_loss: 3.1170e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7066e-04 - val_loss: 3.1127e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7003e-04 - val_loss: 3.1085e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6940e-04 - val_loss: 3.1044e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6878e-04 - val_loss: 3.1003e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6816e-04 - val_loss: 3.0962e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6754e-04 - val_loss: 3.0920e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6692e-04 - val_loss: 3.0880e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6630e-04 - val_loss: 3.0838e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6569e-04 - val_loss: 3.0798e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6507e-04 - val_loss: 3.0756e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6446e-04 - val_loss: 3.0716e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6385e-04 - val_loss: 3.0675e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6324e-04 - val_loss: 3.0635e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6262e-04 - val_loss: 3.0593e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6202e-04 - val_loss: 3.0552e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6140e-04 - val_loss: 3.0513e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6081e-04 - val_loss: 3.0472e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6020e-04 - val_loss: 3.0432e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5960e-04 - val_loss: 3.0392e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5900e-04 - val_loss: 3.0352e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5841e-04 - val_loss: 3.0313e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5780e-04 - val_loss: 3.0274e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5721e-04 - val_loss: 3.0234e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5661e-04 - val_loss: 3.0195e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.5602e-04 - val_loss: 3.0157e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5543e-04 - val_loss: 3.0117e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5484e-04 - val_loss: 3.0078e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5425e-04 - val_loss: 3.0037e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5367e-04 - val_loss: 2.9998e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5308e-04 - val_loss: 2.9960e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5249e-04 - val_loss: 2.9920e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5192e-04 - val_loss: 2.9883e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5134e-04 - val_loss: 2.9844e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5075e-04 - val_loss: 2.9806e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5018e-04 - val_loss: 2.9768e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4960e-04 - val_loss: 2.9730e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4902e-04 - val_loss: 2.9693e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4845e-04 - val_loss: 2.9653e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4788e-04 - val_loss: 2.9614e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4731e-04 - val_loss: 2.9576e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4674e-04 - val_loss: 2.9539e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4617e-04 - val_loss: 2.9501e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4560e-04 - val_loss: 2.9463e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4504e-04 - val_loss: 2.9427e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4448e-04 - val_loss: 2.9390e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4391e-04 - val_loss: 2.9352e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4335e-04 - val_loss: 2.9313e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4279e-04 - val_loss: 2.9278e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4223e-04 - val_loss: 2.9241e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4167e-04 - val_loss: 2.9205e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4112e-04 - val_loss: 2.9168e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4057e-04 - val_loss: 2.9130e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4000e-04 - val_loss: 2.9094e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3946e-04 - val_loss: 2.9057e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3891e-04 - val_loss: 2.9020e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3836e-04 - val_loss: 2.8985e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3781e-04 - val_loss: 2.8947e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3727e-04 - val_loss: 2.8912e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3672e-04 - val_loss: 2.8875e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3617e-04 - val_loss: 2.8839e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3563e-04 - val_loss: 2.8804e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3509e-04 - val_loss: 2.8766e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3455e-04 - val_loss: 2.8732e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3402e-04 - val_loss: 2.8696e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3347e-04 - val_loss: 2.8661e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3294e-04 - val_loss: 2.8625e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3241e-04 - val_loss: 2.8589e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3187e-04 - val_loss: 2.8554e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3135e-04 - val_loss: 2.8518e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3081e-04 - val_loss: 2.8482e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3028e-04 - val_loss: 2.8448e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2976e-04 - val_loss: 2.8412e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2922e-04 - val_loss: 2.8378e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2870e-04 - val_loss: 2.8342e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2818e-04 - val_loss: 2.8308e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2765e-04 - val_loss: 2.8274e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 3.2713e-04 - val_loss: 2.8239e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2661e-04 - val_loss: 2.8205e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2609e-04 - val_loss: 2.8171e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2557e-04 - val_loss: 2.8135e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2505e-04 - val_loss: 2.8101e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2454e-04 - val_loss: 2.8067e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2402e-04 - val_loss: 2.8032e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2351e-04 - val_loss: 2.7999e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2300e-04 - val_loss: 2.7963e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2249e-04 - val_loss: 2.7930e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2198e-04 - val_loss: 2.7896e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2147e-04 - val_loss: 2.7862e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.2096e-04 - val_loss: 2.7829e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2045e-04 - val_loss: 2.7796e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1995e-04 - val_loss: 2.7763e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1944e-04 - val_loss: 2.7729e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1894e-04 - val_loss: 2.7696e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1844e-04 - val_loss: 2.7661e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1794e-04 - val_loss: 2.7628e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1744e-04 - val_loss: 2.7595e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.1695e-04 - val_loss: 2.7562e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1644e-04 - val_loss: 2.7529e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.1595e-04 - val_loss: 2.7497e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1546e-04 - val_loss: 2.7464e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1497e-04 - val_loss: 2.7430e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1447e-04 - val_loss: 2.7398e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1398e-04 - val_loss: 2.7364e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1350e-04 - val_loss: 2.7331e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1300e-04 - val_loss: 2.7299e-04\n",
      "0.00040709832683205605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.596877  , -0.26509124, -0.32265404,  0.01187365, -0.31117406,\n",
       "          0.62543154, -0.73705244,  0.3214254 , -0.23465015,  1.111962  ],\n",
       "        [-0.0937803 ,  0.69218284,  0.5723254 ,  0.00946737,  0.4522415 ,\n",
       "         -0.02764956, -0.20428444,  0.33471343,  0.81658024, -0.04199678],\n",
       "        [ 0.12242565, -0.13139273, -0.69210124,  0.08854216,  0.69533813,\n",
       "          1.4135716 , -0.00516706,  1.0838466 ,  0.4192919 ,  0.5363443 ]],\n",
       "       dtype=float32),\n",
       " array([-0.44346634,  0.45568496,  0.44752863,  0.25776002, -0.51009536,\n",
       "         0.42257187,  0.22863944,  0.4557526 , -0.30164236, -0.42065176],\n",
       "       dtype=float32),\n",
       " array([[ 0.08705856,  0.46992967,  0.09966096,  0.5038854 , -0.22098967,\n",
       "         -0.1879343 ,  0.4054801 , -0.5418108 ,  0.14028645, -0.02369673],\n",
       "        [-0.32400087, -0.38921672, -0.37722284,  0.1679618 , -0.24201676,\n",
       "         -0.4271226 , -0.33022496,  0.0986876 , -0.18372993,  0.14371309],\n",
       "        [-0.07586323, -0.6229004 , -0.27781314,  0.56258744,  0.6682413 ,\n",
       "          0.1630641 , -0.70961624, -0.40075478, -0.4898211 , -0.08579108],\n",
       "        [ 0.24081229, -0.51965654,  0.10846058, -0.1749115 , -0.05711263,\n",
       "         -0.02052535, -0.10534135,  0.11933205, -0.30898073, -0.29692176],\n",
       "        [ 0.68903166,  0.31502226, -0.28954306,  0.44186658, -0.35506472,\n",
       "          0.6260048 ,  0.30301455, -0.5135939 ,  0.571319  , -0.21248618],\n",
       "        [-0.2786079 , -0.30394277, -0.43763292, -0.50697845,  0.5228485 ,\n",
       "         -0.31299996,  0.23233889,  0.24406795,  0.145223  , -0.02459879],\n",
       "        [-0.6379107 , -0.35366744,  0.22490934,  0.28713664, -0.34358644,\n",
       "         -0.60225105, -0.2580266 ,  0.19469096,  0.4341747 ,  0.30350426],\n",
       "        [-0.23500037, -0.00985996,  0.3633666 , -0.28048187,  0.8584836 ,\n",
       "         -0.2708449 , -0.39396644,  0.2342069 , -0.3824635 ,  0.05980655],\n",
       "        [-0.30749086, -0.3304723 , -0.25706166, -0.43777296, -0.12250635,\n",
       "          0.2548604 ,  0.51418793, -0.43110305, -0.02356176,  0.5223291 ],\n",
       "        [-0.48089084,  0.28277856, -0.15448138,  0.18446401, -0.3908753 ,\n",
       "         -0.26789966,  0.15123568, -0.3473828 , -0.3305664 ,  0.146958  ]],\n",
       "       dtype=float32),\n",
       " array([-0.6270712 , -0.684941  ,  0.6361079 ,  0.3059973 ,  0.68312496,\n",
       "        -0.61577505, -0.6687509 ,  0.60930115, -0.58068854, -0.5045066 ],\n",
       "       dtype=float32),\n",
       " array([[-0.43293998],\n",
       "        [-0.7693166 ],\n",
       "        [ 0.42252365],\n",
       "        [-0.08486299],\n",
       "        [ 0.77364117],\n",
       "        [-0.42076996],\n",
       "        [-0.63342583],\n",
       "        [ 0.41353118],\n",
       "        [-0.30801952],\n",
       "        [-0.13309114]], dtype=float32),\n",
       " array([0.7380265], dtype=float32)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_5(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure5_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.2045 - val_loss: 33.7137\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0429 - val_loss: 28.4582\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.9060 - val_loss: 22.8149\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 22.8318 - val_loss: 15.5675\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 14.8646 - val_loss: 7.1713\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1988 - val_loss: 0.9926\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4712 - val_loss: 3.8011\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.5733 - val_loss: 8.3190\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8840 - val_loss: 6.2202\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.9743 - val_loss: 2.3533\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9492 - val_loss: 0.2691\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1717 - val_loss: 0.2281\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4918 - val_loss: 1.0821\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5943 - val_loss: 1.8239\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4565 - val_loss: 2.0413\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7019 - val_loss: 1.7611\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3940 - val_loss: 1.2036\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7660 - val_loss: 0.6336\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0710 - val_loss: 0.2735\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5169 - val_loss: 0.2357\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2363 - val_loss: 0.4794\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2575 - val_loss: 0.8239\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4839 - val_loss: 1.0487\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.7318 - val_loss: 1.0326\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.8415 - val_loss: 0.8131\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7667 - val_loss: 0.5228\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5653 - val_loss: 0.2904\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3345 - val_loss: 0.1826\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1585 - val_loss: 0.1994\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0815 - val_loss: 0.2948\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0992 - val_loss: 0.4096\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.1728 - val_loss: 0.4976\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2557 - val_loss: 0.5341\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3127 - val_loss: 0.5124\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3249 - val_loss: 0.4382\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2894 - val_loss: 0.3288\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2182 - val_loss: 0.2095\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1350 - val_loss: 0.1060\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0649 - val_loss: 0.0361\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0243 - val_loss: 0.0060\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0130\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0349 - val_loss: 0.0462\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0662 - val_loss: 0.0877\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0948 - val_loss: 0.1181\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1081 - val_loss: 0.1256\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1021 - val_loss: 0.1101\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0818 - val_loss: 0.0808\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0556 - val_loss: 0.0497\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0323 - val_loss: 0.0268\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0181 - val_loss: 0.0171\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0151 - val_loss: 0.0199\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0206 - val_loss: 0.0302\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0293 - val_loss: 0.0420\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0500\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0383 - val_loss: 0.0513\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0353 - val_loss: 0.0460\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0369\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0202 - val_loss: 0.0275\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0135 - val_loss: 0.0202\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0099 - val_loss: 0.0156\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0132\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0167 - val_loss: 0.0106\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0171 - val_loss: 0.0088\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0154 - val_loss: 0.0065\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0042\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0024\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0041\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 6.8011e-04\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 4.9162e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 6.1758e-04\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 9.4731e-04\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 9.9161e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.8768e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0025 - val_loss: 4.8433e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 3.5961e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 2.8789e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 2.4918e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 2.3203e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 2.3461e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 2.6295e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 3.2476e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0023 - val_loss: 4.2310e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.5450e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0022 - val_loss: 7.0984e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 8.7411e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.7827e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 8.9537e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 8.2578e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 7.7232e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 7.3451e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 7.1007e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 6.9667e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 6.9272e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 6.9700e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 7.0789e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 7.2275e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 7.3843e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 7.5170e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 7.5978e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 7.6093e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 7.5487e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 7.4283e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 7.2693e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 7.0943e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0017 - val_loss: 6.9239e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 6.7746e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.6570e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 6.5778e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 6.5414e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 6.5505e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 6.6056e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 6.7012e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 6.8258e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 6.9602e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.0830e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.1738e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 7.2174e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 7.2057e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.1392e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.0234e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 6.8699e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 6.6917e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 6.5023e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 6.3145e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.1393e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.9867e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.8637e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 5.7735e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.7167e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.6900e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 5.6884e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.7059e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.7359e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.7731e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 5.8117e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.8465e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.8720e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.8844e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.8791e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 5.8555e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.8145e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.7589e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.6932e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 5.6226e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.5517e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.4846e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.4233e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0014 - val_loss: 5.3699e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.3241e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.2862e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.2553e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.2297e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.2076e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 5.1865e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.1647e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.1404e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.1131e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.0825e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.0495e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.0142e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.9779e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.9412e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 4.9044e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.8678e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 4.8328e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.7994e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.7683e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.7397e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.7133e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.6890e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 4.6660e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.6432e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.6199e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.5956e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 4.5699e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 4.5422e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.5128e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.4814e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 4.4485e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 4.4145e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 4.3801e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.3458e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.3124e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 4.2804e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.2499e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 4.2212e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 4.1941e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.1682e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.1436e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.1198e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.0968e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 4.0738e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 4.0510e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 4.0282e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 4.0049e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.9814e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.9569e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.9322e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.9069e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.8813e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.8557e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.8303e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.8045e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.7792e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.7548e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.7306e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.7070e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0010 - val_loss: 3.6838e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 3.6614e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.6391e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.6171e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.5952e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 3.5733e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 3.5516e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 3.5298e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.5081e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.4862e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.4648e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0010 - val_loss: 3.4431e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9692e-04 - val_loss: 3.4219e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9286e-04 - val_loss: 3.4005e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8882e-04 - val_loss: 3.3796e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8479e-04 - val_loss: 3.3591e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.8080e-04 - val_loss: 3.3383e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7682e-04 - val_loss: 3.3182e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7286e-04 - val_loss: 3.2982e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6893e-04 - val_loss: 3.2785e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6500e-04 - val_loss: 3.2591e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6111e-04 - val_loss: 3.2396e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5722e-04 - val_loss: 3.2203e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.5336e-04 - val_loss: 3.2012e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.4952e-04 - val_loss: 3.1820e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4571e-04 - val_loss: 3.1631e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4189e-04 - val_loss: 3.1443e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3812e-04 - val_loss: 3.1254e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3434e-04 - val_loss: 3.1066e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3060e-04 - val_loss: 3.0879e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2686e-04 - val_loss: 3.0690e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2315e-04 - val_loss: 3.0506e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1945e-04 - val_loss: 3.0323e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1578e-04 - val_loss: 3.0143e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.1212e-04 - val_loss: 2.9962e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0848e-04 - val_loss: 2.9786e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.0485e-04 - val_loss: 2.9610e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0125e-04 - val_loss: 2.9438e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9766e-04 - val_loss: 2.9265e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9408e-04 - val_loss: 2.9096e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9053e-04 - val_loss: 2.8927e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8700e-04 - val_loss: 2.8760e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8346e-04 - val_loss: 2.8595e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7997e-04 - val_loss: 2.8430e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7647e-04 - val_loss: 2.8266e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7300e-04 - val_loss: 2.8103e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6955e-04 - val_loss: 2.7942e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6611e-04 - val_loss: 2.7781e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6269e-04 - val_loss: 2.7621e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5927e-04 - val_loss: 2.7463e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5587e-04 - val_loss: 2.7306e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5250e-04 - val_loss: 2.7149e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.4914e-04 - val_loss: 2.6992e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4580e-04 - val_loss: 2.6840e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4247e-04 - val_loss: 2.6686e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3916e-04 - val_loss: 2.6536e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3585e-04 - val_loss: 2.6385e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3257e-04 - val_loss: 2.6237e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2929e-04 - val_loss: 2.6090e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2604e-04 - val_loss: 2.5943e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2280e-04 - val_loss: 2.5798e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1957e-04 - val_loss: 2.5654e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1637e-04 - val_loss: 2.5511e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1318e-04 - val_loss: 2.5369e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0999e-04 - val_loss: 2.5228e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0681e-04 - val_loss: 2.5089e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0366e-04 - val_loss: 2.4951e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0053e-04 - val_loss: 2.4813e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9740e-04 - val_loss: 2.4676e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9429e-04 - val_loss: 2.4541e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9118e-04 - val_loss: 2.4407e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8810e-04 - val_loss: 2.4274e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8504e-04 - val_loss: 2.4142e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8198e-04 - val_loss: 2.4009e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7894e-04 - val_loss: 2.3879e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 7.7592e-04 - val_loss: 2.3751e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7290e-04 - val_loss: 2.3623e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6990e-04 - val_loss: 2.3494e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6690e-04 - val_loss: 2.3370e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6393e-04 - val_loss: 2.3244e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6096e-04 - val_loss: 2.3120e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5802e-04 - val_loss: 2.2997e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5508e-04 - val_loss: 2.2875e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 7.5217e-04 - val_loss: 2.2754e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4925e-04 - val_loss: 2.2633e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4636e-04 - val_loss: 2.2513e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4347e-04 - val_loss: 2.2394e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4060e-04 - val_loss: 2.2276e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3774e-04 - val_loss: 2.2159e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3490e-04 - val_loss: 2.2043e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3206e-04 - val_loss: 2.1927e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2923e-04 - val_loss: 2.1814e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2643e-04 - val_loss: 2.1701e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2362e-04 - val_loss: 2.1590e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2084e-04 - val_loss: 2.1479e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1807e-04 - val_loss: 2.1367e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1531e-04 - val_loss: 2.1256e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1256e-04 - val_loss: 2.1147e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0982e-04 - val_loss: 2.1041e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0710e-04 - val_loss: 2.0932e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0439e-04 - val_loss: 2.0826e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0168e-04 - val_loss: 2.0721e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9900e-04 - val_loss: 2.0615e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9632e-04 - val_loss: 2.0511e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9365e-04 - val_loss: 2.0407e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9100e-04 - val_loss: 2.0306e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8835e-04 - val_loss: 2.0205e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8573e-04 - val_loss: 2.0103e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.8310e-04 - val_loss: 2.0003e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8050e-04 - val_loss: 1.9904e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7790e-04 - val_loss: 1.9806e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7531e-04 - val_loss: 1.9708e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7274e-04 - val_loss: 1.9611e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7017e-04 - val_loss: 1.9515e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6762e-04 - val_loss: 1.9419e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6508e-04 - val_loss: 1.9325e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6255e-04 - val_loss: 1.9230e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.6003e-04 - val_loss: 1.9136e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.5752e-04 - val_loss: 1.9043e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5502e-04 - val_loss: 1.8951e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5253e-04 - val_loss: 1.8861e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5005e-04 - val_loss: 1.8770e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4758e-04 - val_loss: 1.8680e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4514e-04 - val_loss: 1.8592e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4269e-04 - val_loss: 1.8504e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4026e-04 - val_loss: 1.8416e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3783e-04 - val_loss: 1.8329e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3542e-04 - val_loss: 1.8241e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3302e-04 - val_loss: 1.8156e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3063e-04 - val_loss: 1.8070e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2825e-04 - val_loss: 1.7986e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2588e-04 - val_loss: 1.7901e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2351e-04 - val_loss: 1.7818e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2116e-04 - val_loss: 1.7736e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1882e-04 - val_loss: 1.7655e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1649e-04 - val_loss: 1.7571e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1417e-04 - val_loss: 1.7491e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1185e-04 - val_loss: 1.7411e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.0956e-04 - val_loss: 1.7333e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0726e-04 - val_loss: 1.7254e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0498e-04 - val_loss: 1.7175e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0271e-04 - val_loss: 1.7099e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0045e-04 - val_loss: 1.7021e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9819e-04 - val_loss: 1.6945e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9595e-04 - val_loss: 1.6868e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9373e-04 - val_loss: 1.6792e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9150e-04 - val_loss: 1.6718e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8928e-04 - val_loss: 1.6643e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8708e-04 - val_loss: 1.6568e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8489e-04 - val_loss: 1.6495e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8270e-04 - val_loss: 1.6423e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8052e-04 - val_loss: 1.6350e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7836e-04 - val_loss: 1.6280e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7620e-04 - val_loss: 1.6209e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7405e-04 - val_loss: 1.6139e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7192e-04 - val_loss: 1.6070e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6979e-04 - val_loss: 1.6000e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6768e-04 - val_loss: 1.5931e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6555e-04 - val_loss: 1.5864e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6345e-04 - val_loss: 1.5796e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6136e-04 - val_loss: 1.5729e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5928e-04 - val_loss: 1.5661e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5721e-04 - val_loss: 1.5594e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5513e-04 - val_loss: 1.5529e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5308e-04 - val_loss: 1.5462e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5103e-04 - val_loss: 1.5400e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4899e-04 - val_loss: 1.5335e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4696e-04 - val_loss: 1.5271e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4494e-04 - val_loss: 1.5207e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4292e-04 - val_loss: 1.5146e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4092e-04 - val_loss: 1.5083e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3893e-04 - val_loss: 1.5021e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3694e-04 - val_loss: 1.4960e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3496e-04 - val_loss: 1.4899e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3299e-04 - val_loss: 1.4836e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3103e-04 - val_loss: 1.4777e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2908e-04 - val_loss: 1.4717e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2713e-04 - val_loss: 1.4658e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2520e-04 - val_loss: 1.4600e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2327e-04 - val_loss: 1.4541e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2135e-04 - val_loss: 1.4483e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.1944e-04 - val_loss: 1.4426e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1753e-04 - val_loss: 1.4370e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1565e-04 - val_loss: 1.4313e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1375e-04 - val_loss: 1.4257e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1188e-04 - val_loss: 1.4201e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1000e-04 - val_loss: 1.4147e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0815e-04 - val_loss: 1.4090e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0629e-04 - val_loss: 1.4035e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0445e-04 - val_loss: 1.3981e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0261e-04 - val_loss: 1.3928e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0079e-04 - val_loss: 1.3875e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9896e-04 - val_loss: 1.3821e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9715e-04 - val_loss: 1.3769e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9534e-04 - val_loss: 1.3718e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.9354e-04 - val_loss: 1.3665e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9175e-04 - val_loss: 1.3614e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8996e-04 - val_loss: 1.3562e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8820e-04 - val_loss: 1.3512e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.8643e-04 - val_loss: 1.3460e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8466e-04 - val_loss: 1.3410e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8291e-04 - val_loss: 1.3361e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.8117e-04 - val_loss: 1.3313e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7943e-04 - val_loss: 1.3264e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7770e-04 - val_loss: 1.3216e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7598e-04 - val_loss: 1.3168e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7427e-04 - val_loss: 1.3120e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7256e-04 - val_loss: 1.3074e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7087e-04 - val_loss: 1.3026e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6917e-04 - val_loss: 1.2980e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6749e-04 - val_loss: 1.2933e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6581e-04 - val_loss: 1.2887e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.6414e-04 - val_loss: 1.2840e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.6247e-04 - val_loss: 1.2795e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6082e-04 - val_loss: 1.2749e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5917e-04 - val_loss: 1.2704e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5752e-04 - val_loss: 1.2660e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5589e-04 - val_loss: 1.2616e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5427e-04 - val_loss: 1.2572e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5264e-04 - val_loss: 1.2529e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5103e-04 - val_loss: 1.2485e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4943e-04 - val_loss: 1.2443e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4783e-04 - val_loss: 1.2400e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4623e-04 - val_loss: 1.2359e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4465e-04 - val_loss: 1.2317e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4307e-04 - val_loss: 1.2275e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4150e-04 - val_loss: 1.2233e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3994e-04 - val_loss: 1.2192e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3838e-04 - val_loss: 1.2152e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3682e-04 - val_loss: 1.2111e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3529e-04 - val_loss: 1.2071e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3375e-04 - val_loss: 1.2031e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3221e-04 - val_loss: 1.1991e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3068e-04 - val_loss: 1.1950e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2917e-04 - val_loss: 1.1912e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2766e-04 - val_loss: 1.1872e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2616e-04 - val_loss: 1.1834e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2465e-04 - val_loss: 1.1796e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2317e-04 - val_loss: 1.1758e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2169e-04 - val_loss: 1.1721e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2021e-04 - val_loss: 1.1683e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1873e-04 - val_loss: 1.1645e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1727e-04 - val_loss: 1.1608e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1581e-04 - val_loss: 1.1572e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1435e-04 - val_loss: 1.1534e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1291e-04 - val_loss: 1.1499e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1147e-04 - val_loss: 1.1462e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1004e-04 - val_loss: 1.1426e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0860e-04 - val_loss: 1.1390e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0718e-04 - val_loss: 1.1356e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0577e-04 - val_loss: 1.1321e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0436e-04 - val_loss: 1.1286e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0296e-04 - val_loss: 1.1252e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0156e-04 - val_loss: 1.1217e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0016e-04 - val_loss: 1.1183e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9877e-04 - val_loss: 1.1148e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9740e-04 - val_loss: 1.1115e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.9602e-04 - val_loss: 1.1081e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9466e-04 - val_loss: 1.1047e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9330e-04 - val_loss: 1.1015e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9194e-04 - val_loss: 1.0982e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9059e-04 - val_loss: 1.0950e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8925e-04 - val_loss: 1.0917e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8791e-04 - val_loss: 1.0884e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8658e-04 - val_loss: 1.0852e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8525e-04 - val_loss: 1.0820e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8393e-04 - val_loss: 1.0788e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8262e-04 - val_loss: 1.0758e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8131e-04 - val_loss: 1.0726e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8001e-04 - val_loss: 1.0695e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7870e-04 - val_loss: 1.0664e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7742e-04 - val_loss: 1.0633e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7613e-04 - val_loss: 1.0603e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7485e-04 - val_loss: 1.0573e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7357e-04 - val_loss: 1.0543e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7230e-04 - val_loss: 1.0514e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7105e-04 - val_loss: 1.0484e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6978e-04 - val_loss: 1.0454e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6853e-04 - val_loss: 1.0424e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6728e-04 - val_loss: 1.0395e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6604e-04 - val_loss: 1.0367e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6480e-04 - val_loss: 1.0337e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6357e-04 - val_loss: 1.0308e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6234e-04 - val_loss: 1.0280e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6111e-04 - val_loss: 1.0252e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5990e-04 - val_loss: 1.0224e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5870e-04 - val_loss: 1.0195e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5748e-04 - val_loss: 1.0168e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.5628e-04 - val_loss: 1.0139e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5509e-04 - val_loss: 1.0112e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5389e-04 - val_loss: 1.0085e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5271e-04 - val_loss: 1.0058e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5153e-04 - val_loss: 1.0030e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5036e-04 - val_loss: 1.0004e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4919e-04 - val_loss: 9.9780e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4801e-04 - val_loss: 9.9507e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4685e-04 - val_loss: 9.9246e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4570e-04 - val_loss: 9.8990e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4455e-04 - val_loss: 9.8724e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4340e-04 - val_loss: 9.8468e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4226e-04 - val_loss: 9.8200e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4112e-04 - val_loss: 9.7952e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3999e-04 - val_loss: 9.7687e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3887e-04 - val_loss: 9.7438e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3775e-04 - val_loss: 9.7182e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3663e-04 - val_loss: 9.6939e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3552e-04 - val_loss: 9.6691e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3441e-04 - val_loss: 9.6444e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.3331e-04 - val_loss: 9.6206e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3222e-04 - val_loss: 9.5949e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3112e-04 - val_loss: 9.5713e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3004e-04 - val_loss: 9.5469e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2895e-04 - val_loss: 9.5216e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2787e-04 - val_loss: 9.4981e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2680e-04 - val_loss: 9.4729e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.2573e-04 - val_loss: 9.4489e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2466e-04 - val_loss: 9.4254e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2360e-04 - val_loss: 9.4020e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2254e-04 - val_loss: 9.3792e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2149e-04 - val_loss: 9.3567e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2044e-04 - val_loss: 9.3332e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1940e-04 - val_loss: 9.3106e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1835e-04 - val_loss: 9.2882e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1733e-04 - val_loss: 9.2636e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1629e-04 - val_loss: 9.2413e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1527e-04 - val_loss: 9.2187e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1425e-04 - val_loss: 9.1960e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1323e-04 - val_loss: 9.1742e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1221e-04 - val_loss: 9.1516e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1121e-04 - val_loss: 9.1304e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1021e-04 - val_loss: 9.1078e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0921e-04 - val_loss: 9.0858e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0821e-04 - val_loss: 9.0641e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0722e-04 - val_loss: 9.0427e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0623e-04 - val_loss: 9.0212e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0524e-04 - val_loss: 8.9992e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0427e-04 - val_loss: 8.9775e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0329e-04 - val_loss: 8.9567e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0231e-04 - val_loss: 8.9355e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0135e-04 - val_loss: 8.9140e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0039e-04 - val_loss: 8.8933e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9943e-04 - val_loss: 8.8729e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9848e-04 - val_loss: 8.8519e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9752e-04 - val_loss: 8.8312e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9658e-04 - val_loss: 8.8102e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9564e-04 - val_loss: 8.7895e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9469e-04 - val_loss: 8.7695e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9375e-04 - val_loss: 8.7489e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9283e-04 - val_loss: 8.7288e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9190e-04 - val_loss: 8.7075e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9098e-04 - val_loss: 8.6881e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9006e-04 - val_loss: 8.6686e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8914e-04 - val_loss: 8.6485e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8823e-04 - val_loss: 8.6284e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8732e-04 - val_loss: 8.6088e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8641e-04 - val_loss: 8.5892e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8551e-04 - val_loss: 8.5699e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8462e-04 - val_loss: 8.5505e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8373e-04 - val_loss: 8.5296e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8283e-04 - val_loss: 8.5116e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8195e-04 - val_loss: 8.4922e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8107e-04 - val_loss: 8.4733e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8019e-04 - val_loss: 8.4534e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7931e-04 - val_loss: 8.4347e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7844e-04 - val_loss: 8.4164e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7757e-04 - val_loss: 8.3977e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7670e-04 - val_loss: 8.3798e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7584e-04 - val_loss: 8.3605e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7499e-04 - val_loss: 8.3417e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7413e-04 - val_loss: 8.3230e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7328e-04 - val_loss: 8.3053e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7244e-04 - val_loss: 8.2858e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7159e-04 - val_loss: 8.2686e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7075e-04 - val_loss: 8.2497e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6991e-04 - val_loss: 8.2316e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6908e-04 - val_loss: 8.2135e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6825e-04 - val_loss: 8.1954e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6742e-04 - val_loss: 8.1773e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6660e-04 - val_loss: 8.1592e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6578e-04 - val_loss: 8.1421e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6497e-04 - val_loss: 8.1239e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6415e-04 - val_loss: 8.1061e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.6334e-04 - val_loss: 8.0889e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6254e-04 - val_loss: 8.0713e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6173e-04 - val_loss: 8.0538e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6093e-04 - val_loss: 8.0367e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6013e-04 - val_loss: 8.0197e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5934e-04 - val_loss: 8.0024e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5855e-04 - val_loss: 7.9847e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5776e-04 - val_loss: 7.9677e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5698e-04 - val_loss: 7.9499e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.5620e-04 - val_loss: 7.9338e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5541e-04 - val_loss: 7.9167e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5464e-04 - val_loss: 7.8994e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5387e-04 - val_loss: 7.8830e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5310e-04 - val_loss: 7.8660e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5233e-04 - val_loss: 7.8491e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5157e-04 - val_loss: 7.8328e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5082e-04 - val_loss: 7.8155e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5006e-04 - val_loss: 7.7995e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4930e-04 - val_loss: 7.7828e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4855e-04 - val_loss: 7.7667e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4781e-04 - val_loss: 7.7503e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4707e-04 - val_loss: 7.7340e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.4632e-04 - val_loss: 7.7175e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4558e-04 - val_loss: 7.7020e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4485e-04 - val_loss: 7.6859e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4412e-04 - val_loss: 7.6697e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4339e-04 - val_loss: 7.6534e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4265e-04 - val_loss: 7.6384e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4193e-04 - val_loss: 7.6223e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4121e-04 - val_loss: 7.6060e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4050e-04 - val_loss: 7.5897e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3978e-04 - val_loss: 7.5732e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3906e-04 - val_loss: 7.5579e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3836e-04 - val_loss: 7.5428e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3765e-04 - val_loss: 7.5271e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3695e-04 - val_loss: 7.5109e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.3624e-04 - val_loss: 7.4957e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3555e-04 - val_loss: 7.4800e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3485e-04 - val_loss: 7.4652e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3415e-04 - val_loss: 7.4498e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3346e-04 - val_loss: 7.4344e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3277e-04 - val_loss: 7.4190e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3209e-04 - val_loss: 7.4036e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3141e-04 - val_loss: 7.3884e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3073e-04 - val_loss: 7.3738e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3005e-04 - val_loss: 7.3582e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2938e-04 - val_loss: 7.3432e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2870e-04 - val_loss: 7.3284e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2804e-04 - val_loss: 7.3131e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2737e-04 - val_loss: 7.2981e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2671e-04 - val_loss: 7.2828e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2605e-04 - val_loss: 7.2686e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2538e-04 - val_loss: 7.2542e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2473e-04 - val_loss: 7.2389e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2408e-04 - val_loss: 7.2244e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.2342e-04 - val_loss: 7.2098e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2277e-04 - val_loss: 7.1955e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2213e-04 - val_loss: 7.1806e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2149e-04 - val_loss: 7.1662e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.2085e-04 - val_loss: 7.1519e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2020e-04 - val_loss: 7.1379e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1957e-04 - val_loss: 7.1230e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1894e-04 - val_loss: 7.1090e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1831e-04 - val_loss: 7.0943e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1767e-04 - val_loss: 7.0793e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1705e-04 - val_loss: 7.0660e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1642e-04 - val_loss: 7.0515e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1580e-04 - val_loss: 7.0374e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1518e-04 - val_loss: 7.0238e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.1457e-04 - val_loss: 7.0095e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1395e-04 - val_loss: 6.9951e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1334e-04 - val_loss: 6.9818e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1273e-04 - val_loss: 6.9676e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1212e-04 - val_loss: 6.9537e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1152e-04 - val_loss: 6.9399e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1092e-04 - val_loss: 6.9268e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1031e-04 - val_loss: 6.9121e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0972e-04 - val_loss: 6.8984e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0912e-04 - val_loss: 6.8849e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0853e-04 - val_loss: 6.8708e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0793e-04 - val_loss: 6.8567e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0734e-04 - val_loss: 6.8430e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0676e-04 - val_loss: 6.8298e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0617e-04 - val_loss: 6.8167e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0559e-04 - val_loss: 6.8029e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0501e-04 - val_loss: 6.7890e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0443e-04 - val_loss: 6.7767e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0385e-04 - val_loss: 6.7630e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0328e-04 - val_loss: 6.7500e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0271e-04 - val_loss: 6.7360e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0214e-04 - val_loss: 6.7231e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0157e-04 - val_loss: 6.7101e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0100e-04 - val_loss: 6.6971e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0044e-04 - val_loss: 6.6834e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9988e-04 - val_loss: 6.6707e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9932e-04 - val_loss: 6.6576e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.9877e-04 - val_loss: 6.6440e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9821e-04 - val_loss: 6.6319e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9766e-04 - val_loss: 6.6177e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9710e-04 - val_loss: 6.6051e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9656e-04 - val_loss: 6.5922e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9601e-04 - val_loss: 6.5793e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9547e-04 - val_loss: 6.5669e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9493e-04 - val_loss: 6.5540e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9438e-04 - val_loss: 6.5419e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9384e-04 - val_loss: 6.5287e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9331e-04 - val_loss: 6.5155e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9277e-04 - val_loss: 6.5030e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9224e-04 - val_loss: 6.4903e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9171e-04 - val_loss: 6.4783e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9119e-04 - val_loss: 6.4649e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9065e-04 - val_loss: 6.4525e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9013e-04 - val_loss: 6.4397e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8960e-04 - val_loss: 6.4279e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8908e-04 - val_loss: 6.4155e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8857e-04 - val_loss: 6.4031e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8805e-04 - val_loss: 6.3906e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8753e-04 - val_loss: 6.3786e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8702e-04 - val_loss: 6.3659e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8651e-04 - val_loss: 6.3535e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8600e-04 - val_loss: 6.3409e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8550e-04 - val_loss: 6.3289e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8498e-04 - val_loss: 6.3170e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8448e-04 - val_loss: 6.3047e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8398e-04 - val_loss: 6.2921e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8348e-04 - val_loss: 6.2795e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8298e-04 - val_loss: 6.2675e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8249e-04 - val_loss: 6.2557e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8199e-04 - val_loss: 6.2443e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8150e-04 - val_loss: 6.2318e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8101e-04 - val_loss: 6.2203e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8052e-04 - val_loss: 6.2079e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8003e-04 - val_loss: 6.1965e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7955e-04 - val_loss: 6.1842e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7906e-04 - val_loss: 6.1724e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7858e-04 - val_loss: 6.1618e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7810e-04 - val_loss: 6.1490e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7762e-04 - val_loss: 6.1376e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7714e-04 - val_loss: 6.1262e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7667e-04 - val_loss: 6.1138e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7619e-04 - val_loss: 6.1018e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7572e-04 - val_loss: 6.0903e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7525e-04 - val_loss: 6.0786e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7478e-04 - val_loss: 6.0670e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 1.7432e-04 - val_loss: 6.0556e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7385e-04 - val_loss: 6.0435e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7339e-04 - val_loss: 6.0325e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7293e-04 - val_loss: 6.0209e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7246e-04 - val_loss: 6.0102e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7201e-04 - val_loss: 5.9982e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7155e-04 - val_loss: 5.9868e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7109e-04 - val_loss: 5.9757e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7064e-04 - val_loss: 5.9641e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7019e-04 - val_loss: 5.9530e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6973e-04 - val_loss: 5.9413e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6929e-04 - val_loss: 5.9301e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6884e-04 - val_loss: 5.9188e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6840e-04 - val_loss: 5.9079e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6795e-04 - val_loss: 5.8969e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6751e-04 - val_loss: 5.8857e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6707e-04 - val_loss: 5.8743e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6663e-04 - val_loss: 5.8629e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6619e-04 - val_loss: 5.8518e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6575e-04 - val_loss: 5.8405e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6532e-04 - val_loss: 5.8298e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6489e-04 - val_loss: 5.8188e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6445e-04 - val_loss: 5.8077e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6403e-04 - val_loss: 5.7974e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6360e-04 - val_loss: 5.7862e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6317e-04 - val_loss: 5.7755e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6274e-04 - val_loss: 5.7643e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6232e-04 - val_loss: 5.7534e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6190e-04 - val_loss: 5.7429e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6148e-04 - val_loss: 5.7314e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6106e-04 - val_loss: 5.7215e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6064e-04 - val_loss: 5.7109e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6022e-04 - val_loss: 5.7000e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5981e-04 - val_loss: 5.6893e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5939e-04 - val_loss: 5.6784e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5898e-04 - val_loss: 5.6674e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5857e-04 - val_loss: 5.6576e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5816e-04 - val_loss: 5.6463e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5775e-04 - val_loss: 5.6360e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5735e-04 - val_loss: 5.6250e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5694e-04 - val_loss: 5.6146e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5654e-04 - val_loss: 5.6051e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5614e-04 - val_loss: 5.5943e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5574e-04 - val_loss: 5.5839e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5534e-04 - val_loss: 5.5737e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5494e-04 - val_loss: 5.5621e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5454e-04 - val_loss: 5.5513e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5415e-04 - val_loss: 5.5415e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5375e-04 - val_loss: 5.5313e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5336e-04 - val_loss: 5.5214e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5297e-04 - val_loss: 5.5105e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5257e-04 - val_loss: 5.5006e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5219e-04 - val_loss: 5.4897e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5180e-04 - val_loss: 5.4803e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 1.5142e-04 - val_loss: 5.4699e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5103e-04 - val_loss: 5.4596e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5065e-04 - val_loss: 5.4495e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5027e-04 - val_loss: 5.4397e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4989e-04 - val_loss: 5.4292e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4951e-04 - val_loss: 5.4199e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4913e-04 - val_loss: 5.4103e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4875e-04 - val_loss: 5.3991e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4837e-04 - val_loss: 5.3888e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4800e-04 - val_loss: 5.3785e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4763e-04 - val_loss: 5.3697e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4726e-04 - val_loss: 5.3598e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4689e-04 - val_loss: 5.3495e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4652e-04 - val_loss: 5.3402e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4615e-04 - val_loss: 5.3301e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4579e-04 - val_loss: 5.3204e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4542e-04 - val_loss: 5.3109e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4505e-04 - val_loss: 5.3007e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4469e-04 - val_loss: 5.2908e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4433e-04 - val_loss: 5.2811e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4397e-04 - val_loss: 5.2708e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4361e-04 - val_loss: 5.2618e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4325e-04 - val_loss: 5.2520e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4290e-04 - val_loss: 5.2413e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4254e-04 - val_loss: 5.2324e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4219e-04 - val_loss: 5.2224e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4183e-04 - val_loss: 5.2134e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4148e-04 - val_loss: 5.2035e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4113e-04 - val_loss: 5.1939e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4078e-04 - val_loss: 5.1845e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4043e-04 - val_loss: 5.1755e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4009e-04 - val_loss: 5.1661e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3974e-04 - val_loss: 5.1566e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3939e-04 - val_loss: 5.1469e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3905e-04 - val_loss: 5.1371e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3871e-04 - val_loss: 5.1279e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3837e-04 - val_loss: 5.1184e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3803e-04 - val_loss: 5.1089e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3769e-04 - val_loss: 5.0997e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3735e-04 - val_loss: 5.0906e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3701e-04 - val_loss: 5.0815e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3668e-04 - val_loss: 5.0716e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3634e-04 - val_loss: 5.0629e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3601e-04 - val_loss: 5.0528e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3568e-04 - val_loss: 5.0439e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3534e-04 - val_loss: 5.0357e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3501e-04 - val_loss: 5.0252e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3468e-04 - val_loss: 5.0173e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3436e-04 - val_loss: 5.0078e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3403e-04 - val_loss: 4.9990e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3370e-04 - val_loss: 4.9896e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3338e-04 - val_loss: 4.9804e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3305e-04 - val_loss: 4.9712e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3273e-04 - val_loss: 4.9617e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3241e-04 - val_loss: 4.9520e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.3209e-04 - val_loss: 4.9431e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3177e-04 - val_loss: 4.9354e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3145e-04 - val_loss: 4.9255e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3114e-04 - val_loss: 4.9166e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3082e-04 - val_loss: 4.9076e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3050e-04 - val_loss: 4.8993e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3019e-04 - val_loss: 4.8910e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2988e-04 - val_loss: 4.8819e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2956e-04 - val_loss: 4.8732e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2925e-04 - val_loss: 4.8648e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2894e-04 - val_loss: 4.8551e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2864e-04 - val_loss: 4.8462e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2833e-04 - val_loss: 4.8373e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2801e-04 - val_loss: 4.8290e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2771e-04 - val_loss: 4.8204e-05\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 125us/step - loss: 1.2741e-04 - val_loss: 4.8115e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2710e-04 - val_loss: 4.8028e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2680e-04 - val_loss: 4.7941e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2650e-04 - val_loss: 4.7855e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2619e-04 - val_loss: 4.7771e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2590e-04 - val_loss: 4.7684e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2560e-04 - val_loss: 4.7599e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2530e-04 - val_loss: 4.7510e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2500e-04 - val_loss: 4.7429e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2471e-04 - val_loss: 4.7344e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2441e-04 - val_loss: 4.7255e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2411e-04 - val_loss: 4.7168e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2382e-04 - val_loss: 4.7085e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2353e-04 - val_loss: 4.6998e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2324e-04 - val_loss: 4.6912e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2295e-04 - val_loss: 4.6824e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2266e-04 - val_loss: 4.6749e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2237e-04 - val_loss: 4.6666e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2208e-04 - val_loss: 4.6579e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2179e-04 - val_loss: 4.6503e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2151e-04 - val_loss: 4.6418e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2122e-04 - val_loss: 4.6338e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2093e-04 - val_loss: 4.6250e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.2065e-04 - val_loss: 4.6166e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2037e-04 - val_loss: 4.6081e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2009e-04 - val_loss: 4.5996e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1981e-04 - val_loss: 4.5916e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1953e-04 - val_loss: 4.5834e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1925e-04 - val_loss: 4.5754e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1897e-04 - val_loss: 4.5669e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1870e-04 - val_loss: 4.5593e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1842e-04 - val_loss: 4.5512e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1815e-04 - val_loss: 4.5433e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1787e-04 - val_loss: 4.5347e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1759e-04 - val_loss: 4.5267e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1732e-04 - val_loss: 4.5189e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1705e-04 - val_loss: 4.5104e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1678e-04 - val_loss: 4.5018e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1651e-04 - val_loss: 4.4944e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1624e-04 - val_loss: 4.4867e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1597e-04 - val_loss: 4.4782e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1571e-04 - val_loss: 4.4699e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1544e-04 - val_loss: 4.4630e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1518e-04 - val_loss: 4.4547e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1491e-04 - val_loss: 4.4467e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1464e-04 - val_loss: 4.4391e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1438e-04 - val_loss: 4.4312e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1412e-04 - val_loss: 4.4237e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1386e-04 - val_loss: 4.4153e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1359e-04 - val_loss: 4.4075e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1333e-04 - val_loss: 4.3997e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1307e-04 - val_loss: 4.3914e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1282e-04 - val_loss: 4.3835e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1256e-04 - val_loss: 4.3762e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1230e-04 - val_loss: 4.3683e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1205e-04 - val_loss: 4.3611e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1179e-04 - val_loss: 4.3534e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1154e-04 - val_loss: 4.3455e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1128e-04 - val_loss: 4.3374e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1103e-04 - val_loss: 4.3301e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1077e-04 - val_loss: 4.3224e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1052e-04 - val_loss: 4.3146e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1027e-04 - val_loss: 4.3073e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1002e-04 - val_loss: 4.3001e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0977e-04 - val_loss: 4.2918e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0953e-04 - val_loss: 4.2841e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0928e-04 - val_loss: 4.2770e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0903e-04 - val_loss: 4.2694e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0878e-04 - val_loss: 4.2619e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0854e-04 - val_loss: 4.2549e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0830e-04 - val_loss: 4.2472e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0805e-04 - val_loss: 4.2397e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0781e-04 - val_loss: 4.2316e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0757e-04 - val_loss: 4.2244e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0732e-04 - val_loss: 4.2170e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0708e-04 - val_loss: 4.2096e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0684e-04 - val_loss: 4.2023e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0661e-04 - val_loss: 4.1953e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0636e-04 - val_loss: 4.1878e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0613e-04 - val_loss: 4.1805e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0589e-04 - val_loss: 4.1726e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0566e-04 - val_loss: 4.1655e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0542e-04 - val_loss: 4.1586e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0518e-04 - val_loss: 4.1510e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0495e-04 - val_loss: 4.1435e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0471e-04 - val_loss: 4.1365e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0448e-04 - val_loss: 4.1286e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.0425e-04 - val_loss: 4.1218e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0402e-04 - val_loss: 4.1151e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0379e-04 - val_loss: 4.1080e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0356e-04 - val_loss: 4.1006e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0333e-04 - val_loss: 4.0935e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0310e-04 - val_loss: 4.0864e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0287e-04 - val_loss: 4.0793e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0264e-04 - val_loss: 4.0718e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0242e-04 - val_loss: 4.0645e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0219e-04 - val_loss: 4.0583e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0197e-04 - val_loss: 4.0508e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0174e-04 - val_loss: 4.0436e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0152e-04 - val_loss: 4.0364e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0129e-04 - val_loss: 4.0291e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.0107e-04 - val_loss: 4.0219e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0085e-04 - val_loss: 4.0160e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0063e-04 - val_loss: 4.0084e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0040e-04 - val_loss: 4.0012e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0018e-04 - val_loss: 3.9942e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9963e-05 - val_loss: 3.9878e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9747e-05 - val_loss: 3.9805e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9527e-05 - val_loss: 3.9737e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9312e-05 - val_loss: 3.9668e-05\n",
      "0.00019706883176695555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.7115876 ,  0.28496602,  0.8704008 , -0.2489118 ,  0.8805716 ,\n",
       "         -0.17566952,  0.57391965,  0.32014492, -0.92153245,  0.25783142],\n",
       "        [-0.0235457 , -1.4158196 , -0.7305759 ,  0.5334021 ,  0.07287913,\n",
       "         -0.93123466, -0.5096066 ,  0.7152222 ,  0.7974308 , -0.8070359 ],\n",
       "        [-0.52847797,  0.21350288,  0.26874876,  0.6758865 ,  1.2268987 ,\n",
       "         -0.57691526, -1.0479962 ,  0.712552  , -0.42414522,  0.4681817 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.15485458, -0.10824323,  0.06342434,  0.21577683,  0.37591812,\n",
       "        -0.1565053 ,  0.5715749 , -0.17358758,  0.4250253 , -0.19761698],\n",
       "       dtype=float32),\n",
       " array([[-0.24552092,  0.37862003, -0.17195041,  0.20588355,  0.08291757,\n",
       "          0.21875459,  0.10731257,  0.07907016,  0.15094492,  0.31025666,\n",
       "         -0.11159744, -0.1751987 ,  0.22116084, -0.27511403, -0.43708834],\n",
       "        [-0.4189066 , -0.27132753,  0.09392748,  0.23210411, -0.37294394,\n",
       "         -0.17324091, -0.30917874, -0.4935607 , -0.24403867, -0.2147508 ,\n",
       "          0.10138512, -0.15013015, -0.01096105,  0.02804302, -0.21535766],\n",
       "        [-0.2887194 ,  0.10631334,  0.20839545, -0.44989544, -0.2847631 ,\n",
       "          0.49298784,  0.07225306,  0.02804318, -0.050124  ,  0.50592065,\n",
       "          0.39471617, -0.01728513,  0.20083857, -0.54079884, -0.38748875],\n",
       "        [-0.0479251 , -0.33709547, -0.3014336 ,  0.2742112 , -0.26801434,\n",
       "         -0.24172735,  0.21165161, -0.0105285 , -0.09503639,  0.46983123,\n",
       "         -0.44449905,  0.5591328 , -0.18930544, -0.48671463,  0.27318054],\n",
       "        [-0.16067457, -0.6944117 , -0.12262979,  0.3861239 , -0.2577743 ,\n",
       "          0.61345696, -0.20129585, -0.552528  , -0.08761901,  0.68030024,\n",
       "         -0.39003333, -0.22992454,  0.3321443 , -0.45633638,  0.05181361],\n",
       "        [-0.3169978 ,  0.20051955, -0.47958976, -0.26350608, -0.6727818 ,\n",
       "         -0.20534934, -0.16096683,  0.17542449, -0.5365321 ,  0.17789987,\n",
       "          0.4821829 , -0.26773402, -0.5085469 , -0.7997059 ,  0.18158297],\n",
       "        [-0.61463696, -0.18132477,  0.44926035,  0.24167779,  0.0437197 ,\n",
       "          0.54842633,  0.15544192, -0.43064833, -0.29747486, -0.19984654,\n",
       "         -0.3861844 ,  0.15693185,  0.46665555,  0.13517098,  0.3669988 ],\n",
       "        [-0.27796614, -0.33617598,  0.10657109,  0.37314948,  0.30934498,\n",
       "         -0.21280602, -0.4426149 ,  0.5578301 ,  0.23399733, -0.46699038,\n",
       "          0.34718087, -0.20746455, -0.44271788, -0.16492675,  0.08722531],\n",
       "        [-0.36310634, -0.35538378,  0.06667472,  0.46774992,  0.14603105,\n",
       "          0.43579075, -0.27401266, -0.6754815 ,  0.03426515,  0.35167584,\n",
       "          0.1648594 , -0.42493612, -0.17612858,  0.09302273,  0.63600487],\n",
       "        [ 0.35788572,  0.3710678 , -0.13603847, -0.29517373, -0.36976558,\n",
       "          0.08639521,  0.22658975, -0.06328355,  0.09315817,  0.23106748,\n",
       "          0.15616411, -0.32242224, -0.13319983,  0.64452416, -0.3403861 ]],\n",
       "       dtype=float32),\n",
       " array([-0.65363574, -0.5690828 ,  0.6425122 ,  0.48913974,  0.49657825,\n",
       "         0.6443788 , -0.45331275, -0.6687678 , -0.00877493,  0.65967804,\n",
       "        -0.6089809 , -0.4139852 ,  0.6511667 ,  0.10900876,  0.662067  ],\n",
       "       dtype=float32),\n",
       " array([[-0.6382071 ],\n",
       "        [-0.3638108 ],\n",
       "        [ 0.48639444],\n",
       "        [ 0.2656107 ],\n",
       "        [ 0.09359492],\n",
       "        [ 0.5586857 ],\n",
       "        [-0.17517653],\n",
       "        [-0.7955109 ],\n",
       "        [-0.15710005],\n",
       "        [ 0.6271596 ],\n",
       "        [-0.38651156],\n",
       "        [-0.13662603],\n",
       "        [ 0.5614013 ],\n",
       "        [-0.09813005],\n",
       "        [ 0.6830672 ]], dtype=float32),\n",
       " array([0.729211], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_6(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure6_3rd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
